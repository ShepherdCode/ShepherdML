{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization and Generalization\n",
    "Textbook by Charu Aggarwal. Chapter 4. Exercise 3. Implement perceptron on Ionosphere data. Test the effect of regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "First, obtain the Ionosphere data. \n",
    "Published by Johns Hopkins in 1989."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation_report', 'ionosphere_csv', 'ionosphere_json', 'ionosphere_zip', 'ionosphere_arff', 'ionosphere']\n"
     ]
    }
   ],
   "source": [
    "# I had not used datahub before so this took a while to figure out.\n",
    "from datapackage import Package\n",
    "# https://datahub.io/machine-learning/ionosphere#python\n",
    "package = Package('https://datahub.io/machine-learning/ionosphere/datapackage.json')\n",
    "\n",
    "# print list of all resources:\n",
    "print(package.resource_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print processed tabular data (if exists any)\n",
    "for resource in package.resources:\n",
    "    #print(type(resource))\n",
    "    #print(resource.descriptor)\n",
    "    #print(resource.descriptor['datahub']['type'])\n",
    "    if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "        ion_resource = resource\n",
    "#print(csv_resource.descriptor)\n",
    "#print(ion_resource.name)\n",
    "#dir(ion_resource)\n",
    "# ion_resource.headers\n",
    "# This data consists of 34 features, 'a01'..'a34', all decimal numbers,\n",
    "# plus 'class'. The headers and data are a list not a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, Decimal('1'), {'g': 225, 'b': 126})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ion_table = ion_resource.read()\n",
    "label_counts={}\n",
    "min_val = ion_table[0][0]\n",
    "max_val = ion_table[0][0]\n",
    "for one_ion in ion_table:\n",
    "    ion_class = one_ion[-1]\n",
    "    if (ion_class not in label_counts):\n",
    "        label_counts[ion_class] = 0\n",
    "    label_counts[ion_class] += 1\n",
    "    for x in range(34):\n",
    "        value=float(one_ion[x])\n",
    "        one_ion[x]=value # numbers that were loaded as strings\n",
    "        min_val = min(min_val,value)\n",
    "        max_val = max(max_val,value)\n",
    "\n",
    "# This shows all the features are between -1 and +1 (correlations?).\n",
    "# Note all the negative ones were loaded as strings.\n",
    "# We have two imbalanced classes labeled g and b. \n",
    "min_val,max_val,label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "We know this much: must use 34 correlations to predict a binary class.\n",
    "Create train vs test sets.\n",
    "Apply a scaler.\n",
    "Before using Perceptron, try a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 34), (351, 1))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np_ion=np.array(ion_table)\n",
    "np_ion.shape\n",
    "X=np_ion[:,:34]\n",
    "y=np_ion[:,34:35]\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((263, 34), (263,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "y_train=y_train.ravel()\n",
    "y_test=y_test.ravel()\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522727272727273"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)\n",
    "log.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to train a Perceptron\n",
    "Start with no regularization. Then try regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "peep = Perceptron(penalty=None,alpha=0.01)\n",
    "peep.fit(X_train,y_train)\n",
    "score1=peep.score(X_train,y_train)  # optimistic score on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaPerceptron accuracy on train set, test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.908745247148289, 0.8181818181818182)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2=peep.score(X_test,y_test)\n",
    "print(\"VanillaPerceptron accuracy on train set, test set:\")\n",
    "score1,score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "peep = Perceptron(penalty='l1',alpha=0.01)\n",
    "peep.fit(X_train,y_train)\n",
    "score3=peep.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "peep = Perceptron(penalty='l2',alpha=0.01)\n",
    "peep.fit(X_train,y_train)\n",
    "score4=peep.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron+L1, Perceptron+L2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.875, 0.8295454545454546)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Perceptron+L1, Perceptron+L2\")\n",
    "score3,score4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Note we did not use a random seed so results change on every run.\n",
    "Generally, Perceptron accuracy <= Logistic Regression, \n",
    "indicating the Perceptron is doing about as well as can be expected.\n",
    "\n",
    "Generally, L1 and L2 regularization were no help or actually hurt.\n",
    "That was unless the alpha was set to 0.01 \n",
    "which seems to be a magic number for this data.\n",
    "(I learned this hyperparameter on the test data. \n",
    "For a real experiment, I would learn it on a validation set,\n",
    "not the test set.)\n",
    "With alpha = 0.01, L2 regularization helps a little\n",
    "and L1 helps a lot. \n",
    "\n",
    "### Did L1 regularization reduce feature dimensions?\n",
    "This tests if L1 zeroed out many features, as claimed in the book.\n",
    "The answer is yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.68421204,  0.        ,  1.87586143,  0.        ,  1.21036935,\n",
       "         2.01586437,  0.        ,  3.50675494,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.66519366,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.11598845,  0.        ,  0.        ,  0.91146394,\n",
       "         0.        , -3.1340329 ,  0.        ,  0.        ,  0.        ,\n",
       "         1.03483693,  0.        ,  0.        , -1.64605064]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peep = Perceptron(penalty='l1',alpha=0.01)\n",
    "peep.fit(X_train,y_train)\n",
    "peep.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.65499021,  0.        ,  3.20379293,  3.72405769,  3.37091218,\n",
       "        -1.30186641,  2.39037932,  5.15498796,  2.58934064,  1.53373799,\n",
       "        -0.70795674,  0.12886974,  0.32139925,  1.554493  ,  2.07367581,\n",
       "         0.71903772,  0.60032163,  0.6624338 ,  2.23543353, -0.52072256,\n",
       "         3.00765067, -4.23203806,  1.1359442 , -2.59423479, -0.60161967,\n",
       "        -2.84845442, -3.19964909, -0.65817278,  0.66307534,  0.62286416,\n",
       "         1.35601047, -0.38172148,  0.95966684, -0.37273396]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peep = Perceptron(penalty='l2',alpha=0.01)\n",
    "peep.fit(X_train,y_train)\n",
    "peep.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
