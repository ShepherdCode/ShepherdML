{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojm_6E9f9Kcf"
   },
   "source": [
    "# MLP 202\n",
    "* Operate on 16000 GenCode 34 seqs.\n",
    "* 5-way cross validation. Save best model per CV.\n",
    "* Report mean accuracy from final re-validation with best 5.\n",
    "* Use Adam with a learn rate decay schdule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "hh6XplUvC0j0",
    "outputId": "a9377641-e5ea-4d58-bac4-1c0279f39f14"
   },
   "outputs": [],
   "source": [
    "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
    "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
    "DATAPATH=\"\"\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    NC_FILENAME = DATAPATH+NC_FILENAME\n",
    "    PC_FILENAME = DATAPATH+PC_FILENAME\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATAPATH=\"\" \n",
    "\n",
    "EPOCHS=200\n",
    "SPLITS=5\n",
    "K=1\n",
    "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "EMBED_DIMEN=16\n",
    "FILENAME='MLP202'\n",
    "NEURONS=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VQY7aTj29Kch"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LayerNormalization\n",
    "import time\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7jcg6Wl9Kc2"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qLFNO1Xa9Kc3"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    adam_default_learn_rate = 0.001\n",
    "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = adam_default_learn_rate*10,\n",
    "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    model.compile(loss=bc, optimizer=opt, metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return model\n",
    "\n",
    "def build_model(maxlen):\n",
    "    act=\"sigmoid\"\n",
    "    #embed_layer  = keras.layers.Embedding(\n",
    "    #    VOCABULARY_SIZE,EMBED_DIMEN,input_length=maxlen);\n",
    "    dense1_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt,\n",
    "                                      input_dim=VOCABULARY_SIZE)\n",
    "    dense2_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
    "    #dense3_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,activation=\"sigmoid\",dtype=dt)\n",
    "    mlp = keras.models.Sequential()\n",
    "    #mlp.add(embed_layer)\n",
    "    mlp.add(dense1_layer)\n",
    "    mlp.add(dense2_layer)\n",
    "    #mlp.add(dense3_layer)\n",
    "    mlp.add(output_layer)\n",
    "    mlpc = compile_model(mlp)\n",
    "    return mlpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV6k-xOm9Kcn"
   },
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1I-O_qzw9Kco"
   },
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRAaO9jP9Kcr"
   },
   "source": [
    "## Make K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e8xcZ4Mr9Kcs"
   },
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1 -1:  # stop at minus one for spaced seed\n",
    "            #kmer=seq[i:i+2]+seq[i+3:i+5]    # SPACED SEED 2/1/2 for K=4\n",
    "            kmer=seq[i:i+K]  \n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sEtA0xiV9Kcv"
   },
   "outputs": [],
   "source": [
    "def make_kmers(MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jaXyySyO9Kcz"
   },
   "outputs": [],
   "source": [
    "def make_frequencies(Xin):\n",
    "    Xout=[]\n",
    "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
    "    for seq in Xin:\n",
    "        freqs =[0] * VOCABULARY_SIZE\n",
    "        total = 0\n",
    "        for kmerval in seq:\n",
    "            freqs[kmerval] += 1\n",
    "            total += 1\n",
    "        for c in range(VOCABULARY_SIZE):\n",
    "            freqs[c] = freqs[c]/total\n",
    "        Xout.append(freqs)\n",
    "    Xnum = np.asarray(Xout)\n",
    "    return (Xnum)\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
    "    return slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdIS2utq9Kc9"
   },
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BVo4tbB_9Kc-"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,given_model):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        fold += 1\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]        \n",
    "        # Avoid continually improving the same model.\n",
    "        model = compile_model(keras.models.clone_model(given_model))\n",
    "        bestname=DATAPATH+FILENAME+\".cv.\"+str(fold)+\".best\"\n",
    "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
    "            filepath=bestname, save_best_only=True, \n",
    "            monitor='val_accuracy', mode='max')]   \n",
    "        print(\"FIT\")\n",
    "        start_time=time.time()\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                callbacks=mycallbacks,\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "        end_time=time.time()\n",
    "        elapsed_time=(end_time-start_time)                        \n",
    "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "        best_model=keras.models.load_model(bestname)\n",
    "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
    "        cv_scores.append(scores[1] * 100)  \n",
    "    print()\n",
    "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd3Wj_vI9KdP"
   },
   "source": [
    "## Train on RNA lengths 200-1Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "f8fNo6sn9KdH",
    "outputId": "92ff8a5d-95db-49ff-b63a-3f6d8c374b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Ready: train_set\n",
      "Compile the model\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: MLP202.model/assets\n",
      "Data prep\n",
      "Data reshape\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta(NC_FILENAME,0)\n",
    "pc_seq=load_fasta(PC_FILENAME,1)\n",
    "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "print(\"Ready: train_set\")\n",
    "#train_set\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN)\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once\n",
    "model.save(DATAPATH+FILENAME+'.model')\n",
    "print (\"Data prep\")\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "print (\"Data reshape\")\n",
    "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
    "X_train=make_frequencies(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mQ8eW5Rg9KdQ",
    "outputId": "1e5eae23-481a-4a8e-e818-c50ed78315d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross valiation\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/200\n",
      "429/453 [===========================>..] - ETA: 0s - loss: 0.6064 - accuracy: 0.6681INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.6040 - accuracy: 0.6703 - val_loss: 0.5508 - val_accuracy: 0.7188\n",
      "Epoch 2/200\n",
      "435/453 [===========================>..] - ETA: 0s - loss: 0.5613 - accuracy: 0.7055INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5592 - accuracy: 0.7068 - val_loss: 0.5323 - val_accuracy: 0.7374\n",
      "Epoch 3/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7157 - val_loss: 0.5259 - val_accuracy: 0.7368\n",
      "Epoch 4/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7208 - val_loss: 0.5284 - val_accuracy: 0.7368\n",
      "Epoch 5/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7179 - val_loss: 0.5277 - val_accuracy: 0.7374\n",
      "Epoch 6/200\n",
      "439/453 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.7200INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5448 - accuracy: 0.7190 - val_loss: 0.5404 - val_accuracy: 0.7405\n",
      "Epoch 7/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7201 - val_loss: 0.5259 - val_accuracy: 0.7387\n",
      "Epoch 8/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7189 - val_loss: 0.5305 - val_accuracy: 0.7331\n",
      "Epoch 9/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7217 - val_loss: 0.5259 - val_accuracy: 0.7374\n",
      "Epoch 10/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7214 - val_loss: 0.5263 - val_accuracy: 0.7337\n",
      "Epoch 11/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7221 - val_loss: 0.5227 - val_accuracy: 0.7362\n",
      "Epoch 12/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7212 - val_loss: 0.5269 - val_accuracy: 0.7349\n",
      "Epoch 13/200\n",
      "428/453 [===========================>..] - ETA: 0s - loss: 0.5404 - accuracy: 0.7228INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5412 - accuracy: 0.7222 - val_loss: 0.5235 - val_accuracy: 0.7412\n",
      "Epoch 14/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7226 - val_loss: 0.5344 - val_accuracy: 0.7325\n",
      "Epoch 15/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7216 - val_loss: 0.5305 - val_accuracy: 0.7306\n",
      "Epoch 16/200\n",
      "429/453 [===========================>..] - ETA: 0s - loss: 0.5412 - accuracy: 0.7217INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7216 - val_loss: 0.5246 - val_accuracy: 0.7418\n",
      "Epoch 17/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7225 - val_loss: 0.5250 - val_accuracy: 0.7387\n",
      "Epoch 18/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7222 - val_loss: 0.5319 - val_accuracy: 0.7325\n",
      "Epoch 19/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7232 - val_loss: 0.5280 - val_accuracy: 0.7325\n",
      "Epoch 20/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7235 - val_loss: 0.5237 - val_accuracy: 0.7343\n",
      "Epoch 21/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7239 - val_loss: 0.5240 - val_accuracy: 0.7325\n",
      "Epoch 22/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7221 - val_loss: 0.5238 - val_accuracy: 0.7349\n",
      "Epoch 23/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7238 - val_loss: 0.5231 - val_accuracy: 0.7399\n",
      "Epoch 24/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7234 - val_loss: 0.5237 - val_accuracy: 0.7418\n",
      "Epoch 25/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7219 - val_loss: 0.5238 - val_accuracy: 0.7405\n",
      "Epoch 26/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7223 - val_loss: 0.5296 - val_accuracy: 0.7331\n",
      "Epoch 27/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7238 - val_loss: 0.5233 - val_accuracy: 0.7356\n",
      "Epoch 28/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7227 - val_loss: 0.5409 - val_accuracy: 0.7331\n",
      "Epoch 29/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7239 - val_loss: 0.5332 - val_accuracy: 0.7312\n",
      "Epoch 30/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7254 - val_loss: 0.5231 - val_accuracy: 0.7374\n",
      "Epoch 31/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5395 - accuracy: 0.7257 - val_loss: 0.5359 - val_accuracy: 0.7287\n",
      "Epoch 32/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5398 - accuracy: 0.7246 - val_loss: 0.5245 - val_accuracy: 0.7387\n",
      "Epoch 33/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5395 - accuracy: 0.7226 - val_loss: 0.5258 - val_accuracy: 0.7343\n",
      "Epoch 34/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5387 - accuracy: 0.7250 - val_loss: 0.5268 - val_accuracy: 0.7318\n",
      "Epoch 35/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5393 - accuracy: 0.7226 - val_loss: 0.5275 - val_accuracy: 0.7325\n",
      "Epoch 36/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5402 - accuracy: 0.7227 - val_loss: 0.5266 - val_accuracy: 0.7362\n",
      "Epoch 37/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5385 - accuracy: 0.7234 - val_loss: 0.5275 - val_accuracy: 0.7356\n",
      "Epoch 38/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7223 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
      "Epoch 39/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7233 - val_loss: 0.5237 - val_accuracy: 0.7387\n",
      "Epoch 40/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7217 - val_loss: 0.5222 - val_accuracy: 0.7374\n",
      "Epoch 41/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7231 - val_loss: 0.5238 - val_accuracy: 0.7362\n",
      "Epoch 42/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7226 - val_loss: 0.5250 - val_accuracy: 0.7318\n",
      "Epoch 43/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7243 - val_loss: 0.5226 - val_accuracy: 0.7349\n",
      "Epoch 44/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7239 - val_loss: 0.5373 - val_accuracy: 0.7362\n",
      "Epoch 45/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7230 - val_loss: 0.5233 - val_accuracy: 0.7387\n",
      "Epoch 46/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7232 - val_loss: 0.5225 - val_accuracy: 0.7356\n",
      "Epoch 47/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7252 - val_loss: 0.5222 - val_accuracy: 0.7368\n",
      "Epoch 48/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7253 - val_loss: 0.5224 - val_accuracy: 0.7387\n",
      "Epoch 49/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7246 - val_loss: 0.5222 - val_accuracy: 0.7374\n",
      "Epoch 50/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7254 - val_loss: 0.5227 - val_accuracy: 0.7399\n",
      "Epoch 51/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7255 - val_loss: 0.5260 - val_accuracy: 0.7312\n",
      "Epoch 52/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7254 - val_loss: 0.5258 - val_accuracy: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7266 - val_loss: 0.5224 - val_accuracy: 0.7356\n",
      "Epoch 54/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7261 - val_loss: 0.5218 - val_accuracy: 0.7349\n",
      "Epoch 55/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7243 - val_loss: 0.5220 - val_accuracy: 0.7343\n",
      "Epoch 56/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7241 - val_loss: 0.5256 - val_accuracy: 0.7281\n",
      "Epoch 57/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7240 - val_loss: 0.5239 - val_accuracy: 0.7343\n",
      "Epoch 58/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7234 - val_loss: 0.5229 - val_accuracy: 0.7337\n",
      "Epoch 59/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7230 - val_loss: 0.5241 - val_accuracy: 0.7325\n",
      "Epoch 60/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7239 - val_loss: 0.5232 - val_accuracy: 0.7331\n",
      "Epoch 61/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7237 - val_loss: 0.5233 - val_accuracy: 0.7337\n",
      "Epoch 62/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7248 - val_loss: 0.5232 - val_accuracy: 0.7312\n",
      "Epoch 63/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7239 - val_loss: 0.5230 - val_accuracy: 0.7337\n",
      "Epoch 64/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7279 - val_loss: 0.5240 - val_accuracy: 0.7343\n",
      "Epoch 65/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7236 - val_loss: 0.5226 - val_accuracy: 0.7349\n",
      "Epoch 66/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7248 - val_loss: 0.5226 - val_accuracy: 0.7337\n",
      "Epoch 67/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7255 - val_loss: 0.5248 - val_accuracy: 0.7325\n",
      "Epoch 68/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7247 - val_loss: 0.5239 - val_accuracy: 0.7343\n",
      "Epoch 69/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7223 - val_loss: 0.5227 - val_accuracy: 0.7331\n",
      "Epoch 70/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7264 - val_loss: 0.5250 - val_accuracy: 0.7331\n",
      "Epoch 71/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7255 - val_loss: 0.5230 - val_accuracy: 0.7306\n",
      "Epoch 72/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7241 - val_loss: 0.5320 - val_accuracy: 0.7318\n",
      "Epoch 73/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7255 - val_loss: 0.5230 - val_accuracy: 0.7306\n",
      "Epoch 74/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7240 - val_loss: 0.5336 - val_accuracy: 0.7331\n",
      "Epoch 75/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7259 - val_loss: 0.5270 - val_accuracy: 0.7306\n",
      "Epoch 76/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7246 - val_loss: 0.5268 - val_accuracy: 0.7306\n",
      "Epoch 77/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7242 - val_loss: 0.5238 - val_accuracy: 0.7294\n",
      "Epoch 78/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7260 - val_loss: 0.5247 - val_accuracy: 0.7343\n",
      "Epoch 79/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7256 - val_loss: 0.5268 - val_accuracy: 0.7294\n",
      "Epoch 80/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7243 - val_loss: 0.5245 - val_accuracy: 0.7325\n",
      "Epoch 81/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7266 - val_loss: 0.5306 - val_accuracy: 0.7331\n",
      "Epoch 82/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7263 - val_loss: 0.5221 - val_accuracy: 0.7337\n",
      "Epoch 83/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7252 - val_loss: 0.5228 - val_accuracy: 0.7318\n",
      "Epoch 84/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7248 - val_loss: 0.5255 - val_accuracy: 0.7318\n",
      "Epoch 85/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7266 - val_loss: 0.5236 - val_accuracy: 0.7356\n",
      "Epoch 86/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7266 - val_loss: 0.5247 - val_accuracy: 0.7294\n",
      "Epoch 87/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7257 - val_loss: 0.5249 - val_accuracy: 0.7325\n",
      "Epoch 88/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7263 - val_loss: 0.5223 - val_accuracy: 0.7306\n",
      "Epoch 89/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7257 - val_loss: 0.5236 - val_accuracy: 0.7337\n",
      "Epoch 90/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7256 - val_loss: 0.5228 - val_accuracy: 0.7331\n",
      "Epoch 91/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7252 - val_loss: 0.5220 - val_accuracy: 0.7343\n",
      "Epoch 92/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7270 - val_loss: 0.5245 - val_accuracy: 0.7275\n",
      "Epoch 93/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7259 - val_loss: 0.5233 - val_accuracy: 0.7337\n",
      "Epoch 94/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7267 - val_loss: 0.5236 - val_accuracy: 0.7294\n",
      "Epoch 95/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7248 - val_loss: 0.5225 - val_accuracy: 0.7275\n",
      "Epoch 96/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7263 - val_loss: 0.5238 - val_accuracy: 0.7349\n",
      "Epoch 97/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7255 - val_loss: 0.5335 - val_accuracy: 0.7269\n",
      "Epoch 98/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7270 - val_loss: 0.5236 - val_accuracy: 0.7300\n",
      "Epoch 99/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7245 - val_loss: 0.5233 - val_accuracy: 0.7368\n",
      "Epoch 100/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7246 - val_loss: 0.5289 - val_accuracy: 0.7343\n",
      "Epoch 101/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7267 - val_loss: 0.5306 - val_accuracy: 0.7318\n",
      "Epoch 102/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7250 - val_loss: 0.5244 - val_accuracy: 0.7343\n",
      "Epoch 103/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7250 - val_loss: 0.5222 - val_accuracy: 0.7356\n",
      "Epoch 104/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7268 - val_loss: 0.5269 - val_accuracy: 0.7337\n",
      "Epoch 105/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7268 - val_loss: 0.5241 - val_accuracy: 0.7343\n",
      "Epoch 106/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7272 - val_loss: 0.5221 - val_accuracy: 0.7368\n",
      "Epoch 107/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7276 - val_loss: 0.5273 - val_accuracy: 0.7374\n",
      "Epoch 108/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7255 - val_loss: 0.5220 - val_accuracy: 0.7349\n",
      "Epoch 109/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7266 - val_loss: 0.5224 - val_accuracy: 0.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7260 - val_loss: 0.5239 - val_accuracy: 0.7281\n",
      "Epoch 111/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7257 - val_loss: 0.5313 - val_accuracy: 0.7256\n",
      "Epoch 112/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7259 - val_loss: 0.5218 - val_accuracy: 0.7343\n",
      "Epoch 113/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7255 - val_loss: 0.5220 - val_accuracy: 0.7362\n",
      "Epoch 114/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7256 - val_loss: 0.5225 - val_accuracy: 0.7349\n",
      "Epoch 115/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7273 - val_loss: 0.5237 - val_accuracy: 0.7356\n",
      "Epoch 116/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7275 - val_loss: 0.5232 - val_accuracy: 0.7337\n",
      "Epoch 117/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7244 - val_loss: 0.5222 - val_accuracy: 0.7331\n",
      "Epoch 118/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7253 - val_loss: 0.5226 - val_accuracy: 0.7325\n",
      "Epoch 119/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7271 - val_loss: 0.5236 - val_accuracy: 0.7356\n",
      "Epoch 120/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7257 - val_loss: 0.5224 - val_accuracy: 0.7318\n",
      "Epoch 121/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7299 - val_loss: 0.5280 - val_accuracy: 0.7300\n",
      "Epoch 122/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7264 - val_loss: 0.5231 - val_accuracy: 0.7349\n",
      "Epoch 123/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7259 - val_loss: 0.5226 - val_accuracy: 0.7337\n",
      "Epoch 124/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7257 - val_loss: 0.5246 - val_accuracy: 0.7337\n",
      "Epoch 125/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7263 - val_loss: 0.5264 - val_accuracy: 0.7343\n",
      "Epoch 126/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7281 - val_loss: 0.5230 - val_accuracy: 0.7331\n",
      "Epoch 127/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7275 - val_loss: 0.5243 - val_accuracy: 0.7356\n",
      "Epoch 128/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7282 - val_loss: 0.5222 - val_accuracy: 0.7368\n",
      "Epoch 129/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7237 - val_loss: 0.5254 - val_accuracy: 0.7318\n",
      "Epoch 130/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7276 - val_loss: 0.5238 - val_accuracy: 0.7300\n",
      "Epoch 131/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7270 - val_loss: 0.5231 - val_accuracy: 0.7281\n",
      "Epoch 132/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7264 - val_loss: 0.5233 - val_accuracy: 0.7387\n",
      "Epoch 133/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7282 - val_loss: 0.5217 - val_accuracy: 0.7368\n",
      "Epoch 134/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7278 - val_loss: 0.5210 - val_accuracy: 0.7318\n",
      "Epoch 135/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7265 - val_loss: 0.5233 - val_accuracy: 0.7349\n",
      "Epoch 136/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7266 - val_loss: 0.5250 - val_accuracy: 0.7331\n",
      "Epoch 137/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7270 - val_loss: 0.5223 - val_accuracy: 0.7337\n",
      "Epoch 138/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7267 - val_loss: 0.5218 - val_accuracy: 0.7337\n",
      "Epoch 139/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7275 - val_loss: 0.5321 - val_accuracy: 0.7312\n",
      "Epoch 140/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7271 - val_loss: 0.5285 - val_accuracy: 0.7325\n",
      "Epoch 141/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7277 - val_loss: 0.5230 - val_accuracy: 0.7343\n",
      "Epoch 142/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7274 - val_loss: 0.5242 - val_accuracy: 0.7300\n",
      "Epoch 143/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5298 - accuracy: 0.7268 - val_loss: 0.5234 - val_accuracy: 0.7343\n",
      "Epoch 144/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7286 - val_loss: 0.5225 - val_accuracy: 0.7374\n",
      "Epoch 145/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7276 - val_loss: 0.5248 - val_accuracy: 0.7362\n",
      "Epoch 146/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7268 - val_loss: 0.5246 - val_accuracy: 0.7349\n",
      "Epoch 147/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7250 - val_loss: 0.5209 - val_accuracy: 0.7368\n",
      "Epoch 148/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7276 - val_loss: 0.5245 - val_accuracy: 0.7381\n",
      "Epoch 149/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7292 - val_loss: 0.5274 - val_accuracy: 0.7325\n",
      "Epoch 150/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7268 - val_loss: 0.5256 - val_accuracy: 0.7362\n",
      "Epoch 151/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7261 - val_loss: 0.5218 - val_accuracy: 0.7374\n",
      "Epoch 152/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7271 - val_loss: 0.5238 - val_accuracy: 0.7374\n",
      "Epoch 153/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7301 - val_loss: 0.5228 - val_accuracy: 0.7356\n",
      "Epoch 154/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7289 - val_loss: 0.5219 - val_accuracy: 0.7399\n",
      "Epoch 155/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7272 - val_loss: 0.5210 - val_accuracy: 0.7381\n",
      "Epoch 156/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7272 - val_loss: 0.5220 - val_accuracy: 0.7374\n",
      "Epoch 157/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7280 - val_loss: 0.5211 - val_accuracy: 0.7393\n",
      "Epoch 158/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7261 - val_loss: 0.5244 - val_accuracy: 0.7374\n",
      "Epoch 159/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7303 - val_loss: 0.5214 - val_accuracy: 0.7337\n",
      "Epoch 160/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7281 - val_loss: 0.5197 - val_accuracy: 0.7356\n",
      "Epoch 161/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7282 - val_loss: 0.5216 - val_accuracy: 0.7387\n",
      "Epoch 162/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7281 - val_loss: 0.5268 - val_accuracy: 0.7405\n",
      "Epoch 163/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7272 - val_loss: 0.5203 - val_accuracy: 0.7362\n",
      "Epoch 164/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7252 - val_loss: 0.5193 - val_accuracy: 0.7356\n",
      "Epoch 165/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7284 - val_loss: 0.5208 - val_accuracy: 0.7368\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7279 - val_loss: 0.5206 - val_accuracy: 0.7343\n",
      "Epoch 167/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7268 - val_loss: 0.5225 - val_accuracy: 0.7405\n",
      "Epoch 168/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7268 - val_loss: 0.5211 - val_accuracy: 0.7349\n",
      "Epoch 169/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7278 - val_loss: 0.5199 - val_accuracy: 0.7412\n",
      "Epoch 170/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7284 - val_loss: 0.5204 - val_accuracy: 0.7362\n",
      "Epoch 171/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.7266 - val_loss: 0.5239 - val_accuracy: 0.7362\n",
      "Epoch 172/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7270 - val_loss: 0.5201 - val_accuracy: 0.7381\n",
      "Epoch 173/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7259 - val_loss: 0.5182 - val_accuracy: 0.7418\n",
      "Epoch 174/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.7274 - val_loss: 0.5194 - val_accuracy: 0.7412\n",
      "Epoch 175/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7288 - val_loss: 0.5195 - val_accuracy: 0.7337\n",
      "Epoch 176/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5267 - accuracy: 0.7271 - val_loss: 0.5204 - val_accuracy: 0.7405\n",
      "Epoch 177/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7281 - val_loss: 0.5185 - val_accuracy: 0.7399\n",
      "Epoch 178/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7248 - val_loss: 0.5191 - val_accuracy: 0.7374\n",
      "Epoch 179/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7280 - val_loss: 0.5179 - val_accuracy: 0.7393\n",
      "Epoch 180/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7294 - val_loss: 0.5293 - val_accuracy: 0.7381\n",
      "Epoch 181/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7301 - val_loss: 0.5196 - val_accuracy: 0.7374\n",
      "Epoch 182/200\n",
      "430/453 [===========================>..] - ETA: 0s - loss: 0.5271 - accuracy: 0.7274INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5270 - accuracy: 0.7272 - val_loss: 0.5188 - val_accuracy: 0.7430\n",
      "Epoch 183/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7282 - val_loss: 0.5176 - val_accuracy: 0.7399\n",
      "Epoch 184/200\n",
      "437/453 [===========================>..] - ETA: 0s - loss: 0.5254 - accuracy: 0.7302INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5258 - accuracy: 0.7302 - val_loss: 0.5247 - val_accuracy: 0.7436\n",
      "Epoch 185/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7291 - val_loss: 0.5182 - val_accuracy: 0.7381\n",
      "Epoch 186/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7305 - val_loss: 0.5169 - val_accuracy: 0.7436\n",
      "Epoch 187/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.7300 - val_loss: 0.5180 - val_accuracy: 0.7368\n",
      "Epoch 188/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5259 - accuracy: 0.7304 - val_loss: 0.5192 - val_accuracy: 0.7368\n",
      "Epoch 189/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7294 - val_loss: 0.5179 - val_accuracy: 0.7399\n",
      "Epoch 190/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7299 - val_loss: 0.5190 - val_accuracy: 0.7412\n",
      "Epoch 191/200\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7279INFO:tensorflow:Assets written to: MLP202.cv.1.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5259 - accuracy: 0.7279 - val_loss: 0.5171 - val_accuracy: 0.7461\n",
      "Epoch 192/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7317 - val_loss: 0.5224 - val_accuracy: 0.7393\n",
      "Epoch 193/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7292 - val_loss: 0.5175 - val_accuracy: 0.7418\n",
      "Epoch 194/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7314 - val_loss: 0.5171 - val_accuracy: 0.7412\n",
      "Epoch 195/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.7306 - val_loss: 0.5174 - val_accuracy: 0.7387\n",
      "Epoch 196/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5252 - accuracy: 0.7309 - val_loss: 0.5183 - val_accuracy: 0.7430\n",
      "Epoch 197/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7310 - val_loss: 0.5171 - val_accuracy: 0.7461\n",
      "Epoch 198/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7320 - val_loss: 0.5145 - val_accuracy: 0.7443\n",
      "Epoch 199/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7328 - val_loss: 0.5144 - val_accuracy: 0.7455\n",
      "Epoch 200/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7331 - val_loss: 0.5184 - val_accuracy: 0.7455\n",
      "Fold 1, 200 epochs, 200 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 74.61%\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/200\n",
      "447/453 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.6737INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 3s 6ms/step - loss: 0.5995 - accuracy: 0.6734 - val_loss: 0.5604 - val_accuracy: 0.7045\n",
      "Epoch 2/200\n",
      "425/453 [===========================>..] - ETA: 0s - loss: 0.5547 - accuracy: 0.7115INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5533 - accuracy: 0.7126 - val_loss: 0.5551 - val_accuracy: 0.7182\n",
      "Epoch 3/200\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7200INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5474 - accuracy: 0.7200 - val_loss: 0.5522 - val_accuracy: 0.7275\n",
      "Epoch 4/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7210 - val_loss: 0.5494 - val_accuracy: 0.7275\n",
      "Epoch 5/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7199 - val_loss: 0.5541 - val_accuracy: 0.7157\n",
      "Epoch 6/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7170 - val_loss: 0.5548 - val_accuracy: 0.7275\n",
      "Epoch 7/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7232 - val_loss: 0.5497 - val_accuracy: 0.7275\n",
      "Epoch 8/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7209 - val_loss: 0.5482 - val_accuracy: 0.7200\n",
      "Epoch 9/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7219 - val_loss: 0.5586 - val_accuracy: 0.7263\n",
      "Epoch 10/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7206 - val_loss: 0.5465 - val_accuracy: 0.7238\n",
      "Epoch 11/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7223 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
      "Epoch 12/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7227 - val_loss: 0.5460 - val_accuracy: 0.7269\n",
      "Epoch 13/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7237 - val_loss: 0.5481 - val_accuracy: 0.7213\n",
      "Epoch 14/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7240 - val_loss: 0.5477 - val_accuracy: 0.7275\n",
      "Epoch 15/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7248 - val_loss: 0.5478 - val_accuracy: 0.7269\n",
      "Epoch 16/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7231 - val_loss: 0.5493 - val_accuracy: 0.7219\n",
      "Epoch 17/200\n",
      "441/453 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.7243INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5386 - accuracy: 0.7241 - val_loss: 0.5459 - val_accuracy: 0.7300\n",
      "Epoch 18/200\n",
      "437/453 [===========================>..] - ETA: 0s - loss: 0.5368 - accuracy: 0.72 - ETA: 0s - loss: 0.5382 - accuracy: 0.7249INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5383 - accuracy: 0.7251 - val_loss: 0.5464 - val_accuracy: 0.7312\n",
      "Epoch 19/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7228 - val_loss: 0.5459 - val_accuracy: 0.7250\n",
      "Epoch 20/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7248 - val_loss: 0.5456 - val_accuracy: 0.7312\n",
      "Epoch 21/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7239 - val_loss: 0.5503 - val_accuracy: 0.7294\n",
      "Epoch 22/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7241 - val_loss: 0.5463 - val_accuracy: 0.7281\n",
      "Epoch 23/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7249 - val_loss: 0.5466 - val_accuracy: 0.7275\n",
      "Epoch 24/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7241 - val_loss: 0.5478 - val_accuracy: 0.7300\n",
      "Epoch 25/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7248 - val_loss: 0.5462 - val_accuracy: 0.7300\n",
      "Epoch 26/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7244 - val_loss: 0.5477 - val_accuracy: 0.7256\n",
      "Epoch 27/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7250 - val_loss: 0.5460 - val_accuracy: 0.7281\n",
      "Epoch 28/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7234 - val_loss: 0.5471 - val_accuracy: 0.7281\n",
      "Epoch 29/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7245 - val_loss: 0.5455 - val_accuracy: 0.7281\n",
      "Epoch 30/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7247 - val_loss: 0.5494 - val_accuracy: 0.7263\n",
      "Epoch 31/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7244 - val_loss: 0.5460 - val_accuracy: 0.7287\n",
      "Epoch 32/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7239 - val_loss: 0.5560 - val_accuracy: 0.7163\n",
      "Epoch 33/200\n",
      "452/453 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7239INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5376 - accuracy: 0.7241 - val_loss: 0.5454 - val_accuracy: 0.7331\n",
      "Epoch 34/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7248 - val_loss: 0.5460 - val_accuracy: 0.7238\n",
      "Epoch 35/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7242 - val_loss: 0.5454 - val_accuracy: 0.7287\n",
      "Epoch 36/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7238 - val_loss: 0.5508 - val_accuracy: 0.7312\n",
      "Epoch 37/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7270 - val_loss: 0.5467 - val_accuracy: 0.7281\n",
      "Epoch 38/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7254 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 39/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7229 - val_loss: 0.5463 - val_accuracy: 0.7318\n",
      "Epoch 40/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7241 - val_loss: 0.5506 - val_accuracy: 0.7207\n",
      "Epoch 41/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7258 - val_loss: 0.5468 - val_accuracy: 0.7281\n",
      "Epoch 42/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7249 - val_loss: 0.5438 - val_accuracy: 0.7306\n",
      "Epoch 43/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7242 - val_loss: 0.5449 - val_accuracy: 0.7294\n",
      "Epoch 44/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7260 - val_loss: 0.5451 - val_accuracy: 0.7238\n",
      "Epoch 45/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7277 - val_loss: 0.5502 - val_accuracy: 0.7256\n",
      "Epoch 46/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7236 - val_loss: 0.5453 - val_accuracy: 0.7275\n",
      "Epoch 47/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7252 - val_loss: 0.5524 - val_accuracy: 0.7219\n",
      "Epoch 48/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7260 - val_loss: 0.5455 - val_accuracy: 0.7325\n",
      "Epoch 49/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7246 - val_loss: 0.5456 - val_accuracy: 0.7263\n",
      "Epoch 50/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7255 - val_loss: 0.5430 - val_accuracy: 0.7306\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7252 - val_loss: 0.5454 - val_accuracy: 0.7263\n",
      "Epoch 52/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7261 - val_loss: 0.5545 - val_accuracy: 0.7213\n",
      "Epoch 53/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7246 - val_loss: 0.5449 - val_accuracy: 0.7275\n",
      "Epoch 54/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7238 - val_loss: 0.5453 - val_accuracy: 0.7263\n",
      "Epoch 55/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7259 - val_loss: 0.5453 - val_accuracy: 0.7275\n",
      "Epoch 56/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7241 - val_loss: 0.5462 - val_accuracy: 0.7256\n",
      "Epoch 57/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7251 - val_loss: 0.5435 - val_accuracy: 0.7287\n",
      "Epoch 58/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7239 - val_loss: 0.5429 - val_accuracy: 0.7312\n",
      "Epoch 59/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.7248 - val_loss: 0.5442 - val_accuracy: 0.7287\n",
      "Epoch 60/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7262 - val_loss: 0.5457 - val_accuracy: 0.7281\n",
      "Epoch 61/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7255 - val_loss: 0.5456 - val_accuracy: 0.7263\n",
      "Epoch 62/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7243 - val_loss: 0.5500 - val_accuracy: 0.7225\n",
      "Epoch 63/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7237 - val_loss: 0.5447 - val_accuracy: 0.7318\n",
      "Epoch 64/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7255 - val_loss: 0.5428 - val_accuracy: 0.7300\n",
      "Epoch 65/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7264 - val_loss: 0.5449 - val_accuracy: 0.7275\n",
      "Epoch 66/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7242 - val_loss: 0.5449 - val_accuracy: 0.7250\n",
      "Epoch 67/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7246 - val_loss: 0.5453 - val_accuracy: 0.7263\n",
      "Epoch 68/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7249 - val_loss: 0.5441 - val_accuracy: 0.7306\n",
      "Epoch 69/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7252 - val_loss: 0.5429 - val_accuracy: 0.7287\n",
      "Epoch 70/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7241 - val_loss: 0.5436 - val_accuracy: 0.7318\n",
      "Epoch 71/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7240 - val_loss: 0.5469 - val_accuracy: 0.7287\n",
      "Epoch 72/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7247 - val_loss: 0.5492 - val_accuracy: 0.7256\n",
      "Epoch 73/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7229 - val_loss: 0.5467 - val_accuracy: 0.7238\n",
      "Epoch 74/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7239 - val_loss: 0.5493 - val_accuracy: 0.7287\n",
      "Epoch 75/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7246 - val_loss: 0.5426 - val_accuracy: 0.7318\n",
      "Epoch 76/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7252 - val_loss: 0.5484 - val_accuracy: 0.7232\n",
      "Epoch 77/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7255 - val_loss: 0.5427 - val_accuracy: 0.7312\n",
      "Epoch 78/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5339 - accuracy: 0.7232 - val_loss: 0.5431 - val_accuracy: 0.7281\n",
      "Epoch 79/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7261 - val_loss: 0.5429 - val_accuracy: 0.7275\n",
      "Epoch 80/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7252 - val_loss: 0.5421 - val_accuracy: 0.7294\n",
      "Epoch 81/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7233 - val_loss: 0.5428 - val_accuracy: 0.7294\n",
      "Epoch 82/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5336 - accuracy: 0.7237 - val_loss: 0.5417 - val_accuracy: 0.7275\n",
      "Epoch 83/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7246 - val_loss: 0.5423 - val_accuracy: 0.7294\n",
      "Epoch 84/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7239 - val_loss: 0.5423 - val_accuracy: 0.7318\n",
      "Epoch 85/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7240 - val_loss: 0.5435 - val_accuracy: 0.7306\n",
      "Epoch 86/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7253 - val_loss: 0.5453 - val_accuracy: 0.7325\n",
      "Epoch 87/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7261 - val_loss: 0.5423 - val_accuracy: 0.7281\n",
      "Epoch 88/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7241 - val_loss: 0.5438 - val_accuracy: 0.7312\n",
      "Epoch 89/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7255 - val_loss: 0.5458 - val_accuracy: 0.7238\n",
      "Epoch 90/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5331 - accuracy: 0.7244 - val_loss: 0.5422 - val_accuracy: 0.7294\n",
      "Epoch 91/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5330 - accuracy: 0.7255 - val_loss: 0.5434 - val_accuracy: 0.7294\n",
      "Epoch 92/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7253 - val_loss: 0.5451 - val_accuracy: 0.7250\n",
      "Epoch 93/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7237 - val_loss: 0.5426 - val_accuracy: 0.7275\n",
      "Epoch 94/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.7256 - val_loss: 0.5437 - val_accuracy: 0.7263\n",
      "Epoch 95/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7254 - val_loss: 0.5419 - val_accuracy: 0.7306\n",
      "Epoch 96/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5327 - accuracy: 0.7220 - val_loss: 0.5422 - val_accuracy: 0.7318\n",
      "Epoch 97/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7248 - val_loss: 0.5487 - val_accuracy: 0.7263\n",
      "Epoch 98/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5320 - accuracy: 0.7248 - val_loss: 0.5425 - val_accuracy: 0.7306\n",
      "Epoch 99/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7246 - val_loss: 0.5423 - val_accuracy: 0.7263\n",
      "Epoch 100/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7237 - val_loss: 0.5411 - val_accuracy: 0.7294\n",
      "Epoch 101/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7236 - val_loss: 0.5413 - val_accuracy: 0.7287\n",
      "Epoch 102/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5318 - accuracy: 0.7250 - val_loss: 0.5429 - val_accuracy: 0.7312\n",
      "Epoch 103/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7236 - val_loss: 0.5414 - val_accuracy: 0.7300\n",
      "Epoch 104/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7258 - val_loss: 0.5423 - val_accuracy: 0.7300\n",
      "Epoch 105/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5319 - accuracy: 0.7262 - val_loss: 0.5418 - val_accuracy: 0.7312\n",
      "Epoch 106/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5312 - accuracy: 0.7275 - val_loss: 0.5427 - val_accuracy: 0.7325\n",
      "Epoch 107/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7244 - val_loss: 0.5407 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5315 - accuracy: 0.7255 - val_loss: 0.5407 - val_accuracy: 0.7300\n",
      "Epoch 109/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7241 - val_loss: 0.5409 - val_accuracy: 0.7325\n",
      "Epoch 110/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7259 - val_loss: 0.5420 - val_accuracy: 0.7294\n",
      "Epoch 111/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.7262 - val_loss: 0.5430 - val_accuracy: 0.7263\n",
      "Epoch 112/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7249 - val_loss: 0.5414 - val_accuracy: 0.7281\n",
      "Epoch 113/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5313 - accuracy: 0.7236 - val_loss: 0.5461 - val_accuracy: 0.7287\n",
      "Epoch 114/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7251 - val_loss: 0.5429 - val_accuracy: 0.7287\n",
      "Epoch 115/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7254 - val_loss: 0.5438 - val_accuracy: 0.7275\n",
      "Epoch 116/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5314 - accuracy: 0.7260 - val_loss: 0.5420 - val_accuracy: 0.7275\n",
      "Epoch 117/200\n",
      "437/453 [===========================>..] - ETA: 0s - loss: 0.5312 - accuracy: 0.7257INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 3s 6ms/step - loss: 0.5309 - accuracy: 0.7258 - val_loss: 0.5410 - val_accuracy: 0.7337\n",
      "Epoch 118/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5315 - accuracy: 0.7259 - val_loss: 0.5407 - val_accuracy: 0.7281\n",
      "Epoch 119/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5307 - accuracy: 0.7261 - val_loss: 0.5404 - val_accuracy: 0.7312\n",
      "Epoch 120/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7235 - val_loss: 0.5398 - val_accuracy: 0.7300\n",
      "Epoch 121/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7262 - val_loss: 0.5448 - val_accuracy: 0.7287\n",
      "Epoch 122/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7247 - val_loss: 0.5402 - val_accuracy: 0.7294\n",
      "Epoch 123/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7262 - val_loss: 0.5399 - val_accuracy: 0.7281\n",
      "Epoch 124/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7257 - val_loss: 0.5415 - val_accuracy: 0.7294\n",
      "Epoch 125/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.7249 - val_loss: 0.5400 - val_accuracy: 0.7300\n",
      "Epoch 126/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.7248 - val_loss: 0.5403 - val_accuracy: 0.7312\n",
      "Epoch 127/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7263 - val_loss: 0.5413 - val_accuracy: 0.7287\n",
      "Epoch 128/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.7255 - val_loss: 0.5416 - val_accuracy: 0.7300\n",
      "Epoch 129/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5307 - accuracy: 0.7258 - val_loss: 0.5404 - val_accuracy: 0.7325\n",
      "Epoch 130/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5313 - accuracy: 0.7232 - val_loss: 0.5397 - val_accuracy: 0.7318\n",
      "Epoch 131/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7261 - val_loss: 0.5390 - val_accuracy: 0.7294\n",
      "Epoch 132/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7251 - val_loss: 0.5408 - val_accuracy: 0.7331\n",
      "Epoch 133/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.7247 - val_loss: 0.5390 - val_accuracy: 0.7294\n",
      "Epoch 134/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5301 - accuracy: 0.7252 - val_loss: 0.5389 - val_accuracy: 0.7300\n",
      "Epoch 135/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5300 - accuracy: 0.7281 - val_loss: 0.5399 - val_accuracy: 0.7325\n",
      "Epoch 136/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5307 - accuracy: 0.7261 - val_loss: 0.5421 - val_accuracy: 0.7294\n",
      "Epoch 137/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7255 - val_loss: 0.5397 - val_accuracy: 0.7312\n",
      "Epoch 138/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7235 - val_loss: 0.5388 - val_accuracy: 0.7312\n",
      "Epoch 139/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7270 - val_loss: 0.5403 - val_accuracy: 0.7306\n",
      "Epoch 140/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.7254 - val_loss: 0.5394 - val_accuracy: 0.7294\n",
      "Epoch 141/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7246 - val_loss: 0.5430 - val_accuracy: 0.7312\n",
      "Epoch 142/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5303 - accuracy: 0.7253 - val_loss: 0.5408 - val_accuracy: 0.7325\n",
      "Epoch 143/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7271 - val_loss: 0.5415 - val_accuracy: 0.7306\n",
      "Epoch 144/200\n",
      "448/453 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.7275 ETA: 0s - loss: 0.5327 - accuINFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 3s 7ms/step - loss: 0.5299 - accuracy: 0.7275 - val_loss: 0.5438 - val_accuracy: 0.7356\n",
      "Epoch 145/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5301 - accuracy: 0.7257 - val_loss: 0.5392 - val_accuracy: 0.7325\n",
      "Epoch 146/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7266 - val_loss: 0.5376 - val_accuracy: 0.7318\n",
      "Epoch 147/200\n",
      "436/453 [===========================>..] - ETA: 0s - loss: 0.5303 - accuracy: 0.7241INFO:tensorflow:Assets written to: MLP202.cv.2.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7252 - val_loss: 0.5401 - val_accuracy: 0.7381\n",
      "Epoch 148/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7257 - val_loss: 0.5382 - val_accuracy: 0.7312\n",
      "Epoch 149/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7252 - val_loss: 0.5403 - val_accuracy: 0.7287\n",
      "Epoch 150/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5293 - accuracy: 0.7260 - val_loss: 0.5452 - val_accuracy: 0.7250\n",
      "Epoch 151/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5298 - accuracy: 0.7264 - val_loss: 0.5444 - val_accuracy: 0.7325\n",
      "Epoch 152/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7275 - val_loss: 0.5387 - val_accuracy: 0.7287\n",
      "Epoch 153/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7272 - val_loss: 0.5381 - val_accuracy: 0.7362\n",
      "Epoch 154/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7279 - val_loss: 0.5372 - val_accuracy: 0.7349\n",
      "Epoch 155/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7261 - val_loss: 0.5396 - val_accuracy: 0.7238\n",
      "Epoch 156/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7270 - val_loss: 0.5379 - val_accuracy: 0.7337\n",
      "Epoch 157/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5293 - accuracy: 0.7255 - val_loss: 0.5386 - val_accuracy: 0.7318\n",
      "Epoch 158/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7270 - val_loss: 0.5389 - val_accuracy: 0.7306\n",
      "Epoch 159/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7252 - val_loss: 0.5378 - val_accuracy: 0.7306\n",
      "Epoch 160/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7259 - val_loss: 0.5380 - val_accuracy: 0.7312\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7257 - val_loss: 0.5382 - val_accuracy: 0.7349\n",
      "Epoch 162/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5286 - accuracy: 0.7252 - val_loss: 0.5380 - val_accuracy: 0.7331\n",
      "Epoch 163/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7254 - val_loss: 0.5397 - val_accuracy: 0.7300\n",
      "Epoch 164/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5283 - accuracy: 0.7281 - val_loss: 0.5415 - val_accuracy: 0.7244\n",
      "Epoch 165/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7255 - val_loss: 0.5362 - val_accuracy: 0.7349\n",
      "Epoch 166/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5286 - accuracy: 0.7291 - val_loss: 0.5361 - val_accuracy: 0.7337\n",
      "Epoch 167/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5286 - accuracy: 0.7293 - val_loss: 0.5373 - val_accuracy: 0.7312\n",
      "Epoch 168/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7276 - val_loss: 0.5388 - val_accuracy: 0.7325\n",
      "Epoch 169/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7278 - val_loss: 0.5375 - val_accuracy: 0.7343\n",
      "Epoch 170/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7264 - val_loss: 0.5387 - val_accuracy: 0.7318\n",
      "Epoch 171/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7266 - val_loss: 0.5429 - val_accuracy: 0.7343\n",
      "Epoch 172/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7275 - val_loss: 0.5366 - val_accuracy: 0.7318\n",
      "Epoch 173/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7279 - val_loss: 0.5376 - val_accuracy: 0.7318\n",
      "Epoch 174/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.7256 - val_loss: 0.5363 - val_accuracy: 0.7331\n",
      "Epoch 175/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7259 - val_loss: 0.5362 - val_accuracy: 0.7325\n",
      "Epoch 176/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7286 - val_loss: 0.5363 - val_accuracy: 0.7337\n",
      "Epoch 177/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7264 - val_loss: 0.5376 - val_accuracy: 0.7325\n",
      "Epoch 178/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7255 - val_loss: 0.5362 - val_accuracy: 0.7349\n",
      "Epoch 179/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7284 - val_loss: 0.5421 - val_accuracy: 0.7312\n",
      "Epoch 180/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7281 - val_loss: 0.5359 - val_accuracy: 0.7318\n",
      "Epoch 181/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7289 - val_loss: 0.5391 - val_accuracy: 0.7337\n",
      "Epoch 182/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.7299 - val_loss: 0.5365 - val_accuracy: 0.7306\n",
      "Epoch 183/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7275 - val_loss: 0.5396 - val_accuracy: 0.7325\n",
      "Epoch 184/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7290 - val_loss: 0.5391 - val_accuracy: 0.7337\n",
      "Epoch 185/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5266 - accuracy: 0.7261 - val_loss: 0.5356 - val_accuracy: 0.7356\n",
      "Epoch 186/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.7270 - val_loss: 0.5351 - val_accuracy: 0.7356\n",
      "Epoch 187/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5283 - accuracy: 0.7279 - val_loss: 0.5360 - val_accuracy: 0.7362\n",
      "Epoch 188/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5271 - accuracy: 0.7264 - val_loss: 0.5365 - val_accuracy: 0.7306\n",
      "Epoch 189/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7269 - val_loss: 0.5355 - val_accuracy: 0.7356\n",
      "Epoch 190/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7266 - val_loss: 0.5382 - val_accuracy: 0.7325\n",
      "Epoch 191/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7280 - val_loss: 0.5374 - val_accuracy: 0.7337\n",
      "Epoch 192/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5272 - accuracy: 0.7288 - val_loss: 0.5371 - val_accuracy: 0.7337\n",
      "Epoch 193/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7283 - val_loss: 0.5349 - val_accuracy: 0.7349\n",
      "Epoch 194/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7280 - val_loss: 0.5351 - val_accuracy: 0.7362\n",
      "Epoch 195/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5268 - accuracy: 0.7289 - val_loss: 0.5378 - val_accuracy: 0.7331\n",
      "Epoch 196/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5267 - accuracy: 0.7288 - val_loss: 0.5342 - val_accuracy: 0.7362\n",
      "Epoch 197/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7264 - val_loss: 0.5351 - val_accuracy: 0.7294\n",
      "Epoch 198/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.7279 - val_loss: 0.5342 - val_accuracy: 0.7337\n",
      "Epoch 199/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7286 - val_loss: 0.5357 - val_accuracy: 0.7312\n",
      "Epoch 200/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7287 - val_loss: 0.5343 - val_accuracy: 0.7362\n",
      "Fold 2, 200 epochs, 226 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.81%\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/200\n",
      "432/453 [===========================>..] - ETA: 0s - loss: 0.6082 - accuracy: 0.6673INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 3s 7ms/step - loss: 0.6063 - accuracy: 0.6687 - val_loss: 0.5614 - val_accuracy: 0.7076\n",
      "Epoch 2/200\n",
      "452/453 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7127INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5574 - accuracy: 0.7127 - val_loss: 0.5391 - val_accuracy: 0.7275\n",
      "Epoch 3/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7192 - val_loss: 0.5505 - val_accuracy: 0.7207\n",
      "Epoch 4/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7205 - val_loss: 0.5397 - val_accuracy: 0.7256\n",
      "Epoch 5/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7216 - val_loss: 0.5353 - val_accuracy: 0.7250\n",
      "Epoch 6/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7191 - val_loss: 0.5338 - val_accuracy: 0.7256\n",
      "Epoch 7/200\n",
      "432/453 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.7167INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5448 - accuracy: 0.7166 - val_loss: 0.5355 - val_accuracy: 0.7294\n",
      "Epoch 8/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5443 - accuracy: 0.7210 - val_loss: 0.5333 - val_accuracy: 0.7275\n",
      "Epoch 9/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5428 - accuracy: 0.7210 - val_loss: 0.5334 - val_accuracy: 0.7263\n",
      "Epoch 10/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7220 - val_loss: 0.5360 - val_accuracy: 0.7281\n",
      "Epoch 11/200\n",
      "438/453 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.7238INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5413 - accuracy: 0.7232 - val_loss: 0.5326 - val_accuracy: 0.7318\n",
      "Epoch 12/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5402 - accuracy: 0.7234 - val_loss: 0.5500 - val_accuracy: 0.7275\n",
      "Epoch 13/200\n",
      "451/453 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7222INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 3s 6ms/step - loss: 0.5400 - accuracy: 0.7220 - val_loss: 0.5327 - val_accuracy: 0.7343\n",
      "Epoch 14/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7221 - val_loss: 0.5465 - val_accuracy: 0.7238\n",
      "Epoch 15/200\n",
      "451/453 [============================>.] - ETA: 0s - loss: 0.5398 - accuracy: 0.7229INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5397 - accuracy: 0.7229 - val_loss: 0.5332 - val_accuracy: 0.7362\n",
      "Epoch 16/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7241 - val_loss: 0.5354 - val_accuracy: 0.7312\n",
      "Epoch 17/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7234 - val_loss: 0.5362 - val_accuracy: 0.7312\n",
      "Epoch 18/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5387 - accuracy: 0.7224 - val_loss: 0.5329 - val_accuracy: 0.7337\n",
      "Epoch 19/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7223 - val_loss: 0.5464 - val_accuracy: 0.7194\n",
      "Epoch 20/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7218 - val_loss: 0.5322 - val_accuracy: 0.7349\n",
      "Epoch 21/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5384 - accuracy: 0.7243 - val_loss: 0.5337 - val_accuracy: 0.7312\n",
      "Epoch 22/200\n",
      "433/453 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7218 ETA: 0s - loss: 0.5398 - accuracy: 0.72INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5383 - accuracy: 0.7239 - val_loss: 0.5318 - val_accuracy: 0.7368\n",
      "Epoch 23/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5376 - accuracy: 0.7246 - val_loss: 0.5324 - val_accuracy: 0.7356\n",
      "Epoch 24/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7223 - val_loss: 0.5395 - val_accuracy: 0.7349\n",
      "Epoch 25/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7230 - val_loss: 0.5360 - val_accuracy: 0.7300\n",
      "Epoch 26/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5380 - accuracy: 0.7239 - val_loss: 0.5329 - val_accuracy: 0.7306\n",
      "Epoch 27/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7240 - val_loss: 0.5313 - val_accuracy: 0.7312\n",
      "Epoch 28/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7246 - val_loss: 0.5311 - val_accuracy: 0.7318\n",
      "Epoch 29/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7225 - val_loss: 0.5315 - val_accuracy: 0.7362\n",
      "Epoch 30/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7246 - val_loss: 0.5334 - val_accuracy: 0.7294\n",
      "Epoch 31/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7237 - val_loss: 0.5319 - val_accuracy: 0.7306\n",
      "Epoch 32/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7217 - val_loss: 0.5310 - val_accuracy: 0.7300\n",
      "Epoch 33/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5383 - accuracy: 0.7223 - val_loss: 0.5318 - val_accuracy: 0.7343\n",
      "Epoch 34/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7239 - val_loss: 0.5354 - val_accuracy: 0.7300\n",
      "Epoch 35/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5376 - accuracy: 0.7243 - val_loss: 0.5350 - val_accuracy: 0.7294\n",
      "Epoch 36/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7265 - val_loss: 0.5321 - val_accuracy: 0.7306\n",
      "Epoch 37/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7230 - val_loss: 0.5344 - val_accuracy: 0.7312\n",
      "Epoch 38/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7233 - val_loss: 0.5320 - val_accuracy: 0.7306\n",
      "Epoch 39/200\n",
      "442/453 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7238INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5369 - accuracy: 0.7242 - val_loss: 0.5314 - val_accuracy: 0.7393\n",
      "Epoch 40/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7239 - val_loss: 0.5311 - val_accuracy: 0.7356\n",
      "Epoch 41/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7243 - val_loss: 0.5353 - val_accuracy: 0.7368\n",
      "Epoch 42/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7259 - val_loss: 0.5321 - val_accuracy: 0.7331\n",
      "Epoch 43/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7246 - val_loss: 0.5344 - val_accuracy: 0.7306\n",
      "Epoch 44/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7226 - val_loss: 0.5338 - val_accuracy: 0.7287\n",
      "Epoch 45/200\n",
      "436/453 [===========================>..] - ETA: 0s - loss: 0.5351 - accuracy: 0.7238INFO:tensorflow:Assets written to: MLP202.cv.3.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5360 - accuracy: 0.7230 - val_loss: 0.5326 - val_accuracy: 0.7399\n",
      "Epoch 46/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7237 - val_loss: 0.5318 - val_accuracy: 0.7300\n",
      "Epoch 47/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7237 - val_loss: 0.5309 - val_accuracy: 0.7318\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7231 - val_loss: 0.5310 - val_accuracy: 0.7381\n",
      "Epoch 49/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7238 - val_loss: 0.5311 - val_accuracy: 0.7368\n",
      "Epoch 50/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7252 - val_loss: 0.5308 - val_accuracy: 0.7312\n",
      "Epoch 51/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5366 - accuracy: 0.7229 - val_loss: 0.5358 - val_accuracy: 0.7294\n",
      "Epoch 52/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7243 - val_loss: 0.5305 - val_accuracy: 0.7393\n",
      "Epoch 53/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7257 - val_loss: 0.5304 - val_accuracy: 0.7325\n",
      "Epoch 54/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7246 - val_loss: 0.5321 - val_accuracy: 0.7294\n",
      "Epoch 55/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5360 - accuracy: 0.7250 - val_loss: 0.5321 - val_accuracy: 0.7331\n",
      "Epoch 56/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7238 - val_loss: 0.5306 - val_accuracy: 0.7374\n",
      "Epoch 57/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7232 - val_loss: 0.5318 - val_accuracy: 0.7374\n",
      "Epoch 58/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7237 - val_loss: 0.5310 - val_accuracy: 0.7362\n",
      "Epoch 59/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7249 - val_loss: 0.5312 - val_accuracy: 0.7399\n",
      "Epoch 60/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7241 - val_loss: 0.5306 - val_accuracy: 0.7362\n",
      "Epoch 61/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7239 - val_loss: 0.5306 - val_accuracy: 0.7331\n",
      "Epoch 62/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7222 - val_loss: 0.5305 - val_accuracy: 0.7381\n",
      "Epoch 63/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7243 - val_loss: 0.5311 - val_accuracy: 0.7393\n",
      "Epoch 64/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7241 - val_loss: 0.5318 - val_accuracy: 0.7374\n",
      "Epoch 65/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7247 - val_loss: 0.5304 - val_accuracy: 0.7368\n",
      "Epoch 66/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5354 - accuracy: 0.7237 - val_loss: 0.5311 - val_accuracy: 0.7362\n",
      "Epoch 67/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7269 - val_loss: 0.5343 - val_accuracy: 0.7337\n",
      "Epoch 68/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7266 - val_loss: 0.5302 - val_accuracy: 0.7337\n",
      "Epoch 69/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7246 - val_loss: 0.5306 - val_accuracy: 0.7356\n",
      "Epoch 70/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7240 - val_loss: 0.5316 - val_accuracy: 0.7349\n",
      "Epoch 71/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7248 - val_loss: 0.5310 - val_accuracy: 0.7356\n",
      "Epoch 72/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7244 - val_loss: 0.5306 - val_accuracy: 0.7368\n",
      "Epoch 73/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7239 - val_loss: 0.5318 - val_accuracy: 0.7381\n",
      "Epoch 74/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7253 - val_loss: 0.5314 - val_accuracy: 0.7393\n",
      "Epoch 75/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7264 - val_loss: 0.5305 - val_accuracy: 0.7368\n",
      "Epoch 76/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7232 - val_loss: 0.5309 - val_accuracy: 0.7374\n",
      "Epoch 77/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7243 - val_loss: 0.5331 - val_accuracy: 0.7331\n",
      "Epoch 78/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7244 - val_loss: 0.5307 - val_accuracy: 0.7349\n",
      "Epoch 79/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7248 - val_loss: 0.5342 - val_accuracy: 0.7387\n",
      "Epoch 80/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7237 - val_loss: 0.5344 - val_accuracy: 0.7374\n",
      "Epoch 81/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7253 - val_loss: 0.5309 - val_accuracy: 0.7331\n",
      "Epoch 82/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7265 - val_loss: 0.5319 - val_accuracy: 0.7269\n",
      "Epoch 83/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7255 - val_loss: 0.5357 - val_accuracy: 0.7356\n",
      "Epoch 84/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7252 - val_loss: 0.5324 - val_accuracy: 0.7349\n",
      "Epoch 85/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7264 - val_loss: 0.5350 - val_accuracy: 0.7275\n",
      "Epoch 86/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7248 - val_loss: 0.5318 - val_accuracy: 0.7337\n",
      "Epoch 87/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7268 - val_loss: 0.5300 - val_accuracy: 0.7325\n",
      "Epoch 88/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7262 - val_loss: 0.5320 - val_accuracy: 0.7281\n",
      "Epoch 89/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7239 - val_loss: 0.5312 - val_accuracy: 0.7337\n",
      "Epoch 90/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7249 - val_loss: 0.5321 - val_accuracy: 0.7325\n",
      "Epoch 91/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7239 - val_loss: 0.5307 - val_accuracy: 0.7381\n",
      "Epoch 92/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7249 - val_loss: 0.5309 - val_accuracy: 0.7393\n",
      "Epoch 93/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7239 - val_loss: 0.5327 - val_accuracy: 0.7325\n",
      "Epoch 94/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7253 - val_loss: 0.5301 - val_accuracy: 0.7381\n",
      "Epoch 95/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7241 - val_loss: 0.5310 - val_accuracy: 0.7356\n",
      "Epoch 96/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7247 - val_loss: 0.5328 - val_accuracy: 0.7287\n",
      "Epoch 97/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.7261 - val_loss: 0.5313 - val_accuracy: 0.7368\n",
      "Epoch 98/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7257 - val_loss: 0.5327 - val_accuracy: 0.7337\n",
      "Epoch 99/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7241 - val_loss: 0.5328 - val_accuracy: 0.7281\n",
      "Epoch 100/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5338 - accuracy: 0.7255 - val_loss: 0.5300 - val_accuracy: 0.7356\n",
      "Epoch 101/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7239 - val_loss: 0.5335 - val_accuracy: 0.7393\n",
      "Epoch 102/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7247 - val_loss: 0.5358 - val_accuracy: 0.7343\n",
      "Epoch 103/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7254 - val_loss: 0.5314 - val_accuracy: 0.7343\n",
      "Epoch 104/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7245 - val_loss: 0.5333 - val_accuracy: 0.7362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7251 - val_loss: 0.5310 - val_accuracy: 0.7325\n",
      "Epoch 106/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7243 - val_loss: 0.5302 - val_accuracy: 0.7343\n",
      "Epoch 107/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7253 - val_loss: 0.5333 - val_accuracy: 0.7393\n",
      "Epoch 108/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7248 - val_loss: 0.5352 - val_accuracy: 0.7381\n",
      "Epoch 109/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7260 - val_loss: 0.5333 - val_accuracy: 0.7325\n",
      "Epoch 110/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5335 - accuracy: 0.7239 - val_loss: 0.5295 - val_accuracy: 0.7362\n",
      "Epoch 111/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7255 - val_loss: 0.5313 - val_accuracy: 0.7349\n",
      "Epoch 112/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7255 - val_loss: 0.5314 - val_accuracy: 0.7337\n",
      "Epoch 113/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7250 - val_loss: 0.5300 - val_accuracy: 0.7368\n",
      "Epoch 114/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7264 - val_loss: 0.5313 - val_accuracy: 0.7381\n",
      "Epoch 115/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5329 - accuracy: 0.7266 - val_loss: 0.5305 - val_accuracy: 0.7374\n",
      "Epoch 116/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5321 - accuracy: 0.7275 - val_loss: 0.5343 - val_accuracy: 0.7263\n",
      "Epoch 117/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7243 - val_loss: 0.5300 - val_accuracy: 0.7368\n",
      "Epoch 118/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.7247 - val_loss: 0.5318 - val_accuracy: 0.7300\n",
      "Epoch 119/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7254 - val_loss: 0.5321 - val_accuracy: 0.7306\n",
      "Epoch 120/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7263 - val_loss: 0.5317 - val_accuracy: 0.7256\n",
      "Epoch 121/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7250 - val_loss: 0.5302 - val_accuracy: 0.7393\n",
      "Epoch 122/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7262 - val_loss: 0.5316 - val_accuracy: 0.7331\n",
      "Epoch 123/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7261 - val_loss: 0.5305 - val_accuracy: 0.7356\n",
      "Epoch 124/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7261 - val_loss: 0.5338 - val_accuracy: 0.7387\n",
      "Epoch 125/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7273 - val_loss: 0.5304 - val_accuracy: 0.7362\n",
      "Epoch 126/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7247 - val_loss: 0.5298 - val_accuracy: 0.7362\n",
      "Epoch 127/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7267 - val_loss: 0.5316 - val_accuracy: 0.7306\n",
      "Epoch 128/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7263 - val_loss: 0.5330 - val_accuracy: 0.7381\n",
      "Epoch 129/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7248 - val_loss: 0.5303 - val_accuracy: 0.7343\n",
      "Epoch 130/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7237 - val_loss: 0.5307 - val_accuracy: 0.7368\n",
      "Epoch 131/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7270 - val_loss: 0.5322 - val_accuracy: 0.7325\n",
      "Epoch 132/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7263 - val_loss: 0.5296 - val_accuracy: 0.7349\n",
      "Epoch 133/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7275 - val_loss: 0.5316 - val_accuracy: 0.7381\n",
      "Epoch 134/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7260 - val_loss: 0.5304 - val_accuracy: 0.7374\n",
      "Epoch 135/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7261 - val_loss: 0.5290 - val_accuracy: 0.7356\n",
      "Epoch 136/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7258 - val_loss: 0.5300 - val_accuracy: 0.7349\n",
      "Epoch 137/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7249 - val_loss: 0.5321 - val_accuracy: 0.7362\n",
      "Epoch 138/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7261 - val_loss: 0.5295 - val_accuracy: 0.7381\n",
      "Epoch 139/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7252 - val_loss: 0.5362 - val_accuracy: 0.7349\n",
      "Epoch 140/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7275 - val_loss: 0.5306 - val_accuracy: 0.7349\n",
      "Epoch 141/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7264 - val_loss: 0.5304 - val_accuracy: 0.7331\n",
      "Epoch 142/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7252 - val_loss: 0.5293 - val_accuracy: 0.7337\n",
      "Epoch 143/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7272 - val_loss: 0.5340 - val_accuracy: 0.7269\n",
      "Epoch 144/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7265 - val_loss: 0.5291 - val_accuracy: 0.7349\n",
      "Epoch 145/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7285 - val_loss: 0.5315 - val_accuracy: 0.7331\n",
      "Epoch 146/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7280 - val_loss: 0.5298 - val_accuracy: 0.7362\n",
      "Epoch 147/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7254 - val_loss: 0.5342 - val_accuracy: 0.7331\n",
      "Epoch 148/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.7264 - val_loss: 0.5299 - val_accuracy: 0.7343\n",
      "Epoch 149/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7276 - val_loss: 0.5322 - val_accuracy: 0.7331\n",
      "Epoch 150/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7252 - val_loss: 0.5302 - val_accuracy: 0.7381\n",
      "Epoch 151/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7273 - val_loss: 0.5309 - val_accuracy: 0.7331\n",
      "Epoch 152/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7251 - val_loss: 0.5309 - val_accuracy: 0.7343\n",
      "Epoch 153/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.7286 - val_loss: 0.5344 - val_accuracy: 0.7281\n",
      "Epoch 154/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7271 - val_loss: 0.5296 - val_accuracy: 0.7368\n",
      "Epoch 155/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7270 - val_loss: 0.5290 - val_accuracy: 0.7331\n",
      "Epoch 156/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7271 - val_loss: 0.5293 - val_accuracy: 0.7343\n",
      "Epoch 157/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7275 - val_loss: 0.5311 - val_accuracy: 0.7368\n",
      "Epoch 158/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7276 - val_loss: 0.5313 - val_accuracy: 0.7331\n",
      "Epoch 159/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5310 - accuracy: 0.7284 - val_loss: 0.5306 - val_accuracy: 0.7331\n",
      "Epoch 160/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7264 - val_loss: 0.5308 - val_accuracy: 0.7362\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7259 - val_loss: 0.5295 - val_accuracy: 0.7343\n",
      "Epoch 162/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7286 - val_loss: 0.5306 - val_accuracy: 0.7374\n",
      "Epoch 163/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7283 - val_loss: 0.5310 - val_accuracy: 0.7356\n",
      "Epoch 164/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5308 - accuracy: 0.7270 - val_loss: 0.5296 - val_accuracy: 0.7368\n",
      "Epoch 165/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7266 - val_loss: 0.5300 - val_accuracy: 0.7337\n",
      "Epoch 166/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7278 - val_loss: 0.5329 - val_accuracy: 0.7331\n",
      "Epoch 167/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7270 - val_loss: 0.5295 - val_accuracy: 0.7325\n",
      "Epoch 168/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7256 - val_loss: 0.5293 - val_accuracy: 0.7300\n",
      "Epoch 169/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7263 - val_loss: 0.5293 - val_accuracy: 0.7325\n",
      "Epoch 170/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7260 - val_loss: 0.5313 - val_accuracy: 0.7349\n",
      "Epoch 171/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7281 - val_loss: 0.5339 - val_accuracy: 0.7331\n",
      "Epoch 172/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7261 - val_loss: 0.5308 - val_accuracy: 0.7349\n",
      "Epoch 173/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7257 - val_loss: 0.5294 - val_accuracy: 0.7331\n",
      "Epoch 174/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7282 - val_loss: 0.5351 - val_accuracy: 0.7331\n",
      "Epoch 175/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7267 - val_loss: 0.5308 - val_accuracy: 0.7349\n",
      "Epoch 176/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7264 - val_loss: 0.5309 - val_accuracy: 0.7337\n",
      "Epoch 177/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7279 - val_loss: 0.5395 - val_accuracy: 0.7294\n",
      "Epoch 178/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7272 - val_loss: 0.5291 - val_accuracy: 0.7343\n",
      "Epoch 179/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7272 - val_loss: 0.5288 - val_accuracy: 0.7343\n",
      "Epoch 180/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.7272 - val_loss: 0.5307 - val_accuracy: 0.7343\n",
      "Epoch 181/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7277 - val_loss: 0.5308 - val_accuracy: 0.7337\n",
      "Epoch 182/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5285 - accuracy: 0.7293 - val_loss: 0.5305 - val_accuracy: 0.7356\n",
      "Epoch 183/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5297 - accuracy: 0.7286 - val_loss: 0.5299 - val_accuracy: 0.7368\n",
      "Epoch 184/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5292 - accuracy: 0.7262 - val_loss: 0.5304 - val_accuracy: 0.7343\n",
      "Epoch 185/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5295 - accuracy: 0.7260 - val_loss: 0.5294 - val_accuracy: 0.7325\n",
      "Epoch 186/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7275 - val_loss: 0.5297 - val_accuracy: 0.7362\n",
      "Epoch 187/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.7271 - val_loss: 0.5305 - val_accuracy: 0.7343\n",
      "Epoch 188/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5298 - accuracy: 0.7261 - val_loss: 0.5293 - val_accuracy: 0.7337\n",
      "Epoch 189/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5287 - accuracy: 0.7286 - val_loss: 0.5322 - val_accuracy: 0.7325\n",
      "Epoch 190/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5292 - accuracy: 0.7268 - val_loss: 0.5329 - val_accuracy: 0.7337\n",
      "Epoch 191/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7268 - val_loss: 0.5294 - val_accuracy: 0.7356\n",
      "Epoch 192/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7259 - val_loss: 0.5298 - val_accuracy: 0.7356\n",
      "Epoch 193/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5289 - accuracy: 0.7276 - val_loss: 0.5304 - val_accuracy: 0.7343\n",
      "Epoch 194/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7272 - val_loss: 0.5312 - val_accuracy: 0.7368\n",
      "Epoch 195/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.7273 - val_loss: 0.5292 - val_accuracy: 0.7356\n",
      "Epoch 196/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5290 - accuracy: 0.7272 - val_loss: 0.5311 - val_accuracy: 0.7349\n",
      "Epoch 197/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7272 - val_loss: 0.5296 - val_accuracy: 0.7356\n",
      "Epoch 198/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7284 - val_loss: 0.5292 - val_accuracy: 0.7356\n",
      "Epoch 199/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5283 - accuracy: 0.7290 - val_loss: 0.5288 - val_accuracy: 0.7343\n",
      "Epoch 200/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7278 - val_loss: 0.5328 - val_accuracy: 0.7349\n",
      "Fold 3, 200 epochs, 227 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.99%\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/200\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.6789INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 3s 6ms/step - loss: 0.5954 - accuracy: 0.6789 - val_loss: 0.5593 - val_accuracy: 0.7138\n",
      "Epoch 2/200\n",
      "438/453 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7152INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5528 - accuracy: 0.7152 - val_loss: 0.5369 - val_accuracy: 0.7312\n",
      "Epoch 3/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7182 - val_loss: 0.5398 - val_accuracy: 0.7250\n",
      "Epoch 4/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5446 - accuracy: 0.7213 - val_loss: 0.5342 - val_accuracy: 0.7294\n",
      "Epoch 5/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5452 - accuracy: 0.7195 - val_loss: 0.5373 - val_accuracy: 0.7250\n",
      "Epoch 6/200\n",
      "421/453 [==========================>...] - ETA: 0s - loss: 0.5436 - accuracy: 0.7209INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7205 - val_loss: 0.5328 - val_accuracy: 0.7331\n",
      "Epoch 7/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7186 - val_loss: 0.5329 - val_accuracy: 0.7256\n",
      "Epoch 8/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.7210 - val_loss: 0.5312 - val_accuracy: 0.7294\n",
      "Epoch 9/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5416 - accuracy: 0.7216 - val_loss: 0.5321 - val_accuracy: 0.7287\n",
      "Epoch 10/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7201 - val_loss: 0.5369 - val_accuracy: 0.7232\n",
      "Epoch 11/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7226 - val_loss: 0.5317 - val_accuracy: 0.7256\n",
      "Epoch 12/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7225 - val_loss: 0.5297 - val_accuracy: 0.7275\n",
      "Epoch 13/200\n",
      "432/453 [===========================>..] - ETA: 0s - loss: 0.5409 - accuracy: 0.7214 ETA: 0s - loss: 0.5418 - accuracy: 0.72 - ETA: 0s - loss: 0.5418 - accuINFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5406 - accuracy: 0.7212 - val_loss: 0.5321 - val_accuracy: 0.7362\n",
      "Epoch 14/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7230 - val_loss: 0.5307 - val_accuracy: 0.7269\n",
      "Epoch 15/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7220 - val_loss: 0.5313 - val_accuracy: 0.7343\n",
      "Epoch 16/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7196 - val_loss: 0.5334 - val_accuracy: 0.7263\n",
      "Epoch 17/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5400 - accuracy: 0.7241 - val_loss: 0.5288 - val_accuracy: 0.7325\n",
      "Epoch 18/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7209 - val_loss: 0.5330 - val_accuracy: 0.7337\n",
      "Epoch 19/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5395 - accuracy: 0.7248 - val_loss: 0.5326 - val_accuracy: 0.7331\n",
      "Epoch 20/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5397 - accuracy: 0.7236 - val_loss: 0.5303 - val_accuracy: 0.7343\n",
      "Epoch 21/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.7224 - val_loss: 0.5286 - val_accuracy: 0.7349\n",
      "Epoch 22/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5403 - accuracy: 0.7232 - val_loss: 0.5284 - val_accuracy: 0.7349\n",
      "Epoch 23/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5388 - accuracy: 0.7232 - val_loss: 0.5276 - val_accuracy: 0.7343\n",
      "Epoch 24/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5401 - accuracy: 0.7221 - val_loss: 0.5375 - val_accuracy: 0.7337\n",
      "Epoch 25/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5405 - accuracy: 0.7238 - val_loss: 0.5349 - val_accuracy: 0.7325\n",
      "Epoch 26/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7247 - val_loss: 0.5383 - val_accuracy: 0.7318\n",
      "Epoch 27/200\n",
      "447/453 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7225INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5396 - accuracy: 0.7223 - val_loss: 0.5353 - val_accuracy: 0.7368\n",
      "Epoch 28/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7230 - val_loss: 0.5277 - val_accuracy: 0.7356\n",
      "Epoch 29/200\n",
      "445/453 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.7237INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5383 - accuracy: 0.7240 - val_loss: 0.5297 - val_accuracy: 0.7374\n",
      "Epoch 30/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7225 - val_loss: 0.5437 - val_accuracy: 0.7312\n",
      "Epoch 31/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5401 - accuracy: 0.7226 - val_loss: 0.5275 - val_accuracy: 0.7343\n",
      "Epoch 32/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7239 - val_loss: 0.5332 - val_accuracy: 0.7356\n",
      "Epoch 33/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7228 - val_loss: 0.5282 - val_accuracy: 0.7362\n",
      "Epoch 34/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7223 - val_loss: 0.5274 - val_accuracy: 0.7349\n",
      "Epoch 35/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7237 - val_loss: 0.5275 - val_accuracy: 0.7337\n",
      "Epoch 36/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5379 - accuracy: 0.7228 - val_loss: 0.5287 - val_accuracy: 0.7349\n",
      "Epoch 37/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7237 - val_loss: 0.5271 - val_accuracy: 0.7287\n",
      "Epoch 38/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7237 - val_loss: 0.5264 - val_accuracy: 0.7349\n",
      "Epoch 39/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7232 - val_loss: 0.5277 - val_accuracy: 0.7349\n",
      "Epoch 40/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7244 - val_loss: 0.5292 - val_accuracy: 0.7349\n",
      "Epoch 41/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.7250 - val_loss: 0.5257 - val_accuracy: 0.7337\n",
      "Epoch 42/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5373 - accuracy: 0.7244 - val_loss: 0.5254 - val_accuracy: 0.7331\n",
      "Epoch 43/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5371 - accuracy: 0.7238 - val_loss: 0.5253 - val_accuracy: 0.7356\n",
      "Epoch 44/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7248 - val_loss: 0.5285 - val_accuracy: 0.7318\n",
      "Epoch 45/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5374 - accuracy: 0.7235 - val_loss: 0.5261 - val_accuracy: 0.7368\n",
      "Epoch 46/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5374 - accuracy: 0.7226 - val_loss: 0.5259 - val_accuracy: 0.7362\n",
      "Epoch 47/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5380 - accuracy: 0.7225 - val_loss: 0.5280 - val_accuracy: 0.7337\n",
      "Epoch 48/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5369 - accuracy: 0.7216 - val_loss: 0.5274 - val_accuracy: 0.7306\n",
      "Epoch 49/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5374 - accuracy: 0.7244 - val_loss: 0.5275 - val_accuracy: 0.7325\n",
      "Epoch 50/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5372 - accuracy: 0.7241 - val_loss: 0.5256 - val_accuracy: 0.7362\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/453 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.7255INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5370 - accuracy: 0.7242 - val_loss: 0.5245 - val_accuracy: 0.7381\n",
      "Epoch 52/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7230 - val_loss: 0.5258 - val_accuracy: 0.7337\n",
      "Epoch 53/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5375 - accuracy: 0.7222 - val_loss: 0.5271 - val_accuracy: 0.7300\n",
      "Epoch 54/200\n",
      "441/453 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7251INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 5s 11ms/step - loss: 0.5369 - accuracy: 0.7246 - val_loss: 0.5248 - val_accuracy: 0.7387\n",
      "Epoch 55/200\n",
      "453/453 [==============================] - 4s 9ms/step - loss: 0.5368 - accuracy: 0.7230 - val_loss: 0.5258 - val_accuracy: 0.7374\n",
      "Epoch 56/200\n",
      "453/453 [==============================] - 6s 13ms/step - loss: 0.5368 - accuracy: 0.7231 - val_loss: 0.5263 - val_accuracy: 0.7312\n",
      "Epoch 57/200\n",
      "453/453 [==============================] - 3s 7ms/step - loss: 0.5373 - accuracy: 0.7223 - val_loss: 0.5281 - val_accuracy: 0.7356\n",
      "Epoch 58/200\n",
      "453/453 [==============================] - 3s 6ms/step - loss: 0.5366 - accuracy: 0.7247 - val_loss: 0.5261 - val_accuracy: 0.7331\n",
      "Epoch 59/200\n",
      "453/453 [==============================] - 3s 7ms/step - loss: 0.5368 - accuracy: 0.7221 - val_loss: 0.5296 - val_accuracy: 0.7337\n",
      "Epoch 60/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5366 - accuracy: 0.7235 - val_loss: 0.5261 - val_accuracy: 0.7387\n",
      "Epoch 61/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5358 - accuracy: 0.7228 - val_loss: 0.5237 - val_accuracy: 0.7318\n",
      "Epoch 62/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5375 - accuracy: 0.7220 - val_loss: 0.5278 - val_accuracy: 0.7381\n",
      "Epoch 63/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5362 - accuracy: 0.7255 - val_loss: 0.5244 - val_accuracy: 0.7337\n",
      "Epoch 64/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5364 - accuracy: 0.7234 - val_loss: 0.5263 - val_accuracy: 0.7294\n",
      "Epoch 65/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5364 - accuracy: 0.7247 - val_loss: 0.5241 - val_accuracy: 0.7349\n",
      "Epoch 66/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5366 - accuracy: 0.7243 - val_loss: 0.5271 - val_accuracy: 0.7343\n",
      "Epoch 67/200\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 0.5357 - accuracy: 0.7248 - val_loss: 0.5240 - val_accuracy: 0.7356\n",
      "Epoch 68/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5359 - accuracy: 0.7240 - val_loss: 0.5232 - val_accuracy: 0.7343\n",
      "Epoch 69/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.7248 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 70/200\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.5353 - accuracy: 0.7235 - val_loss: 0.5236 - val_accuracy: 0.7362\n",
      "Epoch 71/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5356 - accuracy: 0.7231 - val_loss: 0.5235 - val_accuracy: 0.7349\n",
      "Epoch 72/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7238 - val_loss: 0.5227 - val_accuracy: 0.7349\n",
      "Epoch 73/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7233 - val_loss: 0.5236 - val_accuracy: 0.7300\n",
      "Epoch 74/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7226 - val_loss: 0.5251 - val_accuracy: 0.7368\n",
      "Epoch 75/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7232 - val_loss: 0.5239 - val_accuracy: 0.7356\n",
      "Epoch 76/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7237 - val_loss: 0.5229 - val_accuracy: 0.7349\n",
      "Epoch 77/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7258 - val_loss: 0.5249 - val_accuracy: 0.7381\n",
      "Epoch 78/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7258 - val_loss: 0.5254 - val_accuracy: 0.7343\n",
      "Epoch 79/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7230 - val_loss: 0.5242 - val_accuracy: 0.7368\n",
      "Epoch 80/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7250 - val_loss: 0.5254 - val_accuracy: 0.7318\n",
      "Epoch 81/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7235 - val_loss: 0.5248 - val_accuracy: 0.7306\n",
      "Epoch 82/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7250 - val_loss: 0.5241 - val_accuracy: 0.7343\n",
      "Epoch 83/200\n",
      "433/453 [===========================>..] - ETA: 0s - loss: 0.5351 - accuracy: 0.7230INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5350 - accuracy: 0.7228 - val_loss: 0.5235 - val_accuracy: 0.7399\n",
      "Epoch 84/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7244 - val_loss: 0.5256 - val_accuracy: 0.7331\n",
      "Epoch 85/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7246 - val_loss: 0.5231 - val_accuracy: 0.7275\n",
      "Epoch 86/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7235 - val_loss: 0.5248 - val_accuracy: 0.7381\n",
      "Epoch 87/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7246 - val_loss: 0.5351 - val_accuracy: 0.7312\n",
      "Epoch 88/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7247 - val_loss: 0.5228 - val_accuracy: 0.7374\n",
      "Epoch 89/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7232 - val_loss: 0.5221 - val_accuracy: 0.7318\n",
      "Epoch 90/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7235 - val_loss: 0.5230 - val_accuracy: 0.7331\n",
      "Epoch 91/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7261 - val_loss: 0.5257 - val_accuracy: 0.7325\n",
      "Epoch 92/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7223 - val_loss: 0.5225 - val_accuracy: 0.7318\n",
      "Epoch 93/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7235 - val_loss: 0.5221 - val_accuracy: 0.7306\n",
      "Epoch 94/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7239 - val_loss: 0.5230 - val_accuracy: 0.7374\n",
      "Epoch 95/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7253 - val_loss: 0.5225 - val_accuracy: 0.7349\n",
      "Epoch 96/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7248 - val_loss: 0.5224 - val_accuracy: 0.7368\n",
      "Epoch 97/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7244 - val_loss: 0.5267 - val_accuracy: 0.7362\n",
      "Epoch 98/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7239 - val_loss: 0.5220 - val_accuracy: 0.7343\n",
      "Epoch 99/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7253 - val_loss: 0.5238 - val_accuracy: 0.7349\n",
      "Epoch 100/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7242 - val_loss: 0.5240 - val_accuracy: 0.7331\n",
      "Epoch 101/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7248 - val_loss: 0.5245 - val_accuracy: 0.7294\n",
      "Epoch 102/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7256 - val_loss: 0.5211 - val_accuracy: 0.7318\n",
      "Epoch 103/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7239 - val_loss: 0.5210 - val_accuracy: 0.7343\n",
      "Epoch 104/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7262 - val_loss: 0.5215 - val_accuracy: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7223 - val_loss: 0.5253 - val_accuracy: 0.7343\n",
      "Epoch 106/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7246 - val_loss: 0.5233 - val_accuracy: 0.7318\n",
      "Epoch 107/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7220 - val_loss: 0.5225 - val_accuracy: 0.7337\n",
      "Epoch 108/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7221 - val_loss: 0.5226 - val_accuracy: 0.7368\n",
      "Epoch 109/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7232 - val_loss: 0.5230 - val_accuracy: 0.7362\n",
      "Epoch 110/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7254 - val_loss: 0.5231 - val_accuracy: 0.7381\n",
      "Epoch 111/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7248 - val_loss: 0.5228 - val_accuracy: 0.7294\n",
      "Epoch 112/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7244 - val_loss: 0.5248 - val_accuracy: 0.7325\n",
      "Epoch 113/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7254 - val_loss: 0.5207 - val_accuracy: 0.7362\n",
      "Epoch 114/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7261 - val_loss: 0.5212 - val_accuracy: 0.7294\n",
      "Epoch 115/200\n",
      "449/453 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.7231INFO:tensorflow:Assets written to: MLP202.cv.4.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.7237 - val_loss: 0.5205 - val_accuracy: 0.7412\n",
      "Epoch 116/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7237 - val_loss: 0.5241 - val_accuracy: 0.7356\n",
      "Epoch 117/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7261 - val_loss: 0.5211 - val_accuracy: 0.7343\n",
      "Epoch 118/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7233 - val_loss: 0.5240 - val_accuracy: 0.7368\n",
      "Epoch 119/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7240 - val_loss: 0.5216 - val_accuracy: 0.7244\n",
      "Epoch 120/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7257 - val_loss: 0.5270 - val_accuracy: 0.7356\n",
      "Epoch 121/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7256 - val_loss: 0.5316 - val_accuracy: 0.7312\n",
      "Epoch 122/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7246 - val_loss: 0.5210 - val_accuracy: 0.7306\n",
      "Epoch 123/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7252 - val_loss: 0.5199 - val_accuracy: 0.7337\n",
      "Epoch 124/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7250 - val_loss: 0.5195 - val_accuracy: 0.7306\n",
      "Epoch 125/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7252 - val_loss: 0.5219 - val_accuracy: 0.7318\n",
      "Epoch 126/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7255 - val_loss: 0.5204 - val_accuracy: 0.7287\n",
      "Epoch 127/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7237 - val_loss: 0.5231 - val_accuracy: 0.7325\n",
      "Epoch 128/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7258 - val_loss: 0.5209 - val_accuracy: 0.7294\n",
      "Epoch 129/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7246 - val_loss: 0.5267 - val_accuracy: 0.7318\n",
      "Epoch 130/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7277 - val_loss: 0.5207 - val_accuracy: 0.7312\n",
      "Epoch 131/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7257 - val_loss: 0.5206 - val_accuracy: 0.7312\n",
      "Epoch 132/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7270 - val_loss: 0.5220 - val_accuracy: 0.7318\n",
      "Epoch 133/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7250 - val_loss: 0.5296 - val_accuracy: 0.7225\n",
      "Epoch 134/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7268 - val_loss: 0.5230 - val_accuracy: 0.7300\n",
      "Epoch 135/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7271 - val_loss: 0.5213 - val_accuracy: 0.7306\n",
      "Epoch 136/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7261 - val_loss: 0.5247 - val_accuracy: 0.7331\n",
      "Epoch 137/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7267 - val_loss: 0.5306 - val_accuracy: 0.7325\n",
      "Epoch 138/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7284 - val_loss: 0.5208 - val_accuracy: 0.7337\n",
      "Epoch 139/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7306 - val_loss: 0.5229 - val_accuracy: 0.7368\n",
      "Epoch 140/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7268 - val_loss: 0.5206 - val_accuracy: 0.7306\n",
      "Epoch 141/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7296 - val_loss: 0.5218 - val_accuracy: 0.7331\n",
      "Epoch 142/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7288 - val_loss: 0.5209 - val_accuracy: 0.7325\n",
      "Epoch 143/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7297 - val_loss: 0.5215 - val_accuracy: 0.7300\n",
      "Epoch 144/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7308 - val_loss: 0.5199 - val_accuracy: 0.7325\n",
      "Epoch 145/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7290 - val_loss: 0.5200 - val_accuracy: 0.7337\n",
      "Epoch 146/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7298 - val_loss: 0.5232 - val_accuracy: 0.7325\n",
      "Epoch 147/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7301 - val_loss: 0.5217 - val_accuracy: 0.7331\n",
      "Epoch 148/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7306 - val_loss: 0.5271 - val_accuracy: 0.7405\n",
      "Epoch 149/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7301 - val_loss: 0.5206 - val_accuracy: 0.7349\n",
      "Epoch 150/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7315 - val_loss: 0.5215 - val_accuracy: 0.7331\n",
      "Epoch 151/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7315 - val_loss: 0.5367 - val_accuracy: 0.7300\n",
      "Epoch 152/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7339 - val_loss: 0.5223 - val_accuracy: 0.7337\n",
      "Epoch 153/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7331 - val_loss: 0.5197 - val_accuracy: 0.7381\n",
      "Epoch 154/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7328 - val_loss: 0.5212 - val_accuracy: 0.7312\n",
      "Epoch 155/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7335 - val_loss: 0.5227 - val_accuracy: 0.7331\n",
      "Epoch 156/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5253 - accuracy: 0.7350 - val_loss: 0.5200 - val_accuracy: 0.7387\n",
      "Epoch 157/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7338 - val_loss: 0.5202 - val_accuracy: 0.7349\n",
      "Epoch 158/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5256 - accuracy: 0.7317 - val_loss: 0.5204 - val_accuracy: 0.7362\n",
      "Epoch 159/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5249 - accuracy: 0.7348 - val_loss: 0.5209 - val_accuracy: 0.7387\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7348 - val_loss: 0.5207 - val_accuracy: 0.7381\n",
      "Epoch 161/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.7356 - val_loss: 0.5225 - val_accuracy: 0.7349\n",
      "Epoch 162/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7350 - val_loss: 0.5191 - val_accuracy: 0.7387\n",
      "Epoch 163/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7348 - val_loss: 0.5193 - val_accuracy: 0.7368\n",
      "Epoch 164/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7354 - val_loss: 0.5269 - val_accuracy: 0.7356\n",
      "Epoch 165/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7339 - val_loss: 0.5206 - val_accuracy: 0.7331\n",
      "Epoch 166/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7384 - val_loss: 0.5207 - val_accuracy: 0.7337\n",
      "Epoch 167/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7339 - val_loss: 0.5195 - val_accuracy: 0.7405\n",
      "Epoch 168/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7350 - val_loss: 0.5194 - val_accuracy: 0.7356\n",
      "Epoch 169/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7337 - val_loss: 0.5220 - val_accuracy: 0.7331\n",
      "Epoch 170/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7375 - val_loss: 0.5204 - val_accuracy: 0.7312\n",
      "Epoch 171/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7353 - val_loss: 0.5194 - val_accuracy: 0.7368\n",
      "Epoch 172/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7348 - val_loss: 0.5198 - val_accuracy: 0.7381\n",
      "Epoch 173/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.7347 - val_loss: 0.5215 - val_accuracy: 0.7337\n",
      "Epoch 174/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7368 - val_loss: 0.5197 - val_accuracy: 0.7343\n",
      "Epoch 175/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7372 - val_loss: 0.5249 - val_accuracy: 0.7381\n",
      "Epoch 176/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7365 - val_loss: 0.5180 - val_accuracy: 0.7349\n",
      "Epoch 177/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7336 - val_loss: 0.5233 - val_accuracy: 0.7381\n",
      "Epoch 178/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7328 - val_loss: 0.5183 - val_accuracy: 0.7343\n",
      "Epoch 179/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7373 - val_loss: 0.5207 - val_accuracy: 0.7331\n",
      "Epoch 180/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7364 - val_loss: 0.5216 - val_accuracy: 0.7343\n",
      "Epoch 181/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7330 - val_loss: 0.5209 - val_accuracy: 0.7337\n",
      "Epoch 182/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7366 - val_loss: 0.5197 - val_accuracy: 0.7331\n",
      "Epoch 183/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7355 - val_loss: 0.5204 - val_accuracy: 0.7325\n",
      "Epoch 184/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5233 - accuracy: 0.7364 - val_loss: 0.5201 - val_accuracy: 0.7337\n",
      "Epoch 185/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7366 - val_loss: 0.5258 - val_accuracy: 0.7331\n",
      "Epoch 186/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7373 - val_loss: 0.5226 - val_accuracy: 0.7368\n",
      "Epoch 187/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7361 - val_loss: 0.5226 - val_accuracy: 0.7412\n",
      "Epoch 188/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7328 - val_loss: 0.5199 - val_accuracy: 0.7349\n",
      "Epoch 189/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7342 - val_loss: 0.5210 - val_accuracy: 0.7393\n",
      "Epoch 190/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7364 - val_loss: 0.5225 - val_accuracy: 0.7399\n",
      "Epoch 191/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7370 - val_loss: 0.5191 - val_accuracy: 0.7343\n",
      "Epoch 192/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7344 - val_loss: 0.5187 - val_accuracy: 0.7387\n",
      "Epoch 193/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7354 - val_loss: 0.5191 - val_accuracy: 0.7368\n",
      "Epoch 194/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7366 - val_loss: 0.5190 - val_accuracy: 0.7325\n",
      "Epoch 195/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7372 - val_loss: 0.5184 - val_accuracy: 0.7356\n",
      "Epoch 196/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7366 - val_loss: 0.5210 - val_accuracy: 0.7337\n",
      "Epoch 197/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7349 - val_loss: 0.5179 - val_accuracy: 0.7337\n",
      "Epoch 198/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7370 - val_loss: 0.5190 - val_accuracy: 0.7362\n",
      "Epoch 199/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7381 - val_loss: 0.5203 - val_accuracy: 0.7343\n",
      "Epoch 200/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7369 - val_loss: 0.5194 - val_accuracy: 0.7337\n",
      "Fold 4, 200 epochs, 222 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 74.12%\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/200\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.6728INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.6035 - accuracy: 0.6728 - val_loss: 0.5521 - val_accuracy: 0.7145\n",
      "Epoch 2/200\n",
      "427/453 [===========================>..] - ETA: 0s - loss: 0.5583 - accuracy: 0.7108INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5576 - accuracy: 0.7110 - val_loss: 0.5382 - val_accuracy: 0.7256\n",
      "Epoch 3/200\n",
      "435/453 [===========================>..] - ETA: 0s - loss: 0.5475 - accuracy: 0.7170INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7167 - val_loss: 0.5392 - val_accuracy: 0.7300\n",
      "Epoch 4/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7175 - val_loss: 0.5443 - val_accuracy: 0.7281\n",
      "Epoch 5/200\n",
      "451/453 [============================>.] - ETA: 0s - loss: 0.5442 - accuracy: 0.7199INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7200 - val_loss: 0.5366 - val_accuracy: 0.7331\n",
      "Epoch 6/200\n",
      "449/453 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7206INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5433 - accuracy: 0.7197 - val_loss: 0.5346 - val_accuracy: 0.7349\n",
      "Epoch 7/200\n",
      "450/453 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7226INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7223 - val_loss: 0.5360 - val_accuracy: 0.7381\n",
      "Epoch 8/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7206 - val_loss: 0.5333 - val_accuracy: 0.7318\n",
      "Epoch 9/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7201 - val_loss: 0.5322 - val_accuracy: 0.7337\n",
      "Epoch 10/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7211 - val_loss: 0.5354 - val_accuracy: 0.7349\n",
      "Epoch 11/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7239 - val_loss: 0.5322 - val_accuracy: 0.7331\n",
      "Epoch 12/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7201 - val_loss: 0.5318 - val_accuracy: 0.7343\n",
      "Epoch 13/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7215 - val_loss: 0.5389 - val_accuracy: 0.7343\n",
      "Epoch 14/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7201 - val_loss: 0.5346 - val_accuracy: 0.7368\n",
      "Epoch 15/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7232 - val_loss: 0.5385 - val_accuracy: 0.7349\n",
      "Epoch 16/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7224 - val_loss: 0.5314 - val_accuracy: 0.7337\n",
      "Epoch 17/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7224 - val_loss: 0.5364 - val_accuracy: 0.7337\n",
      "Epoch 18/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7221 - val_loss: 0.5347 - val_accuracy: 0.7343\n",
      "Epoch 19/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7210 - val_loss: 0.5311 - val_accuracy: 0.7374\n",
      "Epoch 20/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7234 - val_loss: 0.5341 - val_accuracy: 0.7331\n",
      "Epoch 21/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7210 - val_loss: 0.5310 - val_accuracy: 0.7356\n",
      "Epoch 22/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7248 - val_loss: 0.5330 - val_accuracy: 0.7356\n",
      "Epoch 23/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7236 - val_loss: 0.5301 - val_accuracy: 0.7318\n",
      "Epoch 24/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7243 - val_loss: 0.5314 - val_accuracy: 0.7306\n",
      "Epoch 25/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7215 - val_loss: 0.5403 - val_accuracy: 0.7374\n",
      "Epoch 26/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7236 - val_loss: 0.5307 - val_accuracy: 0.7356\n",
      "Epoch 27/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7246 - val_loss: 0.5312 - val_accuracy: 0.7294\n",
      "Epoch 28/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7255 - val_loss: 0.5334 - val_accuracy: 0.7349\n",
      "Epoch 29/200\n",
      "453/453 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7226 - val_loss: 0.5391 - val_accuracy: 0.7368\n",
      "Epoch 30/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7241 - val_loss: 0.5310 - val_accuracy: 0.7325\n",
      "Epoch 31/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7230 - val_loss: 0.5308 - val_accuracy: 0.7331\n",
      "Epoch 32/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7226 - val_loss: 0.5353 - val_accuracy: 0.7312\n",
      "Epoch 33/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7223 - val_loss: 0.5393 - val_accuracy: 0.7362\n",
      "Epoch 34/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7250 - val_loss: 0.5292 - val_accuracy: 0.7306\n",
      "Epoch 35/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7219 - val_loss: 0.5288 - val_accuracy: 0.7306\n",
      "Epoch 36/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7248 - val_loss: 0.5326 - val_accuracy: 0.7312\n",
      "Epoch 37/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7245 - val_loss: 0.5289 - val_accuracy: 0.7312\n",
      "Epoch 38/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7246 - val_loss: 0.5293 - val_accuracy: 0.7318\n",
      "Epoch 39/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7247 - val_loss: 0.5307 - val_accuracy: 0.7337\n",
      "Epoch 40/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7239 - val_loss: 0.5286 - val_accuracy: 0.7300\n",
      "Epoch 41/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7212 - val_loss: 0.5310 - val_accuracy: 0.7356\n",
      "Epoch 42/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7237 - val_loss: 0.5302 - val_accuracy: 0.7312\n",
      "Epoch 43/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7235 - val_loss: 0.5285 - val_accuracy: 0.7300\n",
      "Epoch 44/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7254 - val_loss: 0.5380 - val_accuracy: 0.7362\n",
      "Epoch 45/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7229 - val_loss: 0.5281 - val_accuracy: 0.7300\n",
      "Epoch 46/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7244 - val_loss: 0.5389 - val_accuracy: 0.7362\n",
      "Epoch 47/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7257 - val_loss: 0.5282 - val_accuracy: 0.7306\n",
      "Epoch 48/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7250 - val_loss: 0.5294 - val_accuracy: 0.7306\n",
      "Epoch 49/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7252 - val_loss: 0.5324 - val_accuracy: 0.7356\n",
      "Epoch 50/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7242 - val_loss: 0.5279 - val_accuracy: 0.7312\n",
      "Epoch 51/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7239 - val_loss: 0.5281 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7255 - val_loss: 0.5274 - val_accuracy: 0.7312\n",
      "Epoch 53/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7243 - val_loss: 0.5283 - val_accuracy: 0.7318\n",
      "Epoch 54/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7235 - val_loss: 0.5278 - val_accuracy: 0.7300\n",
      "Epoch 55/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7248 - val_loss: 0.5305 - val_accuracy: 0.7356\n",
      "Epoch 56/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7262 - val_loss: 0.5283 - val_accuracy: 0.7281\n",
      "Epoch 57/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7252 - val_loss: 0.5286 - val_accuracy: 0.7337\n",
      "Epoch 58/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7248 - val_loss: 0.5285 - val_accuracy: 0.7318\n",
      "Epoch 59/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7243 - val_loss: 0.5287 - val_accuracy: 0.7362\n",
      "Epoch 60/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7223 - val_loss: 0.5292 - val_accuracy: 0.7294\n",
      "Epoch 61/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7239 - val_loss: 0.5274 - val_accuracy: 0.7300\n",
      "Epoch 62/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7236 - val_loss: 0.5309 - val_accuracy: 0.7362\n",
      "Epoch 63/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7238 - val_loss: 0.5278 - val_accuracy: 0.7287\n",
      "Epoch 64/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7247 - val_loss: 0.5289 - val_accuracy: 0.7325\n",
      "Epoch 65/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7246 - val_loss: 0.5282 - val_accuracy: 0.7312\n",
      "Epoch 66/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7261 - val_loss: 0.5264 - val_accuracy: 0.7325\n",
      "Epoch 67/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7251 - val_loss: 0.5273 - val_accuracy: 0.7318\n",
      "Epoch 68/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7244 - val_loss: 0.5283 - val_accuracy: 0.7318\n",
      "Epoch 69/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7228 - val_loss: 0.5333 - val_accuracy: 0.7362\n",
      "Epoch 70/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7251 - val_loss: 0.5265 - val_accuracy: 0.7294\n",
      "Epoch 71/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7260 - val_loss: 0.5265 - val_accuracy: 0.7294\n",
      "Epoch 72/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7250 - val_loss: 0.5286 - val_accuracy: 0.7306\n",
      "Epoch 73/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7253 - val_loss: 0.5329 - val_accuracy: 0.7331\n",
      "Epoch 74/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7232 - val_loss: 0.5289 - val_accuracy: 0.7312\n",
      "Epoch 75/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7252 - val_loss: 0.5268 - val_accuracy: 0.7312\n",
      "Epoch 76/200\n",
      "436/453 [===========================>..] - ETA: 0s - loss: 0.5361 - accuracy: 0.7246INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5357 - accuracy: 0.7246 - val_loss: 0.5307 - val_accuracy: 0.7387\n",
      "Epoch 77/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7254 - val_loss: 0.5266 - val_accuracy: 0.7318\n",
      "Epoch 78/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7243 - val_loss: 0.5273 - val_accuracy: 0.7287\n",
      "Epoch 79/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7252 - val_loss: 0.5290 - val_accuracy: 0.7337\n",
      "Epoch 80/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7261 - val_loss: 0.5300 - val_accuracy: 0.7368\n",
      "Epoch 81/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7261 - val_loss: 0.5266 - val_accuracy: 0.7312\n",
      "Epoch 82/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7244 - val_loss: 0.5265 - val_accuracy: 0.7312\n",
      "Epoch 83/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7227 - val_loss: 0.5260 - val_accuracy: 0.7318\n",
      "Epoch 84/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7224 - val_loss: 0.5257 - val_accuracy: 0.7306\n",
      "Epoch 85/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7237 - val_loss: 0.5284 - val_accuracy: 0.7343\n",
      "Epoch 86/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7239 - val_loss: 0.5264 - val_accuracy: 0.7306\n",
      "Epoch 87/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7251 - val_loss: 0.5289 - val_accuracy: 0.7318\n",
      "Epoch 88/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7235 - val_loss: 0.5258 - val_accuracy: 0.7325\n",
      "Epoch 89/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7246 - val_loss: 0.5298 - val_accuracy: 0.7343\n",
      "Epoch 90/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7246 - val_loss: 0.5260 - val_accuracy: 0.7318\n",
      "Epoch 91/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7264 - val_loss: 0.5319 - val_accuracy: 0.7281\n",
      "Epoch 92/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7233 - val_loss: 0.5254 - val_accuracy: 0.7300\n",
      "Epoch 93/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7248 - val_loss: 0.5283 - val_accuracy: 0.7337\n",
      "Epoch 94/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7246 - val_loss: 0.5255 - val_accuracy: 0.7337\n",
      "Epoch 95/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7258 - val_loss: 0.5285 - val_accuracy: 0.7325\n",
      "Epoch 96/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7261 - val_loss: 0.5253 - val_accuracy: 0.7331\n",
      "Epoch 97/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7255 - val_loss: 0.5262 - val_accuracy: 0.7349\n",
      "Epoch 98/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7243 - val_loss: 0.5253 - val_accuracy: 0.7337\n",
      "Epoch 99/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7280 - val_loss: 0.5252 - val_accuracy: 0.7325\n",
      "Epoch 100/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7253 - val_loss: 0.5271 - val_accuracy: 0.7349\n",
      "Epoch 101/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7250 - val_loss: 0.5255 - val_accuracy: 0.7331\n",
      "Epoch 102/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7248 - val_loss: 0.5261 - val_accuracy: 0.7343\n",
      "Epoch 103/200\n",
      "430/453 [===========================>..] - ETA: 0s - loss: 0.5340 - accuracy: 0.7235INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5344 - accuracy: 0.7236 - val_loss: 0.5334 - val_accuracy: 0.7412\n",
      "Epoch 104/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7222 - val_loss: 0.5273 - val_accuracy: 0.7343\n",
      "Epoch 105/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7246 - val_loss: 0.5332 - val_accuracy: 0.7381\n",
      "Epoch 106/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7258 - val_loss: 0.5272 - val_accuracy: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7236 - val_loss: 0.5286 - val_accuracy: 0.7306\n",
      "Epoch 108/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7260 - val_loss: 0.5267 - val_accuracy: 0.7349\n",
      "Epoch 109/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7250 - val_loss: 0.5272 - val_accuracy: 0.7356\n",
      "Epoch 110/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7261 - val_loss: 0.5267 - val_accuracy: 0.7349\n",
      "Epoch 111/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7246 - val_loss: 0.5251 - val_accuracy: 0.7356\n",
      "Epoch 112/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7247 - val_loss: 0.5264 - val_accuracy: 0.7356\n",
      "Epoch 113/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7243 - val_loss: 0.5278 - val_accuracy: 0.7362\n",
      "Epoch 114/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7248 - val_loss: 0.5283 - val_accuracy: 0.7393\n",
      "Epoch 115/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7277 - val_loss: 0.5272 - val_accuracy: 0.7368\n",
      "Epoch 116/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7249 - val_loss: 0.5255 - val_accuracy: 0.7349\n",
      "Epoch 117/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7246 - val_loss: 0.5246 - val_accuracy: 0.7368\n",
      "Epoch 118/200\n",
      "421/453 [==========================>...] - ETA: 0s - loss: 0.5327 - accuracy: 0.7234INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5325 - accuracy: 0.7234 - val_loss: 0.5329 - val_accuracy: 0.7424\n",
      "Epoch 119/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7237 - val_loss: 0.5247 - val_accuracy: 0.7356\n",
      "Epoch 120/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7257 - val_loss: 0.5260 - val_accuracy: 0.7368\n",
      "Epoch 121/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7255 - val_loss: 0.5250 - val_accuracy: 0.7362\n",
      "Epoch 122/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7255 - val_loss: 0.5264 - val_accuracy: 0.7356\n",
      "Epoch 123/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7254 - val_loss: 0.5274 - val_accuracy: 0.7362\n",
      "Epoch 124/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7258 - val_loss: 0.5249 - val_accuracy: 0.7356\n",
      "Epoch 125/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7226 - val_loss: 0.5257 - val_accuracy: 0.7374\n",
      "Epoch 126/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.7268 - val_loss: 0.5260 - val_accuracy: 0.7306\n",
      "Epoch 127/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7256 - val_loss: 0.5251 - val_accuracy: 0.7356\n",
      "Epoch 128/200\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 0.5330 - accuracy: 0.7268 - val_loss: 0.5254 - val_accuracy: 0.7368\n",
      "Epoch 129/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7259 - val_loss: 0.5252 - val_accuracy: 0.7374\n",
      "Epoch 130/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7263 - val_loss: 0.5249 - val_accuracy: 0.7374\n",
      "Epoch 131/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7252 - val_loss: 0.5241 - val_accuracy: 0.7374\n",
      "Epoch 132/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7256 - val_loss: 0.5267 - val_accuracy: 0.7405\n",
      "Epoch 133/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7252 - val_loss: 0.5251 - val_accuracy: 0.7356\n",
      "Epoch 134/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7253 - val_loss: 0.5239 - val_accuracy: 0.7387\n",
      "Epoch 135/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7261 - val_loss: 0.5270 - val_accuracy: 0.7424\n",
      "Epoch 136/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7245 - val_loss: 0.5243 - val_accuracy: 0.7368\n",
      "Epoch 137/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7261 - val_loss: 0.5241 - val_accuracy: 0.7393\n",
      "Epoch 138/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7271 - val_loss: 0.5240 - val_accuracy: 0.7393\n",
      "Epoch 139/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7247 - val_loss: 0.5264 - val_accuracy: 0.7405\n",
      "Epoch 140/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7248 - val_loss: 0.5387 - val_accuracy: 0.7399\n",
      "Epoch 141/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7241 - val_loss: 0.5296 - val_accuracy: 0.7424\n",
      "Epoch 142/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7255 - val_loss: 0.5244 - val_accuracy: 0.7381\n",
      "Epoch 143/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7245 - val_loss: 0.5260 - val_accuracy: 0.7412\n",
      "Epoch 144/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7246 - val_loss: 0.5241 - val_accuracy: 0.7381\n",
      "Epoch 145/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7255 - val_loss: 0.5244 - val_accuracy: 0.7412\n",
      "Epoch 146/200\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5316 - accuracy: 0.7253 - val_loss: 0.5246 - val_accuracy: 0.7424\n",
      "Epoch 147/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7261 - val_loss: 0.5236 - val_accuracy: 0.7387\n",
      "Epoch 148/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7248 - val_loss: 0.5233 - val_accuracy: 0.7405\n",
      "Epoch 149/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7274 - val_loss: 0.5249 - val_accuracy: 0.7418\n",
      "Epoch 150/200\n",
      "430/453 [===========================>..] - ETA: 0s - loss: 0.5309 - accuracy: 0.7267INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5318 - accuracy: 0.7265 - val_loss: 0.5259 - val_accuracy: 0.7430\n",
      "Epoch 151/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7266 - val_loss: 0.5243 - val_accuracy: 0.7399\n",
      "Epoch 152/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7240 - val_loss: 0.5270 - val_accuracy: 0.7362\n",
      "Epoch 153/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7250 - val_loss: 0.5242 - val_accuracy: 0.7331\n",
      "Epoch 154/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7265 - val_loss: 0.5226 - val_accuracy: 0.7405\n",
      "Epoch 155/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7254 - val_loss: 0.5243 - val_accuracy: 0.7349\n",
      "Epoch 156/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7261 - val_loss: 0.5231 - val_accuracy: 0.7412\n",
      "Epoch 157/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7258 - val_loss: 0.5225 - val_accuracy: 0.7381\n",
      "Epoch 158/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7263 - val_loss: 0.5228 - val_accuracy: 0.7430\n",
      "Epoch 159/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7269 - val_loss: 0.5250 - val_accuracy: 0.7424\n",
      "Epoch 160/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7272 - val_loss: 0.5233 - val_accuracy: 0.7381\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7239 - val_loss: 0.5250 - val_accuracy: 0.7430\n",
      "Epoch 162/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7243 - val_loss: 0.5245 - val_accuracy: 0.7412\n",
      "Epoch 163/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7257 - val_loss: 0.5277 - val_accuracy: 0.7430\n",
      "Epoch 164/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7255 - val_loss: 0.5237 - val_accuracy: 0.7387\n",
      "Epoch 165/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7259 - val_loss: 0.5241 - val_accuracy: 0.7405\n",
      "Epoch 166/200\n",
      "443/453 [============================>.] - ETA: 0s - loss: 0.5313 - accuracy: 0.7250INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.7250 - val_loss: 0.5252 - val_accuracy: 0.7436\n",
      "Epoch 167/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7257 - val_loss: 0.5223 - val_accuracy: 0.7412\n",
      "Epoch 168/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7264 - val_loss: 0.5238 - val_accuracy: 0.7418\n",
      "Epoch 169/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7254 - val_loss: 0.5248 - val_accuracy: 0.7374\n",
      "Epoch 170/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7257 - val_loss: 0.5250 - val_accuracy: 0.7436\n",
      "Epoch 171/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7267 - val_loss: 0.5281 - val_accuracy: 0.7356\n",
      "Epoch 172/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7284 - val_loss: 0.5236 - val_accuracy: 0.7374\n",
      "Epoch 173/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7255 - val_loss: 0.5251 - val_accuracy: 0.7405\n",
      "Epoch 174/200\n",
      "439/453 [============================>.] - ETA: 0s - loss: 0.5315 - accuracy: 0.7250INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.7255 - val_loss: 0.5219 - val_accuracy: 0.7443\n",
      "Epoch 175/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7260 - val_loss: 0.5215 - val_accuracy: 0.7393\n",
      "Epoch 176/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7255 - val_loss: 0.5227 - val_accuracy: 0.7368\n",
      "Epoch 177/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7272 - val_loss: 0.5224 - val_accuracy: 0.7374\n",
      "Epoch 178/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7269 - val_loss: 0.5227 - val_accuracy: 0.7381\n",
      "Epoch 179/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7258 - val_loss: 0.5224 - val_accuracy: 0.7436\n",
      "Epoch 180/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7272 - val_loss: 0.5229 - val_accuracy: 0.7418\n",
      "Epoch 181/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7277 - val_loss: 0.5215 - val_accuracy: 0.7430\n",
      "Epoch 182/200\n",
      "446/453 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.7268INFO:tensorflow:Assets written to: MLP202.cv.5.best/assets\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 0.5299 - accuracy: 0.7267 - val_loss: 0.5271 - val_accuracy: 0.7467\n",
      "Epoch 183/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7268 - val_loss: 0.5225 - val_accuracy: 0.7418\n",
      "Epoch 184/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7252 - val_loss: 0.5217 - val_accuracy: 0.7449\n",
      "Epoch 185/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7259 - val_loss: 0.5224 - val_accuracy: 0.7343\n",
      "Epoch 186/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7264 - val_loss: 0.5214 - val_accuracy: 0.7393\n",
      "Epoch 187/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7257 - val_loss: 0.5243 - val_accuracy: 0.7374\n",
      "Epoch 188/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7268 - val_loss: 0.5232 - val_accuracy: 0.7412\n",
      "Epoch 189/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7266 - val_loss: 0.5229 - val_accuracy: 0.7436\n",
      "Epoch 190/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7247 - val_loss: 0.5227 - val_accuracy: 0.7412\n",
      "Epoch 191/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7275 - val_loss: 0.5216 - val_accuracy: 0.7424\n",
      "Epoch 192/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7253 - val_loss: 0.5223 - val_accuracy: 0.7399\n",
      "Epoch 193/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7259 - val_loss: 0.5223 - val_accuracy: 0.7374\n",
      "Epoch 194/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7235 - val_loss: 0.5229 - val_accuracy: 0.7399\n",
      "Epoch 195/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7273 - val_loss: 0.5231 - val_accuracy: 0.7449\n",
      "Epoch 196/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7249 - val_loss: 0.5213 - val_accuracy: 0.7418\n",
      "Epoch 197/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7292 - val_loss: 0.5212 - val_accuracy: 0.7449\n",
      "Epoch 198/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7263 - val_loss: 0.5223 - val_accuracy: 0.7424\n",
      "Epoch 199/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7266 - val_loss: 0.5297 - val_accuracy: 0.7412\n",
      "Epoch 200/200\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7277 - val_loss: 0.5239 - val_accuracy: 0.7430\n",
      "Fold 5, 200 epochs, 170 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gdxbn48e+c3dOPei8ucu/dgCHYBmMwHRLAtMRAAr8ACfeSXAiXECCJAyS0XIgTIAnFhA4hNNMcLAzY4IaNKy5yk2Srd526u78/RpZ7A4Fk5/08jx7pnN0zO7M7O+/MnNWuchwHIYQQQnQeV2dnQAghhPhPJ8FYCCGE6GQSjIUQQohOJsFYCCGE6GQSjIUQQohOJsFYCCGE6GQHDcZKqceVUpVKqRX7Wa6UUg8ppdYrpb5QSo3q+GwKIYQQR69DGRk/CUw5wPLTgb5tP9cAf/n62RJCCCH+cxw0GDuOMxeoPcAq5wIzHe1TIFUplddRGRRCCCGOdh3xnXEBsHWX16Vt7wkhhBDiEJjf5saUUtegp7Lx+/2ju3Xr1mFp27aNy3V0XI8mZemapCxdk5Sla5Ky7G3t2rXVjuNk7WtZRwTjMmDXqFrY9t5eHMd5DHgMYMyYMc6iRYs6YPNacXExEydO7LD0OpOUpWuSsnRNUpauScqyN6XU5v0t64huy+vAD9quqj4OaHAcZ1sHpCuEEEL8RzjoyFgp9RwwEchUSpUCdwBuAMdxHgFmAWcA64FW4MpvKrNCCCHE0eigwdhxnEsOstwBru+wHAkhhBD/Yb7VC7gOJh6PU1paSiQSOezPpqSksHr16m8gV9++rlIWn89HYWEhbre7s7MihBBHtS4VjEtLS0lKSqJnz54opQ7rs01NTSQlJX1DOft2dYWyOI5DTU0NpaWlFBUVdWpehBDiaNelrjuPRCJkZGQcdiAWHU8pRUZGxleapRBCCHF4ulQwBiQQdyFyLIQQ4tvR5YJxZwuFQp2dBSGEEP9hJBgLIYQQnUyC8X44jsNNN93EkCFDGDp0KC+88AIA27ZtY/z48YwYMYIhQ4bw0UcfYVkWV1xxRfu6Dz74YCfnXgghxJGkS11N3ZX885//ZOnSpSxbtozq6mrGjh3L+PHjefbZZznttNP45S9/iWVZtLa2snTpUsrKylixQj/yub6+vpNzL4QQ4kjSZYPxr99YyaryxkNe37IsDMM44DqD8pO54+zBh5Texx9/zCWXXIJhGOTk5DBhwgQWLlzI2LFjueqqq4jH45x33nmMGDGCXr16UVJSwk9/+lPOPPNMTj311EPOtxBCCCHT1Idp/PjxzJ07l4KCAq644gpmzpxJWloay5YtY+LEiTzyyCP86Ec/6uxsCiGEOIJ02ZHxoY5gd+joG2WceOKJPProo0ybNo3a2lrmzp3Lvffey+bNmyksLOTqq68mGo2yZMkSzjjjDDweD9/73vfo378/l19+eYflQwghxNGvywbjznb++eczf/58hg8fjlKKP/zhD+Tm5vLUU09x77334na7CYVCzJw5k7KyMq688kps2wbg7rvv7uTcCyGEOJJIMN5Dc3MzoG94ce+993LvvffutnzatGlMmzZtr88tWbLkW8mfEEKIo498ZyyEEEJ0MgnGQgghRCeTYCyEEEJ0MgnGQgghRCeTYCyEEEJ0MgnGQgghRCeTYCyEEEJ0MgnGnSSRSHR2FoQQQnQREoz34bzzzmP06NEMHjyYxx57DIB33nmHUaNGMXz4cCZNmgToG4RceeWVDB06lGHDhvHKK68AEAqF2tN6+eWXueKKKwC44oor+PGPf8yxxx7LzTffzIIFCxg3bhwjR47k+OOP58svvwT0Qy/+53/+hyFDhjBs2DAefvhhPvjgA84777z2dN9//33OP//8b2N3CCGE+IbJHbj24fHHHyc9PZ1wOMzYsWM599xzufrqq5k7dy5FRUXU1tYC8Nvf/paUlBSWL18OQF1d3UHTLi0tZd68eRiGQWNjIx999BGmaTJ79mxuvfVWXnnlFZ544gk2bdrE0qVLMU2T2tpa0tLSuO6666iqqiIrK4snnniCq6666hvdD0IIIb4dXTcYv30LbF9+yKv7rQQYBylO7lA4/Z6DpvXQQw/x6quvArB161Yee+wxxo8fT1FREQDp6ekAzJ49m+eff779c2lpaQdN+8ILL2x/1GNDQwPTpk1j3bp1KKWIx+MAFBcX85Of/ATTNHfb3ve//33+8Y9/cOWVVzJ//nxmzpx50O0JIYTo+rpuMO4kxcXFzJ49m/nz5xMIBJg4cSIjRoxgzZo1h5yGUqr970gkstuyYDDY/vevfvUrTjrpJF599VU2bdrExIkTD5julVdeydlnn43P5+PCCy9sD9ZCCCGObF23NT+EEeyuwh30CMWGhgbS0tIIBAKsWbOGTz/9lEgkwty5c9m4cWP7NHV6ejqTJ09mxowZ/PGPfwT0NHVaWho5OTmsXr2a/v378+qrr+43Xw0NDRQUFADw5JNPtr9/0kkn8eijj3LSSSe1T1Onp6eTn59Pfn4+06dPZ/bs2V+7rEIIIboGuYBrD1OmTCGRSDBw4EBuueUWjjvuOLKysnjsscf47ne/y/Dhw5k6dSoAt912G3V1dQwZMoThw4czZ84cAO655x7OOussjj/+ePLy8va7rZtvvpn//d//ZeTIkbtdXT1t2jS6d+/OsGHDGD58OM8++2z7sssuu4xu3boxcODAb2gPCCGE+LZ13ZFxJ/F6vbz99tv7XHb66afv9joUCvHUU0/ttd4FF1zABRdcsNf7u45+AcaNG8fatWvbX0+fPh0A0zR54IEHeOCBB/ZK4+OPP+bqq68+aDmEEEIcOSQYH0FGjx5NMBjk/vvv7+ysCCGE6EASjI8gixcv7uwsCCGE+AbId8ZCCCFEJ5NgLIQQQnQyCcZCCCFEJ5NgLIQQQnQyCcZCCCFEJ5Ng/DXs+nSmPW3atIkhQ4Z8i7kRQghxpJJgLIQQQnQyCca7uOWWW5gxY0b76zvvvJPp06czadIkRo0axdChQ3nttdcOO91IJNL+3OORI0e23zZz5cqVHHPMMYwYMYJhw4axbt06WlpauOCCCxg+fDhDhgzhhRde6LDyCSGE6Jq67E0/fr/g96ypPfQnJVmW1f5owv0ZkD6AXxzzi/0unzp1Kv/93//N9ddfD8CLL77Iu+++yw033EBycjLV1dUcd9xxnHPOObs9melgZsyYgVKK5cuXs2bNGk499VTWrl3LI488wn/9139x2WWXEYvFsCyLWbNmkZeXx7vvvgvoh0kIIYQ4usnIeBcjR46ksrKS8vJyli1bRlpaGrm5udx6660MGzaMU045hbKyMioqKg4r3Y8//pjLL78cgAEDBtCjRw/Wrl3LuHHjuOuuu/j973/P5s2b8fv9DB06lDlz5vCLX/yCjz76iJSUlG+iqEIIIbqQLjsyPtAIdl+aOugRihdeeCEvv/wy27dvZ+rUqTzzzDNUVVWxePFi3G43PXv23OsZxV/VpZdeyrHHHstbb73FGWecwaOPPsrJJ5/M3Llz+eijj7jtttuYNGkSt99+e4dsTwghRNfUZYNxZ5k6dSpXX3011dXVfPjhh7z44otkZ2fjdruZM2cOmzdvPuw0TzzxRJ555hlOPvlk1q5dy5YtW+jfvz8lJSX06tWLG264gS1btvDFF18wYMAAAoEAl19+Oampqfztb3/7BkophBCiK5FgvIfBgwfT1NREQUEBeXl5XHbZZZx99tkMHTqUMWPGMGDAgMNO87rrruPaa69l6NChmKbJk08+idfr5cUXX+Tpp5/G7Xa3T4cvXLiQn//855imidvt5i9/+cs3UEohhBBdiQTjfVi+fHn735mZmcyfP3+f6zU3N+83jZ49e7JixQoAfD4fTzzxxF7r3HLLLdxyyy27vXfaaadx/PHHd8iUuxBCiCODXMAlhBBCdDIZGX9Ny5cv5/vf//5u73m9Xj777LNOypEQQogjzSEFY6XUFOD/AAP4m+M49+yxvDvwFJDats4tjuPM6uC8dklDhw5l6dKlnZ0NIYQQR7CDTlMrpQxgBnA6MAi4RCk1aI/VbgNedBxnJHAx8OeOzqgQQghxtDqU74yPAdY7jlPiOE4MeB44d491HCC57e8UoLzjsiiEEEIc3ZTjOAdeQakLgCmO4/yo7fX3gWMdx/nJLuvkAe8BaUAQOMVxnMX7SOsa4BqAnJyc0c8///xuy1NSUujTp89XKsih3A7zSNGVyrJ+/fqvdUvO5ubmAz7d6kgiZemapCxdk5RlbyeddNJix3HG7GtZR13AdQnwpOM49yulxgFPK6WGOI5j77qS4ziPAY8BjBkzxpk4ceJuiaxevfor/0tPR92BqyvoSmXx+XyMHDnyK3++uLiYPY/zkUrK0jVJWbomKcvhOZRp6jKg2y6vC9ve29UPgRcBHMeZD/iAzI7IYFd2tPT6hBBCdK5DCcYLgb5KqSKllAd9gdbre6yzBZgEoJQaiA7GVR2ZUbF/iUSis7MghBDiazjoNLXjOAml1E+Ad9H/tvS44zgrlVK/ARY5jvM68HPgr0qpG9EXc13hHOzL6IPYftddRFcf+iMUE5ZF7UG+Z/UOHEDurbfud/ktt9xCt27d2h+heOedd2KaJnPmzKGuro54PM706dM599w9r1/bW3NzM+eee+4+Pzdz5kzuu+8+lFIMGzaMp59+moqKCn784x9TUlKCbds8+uij5Ofnc9ZZZ7Xfyeu+++6jubmZO++8k4kTJzJixAg+/vhjLrnkEvr168f06dOJxWJkZGTwzDPPkJOTQ3NzMz/96U9ZtGgRSinuuOMOGhoa+OKLL/jjH/8IwF//+ldWrVrFgw8+eEj7WgghRMc6pO+M2/5neNYe792+y9+rgBM6Nmvfvo58nrHP5+PVV1/d63OrVq1i+vTpzJs3j8zMTGprawG44YYbmDBhAq+++ir19fUopairqzvgNmKxGIsWLQKgrq6OTz/9FKUUf/vb3/jDH/7A/fffz29/+1tSUlLab/FZV1eH2+3md7/7Hffeey9ut5snnniCRx999OvuPiGEEF9Rl70D14FGsPvSERc97fo846qqqvbnGd94443MnTsXl8vV/jzj3NzcA6blOA633nrrXp/74IMPuPDCC8nM1F+pp6enA/DBBx8wc+ZMAAzDICkp6aDBeOrUqe1/l5aWMnXqVLZt20YsFqOoqAiA2bNns+tV62lpaQCcfPLJvPnmmwwcOJB4PM7QoUMPc28JIYToKF02GHeWjnqecUc8B9k0TWx75wXpe34+GAy2//3Tn/6Un/3sZ5xzzjkUFxdz5513HjDtH/3oR9x1110MGDCAK6+88rDyJYQQomPJgyL2MHXqVJ5//nlefvllLrzwQhoaGr7S84z397mTTz6Zl156iZqaGoD2aepJkya1Py7RsiwaGhrIycmhsrKSmpoaotEob7755gG3V1BQAMBTTz3V/v7kyZOZMWNG++sdo+1jjz2WrVu38uyzz3LJJZcc6u4RQgjxDZBgvId9Pc940aJFDB06lJkzZx7y84z397nBgwfzy1/+kgkTJjB8+HB+9rOfAfB///d/zJkzh6FDhzJ+/HhWrVqF2+3m9ttv55hjjmHy5MkH3Padd97JhRdeyOjRo9unwAFuu+026urqGDJkCMOHD2fOnDntyy666CJOOOGE9qlrIYQQnUOmqfehI55nfKDPTZs2jWnTpu32Xk5ODq+99hqw+/ffN9xwAzfccMNeaRQXF+/2+txzz93nVd6hUGi3kfKuPv74Y2688cb9lkEIIcS3Q0bG/4Hq6+vp168ffr+fSZMmdXZ2hBDiP56MjL+mI/F5xqmpqaxdu7azsyGEEKKNBOOvSZ5nLIQQ4uvqctPUX/PGXaIDybEQ4j+DY1k4tr3/5baNY1n7XW41N5Oorj7kbe0qUVdH5YN/pOS736X+5ZdxHIdEXR2N77yDHY0ePL14/LDaqvDKlbQuXIjjODiOQ+uSJTQVF+9zWwfaJx2tS42MfT4fNTU1ZGRkHPQOV+Kb5TgONTU1+Hy+zs6K+IZZzc2EFy8meOKJKNe31z+3o1GqZ/wZIyWZ9Kuu+lbOeceyiJeX4y4sbN+e4zi0fvop9S+9RMr53yV04nf2zms4TGzzZnC5MFJSCC9dRvOcOXiKikif9gOUx0PrgoW4fF58w4cDEF68mJYFC4it34CRmkr6VVfiKSwkUVVFeMUKouvXE1u/geiGDTiWRep556Iy936+jmPbxMvK8HTr1p6X5g/nEhx3HK7kZBr+9Ro1jz6KcpuYWVmkXnIJSaecQvOHH1L10EOYGZn4RwwnXlpGePkXBI89jqyf/gRXcjLRNWuof/kVGl57DVcoRNKpp+LOzcWqr8M3aBBJU6YQLy2l9PqfoLxeuj/+d4xdbq5k1ddTO/Npap9+GjscJvOaa8j88f9DeTx778PWVrZP/x0Nr72Gt29ffP37ESstI7JqFU4kgqd7d7bd9itq//EMsY0bcaJRUi+eSt4+7pngxOM0vvMOjW/NouWTTzBzc0k6dTLKMIltLMGdX0DSlNPwDx/eXqftlhYq73+AumefBcBTVIQyTaLr1gHgCgQIjBuHt28fUIrWhQuxauvoPeutw6liX1mXCsaFhYWUlpZSVXX4z5iIRCKHHDiceBw7EsHl96PMw9sFO3p16iD3wXZiMb3ePirlPte3bZxYDOV2E43H9yqL4zhgWQfOr+NABzZoPp+PwsJCvW3Haa/Ue77+Jjm2vc/t7O/9g6b3FfPe8tkCkp7+B4nhwzH38a9gjmWRqKrCzMk5ojqS8cpKtl7z/4iuWUPKueeQN3060ZKNNM+ZQ+rUi/ZZ1kNhNTXR8MYbNPzrNcy0NJKmTCE0YTxmejqO4xBdu47y/72F6KrVAMQ2byH3tl8S374dOxzGSEvDTEtDud1A2wglkUB5PDixGOEVKwGHwKhR7dt0HAertpbY5s0kamqwG5vQt8rXElVV1L/8CvHSUoInnEDuHbcTWbmS2qf/QXjJEjAMGme9TfoVV6BMQ4+WmppxbAurukafX7twJSVhNzVR/8ILYJrEt2wBwNu/P9gW0XXrAXDn55OorqbuxRdx5+e3rwdg5uTg7d0bq6WZirvvIdPrpXL1atKvukrvq0SC8pt/QeOsWaRddhnpV0yj7L9vJLJyJcrnw9u7N5GVK/ENHYo7N4fI2rWU/fQGPEVFxDZuxNOzJ/FYOS0ffYSRmop3wADqnnuOhjfeQCmF1dCAcrtJOu007EiY+hde0G2XywW2jf/Jp4ht3oxj29jhMFuvvZbChx8muno1DW+8SeOsWTjRKEmTJ6N8Pqr//Gca3nyTlLPOwuM2aYxEsepqSdTW0jjrbWIlJaScey7xiu20zJuPu3t3Us8/n7RLL8HTqxd1zz9P3T+eIeX883Diceqff4HQ+AmgoPpPMzAzM/EOGEDjW28RLy3FzMsj9aKLiG3eTO1TM0EpPIWFNBd/SO1TT7UHabupmaZ//xu7qYm0H3wf36BB1L/4Eo6VIG/6bzFzcml6711aFy+hubgYHAff4MGETpqIE49/pXPgcKnOmoocM2aMs+O+yh3hQM+bdByHyIoVtMz/lJa5c2lt266Rnk7hnx7GXVBA66JFRNeuI7ZpE+6CAgJjRuNEIkQ3lGBHwpCwaFm4oL3x8PTqhX/YMLx9emOkZwBgh1uxampp/vBDIitXApA0eTLB8SfSPPvfRNbpi6bc2Tmk//AqkiZNQrlcxMvL2fKjq4mVlACQyMujz58exj94MK2ff07Vg38kvHQpTixGYNxx5Nx0E0ZKClZzC56inijDoPbJJ6ma8WdSzzuP7F/cjMvrPeD+surrCS9bhrt7d7xFRSSqqth2569xeb1k/exneAr1DUTilZWU3fBfWM1NFD78MGZaGmU//x+iG0souPdeAqNH67JHo1T/6U+0LlxE5k9+Qug7Jxz0uDS+8w41jz9Bzi2/IDBqFE4iQcv8+bjz8nDn51Pzt79T8+STpF92GVk/u7E9yLV8toCyn/+cpJNPJvfOO1AuV/s0Vftop216adeg2/zxJ1TcczfKMOn22KO4c3L23i/NLVh1tbuNnFrmzWPrtdfhRKN4evem+9/+ijsvT5e7tZW6Z5+l7vkXiJeWknLuOeTefjuuXe6OtqtEVRWNs2bhHzECf9sIagc7GiWyfDmtSz7HnZtD6KSTdhuF7BBevpzo+g0AGCkpePv0xpWUhFVbS3TdeloXLMCqr8PTqzfePr3x9umDY9k0vfsusc2b8Y8YwZqmRgakplL7xJMkampIPuN0Gl5+BXf37u3BwszLo+D++9oDXnjZMmr+9nfi27ZhNTTgCoUwUlOwW1qx6upwrATYDnZjI3ZrKwDeAQOwGhtIlG8DwNOnN3ZzC4nt2zFSUsi7+26d7qOPgmnCHk8gcyUno0wTq74ebBtXKISTSOC03Y0u8/rrWTlwAIPXrqXuH89gtd1EZ38CY8fiHz2K2plP47Tl0V1QQPoPryLlzDOpvO9+6l96CUyT4LHHYubp2966c/Pw9u4FSmHV1eEpKiIwZgytixZT9cc/okyT1KlTdUB78SVwKdIuuoik06ZghILEKyqoffwJYlu3Ehg9Gv/IkXj79tnt+EZWrWLV3XfjX7QY5fWSfOYZ2I1NNL3/PsHjj6dl3jxQCpffT/YtvyCyYiWtn31G2mWXkXb5Zfo8SCSoe+EFap94kuSzzyLz2mtxeTxYzc24AgGUy0Xky7VUP/IXXD4/gbFjCU2cgNl2W147HMaxLFx+Pw3/+heVDzyIkZJCt7/8mcjKlZT9/H/aOyUqECDlnLNJu/RSfP36AdBUXEzt3x/XbewescVdUEDeb39D8PjjD3iMdrBjMTZNvZhYSYk+93r2BCC2aRO+IUPIvP46QhMntp+ndmsryu1Gud1YTU00z5lD4zvv0vLxxyivl6STTyb14qkEDvJ8djsWg0QCVyDQ/l5HPc9YKbXYcZwx+1x2NAZju7WVlgUL8PXti/J42P6b39D0/mwAvH37kHzOOQRGj2Hbrbfqqacd+8A0dS9227advSGlUG2Bzdu/H8mnngaOTcuCBURXryGx5yheKbx9+5J68VTsxkaqH30MJxzGnZ+Pf8xolGESXrKE2ObNuLt1wzdoEOGlS7FbW8n79Z0kqqsp/8sjmOEwKeecQ/0rr2BmZ5M8ZQpGaio1jz+O3dCwc3NeL2ZmJvGyMnyDBhFZtQrvwIGEvvMdcGysxiasulqchAWOg9XUhFVdTWzLlvaRdNKpp9K6eDF2U5PuEVsWyadPwVPUi7rnnsNqasLl8eDYNkZqKolt2zCyMklUVJL6ve9hpCTT9O8PiJWUYGRmYlVXExh3HIGRIympraWH20Ns8yasmlqcWBTfkKHgODT8619gmiiPh/y77qLuH/9o7yjtaJi9AwcSXb2alPPPJ+XsswivWEnVQw/pzkhNDSnnnYe3T29qnngSJxbD26sXdjSqT2DLwkhLw+X341gJEuXbcHfrhlVTgys1hfy77sZITsKqrye6fj0tCxbQMvcjnFgMIysT38CBKJdBy/z5eHr2pGLiBNKfeRaX30/6FVfg6VVExe/uIl5aSuCYY/D260fds8/izs/H27evHlHV12M3NuHOy8NIT6fp/fdx2r6bCh4/DlcoiWjJBhKVVdiNjbtXJbebpNOnkPnjH+POyaF10SJqn5qpG+UDUIEAZno68bKy3RtEpTAzM3ers2ZODoUPP4R/2DDqXniR6kceIfX88wgccwzbbr+D+NateAcMwJ2TQ3NxMUZGBr5BgzCSk7FbWrDq63EFgxi7jGKN5CSMtDSC48bhGzYMQHeG582ndfEiXMEgwWOOITRpEu7sbAAa3niDyKrVumMRStKjqZoarNo6nEQCI12nb9XVo1wK/+jRNM8ppuHVV7GSkzEaGwmdfDLBY4/BU1SEkZGBkZKKcu2cpVBeL2aG7jjHSsuof/FFAqNHEfzOd3ab6YquW4eZlYWRmnrA/fxNKC4uZlz37tQ++RQNb7yBEw6TfdNNZPzwKpo+mEP9Cy+Q9fOftQe/b5odi6GUaj+2TR/MIbxsGYExowmMGnXATudnr7zC6IkTMdLSMdNSD3mWcFfRDRsove56ks44ffeORTB4yDNQdiSCcrn2v30rrn88gX0vR4LxYSkuLmbChAk0vvkWlffdR6KiQi8wTZTLReb115N6wffaT0YAq6GBmr8/jpGeRmDs2PbgbYfDRFauxBUM4ikqwnWA6W+roQGrqQkAl8+HkZq621RyorqaRE0N3n79do7aEgkaZ82i8d33iK1fD4ZBwYMP4OvfH4C5r71G9+eeJ7x0KUmnnkLerT/HyO2p06uro3HWLFxeL8rnJ7J8OdF1a0n53vdIPuMMmucUs/3Xv24fIbiSkzF2ORGMUBJGejrefn0JjBxJy7x51D7zLO68PAoefAAjKYmq/3uIlk8+0dOu+Xl0e+iPuIJBSm+4kURtLYUPP4S3Xz+2/+qXNP17Djhg5uWSe8v/EDhmLLXPvUzDK//UAd+2UX4/nu6FmNm5KMMgvHQpVn096T+8ivSLL2bLD68ktqUM5fOSc+P1KH8ykbXrSZ5yGv7Ro6me8Weq//Sn9n0aHH8iBfffT+1TM9vfD55wAu7u3YhtKEG5Dbw5IZTHjRV1YScUKPANGkTapZcSXbeOrdf8P6y2W5LuYOZkk3TyRDxFRYS/WEm0ZAM44M7LJe93v+PjZcs4LjOd7b+7i/DnywBwd+9G/q9uJtA7E5orafliLVXPvo1tGSjDjZGaiisUIl5eTry0lNDEiaRP+wEtn3xC7T+eweXz4enVqy1Yp+EbMAD/qFHENm2i8a1Z+oKWaFR//WDbGBkZZFx1FUmTT9GjtOoqoss+w66vxAh68eRl4hs6DJXWDdtMIbZyIdF3/4pTV0ZoynmYx3yPWHUzi977N2PP+y5mbu5+GzWrcit1Tz1Oy4oSoiUlpJ5zNhlnjcHILIDkAmjaDnWbILU7ZPTRHbk92RaUzIEV/4RABgy/BHIG7fd8orUWGsvAZYIywGWAcrVb9/4AACAASURBVOnftgXRJvAlQ1pPHMeh6ne3UfPm2xT+eCpJk06C2hKdr1AOBLMgEQE7DsmFkFKo/45HdMPrCerOSiIKzduhuQoyekN6LwjXQdkSqN0ADaWQ1R/6nwGB9L3z3FKt8+hP2/k1keNAS5XOr+nV22ws08uzB0O8BVa8AtXrIaUAApngWKzZWMaAc/4bgplYTU3E1q7AnxaDhq16PycX6O211oDbB6YPos0QbYRIPUQa9E88DP1Og96TdubJikPNBrAT4PbrcseawZsESXn6/eZKaK7QeTe9kFakl8fD+v26jbDtC9i6QB/vYRdD38lguHX6rbVgRcGXwpKFnzIqy9LHxPSCN1nv20AGVK2G6rV6/XirLldKt515zR4IucN0muFavV6kQefFnwZN23RebFunnT0Iuh8L21fAylf1en0n6/3aWq3TTinQx2PRExBrgQFnQuUqmH2nPt4Dz4ai8fpYtVTqfRVvhUtfkGB8OIqLixlaspHKP/wB3+DBZF53LfHybcQ2bybt0kvw9uq1c+VEDMo/b6vcebsnZCVg/WxY/QbkDoXRV+hKb1v6hFNKH9DlL+sDmFwA/lRdGQ0PuNz6hE3toSvRmjf1+v3PACsGxffokzy9FwR1Aw7A4POhxzjY8ikVi14nyxUmWrIVn3+7rp+FY3XlaSjTDURSPqQXgS8F3AHduDg2rJkF696DglEw4nKoXKlP+kjDLg2cqde14+BNxvLl4+o+CjVyqs7j6jehsRwr4uBqLUVtWwTKhdNrEk5KT1x1X0LFCn1C7EswC1IKsZWf+u1VpKkyVKJV75vU7jipPbDNNIzmEqhcTaIpRs2aEKm9W/Emt01Tmn7d6PpSoWAUYasXTn0FRnQLnnQ3yhMEHBqXbcPtbsYfrNINL0o3VLt8V4g3RTeyGX0gsy80V5JY8hbhzW0dFreNNyWB4bX1vlYGdDtGn8Cb50FjKbgDxB0Dd0J3vCLNISItqSTnVONiPw8ASe2h0ykYo4+1y9QNU9WXuhG0YjqY1WyAUDbkj9JlqC3RjYBjk6ipoW5dEMeBwMBuBAb0xFW9HML1ukGNNOjGb188SXqZbem6Xrdx9+XKpRutrAG68cserOvu+n/Dhn/rxhd0I5o/UtfbWNP+t+UJ6Abd8Oq/E9G2xrZFH4N4S1sgCOpAmJQLmf10HY6HdZ3a/sW+099Tr5MgOR+WPafrckfyJO1eTpep860Mvb8cB7yhnefvjvPAm6LrrBXXbcP+jsuuglk6uO5aX5WhOyyN23QgOVwut85zIgwZffU2wrW6Xlmxw09vT95k3R5FGqDsENpwX6ref7EWditnIFPXe9OnOzwtlV8/b6DbDiu6d70oGKPPgdYaXfd3LM8fBfkjYPkrEG2bdVQuff5m9oNLnqd47lwJxofqo+eeI+vuewieeCKFDz+087vCaBN8+Q5sLNavrbgOVuG2xxOmdNc9Zl+KbnxqNugD4g7qxiMpv60nt0Y3IFkDoGLl/hulHZTRdrD32L/eFN1ja9iqT8KkXN2wVq5sXyXizcCXN0hXhtTuuge6/OW2PIR0YGmq0L35PfnToM/knUFEGdBnku7h2glwrLaGxaVP2kg91G+FssV62Y68Jxfo18FM6HmiblhXv64rcmZ/yB2iOyuhXH2i7xgB7AgwjeUQD1Nf30DqgBN156OpXC+r3ajLntFbp5EzRAfK1hq9X8L1+hhEGvV6W+brbYBOx/TrYOYydMMfzNSB0xPQgSc5XwcPpfTIo2Y91KzTx7Zhq/58n0m6F5zaXe+Huo26TniCepsbPtBl6DFO5y/SQNnm9RT0H6Mb4vqtuvEI5ej6k1ygRxcuQweW8s+hdIEeQezZaUku0PXNZe4cVTZt059x+yG9t27UQdeB7uN0oFr8lK6T+SP1duOtuj5kD9RpeoK6/OFa3WmrWae3ccw1kNZTp7HlU0hEKFm3ml7d8nWwrFqj63SkXm/Tl6LrUN5wvZ3NH0PpIigcA31P09tt2KrLm9qjbbS0TNcRl6kbwlhLW4cqBbofB/1P18dz1b90HYg16wa4ei3EWnW5U3tAr4mQ1a+ts2jpH6ftt6stGFZ9CQv/rvf/MdfwqTOC44b21sctvZc+p1qq9Gu3X9f1hq16ZGq2jSbjrXpE6WrrnIZydD2qWqNHfimFOuBkDdDn//Zl8OXbum4qlx6JNleAP13vJ6XaOlFhnaYvRbct3rYOkeHVIzM7oUdvODDwHN2hTsR0YDNMFs1+lTG+zXp/pnbTdSF3qD5+DVt1gA5m6k5TIqY7b56Q3p6vrTNg+vR5uPJVWPqMHj36U/X5lj1YDy7iYX2+epL0udZYrgcToWwIZuvfsRZ9bONhnWYwU7cjyQU7Z0EqV8P25fp4uUzd/pheiDSyfMUKhp42DZLars1IRPWxb6nWMw3BPa4cT8T0vrXjeh9VrNADjUC63s++FN3uttbq/KX30nmOtUD5El2304r0CNeOw8a5epQbSNf7c82bumMy4Rd6f375tj4+A8/R5YlH9DH1BHWHw9w5rS0j40PkJBIsP+tsfPX19HrzDcyWtTDnLqjfok9AO6EPpunTf/eaoEeZjeW6kWmu1A1RMEufHH1O0Y3RlnnwyUNtU0uDdMCpXK3XGXs1ZA/QaUQb2753iOkK1VKlA4DbBwPO0pVozVu6ARg1TZ8Ye9r2ha7U3Y+jePnWvQ+84+h8BrN2ngixVl0R4y36hElEdT5Njx7hly7Y2TgdTEuNrqyGG/pN2fd0nG3rhtFwH/Kx6ZBKbNs6sISy9cn+dcRa9QnvPvx/2fpKZXEcfYJHGnWjnNpd14dOtldZHEd3CJq268b/MI5xp7DiOhB5kzqsoewKpCxd07cRjLvUvzZ9VXXPPod70yZy778f88tnYPavde+t+3G6d9lnMnQ7dt/faR1Ir4n650Ay+x5aWsdcfeDlecP0DwBb916u1M4e5g6etulpsvZe3zChx6FdtQhAMANGTzvwOi4XnXKfGJdL96Q7wgEu0vhGKKU7Q4fSIepMSukZheT8zs7JoTHcXb/DIMRhOCqCccp3z2fdpk0MKErAi7fDoHPhnD/tnOoTQgghurAudzvMr8IIhQiPPxG19TP93cz3/i6BWAghxBHjqAjG7bYt0xcWyfSVEEKII8jRE4wdWwfjvOEHX1cIIYToQo6aYOyLVOirmiUYCyGEOMIcNcE4qUnfq5e8EZ2bESGEEOIwHV3B2OXWN0AQQgghjiBHTTAONZfoQGwe+GlFQgghRFdzdARjx9Ej43yZohZCCHHkOTqCccNWfQN/uXhLCCHEEejoCMbb9OPs5OItIYQQR6KjIxh7gtSmjYScwZ2dEyGEEOKwHRX3pqb3yXwx3MVEt7+zcyKEEEIctqNjZCyEEEIcwSQYCyGEEJ1MgrEQQgjRySQYCyGEEJ1MgrEQQgjRySQYCyGEEJ1MgrEQQgjRySQYCyGEEJ1MgrEQQgjRySQYCyGEEJ1MgrEQQgjRySQYCyGEEJ1MgrEQQgjRySQYCyGEEJ3skIKxUmqKUupLpdR6pdQt+1nnIqXUKqXUSqXUsx2bTSGEEOLoddDnGSulDGAGMBkoBRYqpV53HGfVLuv0Bf4XOMFxnDqlVPY3leH9idvOt71JIYQQokMcysj4GGC94zgljuPEgOeBc/dY52pghuM4dQCO41R2bDYP7IWFW7jmvVZqmqPf5maFEEKIDnEowbgA2LrL69K293bVD+inlPpEKfWpUmpKR2XwUOSm+HGA9ZXN3+ZmhRBCiA6hHOfA07tKqQuAKY7j/Kjt9feBYx3H+cku67wJxIGLgEJgLjDUcZz6PdK6BrgGICcnZ/Tzzz/fIYWoCdv8/MMwPxjk4eTu7g5JszM1NzcTCoU6OxsdQsrSNUlZuiYpS9fUUWU56aSTFjuOM2Zfyw76nTFQBnTb5XVh23u7KgU+cxwnDmxUSq0F+gILd13JcZzHgMcAxowZ40ycOPGQCnAwjuPwy49n4UrNZ+LEwR2SZmcqLi6mo/ZNZ5OydE1Slq5JytI1fRtlOZRp6oVAX6VUkVLKA1wMvL7HOv8CJgIopTLR09YlHZjPA1JKkRdysa6y6dvapBBCCNFhDhqMHcdJAD8B3gVWAy86jrNSKfUbpdQ5bau9C9QopVYBc4CbHMep+aYyvS/5QRfrKuQ7YyGEEEeeQ5mmxnGcWcCsPd67fZe/HeBnbT+doiCk+KQ8SkNrnJTAkf+9sRBCiP8cR80duPJDuijrq2SqWgghxJHl6AvG8u9NQgghjjBHTTDO9Ct8bvneWAghxJHnqAnGLqXonRVinYyMhRBCHGGOmmAM0Dc7JNPUQgghjjhHVTDukx2irD5MczTR2VkRQgghDtlRE4wbEg2M7pEOwF+K13dyboQQQohDd1QE4xe/fJFfl/+aHjlRLhpTyJ+LNzBvQ3VnZ0sIIYQ4JEdFMB5fOB6AGUtncOc5gynKDHLDc59zyytf8MD7a1m4qRZLnncshBCiizqkO3B1dbnBXCYkTeCNDW/wg0E/YMalo7jln1/w7pbXiQY+Ysa8c0hWfemTHSIvxY/hUgDkpfgoygwypCCFvtkhXErRFEmgXOB3G7iNnX2VaMKiJWqRsGxCPpOA56jYdUIIIbqAoyaiTE6ezILIAn6/8Pec1essCgf8m5LSufhdHgK9ZjLS/QsaG5JYurUeBwfbhorGCIm2EbPXdGHZTvtrgPSgh8I0Pw3hOGWRZdiJJOxoLgBJSdUYBGluCZDidzMgL4keGUHSAx4CXgNDKRK2Q2ssgeNAst9NRtBDt/QAPrfBxupmGlrj5Kf6yQh5WVjxCZ9UvM20vjexodbC+bKSeMImNeAhyWdS1VrHvG3FDE6eiOO46Zbmp1dWiBS/vvXnlvpKZi5/mUndTqd3eh4N4TgVjVGSfCZ5qT4yg15cbZ2Q/dnxOE2ldl8vbsWJ23EC7gAA5c3lVLZWMiJ7RMccPCGOIGtq15AdyCbdl97ZWRFHkaMmGAeMANcMu4b7Ft3Hwu0L8Zt+bh57M5N7TObKd65kZfQ+zhl5DtMyh1EVrmJr01aGZ46kd+hY1m6LsrK8AVxhapzPyfB0J0QR2xsjlNa1olLmUms/h8LFsJRTaYzXs7H1U0yVygVpvyIWSWZB3Uss31ZJpLmAeHN/nFgWAIbLBuVgWcZ+8+7ylhHo+QjKFWfh7Coipd+HBTufPunybcVf8AwuTz3xpreIlF4O6PQCHgd/5nyioXdRRpRnVrxNePPV7ct38BguclK8WJZDfTiO13SREfLiMVzYjkNTJEFVU5SYZbflW+FSkOR3UPkzwBWmV+w2LFux0ftbEqqWrKab8Nk9SA96MFyK7Q0RGsJxvG4XIa9J76wQsYYYr2z7nKqmCI4DpqFI9XtIC7pJD3hI9ruJWTaRuE0kbrX/RBM2XtNF0GsS9JjtHZwdHKAhHKemOUosofPscxsk+90k+0yS/W6icZuqtuU+t4HP7cLn1unEbZt4wiFh27gNF5khLz63i4ZwnGjCxme62j5j4OCwrSHCyi9jbHJvJD3kJRq3iFk2PtMg6DXwe0wCHgO/28BruqhrjVPXGmPH48IbwjHqW+PkJPvonhEgGrepa40R9JpkJ3lRCsIxCwDT5cJwKUxD6d8uRUvUoqYliksp0gIevG4XccsmYTnELRuP6SIryUvIaxJPOCgXhDwmSkFrzKK1Le24ZVPfGmdjg8XI1jjJfpPKpih1rTF6ZgTxufdfT79Jdlsn+GAdxs5W0lDCJW9dQmGokGfOfIZkT3JnZ0kcJdSO0dC3bcyYMc6iRYs6LL3i4mLGTxjPyuqVZPgzyA5kY7p0X6OsuYzpn05n0fZFRKwIAH7TTzgRxm/66ZfWj0x/JvPK5xFOhAEYljWMYZnDaIw18vqG15ncYzI5gRyeX/M8PtPHRf0v4s0NbxK1oyS5kyhtLiXLn0VVuAqF4qRukyhM6sZbJa/Tkmjh1O5TyPP35rNtC2iJN3Naz9M5Pv84Pt++lsdW34OhXHwndwqvb57JSPcpTBo0hdroNhZVzGdl/QKS3ekcm30y75Q+z4l5pzI4+RQ21JQzr/Y5WuwKuvlGMyxzBG+V/p1x6VM5q/tVZCd5+bJ2Le+X/hPTyiMpdgJe00eK3000blHeUoZtBXErPyGvgddfjTIi+F1p+FQ6tqMorn2IsvgngCJkD8FNCnWujzEJ4lZJDHbuoKEVIlYzRvLnKHc9Beo0WsNB1lc2U9EQJj8tQE6yF6UUCcumPhynriVGfTgGrhYcKwio9mDpdxt4TBfRuE1LNEFLLMGeX/krdzUmSaT7k3XAdCASt2iMxInE7fb1vKarPa24qseb8wYAkfILwNFBsP0UcEXxZHyIy1NNrOZE7Miuj/G2MMxWrERSh9XZQ+NgJi3HTqRgh3sc9qcNlzrg9RJuQ+GEFuLJmEu88lzyvUNpNhcSC87BqT0Dwv3a190tTCr9VU7Qa+J3GwQ8BpbjEEvYxBJ2ewch6NXnYCRuo9q2ZxouTJfCbUKF8S8iUZPq0u8QjtskeU28bheg2jqMembIpXTHxFAKV9tvw6X/Lt9eQcwMUdcaw+c2CHoM/B6DkNdNTrKX1ICbysYoNS0xkn0mqQEPjuMQtx0Slk3CdvCaO+vejo6b1zSIJWyaogldD6NxFsfuoTaxgYQdo0dwBBOSf0FlY5yYpTuPKX432ck+Ql6DhO3o2TbLwXYcHAcc9LGIWw6NkTjxhIPP7cI0XCQsm7KtW5gwehC5KT5wIJKw2NYQob41TmbIQ3rQiwIStk1da5zGcJyA1ySlrROa5DOJJnTH1uc2CHlNInGbxnCcxkicpkgCt+Ei5NPHJZ6wMVx6X3vdLjyGgdftwmu6CMcsalpi+N0GRZlBknxme8euJZYgHLNoiSawbAeP6cJtuNp+65qyZMnnjBo1kn2FGMOlcBuu9s7mnq9RoNpqnNIvUUq118Ed/fLalhjVzTFsx8Ft6G2bLhceU//eUSfdhovUgBu/28ClFErpG0W1xhJUN0dpiVooBQGPQVbIR5LPxHL08fO5jQ57nrFSarHjOGP2uexoCsYH21kxK8aG+g3kBHNI9aayuGIx729+nw31GyhrLmN0zmgu7HchK2tW8vLal9nWso1wIsz5fc7ntuNuw3SZVIer8RpekjxJlDaVcvV7VwPwmxN+w9jcsWxv2c6LX77Is2ueJZwIM75gPKm+VN7d9C7hRJjcYC5ew8vmxs3t+Qq5Qzw55Un6pfXj5rk3886md9qXFYQKmFA4gWuHX0uqL5W/LPsLf1765/blfVL7cNPYmzg+/3gAbv/kdv61/l+MzhkNwKKKRXhcHmJ2jAxfBkUpRbQmWtnSuIXmeDOGMhiWNYzaSO1ueQqYAYpSilhZs5LrRlxHsieZexbcA8CVQ65kXN44rnn/GkbnjMZQBl9UfUHEiuBSLvymn0sHXErQHWRDyQbGDBqD3/RT0VJBbbSWoBkkbsd5b9N7bGzcSF4wj3F543AbbsKJMLazM5jajk1TrImGaCPdknrQP60/xaVzWFK5CL/p58xeZ5LmTaO0qRSlFOm+dHokF9EvZTgp3iD1sQrKW8rZ0rSFZ1Y/QzQRJeEk6J82gPsm3E+qL5mN9VuZvamY10peoi5aQ9AdoiXezHG5JzI2azyGy+DlDU9Q2ryVCQWncFb3y3CbitrodpZXf8HautVsby2nJdHEsLTxjE0/h16p3clNSsJ0mTg4+usGr8EnWz9n9uZicgN5jMoZyZraNSyomEeOrwcn5p7J2sYlvF/+PCnuLCZkX8Sn1W/xed1sXBhM63cTIzNO4MOyf2PZMDxtPIYBX9TPIRKP0dN7Io4dap/taIwksGybZJ+bgMcgarcStespSu3O6lVrSM7rxfzqN1jY9DdM5cFyEqSpYdQ6S3HhxiHBIP8FuJWfZquCFKM7GWZ/HGyidguO7SERD2DFkwjHnLbRvEXctY2Iq4yIXU840YJJiJCRT4BuuKxUEm2zEtuMl6j3vA/AEP/FjE29gMZIgmjCRimIxCyqW6I0ROuJUo3jKIxEIbYNdltDaTsQjbTSJz+TjKCn/dqOcEx3zCoa9WxNVpKXjKCXpmic+tYmlPLhMVztsxAxyyZiVxOJBIlbe1/XGvQYeFK/IJHxNJFt5wEufHn/JN44nFDTVPxmkGhcdzR3zNQcjKcteEQTukNgtnWcHBIosxUn0dGj7gRGsAQ7moOTSPkKn7cwk1bjOCZWc3/26J59TQ7KXYsTT+/gdA+XjTd7Fi5/KZHyC0g281h2x6kSjA9HR+2sPTmOs9d3qLuKWTFcytU+Ct+hJd5CzIqR5ksDoDnWTF20jsJQIQCfV37Ourp19ErtRf/0/u3TXXErzt/f+zvHjj6WTH8mhaHCvba/vm49DbEGFIphWcN223Y4Eeb3C37PxoaNhBNhTiw8kR8M+gFr69by9KqnaYw14jf9FIQK6JfWj20t2/i0/FOSvclM6j6J3GAula2VfFn7JUurltI3tS/TvzMdheJXn/yKrU1b+eupf8VjeHhw8YO89OVLFKUUMThzMOf3OZ+AO8Ddn93NJ+Wf7HN/mS6ThK1vyjI6ZzQn5J/A8urlLK5YjOky8Rk+XGpnY6iUIuQOEfKEWF+3nrpoHdmBbC4ZcAmbGzfz9sa3SdgJ8oJ5ANREatpnN/Y0Omc0d4y7g82Nm7npw5vaZ0l2XX7j6Bvpk9qHp1Y+xctrX6YqXAVAv7R+FCQK+DT86W7pe1weBqQPoEdyD5RSvLfpvd3Sdbvc+E0/PtOH4zjt6e0q2ZNMY6wRhcLBoVdKL6rD1TTGGgG4eujVrKhewfxt89s7Vju2rZQiakXbX/dO7U1FawUxK0ZuMJcMfwZul5u6SB2ra1djOzZ+00+6SsfxOJS3lDOhcAK/OeE33DHvDoq3FnPZwMu4dvi13DnvTmZvmQ3snEnalyRPEoPSB1ETqWFjw0Ysx9p5/NrKtEN2IJs+qX3wGB6KtxZzcf+LaYo38VbJW3yn4Dtsb9lO3I5TECrAciy+rP2S+mh9++fzgnkMyRxCdbia2kgt4USYWDRGj/QepPvSiSQiRK0oHsODz/DhNb34DT9ZgSzcLjdzts5hde1qkj3JDEgfQL+0fuQGc3ln4zusqFlBui+d03pMITdYALaB13TjNV0sqFhA8dZieqX04p5xfwXHxasbZ/Lk6kfICeQwJmcMq2tX4zN8DMkYRaYvl7gdJeHEiNsxvIaXvGAemf4sAqaflkQTa+pWsq5uHeUt5UStKAPTB1JdUcPK2Eqa4o30CPXn+NzJnFA4lgEZRSwo/4K1tSVk+XIpCHanR1o2OaFUmqNRtjZU8em2T1lVu5y8QCF9UvtR2lzK+obVeAwTv+lhYVUxtdFqPC4vZ/a4gL6pg4lYLVS0bmNr82ayfYWMyz4dkwAbGr6kNl5Gq11FfbSe2tYWNjYvo8Wq0+dD8kiOz5nM9shGTJfJhLyzyPQW6lkR20EBS5ctYcTwUW1HzsHBxqX0LFbMShBNxDCUh6ZYEy9veZBVDR/TOziaSdk/JtWT1/YxXXscR7fFrYl61rcswK18pHryyQ6mkR1KImB6AQ+ObejOXtvXN4ZL4TFcRBMW1a2NNEdbSTgJPCoJQ3nxtn29E/SY2I7NsyUPsLj2HQw8GMrk1Oz/4u4pl0owPhzfVDDuDF25LAfrnOzQHGvGcBl8NPcjhh4zlJZ4C9nBbJI9ycSsGDErRsgTOuxtl7eUk+3Pxm3oC9ciiQiGMtpfO47DpsZNLKlYguVYFIQKyA/lkx/Kx2t4/3979x4j11necfz77M1r79rru71y7PgaY4dL45iQooQ6IWqTCOwCbpWopUAhoRIRIEBVUEQU0f4TUFsJNSqkApUiWieEohoaFLckDhIoKUmwTeLExjG247u9Xme99o739vaPGW/H6931OGz8zi7fjzTyzDtnzzyP3znzO3Nm9uzAuna27+TZQ8+SUmL6xOlc33o9MyfOvODxdrbvpK3QxvWt1/PTp3/K1dddzc8O/oyWhhZmN81m2dRlNNQ2DPzMycJJnnztSU51n+JM7xkKvQW6erso9Bbo7u/mnXPeyS1X3sLRM0fZcmwLi1sWc83sa3j15Kv8cPcPWTZ1Gbcvup0zvWf4/s7vc9W0q3j3vHfT09/DN7Z+g47uDtYtXQcJfri7eMh93ZJ1NNQ28OiOR9nbsZe5TXNpqG3g0OlDtBfa6e3vZVL9JFbNXsW85nm8fOJltu3dxuLWxSxsWcjHrv4Y9bX19Kd+DnYe5IrJxR3G/tTPjhM7mDVpFjMaZ7CnYw8vHn9x4MjQmd4ztHW1sb1tO6+ceIUZE2ewfNpylk9fzvJpy5k9aTYT6yZy8uxJ9nTsYXvbdrYd28a+jn0cPnOYNfPX8KXrv0Rf6uP+n93P1mNbWdKyhIbaBg50HgDgLdPfwtKpS5nXPI+O7g427d3E3o69zJ40m5mNM2msa+TgoYMwGdrPtjOxbiINtQ1093Vztu8shd4CZ3rO0FZooy/18baZb+PGeTdyrOsYO07sYGf7Tgp9BRa1LGLtkrVsb9vO5tc209Pfc95zYdqEady84GbuevtdzGueNzC+9dhWHvj5A7QX2rl65tV0dney7fi2gR1OgJqoOe9oT/n4gskLmDd5HrVRy/a27XQUOrhl4S0snbqUTXs38cqJV0bcJgbv7AzeaWqZ0EINNXT2dHJd63V8YOkHePq1p/nR7h8N/FxN1NDa1MrBzoPF533Z+upr6pk6YSoTaiewdOpS1l+1nsOnD/O1X35tYMe+t7+Xnv4eVkxfQcuEFrr7uvnN67+h/Ww7dVFHXU0dZ/vOkkjU19RTV1M3UGNrUyu9/b20F9p5/5L3s2nvJs72nqW1uZUZjTM41X2Kk2dPMq1xGlMaprDt2DZ60/BnWJw6Ek4E1AAADaVJREFUYSrzJ88npcSJwomBHePTPacHdloBaqOWFdNXsGDKAupq6ujo7mD3yd3sO7WPu952F+uvWs/nN3+e1zpf48cf/DHP//x5w7hS1Rxgl8peqpO9VKdKeunr76Ort+uCHcC+/j6OdR1jzqQ5AzuZ3X3ddPV20dPfQ29/L739vcxtmnvB0a/hFHoLdPZ0Drwzr6+pp9Bb4ODpg7R1tVHoLdBY18jKGStpqm8672effOpJbr7p5oHbhzoPsfX4Vvaf2s+K6StYMnUJh08fZt+pfbQX2uno7qC+pp6m+iZWzVnFiukraOtqY0f7DhZMXsD8yfOH3Hk+0HmAzu5OmuqbmD1pdnHnrfPQQEi/dcZbWTJ1CbMmzTrvSNU5Hd0dHD9znCunXMnJsyd5bOdjvHD0Bc70nKEmaljUsoiuo13MWzCPnv4eJtROoDZqKfQV6OnvYXL9ZGqiht2v76a90M6nrvkU75j1Do6cPsIjOx5hf+d+2rramNIwhZYJLZwonOB413GunXMt71v8PmqiZuCjtkJvgUJfgUJvgSNnjrDv1D7qoo7pjdNprGskCCbVT2Ja4zSa65upjVoOdB7ghaMvcOT0kYGjRVdOuZIbrriB9cvWExEDOxXLpy+/LO+Mx823qSVpOLU1tUMeiamtqWVu09zzxhpqG8472nGpGusaaaxrvGBscctiFrcsHvFnBwdfa3Mrrc2t543NbZo74q8Vzpo0i1mTZo34OOXv7ssf66633zXiz50zpWHKwEdrMybO4JPv+OQFy2zevJk1q9ZUtL5z5jTN4dOrPl3RssumLbukdV+qhtoGlk9f/qY+RrlxcQYuSZLGMsNYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjIzjCVJyswwliQpM8NYkqTMDGNJkjKrKIwj4taI2BERuyLi3hGW+1BEpIhYPXolSpI0vl00jCOiFngIuA1YCdwZESuHWG4y8Bng2dEuUpKk8aySd8bXAbtSSrtTSt3ABmDdEMv9DfAgUBjF+iRJGvcqCeN5wGtlt/eXxgZExCpgfkrpv0axNkmSfidESmnkBSLWA7emlD5Ruv1h4F0ppXtKt2uAJ4GPppT2RMRm4AsppeeGWNfdwN0Ac+bMuXbDhg2j1khnZyfNzc2jtr6c7KU62Ut1spfqZC8Xuummm55PKQ39naqU0ogX4PeBJ8pufxH4YtntFuA4sKd0KQAHgdUjrffaa69No+mpp54a1fXlZC/VyV6qk71UJ3u5EPBcGiYTKzlM/QtgWUQsiogG4A5gY1mYv55SmplSWphSWgg8A6xNQ7wzliRJF7poGKeUeoF7gCeAl4FHU0ovRcSXI2Ltm12gJEnjXV0lC6WUHgceHzR2/zDLrvnty5Ik6XeHZ+CSJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwqCuOIuDUidkTEroi4d4j7PxcR2yNiW0T8JCKuHP1SJUkany4axhFRCzwE3AasBO6MiJWDFvslsDql9HbgMeAro12oJEnjVSXvjK8DdqWUdqeUuoENwLryBVJKT6WUzpRuPgNcMbplSpI0fkVKaeQFItYDt6aUPlG6/WHgXSmle4ZZ/h+Bwymlvx3ivruBuwHmzJlz7YYNG37L8v9fZ2cnzc3No7a+nOylOtlLdbKX6mQvF7rpppueTymtHuq+ut967WUi4s+B1cAfDHV/Sulh4GGA1atXpzVr1ozaY2/evJnRXF9O9lKd7KU62Ut1spdLU0kYHwDml92+ojR2noi4BbgP+IOU0tnRKU+SpPGvks+MfwEsi4hFEdEA3AFsLF8gIq4BvgGsTSkdHf0yJUkavy4aximlXuAe4AngZeDRlNJLEfHliFhbWuyrQDPwvYjYEhEbh1mdJEkapKLPjFNKjwOPDxq7v+z6LaNclyRJvzM8A5ckSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZkZxpIkZWYYS5KUmWEsSVJmhrEkSZlVFMYRcWtE7IiIXRFx7xD3T4iIR0r3PxsRC0e7UEmSxquLhnFE1AIPAbcBK4E7I2LloMU+DrSnlJYC/wA8ONqFSpI0XlXyzvg6YFdKaXdKqRvYAKwbtMw64Nul648B742IGL0yJUkavyoJ43nAa2W395fGhlwmpdQLvA7MGI0CJUka7+ou54NFxN3A3aWbnRGxYxRXPxM4Porry8leqpO9VCd7qU72cqErh7ujkjA+AMwvu31FaWyoZfZHRB3QArQNXlFK6WHg4Qoe85JFxHMppdVvxrovN3upTvZSneylOtnLpankMPUvgGURsSgiGoA7gI2DltkIfKR0fT3wZEopjV6ZkiSNXxd9Z5xS6o2Ie4AngFrgWymllyLiy8BzKaWNwDeB70TELuAExcCWJEkVqOgz45TS48Djg8buL7teAP5kdEu7ZG/K4e9M7KU62Ut1spfqZC+XIDyaLElSXp4OU5KkzMZFGF/sdJ3VLCLmR8RTEbE9Il6KiM+Uxh+IiAMRsaV0uT13rZWIiD0R8atSzc+VxqZHxH9HxK9L/07LXefFRMTysv/7LRHRERGfHSvzEhHfioijEfFi2diQ8xBFXyttP9siYlW+yi80TC9fjYhXSvX+ICKmlsYXRkRX2fx8PV/lFxqml2GfUxHxxdK87IiIP8pT9dCG6eWRsj72RMSW0ni1z8twr8OXb5tJKY3pC8Uvlb0KLAYagK3Aytx1XUL9rcCq0vXJwE6Kpx19APhC7vreQD97gJmDxr4C3Fu6fi/wYO46L7GnWuAwxd8RHBPzArwHWAW8eLF5AG4HfgwEcD3wbO76K+jlD4G60vUHy3pZWL5ctV2G6WXI51TpdWArMAFYVHqdq83dw0i9DLr/74D7x8i8DPc6fNm2mfHwzriS03VWrZTSoZTSC6Xrp4CXufAMZ2Nd+elSvw38ccZa3oj3Aq+mlPbmLqRSKaWfUvzNhnLDzcM64F9T0TPA1IhovTyVXtxQvaSUNqXi2f4AnqF4/oOqN8y8DGcdsCGldDal9BtgF8XXu6owUi+l0yH/KfDvl7WoN2iE1+HLts2MhzCu5HSdY0IU/9rVNcCzpaF7SodAvjUWDu2WJGBTRDwfxTOuAcxJKR0qXT8MzMlT2ht2B+e/qIzFeYHh52Gsb0N/SfFdyjmLIuKXEfF0RNyYq6hLNNRzaizPy43AkZTSr8vGxsS8DHodvmzbzHgI43EhIpqB7wOfTSl1AP8ELAF+DzhE8ZDPWHBDSmkVxb/y9amIeE/5nal4jGfMfIU/iie6WQt8rzQ0VuflPGNtHoYTEfcBvcB3S0OHgAUppWuAzwH/FhFTctVXoXHxnBrkTs7fgR0T8zLE6/CAN3ubGQ9hXMnpOqtaRNRTfAJ8N6X0HwAppSMppb6UUj/wz1TR4amRpJQOlP49CvyAYt1Hzh3CKf17NF+Fl+w24IWU0hEYu/NSMtw8jMltKCI+CrwP+LPSCyWlQ7ptpevPU/yc9apsRVZghOfUWJ2XOuCDwCPnxsbCvAz1Osxl3GbGQxhXcrrOqlX6bOWbwMsppb8vGy///OEDwIuDf7baRERTREw+d53il2xe5PzTpX4E+M88Fb4h5+3hj8V5KTPcPGwE/qL0DdHrgdfLDs1VpYi4FfhrYG1K6UzZ+Kwo/g12ImIxsAzYnafKyozwnNoI3BEREyJiEcVe/vdy1/cG3AK8klLaf26g2udluNdhLuc2k/tbbKNxofjNtp0U97buy13PJdZ+A8VDH9uALaXL7cB3gF+VxjcCrblrraCXxRS//bkVeOncXFD8c5o/AX4N/A8wPXetFfbTRPEPnrSUjY2JeaG4A3EI6KH4edbHh5sHit8Ifai0/fwKWJ27/gp62UXxM7tz28zXS8t+qPTc2wK8ALw/d/0V9DLscwq4rzQvO4Dbctd/sV5K4/8C/NWgZat9XoZ7Hb5s24xn4JIkKbPxcJhakqQxzTCWJCkzw1iSpMwMY0mSMjOMJUnKzDCWJCkzw1iSpMwMY0mSMvs/2tZpUYWeF9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 74.67%\n",
      "\n",
      "5-way Cross Validation mean 74.24% (+/- 0.34%)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Cross valiation\")\n",
    "do_cross_validation(X_train,y_train,model)  \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jN0K-1e2g4WN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E37va5UZg4WQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_201.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
