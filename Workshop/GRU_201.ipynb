{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "GRU_201.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# GRU 201\n",
        "* Operate on 16000 GenCode 34 seqs.\n",
        "* 5-way cross validation. Save best model per CV.\n",
        "* Report mean accuracy from final re-validation with best 5.\n",
        "* Use Adam with a learn rate decay schdule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh6XplUvC0j0",
        "outputId": "b6590aba-b8bd-4660-a184-2ce6a681eb8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
        "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
        "DATAPATH=\"\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    NC_FILENAME = DATAPATH+NC_FILENAME\n",
        "    PC_FILENAME = DATAPATH+PC_FILENAME\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATAPATH=\"\" \n",
        "\n",
        "EPOCHS=200\n",
        "SPLITS=5\n",
        "K=1\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=16\n",
        "FILENAME='GRU201'\n",
        "NEURONS=16"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def compile_model(model):\n",
        "    adam_default_learn_rate = 0.001\n",
        "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = adam_default_learn_rate*10,\n",
        "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
        "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE...\")\n",
        "    model.compile(loss=bc, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return model\n",
        "\n",
        "def build_model():\n",
        "    act=\"elu\"\n",
        "    embed_layer  = keras.layers.Embedding(mask_zero=True,\n",
        "        input_dim=VOCABULARY_SIZE, output_dim=EMBED_DIMEN)\n",
        "    rnn1_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(NEURONS, return_sequences=True, \n",
        "                         dropout=0.00, activation=act))\n",
        "    rnn2_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(NEURONS, dropout=0.00, return_sequences=False, activation=act)) \n",
        "    dense1_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
        "    dense2_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
        "    output_layer = keras.layers.Dense(1,  activation=\"sigmoid\",dtype=dt)\n",
        "    mlp = keras.models.Sequential()\n",
        "    mlp.add(embed_layer)\n",
        "    mlp.add(rnn1_layer)\n",
        "    mlp.add(rnn2_layer)\n",
        "    mlp.add(dense1_layer)\n",
        "    mlp.add(dense2_layer)\n",
        "    mlp.add(output_layer)\n",
        "    mlpc = compile_model(mlp)\n",
        "    return mlpc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "## Load and partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "# Assume file was preprocessed to contain one line per seq.\n",
        "# Prefer Pandas dataframe but df does not support append.\n",
        "# For conversion to tensor, must avoid python lists.\n",
        "def load_fasta(filename,label):\n",
        "    DEFLINE='>'\n",
        "    labels=[]\n",
        "    seqs=[]\n",
        "    lens=[]\n",
        "    nums=[]\n",
        "    num=0\n",
        "    with open (filename,'r') as infile:\n",
        "        for line in infile:\n",
        "            if line[0]!=DEFLINE:\n",
        "                seq=line.rstrip()\n",
        "                num += 1   # first seqnum is 1\n",
        "                seqlen=len(seq)\n",
        "                nums.append(num)\n",
        "                labels.append(label)\n",
        "                seqs.append(seq)\n",
        "                lens.append(seqlen)\n",
        "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
        "    df2=pd.DataFrame(labels,columns=['class'])\n",
        "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
        "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
        "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
        "    return df\n",
        "\n",
        "def separate_X_and_y(data):\n",
        "    y=   data[['class']].copy()\n",
        "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
        "    return (X,y)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRAaO9jP9Kcr"
      },
      "source": [
        "## Make K-mers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xcZ4Mr9Kcs"
      },
      "source": [
        "def make_kmer_table(K):\n",
        "    npad='N'*K\n",
        "    shorter_kmers=['']\n",
        "    for i in range(K):\n",
        "        longer_kmers=[]\n",
        "        for mer in shorter_kmers:\n",
        "            longer_kmers.append(mer+'A')\n",
        "            longer_kmers.append(mer+'C')\n",
        "            longer_kmers.append(mer+'G')\n",
        "            longer_kmers.append(mer+'T')\n",
        "        shorter_kmers = longer_kmers\n",
        "    all_kmers = shorter_kmers\n",
        "    kmer_dict = {}\n",
        "    kmer_dict[npad]=0\n",
        "    value=1\n",
        "    for mer in all_kmers:\n",
        "        kmer_dict[mer]=value\n",
        "        value += 1\n",
        "    return kmer_dict\n",
        "\n",
        "KMER_TABLE=make_kmer_table(K)\n",
        "\n",
        "def strings_to_vectors(data,uniform_len):\n",
        "    all_seqs=[]\n",
        "    for seq in data['sequence']:\n",
        "        i=0\n",
        "        seqlen=len(seq)\n",
        "        kmers=[]\n",
        "        while i < seqlen-K+1 -1:  # stop at minus one for spaced seed\n",
        "            #kmer=seq[i:i+2]+seq[i+3:i+5]    # SPACED SEED 2/1/2 for K=4\n",
        "            kmer=seq[i:i+K]  \n",
        "            i += 1\n",
        "            value=KMER_TABLE[kmer]\n",
        "            kmers.append(value)\n",
        "        pad_val=0\n",
        "        while i < uniform_len:\n",
        "            kmers.append(pad_val)\n",
        "            i += 1\n",
        "        all_seqs.append(kmers)\n",
        "    pd2d=pd.DataFrame(all_seqs)\n",
        "    return pd2d   # return 2D dataframe, uniform dimensions"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtA0xiV9Kcv"
      },
      "source": [
        "def make_kmers(MAXLEN,train_set):\n",
        "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
        "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
        "    # From pandas dataframe to numpy to list to numpy\n",
        "    num_seqs=len(X_train_kmers)\n",
        "    tmp_seqs=[]\n",
        "    for i in range(num_seqs):\n",
        "        kmer_sequence=X_train_kmers.iloc[i]\n",
        "        tmp_seqs.append(kmer_sequence)\n",
        "    X_train_kmers=np.array(tmp_seqs)\n",
        "    tmp_seqs=None\n",
        "    labels=y_train_all.to_numpy()\n",
        "    return (X_train_kmers,labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXyySyO9Kcz"
      },
      "source": [
        "def make_frequencies(Xin):\n",
        "    Xout=[]\n",
        "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
        "    for seq in Xin:\n",
        "        freqs =[0] * VOCABULARY_SIZE\n",
        "        total = 0\n",
        "        for kmerval in seq:\n",
        "            freqs[kmerval] += 1\n",
        "            total += 1\n",
        "        for c in range(VOCABULARY_SIZE):\n",
        "            freqs[c] = freqs[c]/total\n",
        "        Xout.append(freqs)\n",
        "    Xnum = np.asarray(Xout)\n",
        "    return (Xnum)\n",
        "def make_slice(data_set,min_len,max_len):\n",
        "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
        "    return slice"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "def do_cross_validation(X,y,given_model):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        fold += 1\n",
        "        X_train=X[train_index] # use iloc[] for dataframe\n",
        "        y_train=y[train_index]\n",
        "        X_valid=X[valid_index]\n",
        "        y_valid=y[valid_index]        \n",
        "        # Avoid continually improving the same model.\n",
        "        model = compile_model(keras.models.clone_model(given_model))\n",
        "        bestname=DATAPATH+FILENAME+\".cv.\"+str(fold)+\".best\"\n",
        "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
        "            filepath=bestname, save_best_only=True, \n",
        "            monitor='val_accuracy', mode='max')]   \n",
        "        print(\"FIT\")\n",
        "        start_time=time.time()\n",
        "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                callbacks=mycallbacks,\n",
        "                validation_data=(X_valid,y_valid) )\n",
        "        end_time=time.time()\n",
        "        elapsed_time=(end_time-start_time)                        \n",
        "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0,1)\n",
        "        plt.show()\n",
        "        best_model=keras.models.load_model(bestname)\n",
        "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
        "        cv_scores.append(scores[1] * 100)  \n",
        "    print()\n",
        "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Train on RNA lengths 200-1Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fNo6sn9KdH",
        "outputId": "3a52c8bc-cc4f-4a05-e10f-a1a14c6378d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "MINLEN=200\n",
        "MAXLEN=1000\n",
        "print(\"Load data from files.\")\n",
        "nc_seq=load_fasta(NC_FILENAME,0)\n",
        "pc_seq=load_fasta(PC_FILENAME,1)\n",
        "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "print(\"Ready: train_set\")\n",
        "#train_set\n",
        "print (\"Compile the model\")\n",
        "model=build_model()\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "model.save(DATAPATH+FILENAME+'.model')\n",
        "print (\"Data prep\")\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "print (\"Data reshape\")\n",
        "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
        "X_train=make_frequencies(X_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Ready: train_set\n",
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          80        \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 32)          3264      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 32)                4800      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 8,961\n",
            "Trainable params: 8,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.model/assets\n",
            "Data prep\n",
            "Data reshape\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "a5a2188f-c591-4c39-b78a-37edea86d362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"Cross valiation\")\n",
        "do_cross_validation(X_train,y_train,model)  \n",
        "print (\"Done\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross valiation\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "448/453 [============================>.] - ETA: 0s - loss: 0.6561 - accuracy: 0.6399INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.cv.1.best/assets\n",
            "453/453 [==============================] - 11s 25ms/step - loss: 0.6562 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6477 - val_accuracy: 0.6530\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6490 - val_accuracy: 0.6530\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6481 - val_accuracy: 0.6530\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6479 - val_accuracy: 0.6530\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6384 - val_loss: 0.6539 - val_accuracy: 0.6530\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6397 - val_loss: 0.6480 - val_accuracy: 0.6530\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6470 - val_accuracy: 0.6530\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6476 - val_accuracy: 0.6530\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6478 - val_accuracy: 0.6530\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6472 - val_accuracy: 0.6530\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6473 - val_accuracy: 0.6530\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6476 - val_accuracy: 0.6530\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6387 - val_loss: 0.6471 - val_accuracy: 0.6530\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6470 - val_accuracy: 0.6530\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6551 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6479 - val_accuracy: 0.6530\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6469 - val_accuracy: 0.6530\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6471 - val_accuracy: 0.6530\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6472 - val_accuracy: 0.6530\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6397 - val_loss: 0.6480 - val_accuracy: 0.6530\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6480 - val_accuracy: 0.6530\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6472 - val_accuracy: 0.6530\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6397 - val_loss: 0.6475 - val_accuracy: 0.6530\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6488 - val_accuracy: 0.6530\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6523 - val_accuracy: 0.6530\n",
            "Fold 1, 200 epochs, 682 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 65.30%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "450/453 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.6393INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.cv.2.best/assets\n",
            "453/453 [==============================] - 11s 23ms/step - loss: 0.6557 - accuracy: 0.6399 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6517 - val_accuracy: 0.6449\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6512 - val_accuracy: 0.6449\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6402 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6518 - val_accuracy: 0.6449\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6529 - val_accuracy: 0.6449\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6567 - val_accuracy: 0.6449\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6528 - val_accuracy: 0.6449\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6523 - val_accuracy: 0.6449\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6543 - val_accuracy: 0.6449\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6516 - val_accuracy: 0.6449\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6512 - val_accuracy: 0.6449\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6524 - val_accuracy: 0.6449\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6515 - val_accuracy: 0.6449\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6517 - val_accuracy: 0.6449\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6526 - val_accuracy: 0.6449\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6517 - val_accuracy: 0.6449\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6518 - val_accuracy: 0.6449\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6512 - val_accuracy: 0.6449\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6530 - val_accuracy: 0.6449\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6517 - val_accuracy: 0.6449\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Fold 2, 200 epochs, 682 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 64.49%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "453/453 [==============================] - ETA: 0s - loss: 0.6541 - accuracy: 0.6417INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.cv.3.best/assets\n",
            "453/453 [==============================] - 11s 24ms/step - loss: 0.6541 - accuracy: 0.6417 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6427 - val_loss: 0.6630 - val_accuracy: 0.6263\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6674 - val_accuracy: 0.6263\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6633 - val_accuracy: 0.6263\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6635 - val_accuracy: 0.6263\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6628 - val_accuracy: 0.6263\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6631 - val_accuracy: 0.6263\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6633 - val_accuracy: 0.6263\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6518 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6632 - val_accuracy: 0.6263\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6632 - val_accuracy: 0.6263\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6641 - val_accuracy: 0.6263\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6628 - val_accuracy: 0.6263\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6631 - val_accuracy: 0.6263\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6634 - val_accuracy: 0.6263\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6642 - val_accuracy: 0.6263\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6628 - val_accuracy: 0.6263\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6633 - val_accuracy: 0.6263\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6638 - val_accuracy: 0.6263\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6519 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6631 - val_accuracy: 0.6263\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6519 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6632 - val_accuracy: 0.6263\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6518 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6519 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6531 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6640 - val_accuracy: 0.6263\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6630 - val_accuracy: 0.6263\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6627 - val_accuracy: 0.6263\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6645 - val_accuracy: 0.6263\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6628 - val_accuracy: 0.6263\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Fold 3, 200 epochs, 690 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 62.63%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "449/453 [============================>.] - ETA: 0s - loss: 0.6549 - accuracy: 0.6410INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.cv.4.best/assets\n",
            "453/453 [==============================] - 11s 23ms/step - loss: 0.6548 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6555 - val_accuracy: 0.6394\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6556 - val_accuracy: 0.6394\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6553 - val_accuracy: 0.6394\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6595 - val_accuracy: 0.6394\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6549 - val_accuracy: 0.6394\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6552 - val_accuracy: 0.6394\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6412 - val_loss: 0.6563 - val_accuracy: 0.6394\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6405 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6552 - val_accuracy: 0.6394\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6550 - val_accuracy: 0.6394\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6562 - val_accuracy: 0.6394\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6412 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6412 - val_loss: 0.6550 - val_accuracy: 0.6394\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6549 - val_accuracy: 0.6394\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Fold 4, 200 epochs, 688 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 63.94%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "451/453 [============================>.] - ETA: 0s - loss: 0.6563 - accuracy: 0.6396INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU201.cv.5.best/assets\n",
            "453/453 [==============================] - 11s 25ms/step - loss: 0.6562 - accuracy: 0.6400 - val_loss: 0.6515 - val_accuracy: 0.6505\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6546 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6546 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6509 - val_accuracy: 0.6505\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6496 - val_accuracy: 0.6505\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6487 - val_accuracy: 0.6505\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6488 - val_accuracy: 0.6505\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6494 - val_accuracy: 0.6505\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6548 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6501 - val_accuracy: 0.6505\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6501 - val_accuracy: 0.6505\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6542 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6487 - val_accuracy: 0.6505\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6393 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6492 - val_accuracy: 0.6505\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6503 - val_accuracy: 0.6505\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6593 - val_accuracy: 0.6505\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6486 - val_accuracy: 0.6505\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Fold 5, 200 epochs, 697 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 65.05%\n",
            "\n",
            "5-way Cross Validation mean 64.28% (+/- 0.95%)\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN0K-1e2g4WN"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E37va5UZg4WQ"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}