{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP_216.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# MLP 216\n",
        "* Operate on 16000 GenCode 34 seqs.\n",
        "* 5-way cross validation. Save best model per CV.\n",
        "* Report mean accuracy from final re-validation with best 5.\n",
        "* Use Adam with a learn rate decay schdule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh6XplUvC0j0",
        "outputId": "ce1da351-e82b-4bdf-e7eb-a12deaf7c4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
        "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
        "DATAPATH=\"\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    NC_FILENAME = DATAPATH+NC_FILENAME\n",
        "    PC_FILENAME = DATAPATH+PC_FILENAME\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATAPATH=\"\" \n",
        "\n",
        "EPOCHS=200\n",
        "SPLITS=5\n",
        "K=5\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=16\n",
        "FILENAME='MLP216'\n",
        "NEURONS=16  # with 50% dropout"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def compile_model(model):\n",
        "    adam_default_learn_rate = 0.001\n",
        "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = adam_default_learn_rate*10,\n",
        "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
        "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE...\")\n",
        "    model.compile(loss=bc, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return model\n",
        "\n",
        "def build_model(maxlen):\n",
        "    act=\"elu\"\n",
        "    embed_layer  = keras.layers.Embedding(\n",
        "        input_dim=VOCABULARY_SIZE, output_dim=EMBED_DIMEN)\n",
        "    dense1_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt,\n",
        "                    input_dim=[maxlen,EMBED_DIMEN])  # match embed output\n",
        "    drop1_layer = keras.layers.Dropout(0.5)\n",
        "    dense2_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
        "    drop2_layer = keras.layers.Dropout(0.5)\n",
        "    #dense3_layer = keras.layers.Dense(NEURONS, activation=act,dtype=dt)\n",
        "    output_layer = keras.layers.Dense(1,  activation=\"sigmoid\",dtype=dt)\n",
        "    mlp = keras.models.Sequential()\n",
        "    mlp.add(embed_layer)\n",
        "    mlp.add(dense1_layer)\n",
        "    mlp.add(drop1_layer)\n",
        "    mlp.add(dense2_layer)\n",
        "    mlp.add(drop2_layer)\n",
        "    #mlp.add(dense3_layer)\n",
        "    mlp.add(output_layer)\n",
        "    mlpc = compile_model(mlp)\n",
        "    return mlpc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "## Load and partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "# Assume file was preprocessed to contain one line per seq.\n",
        "# Prefer Pandas dataframe but df does not support append.\n",
        "# For conversion to tensor, must avoid python lists.\n",
        "def load_fasta(filename,label):\n",
        "    DEFLINE='>'\n",
        "    labels=[]\n",
        "    seqs=[]\n",
        "    lens=[]\n",
        "    nums=[]\n",
        "    num=0\n",
        "    with open (filename,'r') as infile:\n",
        "        for line in infile:\n",
        "            if line[0]!=DEFLINE:\n",
        "                seq=line.rstrip()\n",
        "                num += 1   # first seqnum is 1\n",
        "                seqlen=len(seq)\n",
        "                nums.append(num)\n",
        "                labels.append(label)\n",
        "                seqs.append(seq)\n",
        "                lens.append(seqlen)\n",
        "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
        "    df2=pd.DataFrame(labels,columns=['class'])\n",
        "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
        "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
        "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
        "    return df\n",
        "\n",
        "def separate_X_and_y(data):\n",
        "    y=   data[['class']].copy()\n",
        "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
        "    return (X,y)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRAaO9jP9Kcr"
      },
      "source": [
        "## Make K-mers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xcZ4Mr9Kcs"
      },
      "source": [
        "def make_kmer_table(K):\n",
        "    npad='N'*K\n",
        "    shorter_kmers=['']\n",
        "    for i in range(K):\n",
        "        longer_kmers=[]\n",
        "        for mer in shorter_kmers:\n",
        "            longer_kmers.append(mer+'A')\n",
        "            longer_kmers.append(mer+'C')\n",
        "            longer_kmers.append(mer+'G')\n",
        "            longer_kmers.append(mer+'T')\n",
        "        shorter_kmers = longer_kmers\n",
        "    all_kmers = shorter_kmers\n",
        "    kmer_dict = {}\n",
        "    kmer_dict[npad]=0\n",
        "    value=1\n",
        "    for mer in all_kmers:\n",
        "        kmer_dict[mer]=value\n",
        "        value += 1\n",
        "    return kmer_dict\n",
        "\n",
        "KMER_TABLE=make_kmer_table(K)\n",
        "\n",
        "def strings_to_vectors(data,uniform_len):\n",
        "    all_seqs=[]\n",
        "    for seq in data['sequence']:\n",
        "        i=0\n",
        "        seqlen=len(seq)\n",
        "        kmers=[]\n",
        "        while i < seqlen-K+1 -1:  # stop at minus one for spaced seed\n",
        "            #kmer=seq[i:i+2]+seq[i+3:i+5]    # SPACED SEED 2/1/2 for K=4\n",
        "            kmer=seq[i:i+K]  \n",
        "            i += 1\n",
        "            value=KMER_TABLE[kmer]\n",
        "            kmers.append(value)\n",
        "        pad_val=0\n",
        "        while i < uniform_len:\n",
        "            kmers.append(pad_val)\n",
        "            i += 1\n",
        "        all_seqs.append(kmers)\n",
        "    pd2d=pd.DataFrame(all_seqs)\n",
        "    return pd2d   # return 2D dataframe, uniform dimensions"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtA0xiV9Kcv"
      },
      "source": [
        "def make_kmers(MAXLEN,train_set):\n",
        "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
        "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
        "    # From pandas dataframe to numpy to list to numpy\n",
        "    num_seqs=len(X_train_kmers)\n",
        "    tmp_seqs=[]\n",
        "    for i in range(num_seqs):\n",
        "        kmer_sequence=X_train_kmers.iloc[i]\n",
        "        tmp_seqs.append(kmer_sequence)\n",
        "    X_train_kmers=np.array(tmp_seqs)\n",
        "    tmp_seqs=None\n",
        "    labels=y_train_all.to_numpy()\n",
        "    return (X_train_kmers,labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXyySyO9Kcz"
      },
      "source": [
        "def make_frequencies(Xin):\n",
        "    Xout=[]\n",
        "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
        "    for seq in Xin:\n",
        "        freqs =[0] * VOCABULARY_SIZE\n",
        "        total = 0\n",
        "        for kmerval in seq:\n",
        "            freqs[kmerval] += 1\n",
        "            total += 1\n",
        "        for c in range(VOCABULARY_SIZE):\n",
        "            freqs[c] = freqs[c]/total\n",
        "        Xout.append(freqs)\n",
        "    Xnum = np.asarray(Xout)\n",
        "    return (Xnum)\n",
        "def make_slice(data_set,min_len,max_len):\n",
        "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
        "    return slice"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "def do_cross_validation(X,y,given_model):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        fold += 1\n",
        "        X_train=X[train_index] # use iloc[] for dataframe\n",
        "        y_train=y[train_index]\n",
        "        X_valid=X[valid_index]\n",
        "        y_valid=y[valid_index]        \n",
        "        # Avoid continually improving the same model.\n",
        "        model = compile_model(keras.models.clone_model(given_model))\n",
        "        bestname=DATAPATH+FILENAME+\".cv.\"+str(fold)+\".best\"\n",
        "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
        "            filepath=bestname, save_best_only=True, \n",
        "            monitor='val_accuracy', mode='max')]   \n",
        "        print(\"FIT\")\n",
        "        start_time=time.time()\n",
        "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                callbacks=mycallbacks,\n",
        "                validation_data=(X_valid,y_valid) )\n",
        "        end_time=time.time()\n",
        "        elapsed_time=(end_time-start_time)                        \n",
        "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0,1)\n",
        "        plt.show()\n",
        "        best_model=keras.models.load_model(bestname)\n",
        "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
        "        cv_scores.append(scores[1] * 100)  \n",
        "    print()\n",
        "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Train on RNA lengths 200-1Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fNo6sn9KdH",
        "outputId": "4fded7da-44e1-4c33-8c9a-000b0d9e8249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "MINLEN=200\n",
        "MAXLEN=1000\n",
        "print(\"Load data from files.\")\n",
        "nc_seq=load_fasta(NC_FILENAME,0)\n",
        "pc_seq=load_fasta(PC_FILENAME,1)\n",
        "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "print(\"Ready: train_set\")\n",
        "#train_set\n",
        "print (\"Compile the model\")\n",
        "model=build_model(MAXLEN)\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "model.save(DATAPATH+FILENAME+'.model')\n",
        "print (\"Data prep\")\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "print (\"Data reshape\")\n",
        "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
        "X_train=make_frequencies(X_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Ready: train_set\n",
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          16400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 16)          272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 16)          272       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, None, 1)           17        \n",
            "=================================================================\n",
            "Total params: 16,961\n",
            "Trainable params: 16,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.model/assets\n",
            "Data prep\n",
            "Data reshape\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "6a7e3b53-3603-4014-8350-1210954f1f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"Cross valiation\")\n",
        "do_cross_validation(X_train,y_train,model)  \n",
        "print (\"Done\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross valiation\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "449/453 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.6393INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.cv.1.best/assets\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 0.6561 - accuracy: 0.6395 - val_loss: 0.6503 - val_accuracy: 0.6530\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6542 - accuracy: 0.6396 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6471 - val_accuracy: 0.6530\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6478 - val_accuracy: 0.6530\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6544 - accuracy: 0.6396 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6483 - val_accuracy: 0.6530\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6469 - val_accuracy: 0.6530\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6547 - accuracy: 0.6396 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6474 - val_accuracy: 0.6530\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6545 - accuracy: 0.6395 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6469 - val_accuracy: 0.6530\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6470 - val_accuracy: 0.6530\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6396 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6476 - val_accuracy: 0.6530\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6471 - val_accuracy: 0.6530\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6478 - val_accuracy: 0.6530\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6480 - val_accuracy: 0.6530\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6492 - val_accuracy: 0.6530\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6396 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6484 - val_accuracy: 0.6530\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.6388 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6547 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6396 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6394 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6475 - val_accuracy: 0.6530\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6483 - val_accuracy: 0.6530\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6477 - val_accuracy: 0.6530\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6478 - val_accuracy: 0.6530\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6396 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6466 - val_accuracy: 0.6530\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6547 - accuracy: 0.6396 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6470 - val_accuracy: 0.6530\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6460 - val_accuracy: 0.6530\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6468 - val_accuracy: 0.6530\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6394 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6459 - val_accuracy: 0.6530\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6396 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6472 - val_accuracy: 0.6530\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6551 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6467 - val_accuracy: 0.6530\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6396 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6397 - val_loss: 0.6501 - val_accuracy: 0.6530\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6464 - val_accuracy: 0.6530\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6461 - val_accuracy: 0.6530\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6463 - val_accuracy: 0.6530\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6397 - val_loss: 0.6456 - val_accuracy: 0.6530\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6397 - val_loss: 0.6458 - val_accuracy: 0.6530\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6396 - val_loss: 0.6486 - val_accuracy: 0.6530\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6397 - val_loss: 0.6487 - val_accuracy: 0.6530\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6397 - val_loss: 0.6457 - val_accuracy: 0.6530\n",
            "Fold 1, 200 epochs, 604 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 65.30%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "452/453 [============================>.] - ETA: 0s - loss: 0.6554 - accuracy: 0.6407INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.cv.2.best/assets\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 0.6555 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6520 - val_accuracy: 0.6449\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6541 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6512 - val_accuracy: 0.6449\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6516 - val_accuracy: 0.6449\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6543 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6515 - val_accuracy: 0.6449\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6403 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6520 - val_accuracy: 0.6449\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6403 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6404 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6516 - val_accuracy: 0.6449\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6404 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6401 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6518 - val_accuracy: 0.6449\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6515 - val_accuracy: 0.6449\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 0.6540 - accuracy: 0.6404 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6513 - val_accuracy: 0.6449\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6404 - val_loss: 0.6510 - val_accuracy: 0.6449\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6516 - val_accuracy: 0.6449\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6405 - val_loss: 0.6520 - val_accuracy: 0.6449\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6518 - val_accuracy: 0.6449\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6524 - val_accuracy: 0.6449\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6403 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6406 - val_loss: 0.6509 - val_accuracy: 0.6449\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6449\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6403 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6449\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6406 - val_loss: 0.6514 - val_accuracy: 0.6449\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6506 - val_accuracy: 0.6449\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6505 - val_accuracy: 0.6449\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.6449\n",
            "Fold 2, 200 epochs, 607 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 64.49%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "447/453 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.6432INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.cv.3.best/assets\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 0.6548 - accuracy: 0.6426 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6423 - val_loss: 0.6639 - val_accuracy: 0.6263\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6426 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6425 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6425 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6421 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6633 - val_accuracy: 0.6263\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6638 - val_accuracy: 0.6263\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6640 - val_accuracy: 0.6263\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6527 - accuracy: 0.6421 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6526 - accuracy: 0.6423 - val_loss: 0.6669 - val_accuracy: 0.6263\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6642 - val_accuracy: 0.6263\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6423 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6637 - val_accuracy: 0.6263\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6426 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6633 - val_accuracy: 0.6263\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6525 - accuracy: 0.6421 - val_loss: 0.6642 - val_accuracy: 0.6263\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6628 - val_accuracy: 0.6263\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6637 - val_accuracy: 0.6263\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6425 - val_loss: 0.6641 - val_accuracy: 0.6263\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6624 - val_accuracy: 0.6263\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6636 - val_accuracy: 0.6263\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6638 - val_accuracy: 0.6263\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6634 - val_accuracy: 0.6263\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6425 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6634 - val_accuracy: 0.6263\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6424 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6519 - accuracy: 0.6427 - val_loss: 0.6627 - val_accuracy: 0.6263\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6426 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6419 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6426 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6519 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6426 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6626 - val_accuracy: 0.6263\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6426 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6621 - val_accuracy: 0.6263\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6426 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6618 - val_accuracy: 0.6263\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6615 - val_accuracy: 0.6263\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6526 - accuracy: 0.6427 - val_loss: 0.6632 - val_accuracy: 0.6263\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.6263\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6613 - val_accuracy: 0.6263\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6426 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.6263\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6616 - val_accuracy: 0.6263\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6524 - accuracy: 0.6423 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6520 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6612 - val_accuracy: 0.6263\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6525 - accuracy: 0.6427 - val_loss: 0.6614 - val_accuracy: 0.6263\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6625 - val_accuracy: 0.6263\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6619 - val_accuracy: 0.6263\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6427 - val_loss: 0.6620 - val_accuracy: 0.6263\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6426 - val_loss: 0.6611 - val_accuracy: 0.6263\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6610 - val_accuracy: 0.6263\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6427 - val_loss: 0.6617 - val_accuracy: 0.6263\n",
            "Fold 3, 200 epochs, 603 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 62.63%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "450/453 [============================>.] - ETA: 0s - loss: 0.6556 - accuracy: 0.6412INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.cv.4.best/assets\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 0.6558 - accuracy: 0.6408 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6555 - val_accuracy: 0.6394\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6552 - val_accuracy: 0.6394\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6566 - val_accuracy: 0.6394\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6550 - val_accuracy: 0.6394\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6561 - val_accuracy: 0.6394\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6576 - val_accuracy: 0.6394\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6405 - val_loss: 0.6550 - val_accuracy: 0.6394\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6411 - val_loss: 0.6562 - val_accuracy: 0.6394\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6535 - accuracy: 0.6410 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6547 - val_accuracy: 0.6394\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6545 - val_accuracy: 0.6394\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6551 - val_accuracy: 0.6394\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6410 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6412 - val_loss: 0.6617 - val_accuracy: 0.6394\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6547 - val_accuracy: 0.6394\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6389 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6564 - val_accuracy: 0.6394\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6408 - val_loss: 0.6547 - val_accuracy: 0.6394\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6548 - val_accuracy: 0.6394\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6412 - val_loss: 0.6544 - val_accuracy: 0.6394\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6549 - val_accuracy: 0.6394\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6549 - val_accuracy: 0.6394\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6550 - val_accuracy: 0.6394\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6541 - val_accuracy: 0.6394\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6408 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6411 - val_loss: 0.6555 - val_accuracy: 0.6394\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6527 - accuracy: 0.6412 - val_loss: 0.6546 - val_accuracy: 0.6394\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6528 - accuracy: 0.6412 - val_loss: 0.6540 - val_accuracy: 0.6394\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6547 - val_accuracy: 0.6394\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6539 - val_accuracy: 0.6394\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6543 - val_accuracy: 0.6394\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6405 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6529 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6531 - accuracy: 0.6412 - val_loss: 0.6542 - val_accuracy: 0.6394\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6412 - val_loss: 0.6562 - val_accuracy: 0.6394\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6412 - val_loss: 0.6538 - val_accuracy: 0.6394\n",
            "Fold 4, 200 epochs, 601 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 63.94%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "447/453 [============================>.] - ETA: 0s - loss: 0.6558 - accuracy: 0.6406INFO:tensorflow:Assets written to: /content/drive/My Drive/data/MLP216.cv.5.best/assets\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 0.6562 - accuracy: 0.6399 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 2/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6545 - accuracy: 0.6400 - val_loss: 0.6489 - val_accuracy: 0.6505\n",
            "Epoch 3/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 4/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 7/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 8/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6508 - val_accuracy: 0.6505\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6399 - val_loss: 0.6489 - val_accuracy: 0.6505\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 25/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.6399 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6484 - val_accuracy: 0.6505\n",
            "Epoch 30/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 31/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 32/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 33/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 34/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6397 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 37/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 39/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 41/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6492 - val_accuracy: 0.6505\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6486 - val_accuracy: 0.6505\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6489 - val_accuracy: 0.6505\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 48/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6546 - accuracy: 0.6399 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 50/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 52/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 54/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 55/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 58/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6542 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 68/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 70/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 76/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 78/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6488 - val_accuracy: 0.6505\n",
            "Epoch 79/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.6505\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6534 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6398 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 84/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 87/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6532 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6499 - val_accuracy: 0.6505\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6399 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6399 - val_loss: 0.6495 - val_accuracy: 0.6505\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6545 - accuracy: 0.6400 - val_loss: 0.6489 - val_accuracy: 0.6505\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 109/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6396 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 117/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6484 - val_accuracy: 0.6505\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6691 - val_accuracy: 0.6505\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6395 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 126/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6399 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 131/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6399 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 135/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6399 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6396 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6478 - val_accuracy: 0.6505\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6542 - accuracy: 0.6399 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.6505\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6547 - accuracy: 0.6397 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.6505\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.6400 - val_loss: 0.6477 - val_accuracy: 0.6505\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6539 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6479 - val_accuracy: 0.6505\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6505\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.6505\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6537 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6505\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6400 - val_loss: 0.6480 - val_accuracy: 0.6505\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 0.6552 - accuracy: 0.6399 - val_loss: 0.6484 - val_accuracy: 0.6505\n",
            "Fold 5, 200 epochs, 605 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 65.05%\n",
            "\n",
            "5-way Cross Validation mean 64.28% (+/- 0.95%)\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN0K-1e2g4WN"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E37va5UZg4WQ"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}