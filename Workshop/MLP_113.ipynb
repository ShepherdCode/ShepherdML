{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "MLP_113.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# MLP 113"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh6XplUvC0j0",
        "outputId": "debf52d4-3971-4ecb-c12f-dc29d801d445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "PATH='/content/drive/'\n",
        "drive.mount(PATH)\n",
        "DATAPATH=PATH+'My Drive/data/'\n",
        "PC_FILENAME = DATAPATH+'pcRNA.fasta'\n",
        "NC_FILENAME = DATAPATH+'ncRNA.fasta'\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)\n",
        "\n",
        "EPOCHS=200\n",
        "SPLITS=1\n",
        "K=3\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=16\n",
        "FILENAME='MLP113'"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "## Load and partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "# Assume file was preprocessed to contain one line per seq.\n",
        "# Prefer Pandas dataframe but df does not support append.\n",
        "# For conversion to tensor, must avoid python lists.\n",
        "def load_fasta(filename,label):\n",
        "    DEFLINE='>'\n",
        "    labels=[]\n",
        "    seqs=[]\n",
        "    lens=[]\n",
        "    nums=[]\n",
        "    num=0\n",
        "    with open (filename,'r') as infile:\n",
        "        for line in infile:\n",
        "            if line[0]!=DEFLINE:\n",
        "                seq=line.rstrip()\n",
        "                num += 1   # first seqnum is 1\n",
        "                seqlen=len(seq)\n",
        "                nums.append(num)\n",
        "                labels.append(label)\n",
        "                seqs.append(seq)\n",
        "                lens.append(seqlen)\n",
        "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
        "    df2=pd.DataFrame(labels,columns=['class'])\n",
        "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
        "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
        "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
        "    return df\n",
        "\n",
        "# Split into train/test stratified by sequence length.\n",
        "def sizebin(df):\n",
        "    return pd.cut(df[\"seqlen\"],\n",
        "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
        "                              labels=[0,1,2,3,4,5])\n",
        "def make_train_test(data):\n",
        "    bin_labels= sizebin(data)\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
        "    # split(x,y) expects that y is the labels. \n",
        "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
        "    for train_index,test_index in splitter.split(data,bin_labels):\n",
        "        train_set = data.iloc[train_index]\n",
        "        test_set = data.iloc[test_index]\n",
        "    return (train_set,test_set)\n",
        "\n",
        "def separate_X_and_y(data):\n",
        "    y=   data[['class']].copy()\n",
        "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
        "    return (X,y)\n",
        "\n",
        "def make_slice(data_set,min_len,max_len):\n",
        "    print(\"original \"+str(data_set.shape))\n",
        "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
        "    no_short=data_set.drop(too_short)\n",
        "    print(\"no short \"+str(no_short.shape))\n",
        "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
        "    no_long_no_short=no_short.drop(too_long)\n",
        "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
        "    return no_long_no_short\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRAaO9jP9Kcr"
      },
      "source": [
        "## Make K-mers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xcZ4Mr9Kcs"
      },
      "source": [
        "def make_kmer_table(K):\n",
        "    npad='N'*K\n",
        "    shorter_kmers=['']\n",
        "    for i in range(K):\n",
        "        longer_kmers=[]\n",
        "        for mer in shorter_kmers:\n",
        "            longer_kmers.append(mer+'A')\n",
        "            longer_kmers.append(mer+'C')\n",
        "            longer_kmers.append(mer+'G')\n",
        "            longer_kmers.append(mer+'T')\n",
        "        shorter_kmers = longer_kmers\n",
        "    all_kmers = shorter_kmers\n",
        "    kmer_dict = {}\n",
        "    kmer_dict[npad]=0\n",
        "    value=1\n",
        "    for mer in all_kmers:\n",
        "        kmer_dict[mer]=value\n",
        "        value += 1\n",
        "    return kmer_dict\n",
        "\n",
        "KMER_TABLE=make_kmer_table(K)\n",
        "\n",
        "def strings_to_vectors(data,uniform_len):\n",
        "    all_seqs=[]\n",
        "    for seq in data['sequence']:\n",
        "        i=0\n",
        "        seqlen=len(seq)\n",
        "        kmers=[]\n",
        "        while i < seqlen-K+1 -1:  # stop at minus one for spaced seed\n",
        "            #kmer=seq[i:i+2]+seq[i+3:i+5]    # SPACED SEED 2/1/2 for K=4\n",
        "            kmer=seq[i:i+K]  \n",
        "            i += 1\n",
        "            value=KMER_TABLE[kmer]\n",
        "            kmers.append(value)\n",
        "        pad_val=0\n",
        "        while i < uniform_len:\n",
        "            kmers.append(pad_val)\n",
        "            i += 1\n",
        "        all_seqs.append(kmers)\n",
        "    pd2d=pd.DataFrame(all_seqs)\n",
        "    return pd2d   # return 2D dataframe, uniform dimensions"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtA0xiV9Kcv"
      },
      "source": [
        "def make_kmers(MAXLEN,train_set):\n",
        "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
        "\n",
        "    # The returned values are Pandas dataframes.\n",
        "    # print(X_train_all.shape,y_train_all.shape)\n",
        "    # (X_train_all,y_train_all)\n",
        "    # y: Pandas dataframe to Python list.\n",
        "    # y_train_all=y_train_all.values.tolist()\n",
        "    # The sequences lengths are bounded but not uniform.\n",
        "    X_train_all\n",
        "    print(type(X_train_all))\n",
        "    print(X_train_all.shape)\n",
        "    print(X_train_all.iloc[0])\n",
        "    print(len(X_train_all.iloc[0]['sequence']))\n",
        "\n",
        "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
        "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
        "    # X: true 2D array (no more lists)\n",
        "    X_train_kmers.shape\n",
        "\n",
        "    print(\"transform...\")\n",
        "    # From pandas dataframe to numpy to list to numpy\n",
        "    print(type(X_train_kmers))\n",
        "    num_seqs=len(X_train_kmers)\n",
        "    tmp_seqs=[]\n",
        "    for i in range(num_seqs):\n",
        "        kmer_sequence=X_train_kmers.iloc[i]\n",
        "        tmp_seqs.append(kmer_sequence)\n",
        "    X_train_kmers=np.array(tmp_seqs)\n",
        "    tmp_seqs=None\n",
        "    print(type(X_train_kmers))\n",
        "    print(X_train_kmers)\n",
        "\n",
        "    labels=y_train_all.to_numpy()\n",
        "    return (X_train_kmers,labels)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXyySyO9Kcz"
      },
      "source": [
        "def make_frequencies(Xin):\n",
        "    # Input:  numpy X(numseq,seqlen)  list of vectors of kmerval where val0=NNN,val1=AAA,etc. \n",
        "    # Output: numpy X(numseq,65)    list of frequencies of 0,1,etc.\n",
        "    Xout=[]\n",
        "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
        "    for seq in Xin:\n",
        "        freqs =[0] * VOCABULARY_SIZE\n",
        "        total = 0\n",
        "        for kmerval in seq:\n",
        "            freqs[kmerval] += 1\n",
        "            total += 1\n",
        "        for c in range(VOCABULARY_SIZE):\n",
        "            freqs[c] = freqs[c]/total\n",
        "        Xout.append(freqs)\n",
        "    Xnum = np.asarray(Xout)\n",
        "    return (Xnum)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def build_model(maxlen,dimen):\n",
        "    act=\"sigmoid\"\n",
        "\n",
        "    embed_layer  = keras.layers.Embedding(\n",
        "        VOCABULARY_SIZE,EMBED_DIMEN,input_length=maxlen);\n",
        "    \n",
        "    neurons=16\n",
        "    dense1_layer = keras.layers.Dense(neurons, activation=act,dtype=dt,input_dim=VOCABULARY_SIZE)\n",
        "    dense2_layer = keras.layers.Dense(neurons, activation=act,dtype=dt)\n",
        "    dense3_layer = keras.layers.Dense(neurons, activation=act,dtype=dt)\n",
        "    output_layer = keras.layers.Dense(1,  activation=act,dtype=dt)\n",
        "\n",
        "    mlp = keras.models.Sequential()\n",
        "    #mlp.add(embed_layer)\n",
        "    mlp.add(dense1_layer)\n",
        "    mlp.add(dense2_layer)\n",
        "    #mlp.add(dense3_layer)\n",
        "    mlp.add(output_layer)\n",
        "    \n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE...\")\n",
        "    mlp.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return mlp"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
        "    model = None\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        X_train=X[train_index] # use iloc[] for dataframe\n",
        "        y_train=y[train_index]\n",
        "        X_valid=X[valid_index]\n",
        "        y_valid=y[valid_index]\n",
        "\n",
        "        print(\"BUILD MODEL\")\n",
        "        model=build_model(maxlen,dimen)\n",
        "\n",
        "        print(\"FIT\")\n",
        "        start_time=time.time()\n",
        "        # this is complaining about string to float\n",
        "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                validation_data=(X_valid,y_valid) )\n",
        "        end_time=time.time()\n",
        "        elapsed_time=(end_time-start_time)\n",
        "                        \n",
        "        fold += 1\n",
        "        print(\"Fold %d, %d epochs, %d sec\"%(fold,eps,elapsed_time))\n",
        "\n",
        "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0,1)\n",
        "        plt.show()\n",
        "\n",
        "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "        # What are the other metrics_names?\n",
        "        # Try this from Geron page 505:\n",
        "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
        "        cv_scores.append(scores[1] * 100)\n",
        "    print()\n",
        "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
        "    return model"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q-PEh7D9KdH"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fNo6sn9KdH",
        "outputId": "99d7bb9d-153a-47e2-8d9a-35e089d40266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "print(\"Load data from files.\")\n",
        "nc_seq=load_fasta(NC_FILENAME,0)\n",
        "pc_seq=load_fasta(PC_FILENAME,1)\n",
        "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "\n",
        "print(\"Put aside the test portion.\")\n",
        "(train_set,test_set)=make_train_test(all_seq)\n",
        "# Do this later when using the test data:\n",
        "# (X_test,y_test)=separate_X_and_y(test_set)\n",
        "\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "all_seq=None\n",
        "\n",
        "print(\"Ready: train_set\")\n",
        "train_set"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Put aside the test portion.\n",
            "Ready: train_set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seqnum</th>\n",
              "      <th>class</th>\n",
              "      <th>sequence</th>\n",
              "      <th>seqlen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>1281</td>\n",
              "      <td>0</td>\n",
              "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9088</th>\n",
              "      <td>9089</td>\n",
              "      <td>0</td>\n",
              "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6069</th>\n",
              "      <td>6070</td>\n",
              "      <td>1</td>\n",
              "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
              "      <td>592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18549</th>\n",
              "      <td>18550</td>\n",
              "      <td>1</td>\n",
              "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
              "      <td>945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15027</th>\n",
              "      <td>15028</td>\n",
              "      <td>1</td>\n",
              "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
              "      <td>4382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3386</th>\n",
              "      <td>3387</td>\n",
              "      <td>0</td>\n",
              "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6495</th>\n",
              "      <td>6496</td>\n",
              "      <td>0</td>\n",
              "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
              "      <td>562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6409</th>\n",
              "      <td>6410</td>\n",
              "      <td>1</td>\n",
              "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7640</th>\n",
              "      <td>7641</td>\n",
              "      <td>1</td>\n",
              "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
              "      <td>3156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14108</th>\n",
              "      <td>14109</td>\n",
              "      <td>0</td>\n",
              "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
              "      <td>466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30290 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       seqnum  class                                           sequence  seqlen\n",
              "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...     348\n",
              "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...     534\n",
              "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...     592\n",
              "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...     945\n",
              "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...    4382\n",
              "...       ...    ...                                                ...     ...\n",
              "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...     578\n",
              "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...     562\n",
              "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...     740\n",
              "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...    3156\n",
              "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...     466\n",
              "\n",
              "[30290 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Len 200-1Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "8c3014cc-fb6c-4f70-ad2a-dac93a7eac1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MINLEN=200\n",
        "MAXLEN=1000\n",
        "\n",
        "print (\"Compile the model\")\n",
        "model=build_model(MAXLEN,EMBED_DIMEN)\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "\n",
        "print(\"Working on full training set, slice by sequence length.\")\n",
        "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "\n",
        "print (\"Sequence to Kmer\")\n",
        "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
        "X_train\n",
        "X_train=make_frequencies(X_train)\n",
        "X_train\n",
        "print (\"Cross valiation\")\n",
        "model1 = do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
        "model1.save(FILENAME+'.short.model')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_288 (Dense)            (None, 16)                1056      \n",
            "_________________________________________________________________\n",
            "dense_289 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_291 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,345\n",
            "Trainable params: 1,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Working on full training set, slice by sequence length.\n",
            "Slice size range [200 - 1000)\n",
            "original (30290, 4)\n",
            "no short (30290, 4)\n",
            "no long, no short (8879, 4)\n",
            "Sequence to Kmer\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(8879, 1)\n",
            "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
            "Name: 1280, dtype: object\n",
            "348\n",
            "transform...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n",
            "[[12 46 54 ...  0  0  0]\n",
            " [ 9 36 14 ...  0  0  0]\n",
            " [34  7 28 ...  0  0  0]\n",
            " ...\n",
            " [37 19  9 ...  0  0  0]\n",
            " [57 36 15 ...  0  0  0]\n",
            " [33  3 12 ...  0  0  0]]\n",
            "Cross valiation\n",
            "BUILD MODEL\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5194 - val_loss: 0.6915 - val_accuracy: 0.4989\n",
            "Epoch 2/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5291 - val_loss: 0.6883 - val_accuracy: 0.5006\n",
            "Epoch 3/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.6144 - val_loss: 0.6804 - val_accuracy: 0.6284\n",
            "Epoch 4/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.6473 - val_loss: 0.6658 - val_accuracy: 0.6616\n",
            "Epoch 5/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6768 - val_loss: 0.6437 - val_accuracy: 0.6830\n",
            "Epoch 6/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6831 - val_loss: 0.6207 - val_accuracy: 0.6841\n",
            "Epoch 7/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6880 - val_loss: 0.6042 - val_accuracy: 0.6903\n",
            "Epoch 8/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6924 - val_loss: 0.5947 - val_accuracy: 0.6926\n",
            "Epoch 9/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.6965 - val_loss: 0.5884 - val_accuracy: 0.6965\n",
            "Epoch 10/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7014 - val_loss: 0.5851 - val_accuracy: 0.6909\n",
            "Epoch 11/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7015 - val_loss: 0.5817 - val_accuracy: 0.6937\n",
            "Epoch 12/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7053 - val_loss: 0.5775 - val_accuracy: 0.6988\n",
            "Epoch 13/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7083 - val_loss: 0.5751 - val_accuracy: 0.6988\n",
            "Epoch 14/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7107 - val_loss: 0.5741 - val_accuracy: 0.7021\n",
            "Epoch 15/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7128 - val_loss: 0.5706 - val_accuracy: 0.7033\n",
            "Epoch 16/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7148 - val_loss: 0.5678 - val_accuracy: 0.7055\n",
            "Epoch 17/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7139 - val_loss: 0.5689 - val_accuracy: 0.6999\n",
            "Epoch 18/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.7149 - val_loss: 0.5636 - val_accuracy: 0.7100\n",
            "Epoch 19/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7186 - val_loss: 0.5618 - val_accuracy: 0.7106\n",
            "Epoch 20/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7177 - val_loss: 0.5605 - val_accuracy: 0.7100\n",
            "Epoch 21/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7207 - val_loss: 0.5626 - val_accuracy: 0.7066\n",
            "Epoch 22/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7215 - val_loss: 0.5569 - val_accuracy: 0.7089\n",
            "Epoch 23/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7227 - val_loss: 0.5552 - val_accuracy: 0.7078\n",
            "Epoch 24/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7252 - val_loss: 0.5534 - val_accuracy: 0.7100\n",
            "Epoch 25/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7273 - val_loss: 0.5515 - val_accuracy: 0.7128\n",
            "Epoch 26/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7284 - val_loss: 0.5509 - val_accuracy: 0.7134\n",
            "Epoch 27/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7318 - val_loss: 0.5490 - val_accuracy: 0.7185\n",
            "Epoch 28/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7315 - val_loss: 0.5462 - val_accuracy: 0.7179\n",
            "Epoch 29/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7315 - val_loss: 0.5454 - val_accuracy: 0.7190\n",
            "Epoch 30/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7357 - val_loss: 0.5485 - val_accuracy: 0.7213\n",
            "Epoch 31/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7338 - val_loss: 0.5409 - val_accuracy: 0.7224\n",
            "Epoch 32/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7388 - val_loss: 0.5388 - val_accuracy: 0.7241\n",
            "Epoch 33/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7374 - val_loss: 0.5368 - val_accuracy: 0.7280\n",
            "Epoch 34/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7401 - val_loss: 0.5366 - val_accuracy: 0.7309\n",
            "Epoch 35/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7425 - val_loss: 0.5325 - val_accuracy: 0.7309\n",
            "Epoch 36/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7450 - val_loss: 0.5303 - val_accuracy: 0.7325\n",
            "Epoch 37/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7487 - val_loss: 0.5285 - val_accuracy: 0.7354\n",
            "Epoch 38/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7497 - val_loss: 0.5262 - val_accuracy: 0.7365\n",
            "Epoch 39/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7502 - val_loss: 0.5255 - val_accuracy: 0.7393\n",
            "Epoch 40/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7511 - val_loss: 0.5210 - val_accuracy: 0.7382\n",
            "Epoch 41/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7529 - val_loss: 0.5197 - val_accuracy: 0.7399\n",
            "Epoch 42/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7545 - val_loss: 0.5166 - val_accuracy: 0.7348\n",
            "Epoch 43/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7588 - val_loss: 0.5139 - val_accuracy: 0.7416\n",
            "Epoch 44/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7611 - val_loss: 0.5125 - val_accuracy: 0.7466\n",
            "Epoch 45/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7629 - val_loss: 0.5111 - val_accuracy: 0.7365\n",
            "Epoch 46/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7645 - val_loss: 0.5064 - val_accuracy: 0.7511\n",
            "Epoch 47/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7636 - val_loss: 0.5047 - val_accuracy: 0.7511\n",
            "Epoch 48/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7698 - val_loss: 0.5033 - val_accuracy: 0.7528\n",
            "Epoch 49/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7528\n",
            "Epoch 50/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7723 - val_loss: 0.4952 - val_accuracy: 0.7534\n",
            "Epoch 51/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7767 - val_loss: 0.4929 - val_accuracy: 0.7523\n",
            "Epoch 52/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7816 - val_loss: 0.4925 - val_accuracy: 0.7584\n",
            "Epoch 53/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7774 - val_loss: 0.4884 - val_accuracy: 0.7584\n",
            "Epoch 54/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7825 - val_loss: 0.4862 - val_accuracy: 0.7539\n",
            "Epoch 55/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7838 - val_loss: 0.4892 - val_accuracy: 0.7613\n",
            "Epoch 56/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7823 - val_loss: 0.4821 - val_accuracy: 0.7573\n",
            "Epoch 57/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7840 - val_loss: 0.4829 - val_accuracy: 0.7663\n",
            "Epoch 58/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7861 - val_loss: 0.4780 - val_accuracy: 0.7596\n",
            "Epoch 59/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7895 - val_loss: 0.4752 - val_accuracy: 0.7562\n",
            "Epoch 60/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7876 - val_loss: 0.4773 - val_accuracy: 0.7663\n",
            "Epoch 61/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7909 - val_loss: 0.4774 - val_accuracy: 0.7652\n",
            "Epoch 62/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7935 - val_loss: 0.4706 - val_accuracy: 0.7607\n",
            "Epoch 63/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7933 - val_loss: 0.4688 - val_accuracy: 0.7601\n",
            "Epoch 64/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7932 - val_loss: 0.4742 - val_accuracy: 0.7691\n",
            "Epoch 65/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7923 - val_loss: 0.4669 - val_accuracy: 0.7697\n",
            "Epoch 66/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7952 - val_loss: 0.4657 - val_accuracy: 0.7697\n",
            "Epoch 67/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7946 - val_loss: 0.4668 - val_accuracy: 0.7691\n",
            "Epoch 68/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7964 - val_loss: 0.4628 - val_accuracy: 0.7697\n",
            "Epoch 69/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7963 - val_loss: 0.4620 - val_accuracy: 0.7635\n",
            "Epoch 70/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7968 - val_loss: 0.4626 - val_accuracy: 0.7663\n",
            "Epoch 71/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7981 - val_loss: 0.4607 - val_accuracy: 0.7748\n",
            "Epoch 72/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7964 - val_loss: 0.4609 - val_accuracy: 0.7748\n",
            "Epoch 73/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8009 - val_loss: 0.4581 - val_accuracy: 0.7703\n",
            "Epoch 74/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7964 - val_loss: 0.4576 - val_accuracy: 0.7748\n",
            "Epoch 75/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7995 - val_loss: 0.4565 - val_accuracy: 0.7697\n",
            "Epoch 76/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8022 - val_loss: 0.4564 - val_accuracy: 0.7742\n",
            "Epoch 77/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8005 - val_loss: 0.4570 - val_accuracy: 0.7742\n",
            "Epoch 78/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8009 - val_loss: 0.4572 - val_accuracy: 0.7753\n",
            "Epoch 79/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7985 - val_loss: 0.4540 - val_accuracy: 0.7736\n",
            "Epoch 80/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8030 - val_loss: 0.4540 - val_accuracy: 0.7748\n",
            "Epoch 81/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8040 - val_loss: 0.4532 - val_accuracy: 0.7725\n",
            "Epoch 82/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8021 - val_loss: 0.4587 - val_accuracy: 0.7821\n",
            "Epoch 83/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8014 - val_loss: 0.4518 - val_accuracy: 0.7776\n",
            "Epoch 84/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8032 - val_loss: 0.4519 - val_accuracy: 0.7793\n",
            "Epoch 85/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8037 - val_loss: 0.4539 - val_accuracy: 0.7776\n",
            "Epoch 86/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8064 - val_loss: 0.4503 - val_accuracy: 0.7776\n",
            "Epoch 87/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8033 - val_loss: 0.4500 - val_accuracy: 0.7765\n",
            "Epoch 88/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8039 - val_loss: 0.4498 - val_accuracy: 0.7804\n",
            "Epoch 89/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8074 - val_loss: 0.4492 - val_accuracy: 0.7827\n",
            "Epoch 90/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8067 - val_loss: 0.4487 - val_accuracy: 0.7832\n",
            "Epoch 91/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8050 - val_loss: 0.4514 - val_accuracy: 0.7770\n",
            "Epoch 92/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8061 - val_loss: 0.4480 - val_accuracy: 0.7832\n",
            "Epoch 93/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8070 - val_loss: 0.4477 - val_accuracy: 0.7838\n",
            "Epoch 94/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8060 - val_loss: 0.4509 - val_accuracy: 0.7770\n",
            "Epoch 95/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8049 - val_loss: 0.4469 - val_accuracy: 0.7843\n",
            "Epoch 96/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8064 - val_loss: 0.4484 - val_accuracy: 0.7787\n",
            "Epoch 97/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8074 - val_loss: 0.4474 - val_accuracy: 0.7810\n",
            "Epoch 98/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8075 - val_loss: 0.4463 - val_accuracy: 0.7849\n",
            "Epoch 99/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8085 - val_loss: 0.4462 - val_accuracy: 0.7849\n",
            "Epoch 100/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8054 - val_loss: 0.4453 - val_accuracy: 0.7855\n",
            "Epoch 101/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8050 - val_loss: 0.4454 - val_accuracy: 0.7843\n",
            "Epoch 102/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8073 - val_loss: 0.4449 - val_accuracy: 0.7866\n",
            "Epoch 103/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8074 - val_loss: 0.4458 - val_accuracy: 0.7827\n",
            "Epoch 104/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8106 - val_loss: 0.4476 - val_accuracy: 0.7798\n",
            "Epoch 105/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8078 - val_loss: 0.4450 - val_accuracy: 0.7832\n",
            "Epoch 106/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8073 - val_loss: 0.4457 - val_accuracy: 0.7810\n",
            "Epoch 107/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8101 - val_loss: 0.4436 - val_accuracy: 0.7866\n",
            "Epoch 108/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8092 - val_loss: 0.4437 - val_accuracy: 0.7883\n",
            "Epoch 109/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8071 - val_loss: 0.4524 - val_accuracy: 0.7782\n",
            "Epoch 110/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8078 - val_loss: 0.4467 - val_accuracy: 0.7753\n",
            "Epoch 111/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8105 - val_loss: 0.4482 - val_accuracy: 0.7821\n",
            "Epoch 112/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8085 - val_loss: 0.4434 - val_accuracy: 0.7860\n",
            "Epoch 113/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8112 - val_loss: 0.4441 - val_accuracy: 0.7827\n",
            "Epoch 114/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4422 - val_accuracy: 0.7889\n",
            "Epoch 115/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8084 - val_loss: 0.4421 - val_accuracy: 0.7872\n",
            "Epoch 116/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8097 - val_loss: 0.4468 - val_accuracy: 0.7815\n",
            "Epoch 117/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8091 - val_loss: 0.4415 - val_accuracy: 0.7883\n",
            "Epoch 118/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8099 - val_loss: 0.4415 - val_accuracy: 0.7883\n",
            "Epoch 119/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8104 - val_loss: 0.4440 - val_accuracy: 0.7798\n",
            "Epoch 120/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8091 - val_loss: 0.4426 - val_accuracy: 0.7838\n",
            "Epoch 121/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8102 - val_loss: 0.4411 - val_accuracy: 0.7889\n",
            "Epoch 122/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.8101 - val_loss: 0.4407 - val_accuracy: 0.7889\n",
            "Epoch 123/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8088 - val_loss: 0.4404 - val_accuracy: 0.7905\n",
            "Epoch 124/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8136 - val_loss: 0.4433 - val_accuracy: 0.7843\n",
            "Epoch 125/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.8116 - val_loss: 0.4423 - val_accuracy: 0.7821\n",
            "Epoch 126/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8105 - val_loss: 0.4399 - val_accuracy: 0.7894\n",
            "Epoch 127/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8106 - val_loss: 0.4404 - val_accuracy: 0.7866\n",
            "Epoch 128/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8115 - val_loss: 0.4412 - val_accuracy: 0.7843\n",
            "Epoch 129/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8142 - val_loss: 0.4419 - val_accuracy: 0.7832\n",
            "Epoch 130/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8112 - val_loss: 0.4402 - val_accuracy: 0.7872\n",
            "Epoch 131/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8121 - val_loss: 0.4426 - val_accuracy: 0.7832\n",
            "Epoch 132/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8095 - val_loss: 0.4396 - val_accuracy: 0.7866\n",
            "Epoch 133/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8112 - val_loss: 0.4419 - val_accuracy: 0.7832\n",
            "Epoch 134/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8112 - val_loss: 0.4457 - val_accuracy: 0.7849\n",
            "Epoch 135/200\n",
            "222/222 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8113 - val_loss: 0.4393 - val_accuracy: 0.7917\n",
            "Epoch 136/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8128 - val_loss: 0.4386 - val_accuracy: 0.7905\n",
            "Epoch 137/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8128 - val_loss: 0.4398 - val_accuracy: 0.7860\n",
            "Epoch 138/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8118 - val_loss: 0.4433 - val_accuracy: 0.7827\n",
            "Epoch 139/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8123 - val_loss: 0.4424 - val_accuracy: 0.7827\n",
            "Epoch 140/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8149 - val_loss: 0.4393 - val_accuracy: 0.7866\n",
            "Epoch 141/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8095 - val_loss: 0.4387 - val_accuracy: 0.7866\n",
            "Epoch 142/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8128 - val_loss: 0.4390 - val_accuracy: 0.7877\n",
            "Epoch 143/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8112 - val_loss: 0.4388 - val_accuracy: 0.7866\n",
            "Epoch 144/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8119 - val_loss: 0.4379 - val_accuracy: 0.7922\n",
            "Epoch 145/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8113 - val_loss: 0.4447 - val_accuracy: 0.7855\n",
            "Epoch 146/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8146 - val_loss: 0.4398 - val_accuracy: 0.7843\n",
            "Epoch 147/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8160 - val_loss: 0.4393 - val_accuracy: 0.7860\n",
            "Epoch 148/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8144 - val_loss: 0.4388 - val_accuracy: 0.7855\n",
            "Epoch 149/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8121 - val_loss: 0.4376 - val_accuracy: 0.7883\n",
            "Epoch 150/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8123 - val_loss: 0.4373 - val_accuracy: 0.7900\n",
            "Epoch 151/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8128 - val_loss: 0.4380 - val_accuracy: 0.7872\n",
            "Epoch 152/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8122 - val_loss: 0.4381 - val_accuracy: 0.7877\n",
            "Epoch 153/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8112 - val_loss: 0.4372 - val_accuracy: 0.7866\n",
            "Epoch 154/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8122 - val_loss: 0.4372 - val_accuracy: 0.7866\n",
            "Epoch 155/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8105 - val_loss: 0.4371 - val_accuracy: 0.7866\n",
            "Epoch 156/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8115 - val_loss: 0.4366 - val_accuracy: 0.7911\n",
            "Epoch 157/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8118 - val_loss: 0.4406 - val_accuracy: 0.7883\n",
            "Epoch 158/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8112 - val_loss: 0.4365 - val_accuracy: 0.7917\n",
            "Epoch 159/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.4366 - val_accuracy: 0.7917\n",
            "Epoch 160/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8126 - val_loss: 0.4403 - val_accuracy: 0.7872\n",
            "Epoch 161/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8144 - val_loss: 0.4372 - val_accuracy: 0.7877\n",
            "Epoch 162/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8133 - val_loss: 0.4368 - val_accuracy: 0.7877\n",
            "Epoch 163/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8136 - val_loss: 0.4380 - val_accuracy: 0.7889\n",
            "Epoch 164/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8122 - val_loss: 0.4366 - val_accuracy: 0.7883\n",
            "Epoch 165/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8133 - val_loss: 0.4373 - val_accuracy: 0.7889\n",
            "Epoch 166/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8122 - val_loss: 0.4416 - val_accuracy: 0.7883\n",
            "Epoch 167/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8121 - val_loss: 0.4360 - val_accuracy: 0.7889\n",
            "Epoch 168/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8126 - val_loss: 0.4358 - val_accuracy: 0.7911\n",
            "Epoch 169/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8135 - val_loss: 0.4385 - val_accuracy: 0.7889\n",
            "Epoch 170/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8125 - val_loss: 0.4417 - val_accuracy: 0.7872\n",
            "Epoch 171/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8136 - val_loss: 0.4362 - val_accuracy: 0.7900\n",
            "Epoch 172/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8160 - val_loss: 0.4410 - val_accuracy: 0.7877\n",
            "Epoch 173/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8156 - val_loss: 0.4361 - val_accuracy: 0.7900\n",
            "Epoch 174/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8116 - val_loss: 0.4355 - val_accuracy: 0.7917\n",
            "Epoch 175/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8154 - val_loss: 0.4373 - val_accuracy: 0.7900\n",
            "Epoch 176/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8118 - val_loss: 0.4402 - val_accuracy: 0.7900\n",
            "Epoch 177/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8126 - val_loss: 0.4363 - val_accuracy: 0.7911\n",
            "Epoch 178/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8122 - val_loss: 0.4356 - val_accuracy: 0.7911\n",
            "Epoch 179/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8153 - val_loss: 0.4355 - val_accuracy: 0.7905\n",
            "Epoch 180/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8136 - val_loss: 0.4383 - val_accuracy: 0.7860\n",
            "Epoch 181/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8123 - val_loss: 0.4368 - val_accuracy: 0.7911\n",
            "Epoch 182/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8132 - val_loss: 0.4353 - val_accuracy: 0.7900\n",
            "Epoch 183/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8115 - val_loss: 0.4369 - val_accuracy: 0.7889\n",
            "Epoch 184/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8139 - val_loss: 0.4356 - val_accuracy: 0.7928\n",
            "Epoch 185/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8140 - val_loss: 0.4381 - val_accuracy: 0.7911\n",
            "Epoch 186/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8132 - val_loss: 0.4352 - val_accuracy: 0.7877\n",
            "Epoch 187/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8142 - val_loss: 0.4355 - val_accuracy: 0.7905\n",
            "Epoch 188/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8147 - val_loss: 0.4391 - val_accuracy: 0.7883\n",
            "Epoch 189/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8137 - val_loss: 0.4366 - val_accuracy: 0.7922\n",
            "Epoch 190/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8136 - val_loss: 0.4386 - val_accuracy: 0.7900\n",
            "Epoch 191/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8137 - val_loss: 0.4353 - val_accuracy: 0.7934\n",
            "Epoch 192/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8160 - val_loss: 0.4370 - val_accuracy: 0.7911\n",
            "Epoch 193/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8136 - val_loss: 0.4375 - val_accuracy: 0.7894\n",
            "Epoch 194/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8122 - val_loss: 0.4352 - val_accuracy: 0.7945\n",
            "Epoch 195/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8109 - val_loss: 0.4383 - val_accuracy: 0.7889\n",
            "Epoch 196/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8149 - val_loss: 0.4350 - val_accuracy: 0.7945\n",
            "Epoch 197/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8135 - val_loss: 0.4404 - val_accuracy: 0.7883\n",
            "Epoch 198/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8139 - val_loss: 0.4362 - val_accuracy: 0.7900\n",
            "Epoch 199/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8132 - val_loss: 0.4346 - val_accuracy: 0.7900\n",
            "Epoch 200/200\n",
            "222/222 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8160 - val_loss: 0.4373 - val_accuracy: 0.7900\n",
            "Fold 1, 200 epochs, 60 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 79.00%\n",
            "\n",
            "Validation core mean 79.00% (+/- 0.00%)\n",
            "INFO:tensorflow:Assets written to: MLP113.short.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC68X4zr9KdU"
      },
      "source": [
        "## Len 1Kb-2Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nm3oU3h9KdV",
        "outputId": "004b2a9a-31bd-4d2e-8638-505bed29ab08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MINLEN=1000\n",
        "MAXLEN=2000\n",
        "\n",
        "print (\"Compile the model\")\n",
        "model=build_model(MAXLEN,EMBED_DIMEN)\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "\n",
        "print(\"Working on full training set, slice by sequence length.\")\n",
        "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "\n",
        "print (\"Sequence to Kmer\")\n",
        "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
        "X_train\n",
        "X_train=make_frequencies(X_train)\n",
        "X_train\n",
        "print (\"Cross valiation\")\n",
        "model2 = do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
        "model2.save(FILENAME+'.medium.model')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_296 (Dense)            (None, 16)                1056      \n",
            "_________________________________________________________________\n",
            "dense_297 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_299 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,345\n",
            "Trainable params: 1,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Working on full training set, slice by sequence length.\n",
            "Slice size range [1000 - 2000)\n",
            "original (30290, 4)\n",
            "no short (9273, 4)\n",
            "no long, no short (3368, 4)\n",
            "Sequence to Kmer\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(3368, 1)\n",
            "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
            "Name: 12641, dtype: object\n",
            "1338\n",
            "transform...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n",
            "[[42 39 27 ...  0  0  0]\n",
            " [57 34  5 ...  0  0  0]\n",
            " [27 44 47 ...  0  0  0]\n",
            " ...\n",
            " [44 47 57 ...  0  0  0]\n",
            " [10 37 20 ...  0  0  0]\n",
            " [47 60 48 ...  0  0  0]]\n",
            "Cross valiation\n",
            "BUILD MODEL\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5698 - val_loss: 0.6714 - val_accuracy: 0.6039\n",
            "Epoch 2/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6221 - val_loss: 0.6709 - val_accuracy: 0.6039\n",
            "Epoch 3/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.6221 - val_loss: 0.6703 - val_accuracy: 0.6039\n",
            "Epoch 4/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6221 - val_loss: 0.6697 - val_accuracy: 0.6039\n",
            "Epoch 5/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6221 - val_loss: 0.6696 - val_accuracy: 0.6039\n",
            "Epoch 6/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6221 - val_loss: 0.6713 - val_accuracy: 0.6039\n",
            "Epoch 7/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6221 - val_loss: 0.6686 - val_accuracy: 0.6039\n",
            "Epoch 8/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6221 - val_loss: 0.6678 - val_accuracy: 0.6039\n",
            "Epoch 9/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6221 - val_loss: 0.6669 - val_accuracy: 0.6039\n",
            "Epoch 10/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6221 - val_loss: 0.6656 - val_accuracy: 0.6039\n",
            "Epoch 11/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6221 - val_loss: 0.6647 - val_accuracy: 0.6039\n",
            "Epoch 12/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6221 - val_loss: 0.6644 - val_accuracy: 0.6039\n",
            "Epoch 13/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6221 - val_loss: 0.6630 - val_accuracy: 0.6039\n",
            "Epoch 14/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6221 - val_loss: 0.6609 - val_accuracy: 0.6039\n",
            "Epoch 15/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6221 - val_loss: 0.6591 - val_accuracy: 0.6039\n",
            "Epoch 16/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6221 - val_loss: 0.6573 - val_accuracy: 0.6039\n",
            "Epoch 17/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6221 - val_loss: 0.6553 - val_accuracy: 0.6039\n",
            "Epoch 18/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6221 - val_loss: 0.6525 - val_accuracy: 0.6039\n",
            "Epoch 19/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6221 - val_loss: 0.6507 - val_accuracy: 0.6039\n",
            "Epoch 20/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6221 - val_loss: 0.6469 - val_accuracy: 0.6039\n",
            "Epoch 21/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6221 - val_loss: 0.6440 - val_accuracy: 0.6039\n",
            "Epoch 22/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6221 - val_loss: 0.6430 - val_accuracy: 0.6039\n",
            "Epoch 23/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6221 - val_loss: 0.6383 - val_accuracy: 0.6039\n",
            "Epoch 24/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6229 - val_loss: 0.6338 - val_accuracy: 0.6068\n",
            "Epoch 25/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6236 - val_loss: 0.6298 - val_accuracy: 0.6142\n",
            "Epoch 26/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6273 - val_loss: 0.6262 - val_accuracy: 0.6157\n",
            "Epoch 27/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6310 - val_loss: 0.6226 - val_accuracy: 0.6187\n",
            "Epoch 28/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6321 - val_loss: 0.6200 - val_accuracy: 0.6187\n",
            "Epoch 29/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.6370 - val_loss: 0.6158 - val_accuracy: 0.6217\n",
            "Epoch 30/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.6433 - val_loss: 0.6108 - val_accuracy: 0.6424\n",
            "Epoch 31/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6161 - accuracy: 0.6459 - val_loss: 0.6074 - val_accuracy: 0.6409\n",
            "Epoch 32/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6470 - val_loss: 0.6037 - val_accuracy: 0.6409\n",
            "Epoch 33/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.6555 - val_loss: 0.6006 - val_accuracy: 0.6513\n",
            "Epoch 34/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.6630 - val_loss: 0.5978 - val_accuracy: 0.6602\n",
            "Epoch 35/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6548 - val_loss: 0.5948 - val_accuracy: 0.6810\n",
            "Epoch 36/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6618 - val_loss: 0.5926 - val_accuracy: 0.6721\n",
            "Epoch 37/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6670 - val_loss: 0.5905 - val_accuracy: 0.6721\n",
            "Epoch 38/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6663 - val_loss: 0.5890 - val_accuracy: 0.6691\n",
            "Epoch 39/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6644 - val_loss: 0.5859 - val_accuracy: 0.6914\n",
            "Epoch 40/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.6663 - val_loss: 0.5838 - val_accuracy: 0.6973\n",
            "Epoch 41/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6707 - val_loss: 0.5843 - val_accuracy: 0.6706\n",
            "Epoch 42/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6704 - val_loss: 0.5807 - val_accuracy: 0.6899\n",
            "Epoch 43/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.6741 - val_loss: 0.5815 - val_accuracy: 0.6736\n",
            "Epoch 44/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6630 - val_loss: 0.5777 - val_accuracy: 0.7077\n",
            "Epoch 45/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5902 - accuracy: 0.6789 - val_loss: 0.5765 - val_accuracy: 0.6973\n",
            "Epoch 46/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6741 - val_loss: 0.5763 - val_accuracy: 0.6929\n",
            "Epoch 47/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6737 - val_loss: 0.5745 - val_accuracy: 0.6958\n",
            "Epoch 48/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6741 - val_loss: 0.5754 - val_accuracy: 0.6899\n",
            "Epoch 49/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.6741 - val_loss: 0.5719 - val_accuracy: 0.7047\n",
            "Epoch 50/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6763 - val_loss: 0.5712 - val_accuracy: 0.7003\n",
            "Epoch 51/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6797 - val_loss: 0.5703 - val_accuracy: 0.7003\n",
            "Epoch 52/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6830 - val_loss: 0.5707 - val_accuracy: 0.6944\n",
            "Epoch 53/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.6774 - val_loss: 0.5710 - val_accuracy: 0.6914\n",
            "Epoch 54/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6819 - val_loss: 0.5674 - val_accuracy: 0.7047\n",
            "Epoch 55/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.6771 - val_loss: 0.5699 - val_accuracy: 0.6929\n",
            "Epoch 56/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.6860 - val_loss: 0.5656 - val_accuracy: 0.7077\n",
            "Epoch 57/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6875 - val_loss: 0.5659 - val_accuracy: 0.6988\n",
            "Epoch 58/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.6830 - val_loss: 0.5638 - val_accuracy: 0.7122\n",
            "Epoch 59/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6778 - val_loss: 0.5656 - val_accuracy: 0.6973\n",
            "Epoch 60/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6871 - val_loss: 0.5634 - val_accuracy: 0.7018\n",
            "Epoch 61/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.6882 - val_loss: 0.5611 - val_accuracy: 0.7136\n",
            "Epoch 62/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.6893 - val_loss: 0.5602 - val_accuracy: 0.7181\n",
            "Epoch 63/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.6863 - val_loss: 0.5594 - val_accuracy: 0.7166\n",
            "Epoch 64/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.6934 - val_loss: 0.5592 - val_accuracy: 0.7107\n",
            "Epoch 65/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.6893 - val_loss: 0.5577 - val_accuracy: 0.7196\n",
            "Epoch 66/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.6938 - val_loss: 0.5590 - val_accuracy: 0.7047\n",
            "Epoch 67/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.6934 - val_loss: 0.5561 - val_accuracy: 0.7196\n",
            "Epoch 68/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7004 - val_loss: 0.5576 - val_accuracy: 0.7062\n",
            "Epoch 69/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6982 - val_loss: 0.5543 - val_accuracy: 0.7226\n",
            "Epoch 70/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6967 - val_loss: 0.5563 - val_accuracy: 0.7062\n",
            "Epoch 71/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.6986 - val_loss: 0.5549 - val_accuracy: 0.7092\n",
            "Epoch 72/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6997 - val_loss: 0.5517 - val_accuracy: 0.7226\n",
            "Epoch 73/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7030 - val_loss: 0.5543 - val_accuracy: 0.7077\n",
            "Epoch 74/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.6993 - val_loss: 0.5525 - val_accuracy: 0.7092\n",
            "Epoch 75/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7027 - val_loss: 0.5501 - val_accuracy: 0.7166\n",
            "Epoch 76/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7060 - val_loss: 0.5499 - val_accuracy: 0.7107\n",
            "Epoch 77/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7016 - val_loss: 0.5520 - val_accuracy: 0.7047\n",
            "Epoch 78/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7082 - val_loss: 0.5481 - val_accuracy: 0.7136\n",
            "Epoch 79/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7086 - val_loss: 0.5457 - val_accuracy: 0.7315\n",
            "Epoch 80/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7108 - val_loss: 0.5454 - val_accuracy: 0.7226\n",
            "Epoch 81/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7105 - val_loss: 0.5437 - val_accuracy: 0.7329\n",
            "Epoch 82/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7123 - val_loss: 0.5433 - val_accuracy: 0.7255\n",
            "Epoch 83/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7097 - val_loss: 0.5442 - val_accuracy: 0.7181\n",
            "Epoch 84/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7179 - val_loss: 0.5409 - val_accuracy: 0.7300\n",
            "Epoch 85/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7179 - val_loss: 0.5405 - val_accuracy: 0.7315\n",
            "Epoch 86/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7157 - val_loss: 0.5425 - val_accuracy: 0.7211\n",
            "Epoch 87/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7183 - val_loss: 0.5402 - val_accuracy: 0.7166\n",
            "Epoch 88/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7183 - val_loss: 0.5371 - val_accuracy: 0.7329\n",
            "Epoch 89/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7168 - val_loss: 0.5363 - val_accuracy: 0.7359\n",
            "Epoch 90/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7227 - val_loss: 0.5360 - val_accuracy: 0.7315\n",
            "Epoch 91/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7249 - val_loss: 0.5340 - val_accuracy: 0.7359\n",
            "Epoch 92/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7242 - val_loss: 0.5355 - val_accuracy: 0.7196\n",
            "Epoch 93/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7257 - val_loss: 0.5350 - val_accuracy: 0.7211\n",
            "Epoch 94/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7235 - val_loss: 0.5310 - val_accuracy: 0.7389\n",
            "Epoch 95/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7290 - val_loss: 0.5304 - val_accuracy: 0.7404\n",
            "Epoch 96/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7301 - val_loss: 0.5338 - val_accuracy: 0.7136\n",
            "Epoch 97/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7279 - val_loss: 0.5296 - val_accuracy: 0.7315\n",
            "Epoch 98/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7361 - val_loss: 0.5269 - val_accuracy: 0.7418\n",
            "Epoch 99/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7305 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 100/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7301 - val_loss: 0.5241 - val_accuracy: 0.7493\n",
            "Epoch 101/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7339 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
            "Epoch 102/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7309 - val_loss: 0.5226 - val_accuracy: 0.7463\n",
            "Epoch 103/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7327 - val_loss: 0.5230 - val_accuracy: 0.7404\n",
            "Epoch 104/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7394 - val_loss: 0.5203 - val_accuracy: 0.7507\n",
            "Epoch 105/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7368 - val_loss: 0.5199 - val_accuracy: 0.7522\n",
            "Epoch 106/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7409 - val_loss: 0.5193 - val_accuracy: 0.7537\n",
            "Epoch 107/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7387 - val_loss: 0.5167 - val_accuracy: 0.7507\n",
            "Epoch 108/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7372 - val_loss: 0.5159 - val_accuracy: 0.7507\n",
            "Epoch 109/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7431 - val_loss: 0.5135 - val_accuracy: 0.7745\n",
            "Epoch 110/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5162 - val_accuracy: 0.7404\n",
            "Epoch 111/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7480 - val_loss: 0.5114 - val_accuracy: 0.7611\n",
            "Epoch 112/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7450 - val_loss: 0.5098 - val_accuracy: 0.7789\n",
            "Epoch 113/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7513 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 114/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7498 - val_loss: 0.5126 - val_accuracy: 0.7359\n",
            "Epoch 115/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7524 - val_loss: 0.5068 - val_accuracy: 0.7685\n",
            "Epoch 116/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7558 - val_loss: 0.5063 - val_accuracy: 0.7611\n",
            "Epoch 117/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7550 - val_loss: 0.5056 - val_accuracy: 0.7611\n",
            "Epoch 118/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7550 - val_loss: 0.5022 - val_accuracy: 0.7789\n",
            "Epoch 119/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7595 - val_loss: 0.5017 - val_accuracy: 0.7685\n",
            "Epoch 120/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7546 - val_loss: 0.5027 - val_accuracy: 0.7596\n",
            "Epoch 121/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7602 - val_loss: 0.5025 - val_accuracy: 0.7522\n",
            "Epoch 122/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7554 - val_loss: 0.5077 - val_accuracy: 0.7374\n",
            "Epoch 123/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7569 - val_loss: 0.4964 - val_accuracy: 0.7715\n",
            "Epoch 124/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7687 - val_loss: 0.4996 - val_accuracy: 0.7493\n",
            "Epoch 125/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7684 - val_loss: 0.4941 - val_accuracy: 0.7774\n",
            "Epoch 126/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7695 - val_loss: 0.4946 - val_accuracy: 0.7730\n",
            "Epoch 127/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7695 - val_loss: 0.4982 - val_accuracy: 0.7463\n",
            "Epoch 128/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7665 - val_loss: 0.4900 - val_accuracy: 0.7878\n",
            "Epoch 129/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7650 - val_loss: 0.4886 - val_accuracy: 0.7878\n",
            "Epoch 130/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7736 - val_loss: 0.4909 - val_accuracy: 0.7641\n",
            "Epoch 131/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7728 - val_loss: 0.4891 - val_accuracy: 0.7685\n",
            "Epoch 132/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7699 - val_loss: 0.4856 - val_accuracy: 0.7908\n",
            "Epoch 133/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7728 - val_loss: 0.4922 - val_accuracy: 0.7522\n",
            "Epoch 134/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7773 - val_loss: 0.4822 - val_accuracy: 0.7938\n",
            "Epoch 135/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7788 - val_loss: 0.4875 - val_accuracy: 0.7567\n",
            "Epoch 136/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7784 - val_loss: 0.4802 - val_accuracy: 0.7953\n",
            "Epoch 137/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7762 - val_loss: 0.4787 - val_accuracy: 0.7938\n",
            "Epoch 138/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7751 - val_loss: 0.4781 - val_accuracy: 0.7938\n",
            "Epoch 139/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7825 - val_loss: 0.4799 - val_accuracy: 0.7774\n",
            "Epoch 140/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7829 - val_loss: 0.4779 - val_accuracy: 0.7878\n",
            "Epoch 141/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7843 - val_loss: 0.4754 - val_accuracy: 0.7938\n",
            "Epoch 142/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.4741 - val_accuracy: 0.7938\n",
            "Epoch 143/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7866 - val_loss: 0.4758 - val_accuracy: 0.7834\n",
            "Epoch 144/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7851 - val_loss: 0.4709 - val_accuracy: 0.7982\n",
            "Epoch 145/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7866 - val_loss: 0.4701 - val_accuracy: 0.7953\n",
            "Epoch 146/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7858 - val_loss: 0.4739 - val_accuracy: 0.7804\n",
            "Epoch 147/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7843 - val_loss: 0.4750 - val_accuracy: 0.7685\n",
            "Epoch 148/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7862 - val_loss: 0.4685 - val_accuracy: 0.7893\n",
            "Epoch 149/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7892 - val_loss: 0.4702 - val_accuracy: 0.7819\n",
            "Epoch 150/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7903 - val_loss: 0.4714 - val_accuracy: 0.7760\n",
            "Epoch 151/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7895 - val_loss: 0.4641 - val_accuracy: 0.7967\n",
            "Epoch 152/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7940 - val_loss: 0.4629 - val_accuracy: 0.7982\n",
            "Epoch 153/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7973 - val_loss: 0.4622 - val_accuracy: 0.8012\n",
            "Epoch 154/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7955 - val_loss: 0.4620 - val_accuracy: 0.7967\n",
            "Epoch 155/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7940 - val_loss: 0.4602 - val_accuracy: 0.7982\n",
            "Epoch 156/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8007 - val_loss: 0.4596 - val_accuracy: 0.8027\n",
            "Epoch 157/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7929 - val_loss: 0.4607 - val_accuracy: 0.7923\n",
            "Epoch 158/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7970 - val_loss: 0.4577 - val_accuracy: 0.8027\n",
            "Epoch 159/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7899 - val_loss: 0.4568 - val_accuracy: 0.8056\n",
            "Epoch 160/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7940 - val_loss: 0.4589 - val_accuracy: 0.7893\n",
            "Epoch 161/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8003 - val_loss: 0.4552 - val_accuracy: 0.8027\n",
            "Epoch 162/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7947 - val_loss: 0.4580 - val_accuracy: 0.7834\n",
            "Epoch 163/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7970 - val_loss: 0.4581 - val_accuracy: 0.7789\n",
            "Epoch 164/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7955 - val_loss: 0.4542 - val_accuracy: 0.8012\n",
            "Epoch 165/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7962 - val_loss: 0.4571 - val_accuracy: 0.7804\n",
            "Epoch 166/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7973 - val_loss: 0.4554 - val_accuracy: 0.7804\n",
            "Epoch 167/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7970 - val_loss: 0.4506 - val_accuracy: 0.8027\n",
            "Epoch 168/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7966 - val_loss: 0.4505 - val_accuracy: 0.7997\n",
            "Epoch 169/200\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8007 - val_loss: 0.4496 - val_accuracy: 0.8012\n",
            "Epoch 170/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8014 - val_loss: 0.4504 - val_accuracy: 0.8012\n",
            "Epoch 171/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7992 - val_loss: 0.4480 - val_accuracy: 0.8056\n",
            "Epoch 172/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8036 - val_loss: 0.4517 - val_accuracy: 0.7878\n",
            "Epoch 173/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.8029 - val_loss: 0.4467 - val_accuracy: 0.8042\n",
            "Epoch 174/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7958 - val_loss: 0.4495 - val_accuracy: 0.7864\n",
            "Epoch 175/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8007 - val_loss: 0.4507 - val_accuracy: 0.7864\n",
            "Epoch 176/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8014 - val_loss: 0.4444 - val_accuracy: 0.7997\n",
            "Epoch 177/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8040 - val_loss: 0.4436 - val_accuracy: 0.8056\n",
            "Epoch 178/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8036 - val_loss: 0.4430 - val_accuracy: 0.8042\n",
            "Epoch 179/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8048 - val_loss: 0.4423 - val_accuracy: 0.8027\n",
            "Epoch 180/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8022 - val_loss: 0.4417 - val_accuracy: 0.8042\n",
            "Epoch 181/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8044 - val_loss: 0.4414 - val_accuracy: 0.8012\n",
            "Epoch 182/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8044 - val_loss: 0.4431 - val_accuracy: 0.7997\n",
            "Epoch 183/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.8048 - val_loss: 0.4453 - val_accuracy: 0.7908\n",
            "Epoch 184/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8040 - val_loss: 0.4413 - val_accuracy: 0.7997\n",
            "Epoch 185/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8044 - val_loss: 0.4413 - val_accuracy: 0.7997\n",
            "Epoch 186/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8036 - val_loss: 0.4442 - val_accuracy: 0.7878\n",
            "Epoch 187/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8066 - val_loss: 0.4393 - val_accuracy: 0.8012\n",
            "Epoch 188/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8070 - val_loss: 0.4382 - val_accuracy: 0.7997\n",
            "Epoch 189/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8048 - val_loss: 0.4446 - val_accuracy: 0.7864\n",
            "Epoch 190/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8051 - val_loss: 0.4371 - val_accuracy: 0.7982\n",
            "Epoch 191/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8092 - val_loss: 0.4361 - val_accuracy: 0.7997\n",
            "Epoch 192/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.8096 - val_loss: 0.4355 - val_accuracy: 0.8027\n",
            "Epoch 193/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8070 - val_loss: 0.4421 - val_accuracy: 0.7878\n",
            "Epoch 194/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8081 - val_loss: 0.4348 - val_accuracy: 0.8042\n",
            "Epoch 195/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8096 - val_loss: 0.4404 - val_accuracy: 0.7893\n",
            "Epoch 196/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8096 - val_loss: 0.4355 - val_accuracy: 0.8042\n",
            "Epoch 197/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8125 - val_loss: 0.4349 - val_accuracy: 0.8042\n",
            "Epoch 198/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8081 - val_loss: 0.4338 - val_accuracy: 0.8027\n",
            "Epoch 199/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8073 - val_loss: 0.4355 - val_accuracy: 0.7997\n",
            "Epoch 200/200\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8144 - val_loss: 0.4323 - val_accuracy: 0.7997\n",
            "Fold 1, 200 epochs, 24 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 79.97%\n",
            "\n",
            "Validation core mean 79.97% (+/- 0.00%)\n",
            "INFO:tensorflow:Assets written to: MLP113.medium.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyACRnZx9Kde"
      },
      "source": [
        "## Len 2Kb-3Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUxmLnQ-9Kde",
        "outputId": "0808cd36-019c-404a-ba4e-e9052b8bedb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MINLEN=2000\n",
        "MAXLEN=3000\n",
        "\n",
        "print (\"Compile the model\")\n",
        "model=build_model(MAXLEN,EMBED_DIMEN)\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "\n",
        "print(\"Working on full training set, slice by sequence length.\")\n",
        "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "\n",
        "print (\"Sequence to Kmer\")\n",
        "(X_train,y_train)=make_kmers(MAXLEN,subset)\n",
        "X_train\n",
        "X_train=make_frequencies(X_train)\n",
        "X_train\n",
        "print (\"Cross valiation\")\n",
        "model3 = do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
        "model3.save(FILENAME+'.long.model')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_304 (Dense)            (None, 16)                1056      \n",
            "_________________________________________________________________\n",
            "dense_305 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_307 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,345\n",
            "Trainable params: 1,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Working on full training set, slice by sequence length.\n",
            "Slice size range [2000 - 3000)\n",
            "original (30290, 4)\n",
            "no short (3221, 4)\n",
            "no long, no short (1351, 4)\n",
            "Sequence to Kmer\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(1351, 1)\n",
            "sequence    GTCATTCTAGCTGCCTGCTGCCTCCGCAGCGTCCCCCCAGCTCTCC...\n",
            "Name: 19713, dtype: object\n",
            "2039\n",
            "transform...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n",
            "[[46 53 20 ...  0  0  0]\n",
            " [ 3 10 37 ...  0  0  0]\n",
            " [12 48 62 ...  0  0  0]\n",
            " ...\n",
            " [13 49  3 ...  0  0  0]\n",
            " [39 25 33 ...  0  0  0]\n",
            " [ 9 36 15 ...  0  0  0]]\n",
            "Cross valiation\n",
            "BUILD MODEL\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.3602 - val_loss: 0.6760 - val_accuracy: 0.6790\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.7083 - val_loss: 0.6347 - val_accuracy: 0.6790\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7083 - val_loss: 0.6276 - val_accuracy: 0.6790\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7083 - val_loss: 0.6290 - val_accuracy: 0.6790\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7083 - val_loss: 0.6284 - val_accuracy: 0.6790\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7083 - val_loss: 0.6295 - val_accuracy: 0.6790\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7083 - val_loss: 0.6289 - val_accuracy: 0.6790\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7083 - val_loss: 0.6281 - val_accuracy: 0.6790\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7083 - val_loss: 0.6297 - val_accuracy: 0.6790\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7083 - val_loss: 0.6285 - val_accuracy: 0.6790\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7083 - val_loss: 0.6290 - val_accuracy: 0.6790\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6790\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7083 - val_loss: 0.6290 - val_accuracy: 0.6790\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7083 - val_loss: 0.6275 - val_accuracy: 0.6790\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6790\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6790\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.7083 - val_loss: 0.6281 - val_accuracy: 0.6790\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6790\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.7083 - val_loss: 0.6275 - val_accuracy: 0.6790\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7083 - val_loss: 0.6273 - val_accuracy: 0.6790\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.7083 - val_loss: 0.6270 - val_accuracy: 0.6790\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7083 - val_loss: 0.6279 - val_accuracy: 0.6790\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7083 - val_loss: 0.6269 - val_accuracy: 0.6790\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7083 - val_loss: 0.6261 - val_accuracy: 0.6790\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7083 - val_loss: 0.6274 - val_accuracy: 0.6790\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7083 - val_loss: 0.6270 - val_accuracy: 0.6790\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.7083 - val_loss: 0.6264 - val_accuracy: 0.6790\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7083 - val_loss: 0.6258 - val_accuracy: 0.6790\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.7083 - val_loss: 0.6267 - val_accuracy: 0.6790\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7083 - val_loss: 0.6257 - val_accuracy: 0.6790\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7083 - val_loss: 0.6257 - val_accuracy: 0.6790\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7083 - val_loss: 0.6252 - val_accuracy: 0.6790\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7083 - val_loss: 0.6263 - val_accuracy: 0.6790\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7083 - val_loss: 0.6244 - val_accuracy: 0.6790\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7083 - val_loss: 0.6252 - val_accuracy: 0.6790\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7083 - val_loss: 0.6246 - val_accuracy: 0.6790\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.7083 - val_loss: 0.6243 - val_accuracy: 0.6790\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7083 - val_loss: 0.6232 - val_accuracy: 0.6790\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.7083 - val_loss: 0.6246 - val_accuracy: 0.6790\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.7083 - val_loss: 0.6230 - val_accuracy: 0.6790\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7083 - val_loss: 0.6228 - val_accuracy: 0.6790\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.7083 - val_loss: 0.6221 - val_accuracy: 0.6790\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7083 - val_loss: 0.6227 - val_accuracy: 0.6790\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7083 - val_loss: 0.6215 - val_accuracy: 0.6790\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.7083 - val_loss: 0.6217 - val_accuracy: 0.6790\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7083 - val_loss: 0.6210 - val_accuracy: 0.6790\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7083 - val_loss: 0.6205 - val_accuracy: 0.6790\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7083 - val_loss: 0.6198 - val_accuracy: 0.6790\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7083 - val_loss: 0.6192 - val_accuracy: 0.6790\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7083 - val_loss: 0.6195 - val_accuracy: 0.6790\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.7083 - val_loss: 0.6181 - val_accuracy: 0.6790\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7083 - val_loss: 0.6180 - val_accuracy: 0.6790\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7083 - val_loss: 0.6173 - val_accuracy: 0.6790\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7083 - val_loss: 0.6167 - val_accuracy: 0.6790\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5919 - accuracy: 0.7083 - val_loss: 0.6164 - val_accuracy: 0.6790\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.7083 - val_loss: 0.6154 - val_accuracy: 0.6790\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7083 - val_loss: 0.6139 - val_accuracy: 0.6790\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7083 - val_loss: 0.6134 - val_accuracy: 0.6790\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7083 - val_loss: 0.6132 - val_accuracy: 0.6790\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7083 - val_loss: 0.6123 - val_accuracy: 0.6790\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.7083 - val_loss: 0.6109 - val_accuracy: 0.6790\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7083 - val_loss: 0.6111 - val_accuracy: 0.6790\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7083 - val_loss: 0.6103 - val_accuracy: 0.6790\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7083 - val_loss: 0.6101 - val_accuracy: 0.6790\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7083 - val_loss: 0.6076 - val_accuracy: 0.6790\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7083 - val_loss: 0.6072 - val_accuracy: 0.6790\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7083 - val_loss: 0.6062 - val_accuracy: 0.6790\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7083 - val_loss: 0.6056 - val_accuracy: 0.6790\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7083 - val_loss: 0.6038 - val_accuracy: 0.6790\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7083 - val_loss: 0.6032 - val_accuracy: 0.6790\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7083 - val_loss: 0.6037 - val_accuracy: 0.6790\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7083 - val_loss: 0.6020 - val_accuracy: 0.6790\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7083 - val_loss: 0.5993 - val_accuracy: 0.6790\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7083 - val_loss: 0.6000 - val_accuracy: 0.6790\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7083 - val_loss: 0.5987 - val_accuracy: 0.6790\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7083 - val_loss: 0.5990 - val_accuracy: 0.6790\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7083 - val_loss: 0.5953 - val_accuracy: 0.6790\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7083 - val_loss: 0.5954 - val_accuracy: 0.6790\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7083 - val_loss: 0.5944 - val_accuracy: 0.6790\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7083 - val_loss: 0.5949 - val_accuracy: 0.6790\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7083 - val_loss: 0.5915 - val_accuracy: 0.6790\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7083 - val_loss: 0.5909 - val_accuracy: 0.6790\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7083 - val_loss: 0.5891 - val_accuracy: 0.6790\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7083 - val_loss: 0.5884 - val_accuracy: 0.6790\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7083 - val_loss: 0.5872 - val_accuracy: 0.6790\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7083 - val_loss: 0.5865 - val_accuracy: 0.6790\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7083 - val_loss: 0.5863 - val_accuracy: 0.6790\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7083 - val_loss: 0.5833 - val_accuracy: 0.6790\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7083 - val_loss: 0.5829 - val_accuracy: 0.6790\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7083 - val_loss: 0.5815 - val_accuracy: 0.6827\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7083 - val_loss: 0.5798 - val_accuracy: 0.6827\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7083 - val_loss: 0.5796 - val_accuracy: 0.6827\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7083 - val_loss: 0.5789 - val_accuracy: 0.6827\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7093 - val_loss: 0.5774 - val_accuracy: 0.6827\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7093 - val_loss: 0.5776 - val_accuracy: 0.6827\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7093 - val_loss: 0.5751 - val_accuracy: 0.6827\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7093 - val_loss: 0.5742 - val_accuracy: 0.6827\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7093 - val_loss: 0.5732 - val_accuracy: 0.6863\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7093 - val_loss: 0.5729 - val_accuracy: 0.6863\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7102 - val_loss: 0.5715 - val_accuracy: 0.6863\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7102 - val_loss: 0.5706 - val_accuracy: 0.6863\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7120 - val_loss: 0.5695 - val_accuracy: 0.6900\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7111 - val_loss: 0.5687 - val_accuracy: 0.6900\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7185 - val_loss: 0.5678 - val_accuracy: 0.6900\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7120 - val_loss: 0.5676 - val_accuracy: 0.6900\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7139 - val_loss: 0.5659 - val_accuracy: 0.6937\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7148 - val_loss: 0.5661 - val_accuracy: 0.6937\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7176 - val_loss: 0.5648 - val_accuracy: 0.6937\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7167 - val_loss: 0.5652 - val_accuracy: 0.6937\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7148 - val_loss: 0.5625 - val_accuracy: 0.6900\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7167 - val_loss: 0.5619 - val_accuracy: 0.6900\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7157 - val_loss: 0.5616 - val_accuracy: 0.6900\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7139 - val_loss: 0.5608 - val_accuracy: 0.6900\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7157 - val_loss: 0.5598 - val_accuracy: 0.6937\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7157 - val_loss: 0.5588 - val_accuracy: 0.6974\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7194 - val_loss: 0.5593 - val_accuracy: 0.6937\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7222 - val_loss: 0.5591 - val_accuracy: 0.6900\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7194 - val_loss: 0.5577 - val_accuracy: 0.6974\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7222 - val_loss: 0.5566 - val_accuracy: 0.7011\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7157 - val_loss: 0.5557 - val_accuracy: 0.7048\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7194 - val_loss: 0.5546 - val_accuracy: 0.7048\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7222 - val_loss: 0.5541 - val_accuracy: 0.7048\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7269 - val_loss: 0.5536 - val_accuracy: 0.7048\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7269 - val_loss: 0.5546 - val_accuracy: 0.7011\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7204 - val_loss: 0.5545 - val_accuracy: 0.6974\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7213 - val_loss: 0.5521 - val_accuracy: 0.7048\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7333 - val_loss: 0.5524 - val_accuracy: 0.7048\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7194 - val_loss: 0.5502 - val_accuracy: 0.7011\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7315 - val_loss: 0.5514 - val_accuracy: 0.7048\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7278 - val_loss: 0.5500 - val_accuracy: 0.7011\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7352 - val_loss: 0.5503 - val_accuracy: 0.7048\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7269 - val_loss: 0.5492 - val_accuracy: 0.7011\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7361 - val_loss: 0.5478 - val_accuracy: 0.7048\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7278 - val_loss: 0.5477 - val_accuracy: 0.7011\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7296 - val_loss: 0.5469 - val_accuracy: 0.7048\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7315 - val_loss: 0.5459 - val_accuracy: 0.7085\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7370 - val_loss: 0.5468 - val_accuracy: 0.7011\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7259 - val_loss: 0.5457 - val_accuracy: 0.7048\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7352 - val_loss: 0.5457 - val_accuracy: 0.7048\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7324 - val_loss: 0.5440 - val_accuracy: 0.7122\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7361 - val_loss: 0.5447 - val_accuracy: 0.7048\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7324 - val_loss: 0.5439 - val_accuracy: 0.7122\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7324 - val_loss: 0.5421 - val_accuracy: 0.7122\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7361 - val_loss: 0.5427 - val_accuracy: 0.7122\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7370 - val_loss: 0.5429 - val_accuracy: 0.7122\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7352 - val_loss: 0.5440 - val_accuracy: 0.7085\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7343 - val_loss: 0.5397 - val_accuracy: 0.7122\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7398 - val_loss: 0.5420 - val_accuracy: 0.7122\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7370 - val_loss: 0.5393 - val_accuracy: 0.7122\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7352 - val_loss: 0.5381 - val_accuracy: 0.7122\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7352 - val_loss: 0.5387 - val_accuracy: 0.7122\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7361 - val_loss: 0.5365 - val_accuracy: 0.7306\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7370 - val_loss: 0.5369 - val_accuracy: 0.7122\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7398 - val_loss: 0.5363 - val_accuracy: 0.7159\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7407 - val_loss: 0.5362 - val_accuracy: 0.7122\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7324 - val_loss: 0.5354 - val_accuracy: 0.7232\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7389 - val_loss: 0.5343 - val_accuracy: 0.7306\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7352 - val_loss: 0.5340 - val_accuracy: 0.7306\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7361 - val_loss: 0.5339 - val_accuracy: 0.7232\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7370 - val_loss: 0.5327 - val_accuracy: 0.7343\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7380 - val_loss: 0.5328 - val_accuracy: 0.7269\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7380 - val_loss: 0.5317 - val_accuracy: 0.7343\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7370 - val_loss: 0.5308 - val_accuracy: 0.7380\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7389 - val_loss: 0.5299 - val_accuracy: 0.7343\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7407 - val_loss: 0.5303 - val_accuracy: 0.7343\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7417 - val_loss: 0.5311 - val_accuracy: 0.7269\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7380 - val_loss: 0.5293 - val_accuracy: 0.7343\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7380 - val_loss: 0.5293 - val_accuracy: 0.7306\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7389 - val_loss: 0.5274 - val_accuracy: 0.7343\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7435 - val_loss: 0.5269 - val_accuracy: 0.7343\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7426 - val_loss: 0.5290 - val_accuracy: 0.7269\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7361 - val_loss: 0.5288 - val_accuracy: 0.7343\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7417 - val_loss: 0.5257 - val_accuracy: 0.7343\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7435 - val_loss: 0.5253 - val_accuracy: 0.7343\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7444 - val_loss: 0.5260 - val_accuracy: 0.7306\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7435 - val_loss: 0.5261 - val_accuracy: 0.7269\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7435 - val_loss: 0.5240 - val_accuracy: 0.7343\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7463 - val_loss: 0.5232 - val_accuracy: 0.7343\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7454 - val_loss: 0.5231 - val_accuracy: 0.7343\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7426 - val_loss: 0.5212 - val_accuracy: 0.7417\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7426 - val_loss: 0.5218 - val_accuracy: 0.7343\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7426 - val_loss: 0.5220 - val_accuracy: 0.7269\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7426 - val_loss: 0.5212 - val_accuracy: 0.7306\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7435 - val_loss: 0.5202 - val_accuracy: 0.7343\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7426 - val_loss: 0.5198 - val_accuracy: 0.7343\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7417 - val_loss: 0.5199 - val_accuracy: 0.7269\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7435 - val_loss: 0.5182 - val_accuracy: 0.7380\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7463 - val_loss: 0.5180 - val_accuracy: 0.7380\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7454 - val_loss: 0.5167 - val_accuracy: 0.7417\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7472 - val_loss: 0.5161 - val_accuracy: 0.7417\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7463 - val_loss: 0.5153 - val_accuracy: 0.7417\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7454 - val_loss: 0.5161 - val_accuracy: 0.7380\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7472 - val_loss: 0.5175 - val_accuracy: 0.7343\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7472 - val_loss: 0.5144 - val_accuracy: 0.7380\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7472 - val_loss: 0.5143 - val_accuracy: 0.7380\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7454 - val_loss: 0.5141 - val_accuracy: 0.7380\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7481 - val_loss: 0.5113 - val_accuracy: 0.7380\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7519 - val_loss: 0.5117 - val_accuracy: 0.7417\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7481 - val_loss: 0.5119 - val_accuracy: 0.7380\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7546 - val_loss: 0.5115 - val_accuracy: 0.7417\n",
            "Fold 1, 200 epochs, 12 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 74.17%\n",
            "\n",
            "Validation core mean 74.17% (+/- 0.00%)\n",
            "INFO:tensorflow:Assets written to: MLP113.long.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}