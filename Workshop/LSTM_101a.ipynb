{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVjzLkNimqS8"
   },
   "source": [
    "# LSTM 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubTxCruBmqS-",
    "outputId": "58392f51-89da-4596-ef24-577728781960"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#PATH='/content/drive/'\n",
    "#drive.mount(PATH)\n",
    "#DATAPATH=PATH+'My Drive/data/'\n",
    "#PC_FILENAME = DATAPATH+'pcRNA.fasta'\n",
    "#NC_FILENAME = DATAPATH+'ncRNA.fasta'\n",
    "# LOCAL\n",
    "PC_FILENAME = 'pcRNA.fasta'\n",
    "NC_FILENAME = 'ncRNA.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7OrrqZOfmqTF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=100\n",
    "SPLITS=1\n",
    "K=3\n",
    "EMBED_DIMEN=16\n",
    "FILENAME='LSTM101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Jl4LG19mqTK"
   },
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kffm79SEmqTL"
   },
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Uoj6Nc3tmqTQ"
   },
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cn1oP6rcmqTa"
   },
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    vocabulary_size=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "\n",
    "    neurons=16\n",
    "    rnn = keras.models.Sequential()\n",
    "    embed_layer = keras.layers.Embedding(\n",
    "        vocabulary_size,EMBED_DIMEN,input_length=maxlen);\n",
    "    rnn1_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(neurons, return_sequences=True, dropout=0.50, \n",
    "            input_shape=[maxlen,dimen]))\n",
    "    rnn2_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(neurons, dropout=0.50, return_sequences=True))\n",
    "    dense1_layer = keras.layers.Dense(neurons,activation=act,dtype=dt)\n",
    "    dense2_layer = keras.layers.Dense(neurons,activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,activation=act,dtype=dt)\n",
    "\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    rnn.add(rnn2_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7xpthbwcmqTe"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    rnn2=None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        start_time=time.time()\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "        end_time=time.time()\n",
    "        elapsed_time=(end_time-start_time)\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs, %d sec\"%(fold,eps,elapsed_time))\n",
    "                      \n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "    return rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5E_UIKJEmqTh"
   },
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "Dwd6l1s8mqTn",
    "outputId": "e187cb15-d03f-470d-f969-10a2bc2afdff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9089</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>6070</td>\n",
       "      <td>1</td>\n",
       "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>18550</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3387</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>6410</td>\n",
       "      <td>1</td>\n",
       "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7641</td>\n",
       "      <td>1</td>\n",
       "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14109</td>\n",
       "      <td>0</td>\n",
       "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...   \n",
       "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...   \n",
       "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...   \n",
       "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...   \n",
       "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...   \n",
       "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...   \n",
       "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...   \n",
       "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...   \n",
       "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...   \n",
       "\n",
       "       seqlen  \n",
       "1280      348  \n",
       "9088      534  \n",
       "6069      592  \n",
       "18549     945  \n",
       "15027    4382  \n",
       "...       ...  \n",
       "3386      578  \n",
       "6495      562  \n",
       "6409      740  \n",
       "7640     3156  \n",
       "14108     466  \n",
       "\n",
       "[30290 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta(NC_FILENAME,0)\n",
    "pc_seq=load_fasta(PC_FILENAME,1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3KW8eUOmqTs",
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_evesETdmqTs",
    "outputId": "63748b15-e441-4e57-abcc-02707921a78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [200 - 1000)\n",
      "original (30290, 4)\n",
      "no short (30290, 4)\n",
      "no long, no short (8879, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(8879, 1)\n",
      "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
      "Name: 1280, dtype: object\n",
      "348\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[12 46 54 ...  0  0  0]\n",
      " [ 9 36 14 ...  0  0  0]\n",
      " [34  7 28 ...  0  0  0]\n",
      " ...\n",
      " [37 19  9 ...  0  0  0]\n",
      " [57 36 15 ...  0  0  0]\n",
      " [33  3 12 ...  0  0  0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 32)          4224      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 32)          6272      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000, 16)          528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 16)          272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 1)           17        \n",
      "=================================================================\n",
      "Total params: 12,353\n",
      "Trainable params: 12,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/100\n",
      "222/222 [==============================] - 364s 2s/step - loss: 0.6940 - accuracy: 0.5437 - val_loss: 0.6684 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 337s 2s/step - loss: 0.6606 - accuracy: 0.6093 - val_loss: 0.6548 - val_accuracy: 0.6194\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 337s 2s/step - loss: 0.6397 - accuracy: 0.6426 - val_loss: 0.6143 - val_accuracy: 0.6920\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 334s 2s/step - loss: 0.6129 - accuracy: 0.6788 - val_loss: 0.6065 - val_accuracy: 0.6633\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - 328s 1s/step - loss: 0.6334 - accuracy: 0.6512 - val_loss: 0.6210 - val_accuracy: 0.6728\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 328s 1s/step - loss: 0.6291 - accuracy: 0.6624 - val_loss: 0.6517 - val_accuracy: 0.6317\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 329s 1s/step - loss: 0.6473 - accuracy: 0.6276 - val_loss: 0.6688 - val_accuracy: 0.5687\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 333s 2s/step - loss: 0.6444 - accuracy: 0.6353 - val_loss: 0.6370 - val_accuracy: 0.6303\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - 318s 1s/step - loss: 0.6462 - accuracy: 0.6307 - val_loss: 0.6501 - val_accuracy: 0.6241\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.6796 - accuracy: 0.5561 - val_loss: 0.6802 - val_accuracy: 0.5718\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 291s 1s/step - loss: 0.6769 - accuracy: 0.5718 - val_loss: 0.6436 - val_accuracy: 0.6403\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 297s 1s/step - loss: 0.6609 - accuracy: 0.6045 - val_loss: 0.6617 - val_accuracy: 0.5825\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - 305s 1s/step - loss: 0.6643 - accuracy: 0.5857 - val_loss: 0.6662 - val_accuracy: 0.5710\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 305s 1s/step - loss: 0.6662 - accuracy: 0.5887 - val_loss: 0.6450 - val_accuracy: 0.6672\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 305s 1s/step - loss: 0.6537 - accuracy: 0.6278 - val_loss: 0.6677 - val_accuracy: 0.5989\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 295s 1s/step - loss: 0.6602 - accuracy: 0.6217 - val_loss: 0.6614 - val_accuracy: 0.6161\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.6711 - accuracy: 0.5829 - val_loss: 0.6674 - val_accuracy: 0.5923\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 270s 1s/step - loss: 0.6674 - accuracy: 0.5853 - val_loss: 0.6731 - val_accuracy: 0.5478\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 270s 1s/step - loss: 0.6701 - accuracy: 0.5842 - val_loss: 0.6833 - val_accuracy: 0.5761\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 270s 1s/step - loss: 0.6659 - accuracy: 0.6038 - val_loss: 0.6579 - val_accuracy: 0.6199\n",
      "Epoch 21/100\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.6656 - accuracy: 0.6014 - val_loss: 0.6644 - val_accuracy: 0.6130\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.6592 - accuracy: 0.6221 - val_loss: 0.6517 - val_accuracy: 0.6341\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 264s 1s/step - loss: 0.6691 - accuracy: 0.5890 - val_loss: 0.6690 - val_accuracy: 0.5932\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.6696 - accuracy: 0.5851 - val_loss: 0.6712 - val_accuracy: 0.5892\n",
      "Epoch 25/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.6646 - accuracy: 0.5965 - val_loss: 0.6616 - val_accuracy: 0.5960\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.6524 - accuracy: 0.6137 - val_loss: 0.6442 - val_accuracy: 0.6196\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.6509 - accuracy: 0.6199 - val_loss: 0.6699 - val_accuracy: 0.5684\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.6493 - accuracy: 0.6207 - val_loss: 0.6528 - val_accuracy: 0.6159\n",
      "Epoch 29/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.6371 - accuracy: 0.6418 - val_loss: 0.6718 - val_accuracy: 0.5911\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.6411 - accuracy: 0.6277 - val_loss: 0.6340 - val_accuracy: 0.6220\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.6095 - accuracy: 0.6850 - val_loss: 0.5917 - val_accuracy: 0.7009\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.5788 - accuracy: 0.7134 - val_loss: 0.5900 - val_accuracy: 0.7099\n",
      "Epoch 33/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.5839 - accuracy: 0.6998 - val_loss: 0.5813 - val_accuracy: 0.7042\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.5675 - accuracy: 0.7058 - val_loss: 0.5665 - val_accuracy: 0.7137\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 257s 1s/step - loss: 0.5390 - accuracy: 0.7418 - val_loss: 0.5527 - val_accuracy: 0.7234\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.5091 - accuracy: 0.7630 - val_loss: 0.5065 - val_accuracy: 0.7575\n",
      "Epoch 37/100\n",
      "222/222 [==============================] - 261s 1s/step - loss: 0.4879 - accuracy: 0.7759 - val_loss: 0.4863 - val_accuracy: 0.7724\n",
      "Epoch 38/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4737 - accuracy: 0.7836 - val_loss: 0.4712 - val_accuracy: 0.7822\n",
      "Epoch 39/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4660 - accuracy: 0.7866 - val_loss: 0.4700 - val_accuracy: 0.7823\n",
      "Epoch 40/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4648 - accuracy: 0.7843 - val_loss: 0.4736 - val_accuracy: 0.7789\n",
      "Epoch 41/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4492 - accuracy: 0.7962 - val_loss: 0.4650 - val_accuracy: 0.7825\n",
      "Epoch 42/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4444 - accuracy: 0.7987 - val_loss: 0.4584 - val_accuracy: 0.7917\n",
      "Epoch 43/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4487 - accuracy: 0.7973 - val_loss: 0.4500 - val_accuracy: 0.7919\n",
      "Epoch 44/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4431 - accuracy: 0.7991 - val_loss: 0.4557 - val_accuracy: 0.7893\n",
      "Epoch 45/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4404 - accuracy: 0.7998 - val_loss: 0.4457 - val_accuracy: 0.7931\n",
      "Epoch 46/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4457 - accuracy: 0.7960 - val_loss: 0.4431 - val_accuracy: 0.7961\n",
      "Epoch 47/100\n",
      "222/222 [==============================] - 262s 1s/step - loss: 0.4349 - accuracy: 0.8025 - val_loss: 0.4529 - val_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4338 - accuracy: 0.8047 - val_loss: 0.4381 - val_accuracy: 0.7965\n",
      "Epoch 49/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4378 - accuracy: 0.7992 - val_loss: 0.4410 - val_accuracy: 0.7954\n",
      "Epoch 50/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4302 - accuracy: 0.8044 - val_loss: 0.4416 - val_accuracy: 0.8007\n",
      "Epoch 51/100\n",
      "222/222 [==============================] - 263s 1s/step - loss: 0.4270 - accuracy: 0.8078 - val_loss: 0.4442 - val_accuracy: 0.7943\n",
      "Epoch 52/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4309 - accuracy: 0.8031 - val_loss: 0.4538 - val_accuracy: 0.7896\n",
      "Epoch 53/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4201 - accuracy: 0.8121 - val_loss: 0.4356 - val_accuracy: 0.7995\n",
      "Epoch 54/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.4264 - accuracy: 0.8063 - val_loss: 0.4693 - val_accuracy: 0.7889\n",
      "Epoch 55/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4233 - accuracy: 0.8079 - val_loss: 0.4372 - val_accuracy: 0.8024\n",
      "Epoch 56/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.4345 - val_accuracy: 0.8039\n",
      "Epoch 57/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4213 - accuracy: 0.8097 - val_loss: 0.4438 - val_accuracy: 0.7996\n",
      "Epoch 58/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4199 - accuracy: 0.8085 - val_loss: 0.4366 - val_accuracy: 0.8021\n",
      "Epoch 59/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4154 - accuracy: 0.8129 - val_loss: 0.4399 - val_accuracy: 0.8022\n",
      "Epoch 60/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4210 - accuracy: 0.8069 - val_loss: 0.4345 - val_accuracy: 0.8011\n",
      "Epoch 61/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4174 - accuracy: 0.8122 - val_loss: 0.4487 - val_accuracy: 0.7960\n",
      "Epoch 62/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4156 - accuracy: 0.8123 - val_loss: 0.4521 - val_accuracy: 0.7914\n",
      "Epoch 63/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4084 - accuracy: 0.8164 - val_loss: 0.4433 - val_accuracy: 0.7907\n",
      "Epoch 64/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4121 - accuracy: 0.8134 - val_loss: 0.4358 - val_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "222/222 [==============================] - 262s 1s/step - loss: 0.4150 - accuracy: 0.8126 - val_loss: 0.4274 - val_accuracy: 0.8031\n",
      "Epoch 66/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4153 - accuracy: 0.8151 - val_loss: 0.4436 - val_accuracy: 0.7998\n",
      "Epoch 67/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4136 - accuracy: 0.8131 - val_loss: 0.4393 - val_accuracy: 0.8005\n",
      "Epoch 68/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4103 - accuracy: 0.8153 - val_loss: 0.4409 - val_accuracy: 0.7980\n",
      "Epoch 69/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4142 - accuracy: 0.8111 - val_loss: 0.4326 - val_accuracy: 0.8010\n",
      "Epoch 70/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4135 - accuracy: 0.8131 - val_loss: 0.4362 - val_accuracy: 0.8024\n",
      "Epoch 71/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.4125 - accuracy: 0.8153 - val_loss: 0.4299 - val_accuracy: 0.7996\n",
      "Epoch 72/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4098 - accuracy: 0.8161 - val_loss: 0.4305 - val_accuracy: 0.8005\n",
      "Epoch 73/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4100 - accuracy: 0.8146 - val_loss: 0.4304 - val_accuracy: 0.8012\n",
      "Epoch 74/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4122 - accuracy: 0.8125 - val_loss: 0.4435 - val_accuracy: 0.7891\n",
      "Epoch 75/100\n",
      "222/222 [==============================] - 262s 1s/step - loss: 0.4087 - accuracy: 0.8171 - val_loss: 0.4433 - val_accuracy: 0.7983\n",
      "Epoch 76/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4063 - accuracy: 0.8168 - val_loss: 0.4429 - val_accuracy: 0.8004\n",
      "Epoch 77/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.4448 - val_accuracy: 0.7939\n",
      "Epoch 78/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.4052 - accuracy: 0.8158 - val_loss: 0.4311 - val_accuracy: 0.8038\n",
      "Epoch 79/100\n",
      "222/222 [==============================] - 262s 1s/step - loss: 0.4072 - accuracy: 0.8160 - val_loss: 0.4321 - val_accuracy: 0.8023\n",
      "Epoch 80/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4050 - accuracy: 0.8179 - val_loss: 0.4496 - val_accuracy: 0.7940\n",
      "Epoch 81/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4025 - accuracy: 0.8190 - val_loss: 0.4278 - val_accuracy: 0.8031\n",
      "Epoch 82/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4051 - accuracy: 0.8197 - val_loss: 0.4452 - val_accuracy: 0.7997\n",
      "Epoch 83/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4020 - accuracy: 0.8210 - val_loss: 0.4347 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "222/222 [==============================] - 268s 1s/step - loss: 0.4068 - accuracy: 0.8183 - val_loss: 0.4319 - val_accuracy: 0.8032\n",
      "Epoch 85/100\n",
      "222/222 [==============================] - 264s 1s/step - loss: 0.4068 - accuracy: 0.8163 - val_loss: 0.4247 - val_accuracy: 0.7993\n",
      "Epoch 86/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.4057 - accuracy: 0.8174 - val_loss: 0.4302 - val_accuracy: 0.7982\n",
      "Epoch 87/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4017 - accuracy: 0.8189 - val_loss: 0.4543 - val_accuracy: 0.7967\n",
      "Epoch 88/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.4003 - accuracy: 0.8195 - val_loss: 0.4393 - val_accuracy: 0.8029\n",
      "Epoch 89/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4063 - accuracy: 0.8175 - val_loss: 0.4324 - val_accuracy: 0.7957\n",
      "Epoch 90/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4048 - accuracy: 0.8156 - val_loss: 0.4392 - val_accuracy: 0.8017\n",
      "Epoch 91/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.3993 - accuracy: 0.8191 - val_loss: 0.4268 - val_accuracy: 0.8072\n",
      "Epoch 92/100\n",
      "222/222 [==============================] - 262s 1s/step - loss: 0.3999 - accuracy: 0.8233 - val_loss: 0.4321 - val_accuracy: 0.8046\n",
      "Epoch 93/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.3971 - accuracy: 0.8234 - val_loss: 0.4280 - val_accuracy: 0.8052\n",
      "Epoch 94/100\n",
      "222/222 [==============================] - 264s 1s/step - loss: 0.3999 - accuracy: 0.8202 - val_loss: 0.4195 - val_accuracy: 0.8087\n",
      "Epoch 95/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.4010 - accuracy: 0.8155 - val_loss: 0.4258 - val_accuracy: 0.8052\n",
      "Epoch 96/100\n",
      "222/222 [==============================] - 260s 1s/step - loss: 0.3953 - accuracy: 0.8211 - val_loss: 0.4257 - val_accuracy: 0.8038\n",
      "Epoch 97/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.3964 - accuracy: 0.8198 - val_loss: 0.4315 - val_accuracy: 0.7996\n",
      "Epoch 98/100\n",
      "222/222 [==============================] - 258s 1s/step - loss: 0.3958 - accuracy: 0.8229 - val_loss: 0.4654 - val_accuracy: 0.7951\n",
      "Epoch 99/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.3981 - accuracy: 0.8213 - val_loss: 0.4227 - val_accuracy: 0.8097\n",
      "Epoch 100/100\n",
      "222/222 [==============================] - 259s 1s/step - loss: 0.3949 - accuracy: 0.8231 - val_loss: 0.4487 - val_accuracy: 0.7965\n",
      "Fold 1, 100 epochs, 27142 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.65%\n",
      "\n",
      "Validation core mean 79.65% (+/- 0.00%)\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: LSTM101.short.model/assets\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model1=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model1.save(FILENAME+'.short.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw1F0iw9mqTv"
   },
   "source": [
    "## Len 1K-2Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xwRg1mcHmqTw",
    "outputId": "86e0137a-6264-48ac-e1aa-ced05be58c2f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [1000 - 2000)\n",
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[42 39 27 ...  0  0  0]\n",
      " [57 34  5 ...  0  0  0]\n",
      " [27 44 47 ...  0  0  0]\n",
      " ...\n",
      " [44 47 57 ...  0  0  0]\n",
      " [10 37 20 ...  0  0  0]\n",
      " [47 60 48 ...  0  0  0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 2000, 32)          4224      \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 2000, 32)          6272      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2000, 16)          528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000, 16)          272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2000, 1)           17        \n",
      "=================================================================\n",
      "Total params: 12,353\n",
      "Trainable params: 12,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 239s 3s/step - loss: 0.6629 - accuracy: 0.6221 - val_loss: 0.6596 - val_accuracy: 0.6039\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 219s 3s/step - loss: 0.6426 - accuracy: 0.6336 - val_loss: 0.6352 - val_accuracy: 0.6652\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 219s 3s/step - loss: 0.6416 - accuracy: 0.6192 - val_loss: 0.6427 - val_accuracy: 0.6039\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.6392 - accuracy: 0.6221 - val_loss: 0.6337 - val_accuracy: 0.6039\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.6422 - accuracy: 0.6351 - val_loss: 0.6318 - val_accuracy: 0.6565\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6131 - accuracy: 0.6764 - val_loss: 0.5948 - val_accuracy: 0.6937\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.5914 - accuracy: 0.6855 - val_loss: 0.6000 - val_accuracy: 0.7050\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 219s 3s/step - loss: 0.5986 - accuracy: 0.6899 - val_loss: 0.5940 - val_accuracy: 0.7077\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.5946 - accuracy: 0.6859 - val_loss: 0.6171 - val_accuracy: 0.6295\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.5942 - accuracy: 0.6741 - val_loss: 0.5816 - val_accuracy: 0.7270\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.5975 - accuracy: 0.6875 - val_loss: 0.6015 - val_accuracy: 0.6669\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.5982 - accuracy: 0.6824 - val_loss: 0.6174 - val_accuracy: 0.7003\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6055 - accuracy: 0.6706 - val_loss: 0.6283 - val_accuracy: 0.5821\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6140 - accuracy: 0.6242 - val_loss: 0.6144 - val_accuracy: 0.6143\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 213s 3s/step - loss: 0.6043 - accuracy: 0.6665 - val_loss: 0.6006 - val_accuracy: 0.7096\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6060 - accuracy: 0.6926 - val_loss: 0.6349 - val_accuracy: 0.6988\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6491 - accuracy: 0.6421 - val_loss: 0.6334 - val_accuracy: 0.6556\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6412 - accuracy: 0.6152 - val_loss: 0.6244 - val_accuracy: 0.6039\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.6233 - accuracy: 0.6221 - val_loss: 0.6179 - val_accuracy: 0.6039\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6220 - accuracy: 0.6425 - val_loss: 0.6116 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.6185 - accuracy: 0.6798 - val_loss: 0.6159 - val_accuracy: 0.6832\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.6302 - accuracy: 0.6633 - val_loss: 0.6033 - val_accuracy: 0.7047\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 212s 2s/step - loss: 0.6069 - accuracy: 0.6975 - val_loss: 0.6014 - val_accuracy: 0.7053\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.6028 - accuracy: 0.7011 - val_loss: 0.5860 - val_accuracy: 0.7151\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.5891 - accuracy: 0.6971 - val_loss: 0.5805 - val_accuracy: 0.7195\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.5967 - accuracy: 0.6748 - val_loss: 0.5940 - val_accuracy: 0.6796\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.5948 - accuracy: 0.6678 - val_loss: 0.5921 - val_accuracy: 0.6810\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 211s 2s/step - loss: 0.6295 - accuracy: 0.6168 - val_loss: 0.6515 - val_accuracy: 0.6039\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 208s 2s/step - loss: 0.6254 - accuracy: 0.6220 - val_loss: 0.6166 - val_accuracy: 0.6039\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 208s 2s/step - loss: 0.5971 - accuracy: 0.6484 - val_loss: 0.5984 - val_accuracy: 0.6946\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.5902 - accuracy: 0.6996 - val_loss: 0.5858 - val_accuracy: 0.7173\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 208s 2s/step - loss: 0.5829 - accuracy: 0.7099 - val_loss: 0.5765 - val_accuracy: 0.7183\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.5779 - accuracy: 0.7095 - val_loss: 0.6276 - val_accuracy: 0.6351\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.6047 - accuracy: 0.6698 - val_loss: 0.6970 - val_accuracy: 0.5276\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.6381 - accuracy: 0.6132 - val_loss: 0.6155 - val_accuracy: 0.6322\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 208s 2s/step - loss: 0.6119 - accuracy: 0.6282 - val_loss: 0.6226 - val_accuracy: 0.6115\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.5999 - accuracy: 0.6503 - val_loss: 0.5893 - val_accuracy: 0.6755\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 221s 3s/step - loss: 0.5984 - accuracy: 0.6987 - val_loss: 0.5715 - val_accuracy: 0.7381\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 221s 3s/step - loss: 0.6190 - accuracy: 0.6610 - val_loss: 0.6183 - val_accuracy: 0.6911\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 223s 3s/step - loss: 0.6065 - accuracy: 0.6987 - val_loss: 0.6009 - val_accuracy: 0.6962\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 221s 3s/step - loss: 0.6099 - accuracy: 0.6801 - val_loss: 0.5946 - val_accuracy: 0.6845\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 222s 3s/step - loss: 0.6323 - accuracy: 0.6414 - val_loss: 0.6272 - val_accuracy: 0.6297\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.6299 - accuracy: 0.6437 - val_loss: 0.6204 - val_accuracy: 0.6439\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6323 - accuracy: 0.6336 - val_loss: 0.6164 - val_accuracy: 0.6473\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6273 - accuracy: 0.6442 - val_loss: 0.6330 - val_accuracy: 0.6113\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 215s 3s/step - loss: 0.6292 - accuracy: 0.6308 - val_loss: 0.6179 - val_accuracy: 0.6382\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6254 - accuracy: 0.6446 - val_loss: 0.5922 - val_accuracy: 0.6986\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6215 - accuracy: 0.6591 - val_loss: 0.6189 - val_accuracy: 0.6420\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6636 - accuracy: 0.6261 - val_loss: 0.6743 - val_accuracy: 0.6030\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6626 - accuracy: 0.6181 - val_loss: 0.6678 - val_accuracy: 0.6042\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6593 - accuracy: 0.6196 - val_loss: 0.6628 - val_accuracy: 0.6083\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.6536 - accuracy: 0.6228 - val_loss: 0.6501 - val_accuracy: 0.6149\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6430 - accuracy: 0.6321 - val_loss: 0.6339 - val_accuracy: 0.6343\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6333 - accuracy: 0.6303 - val_loss: 0.6357 - val_accuracy: 0.6185\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6307 - accuracy: 0.6344 - val_loss: 0.6225 - val_accuracy: 0.6328\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6414 - accuracy: 0.6225 - val_loss: 0.6264 - val_accuracy: 0.6213\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 219s 3s/step - loss: 0.6781 - accuracy: 0.6208 - val_loss: 0.6695 - val_accuracy: 0.6037\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6614 - accuracy: 0.6188 - val_loss: 0.6696 - val_accuracy: 0.6043\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6594 - accuracy: 0.6202 - val_loss: 0.6647 - val_accuracy: 0.6051\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6560 - accuracy: 0.6223 - val_loss: 0.6540 - val_accuracy: 0.6192\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6496 - accuracy: 0.6306 - val_loss: 0.6476 - val_accuracy: 0.6210\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6400 - accuracy: 0.6449 - val_loss: 0.6117 - val_accuracy: 0.6835\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6169 - accuracy: 0.6773 - val_loss: 0.6072 - val_accuracy: 0.6842\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6228 - accuracy: 0.6589 - val_loss: 0.6560 - val_accuracy: 0.6194\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6419 - accuracy: 0.6284 - val_loss: 0.6411 - val_accuracy: 0.6199\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6287 - accuracy: 0.6360 - val_loss: 0.6392 - val_accuracy: 0.6264\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6225 - accuracy: 0.6376 - val_loss: 0.6169 - val_accuracy: 0.6318\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.6234 - accuracy: 0.6435 - val_loss: 0.6391 - val_accuracy: 0.6182\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6373 - accuracy: 0.6375 - val_loss: 0.6228 - val_accuracy: 0.6418\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.6296 - accuracy: 0.6436 - val_loss: 0.6315 - val_accuracy: 0.6346\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6243 - accuracy: 0.6479 - val_loss: 0.6173 - val_accuracy: 0.6457\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6211 - accuracy: 0.6439 - val_loss: 0.6464 - val_accuracy: 0.5818\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.6366 - accuracy: 0.6043 - val_loss: 0.6126 - val_accuracy: 0.6493\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 216s 3s/step - loss: 0.6120 - accuracy: 0.6491 - val_loss: 0.6003 - val_accuracy: 0.6733\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6051 - accuracy: 0.6612 - val_loss: 0.5957 - val_accuracy: 0.6806\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.5988 - accuracy: 0.6637 - val_loss: 0.5853 - val_accuracy: 0.6761\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6091 - accuracy: 0.6520 - val_loss: 0.6029 - val_accuracy: 0.6290\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 217s 3s/step - loss: 0.6113 - accuracy: 0.6400 - val_loss: 0.5992 - val_accuracy: 0.6528\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 214s 3s/step - loss: 0.6052 - accuracy: 0.6474 - val_loss: 0.5972 - val_accuracy: 0.6640\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6053 - accuracy: 0.6504 - val_loss: 0.5889 - val_accuracy: 0.6652\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.6027 - accuracy: 0.6541 - val_loss: 0.5884 - val_accuracy: 0.6665\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.5986 - accuracy: 0.6550 - val_loss: 0.5987 - val_accuracy: 0.6624\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.5979 - accuracy: 0.6570 - val_loss: 0.5916 - val_accuracy: 0.6688\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 215s 3s/step - loss: 0.5936 - accuracy: 0.6611 - val_loss: 0.5869 - val_accuracy: 0.6675\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 218s 3s/step - loss: 0.5978 - accuracy: 0.6603 - val_loss: 0.5986 - val_accuracy: 0.6523\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 225s 3s/step - loss: 0.5899 - accuracy: 0.6672 - val_loss: 0.5836 - val_accuracy: 0.6732\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 254s 3s/step - loss: 0.6285 - accuracy: 0.6246 - val_loss: 0.6660 - val_accuracy: 0.6119\n",
      "Epoch 88/100\n",
      "66/85 [======================>.......] - ETA: 1:13 - loss: 0.6539 - accuracy: 0.6173"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cec367b4740e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print this only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross valiation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAXLEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBED_DIMEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.medium.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2d4fc8ad99d5>\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, eps, maxlen, dimen)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# this is complaining about string to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# verbose=1 for ascii art, verbose=0 for none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 validation_data=(X_valid,y_valid) )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model2=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model2.save(FILENAME+'.medium.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaFKdlJ3mqTz"
   },
   "source": [
    "## Len 2K-3Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uDUUlKuqmqT0",
    "outputId": "23054b7d-465b-4768-b2b0-e89f5f69882a"
   },
   "outputs": [],
   "source": [
    "MINLEN=2000\n",
    "MAXLEN=3000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model3=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model3.save(FILENAME+'.long.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Skqq7LKXmqT4"
   },
   "outputs": [],
   "source": [
    "#model1.save(FILENAME+'.short.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW619OmCmqT7"
   },
   "outputs": [],
   "source": [
    "\n",
    "#abc\n",
    "#efg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#hij\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n47g-tyC9GHT"
   },
   "source": [
    "c\n",
    "d\n",
    "e\n",
    "f \n",
    "g\n",
    "h\n",
    "i\n",
    "j\n",
    "k\n",
    "l\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GRU_105.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
