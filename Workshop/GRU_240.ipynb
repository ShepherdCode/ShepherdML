{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GRU_240.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# GRU 240\n",
        "Test the RNA length effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh6XplUvC0j0",
        "outputId": "91727546-2b7e-436e-e026-79721f8ba3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
        "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
        "DATAPATH=\"\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    NC_FILENAME = DATAPATH+NC_FILENAME\n",
        "    PC_FILENAME = DATAPATH+PC_FILENAME\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATAPATH=\"\" \n",
        "\n",
        "EPOCHS=100  # use 2 for debug, 200 for real\n",
        "K=3\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=4\n",
        "FILENAME='GRU240'\n",
        "NEURONS=4\n",
        "ACT=\"tanh\"\n",
        "DROP=0.5\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def compile_model(model):\n",
        "    adam_default_learn_rate = 0.001\n",
        "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = adam_default_learn_rate*10,\n",
        "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
        "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "    alrd = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE...\")\n",
        "    #model.compile(loss=bc, optimizer=alrd, metrics=[\"accuracy\"])\n",
        "    model.compile(loss=bc, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return model\n",
        "\n",
        "def build_model():\n",
        "    embed_layer  = keras.layers.Embedding(\n",
        "        #VOCABULARY_SIZE, EMBED_DIMEN, input_length=1000, input_length=1000, mask_zero=True)\n",
        "        #input_dim=[None,VOCABULARY_SIZE], output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "        input_dim=VOCABULARY_SIZE, output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "    #rnn1_layer = keras.layers.Bidirectional(\n",
        "    rnn1_layer = keras.layers.GRU(NEURONS, return_sequences=False,  #   True, \n",
        "          input_shape=[1000,EMBED_DIMEN], activation=ACT, dropout=DROP)#)#bi\n",
        "    #rnn2_layer = keras.layers.Bidirectional(\n",
        "    rnn2_layer = keras.layers.GRU(NEURONS, return_sequences=False, \n",
        "        activation=ACT, dropout=DROP)#)#bi\n",
        "    dense1_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    #drop1_layer = keras.layers.Dropout(DROP)\n",
        "    dense2_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    #drop2_layer = keras.layers.Dropout(DROP)\n",
        "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\", dtype=dt)\n",
        "    mlp = keras.models.Sequential()\n",
        "    mlp.add(embed_layer)\n",
        "    mlp.add(rnn1_layer)\n",
        "    #mlp.add(rnn2_layer)\n",
        "    #mlp.add(dense1_layer)\n",
        "    #mlp.add(drop1_layer)\n",
        "    #mlp.add(dense2_layer)\n",
        "    #mlp.add(drop2_layer)\n",
        "    mlp.add(output_layer)\n",
        "    mlpc = compile_model(mlp)\n",
        "    return mlpc"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "## Load and partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "# Assume file was preprocessed to contain one line per seq.\n",
        "# Prefer Pandas dataframe but df does not support append.\n",
        "# For conversion to tensor, must avoid python lists.\n",
        "def load_fasta(filename,label):\n",
        "    DEFLINE='>'\n",
        "    labels=[]\n",
        "    seqs=[]\n",
        "    lens=[]\n",
        "    nums=[]\n",
        "    num=0\n",
        "    with open (filename,'r') as infile:\n",
        "        for line in infile:\n",
        "            if line[0]!=DEFLINE:\n",
        "                seq=line.rstrip()\n",
        "                num += 1   # first seqnum is 1\n",
        "                seqlen=len(seq)\n",
        "                nums.append(num)\n",
        "                labels.append(label)\n",
        "                seqs.append(seq)\n",
        "                lens.append(seqlen)\n",
        "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
        "    df2=pd.DataFrame(labels,columns=['class'])\n",
        "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
        "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
        "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
        "    return df\n",
        "\n",
        "def separate_X_and_y(data):\n",
        "    y=   data[['class']].copy()\n",
        "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
        "    return (X,y)\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRAaO9jP9Kcr"
      },
      "source": [
        "## Make K-mers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xcZ4Mr9Kcs"
      },
      "source": [
        "def make_kmer_table(K):\n",
        "    npad='N'*K\n",
        "    shorter_kmers=['']\n",
        "    for i in range(K):\n",
        "        longer_kmers=[]\n",
        "        for mer in shorter_kmers:\n",
        "            longer_kmers.append(mer+'A')\n",
        "            longer_kmers.append(mer+'C')\n",
        "            longer_kmers.append(mer+'G')\n",
        "            longer_kmers.append(mer+'T')\n",
        "        shorter_kmers = longer_kmers\n",
        "    all_kmers = shorter_kmers\n",
        "    kmer_dict = {}\n",
        "    kmer_dict[npad]=0\n",
        "    value=1\n",
        "    for mer in all_kmers:\n",
        "        kmer_dict[mer]=value\n",
        "        value += 1\n",
        "    return kmer_dict\n",
        "\n",
        "KMER_TABLE=make_kmer_table(K)\n",
        "\n",
        "def strings_to_vectors(data,uniform_len):\n",
        "    all_seqs=[]\n",
        "    for seq in data['sequence']:\n",
        "        i=0\n",
        "        seqlen=len(seq)\n",
        "        kmers=[]\n",
        "        while i < seqlen-K+1 -1:  # stop at minus one for spaced seed\n",
        "            #kmer=seq[i:i+2]+seq[i+3:i+5]    # SPACED SEED 2/1/2 for K=4\n",
        "            kmer=seq[i:i+K]  \n",
        "            i += 1\n",
        "            value=KMER_TABLE[kmer]\n",
        "            kmers.append(value)\n",
        "        pad_val=0\n",
        "        while i < uniform_len:\n",
        "            kmers.append(pad_val)\n",
        "            i += 1\n",
        "        all_seqs.append(kmers)\n",
        "    pd2d=pd.DataFrame(all_seqs)\n",
        "    return pd2d   # return 2D dataframe, uniform dimensions"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtA0xiV9Kcv"
      },
      "source": [
        "def make_kmers(MAXLEN,train_set):\n",
        "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
        "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
        "    # From pandas dataframe to numpy to list to numpy\n",
        "    num_seqs=len(X_train_kmers)\n",
        "    tmp_seqs=[]\n",
        "    for i in range(num_seqs):\n",
        "        kmer_sequence=X_train_kmers.iloc[i]\n",
        "        tmp_seqs.append(kmer_sequence)\n",
        "    X_train_kmers=np.array(tmp_seqs)\n",
        "    tmp_seqs=None\n",
        "    labels=y_train_all.to_numpy()\n",
        "    return (X_train_kmers,labels)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXyySyO9Kcz"
      },
      "source": [
        "def make_frequencies(Xin):\n",
        "    Xout=[]\n",
        "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
        "    for seq in Xin:\n",
        "        freqs =[0] * VOCABULARY_SIZE\n",
        "        total = 0\n",
        "        for kmerval in seq:\n",
        "            freqs[kmerval] += 1\n",
        "            total += 1\n",
        "        for c in range(VOCABULARY_SIZE):\n",
        "            freqs[c] = freqs[c]/total\n",
        "        Xout.append(freqs)\n",
        "    Xnum = np.asarray(Xout)\n",
        "    return (Xnum)\n",
        "def make_slice(data_set,min_len,max_len):\n",
        "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
        "    return slice"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "bestname=DATAPATH+FILENAME+\".best\"\n",
        "def just_train(X,y): # give me training set\n",
        "    model=build_model()\n",
        "    print(model.summary())\n",
        "    mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
        "        filepath=bestname, save_best_only=True, \n",
        "        monitor='accuracy', mode='max')]   \n",
        "    print(\"FIT\")\n",
        "    start_time=time.time()\n",
        "    history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "            epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "            callbacks=mycallbacks )  # no validation data\n",
        "    end_time=time.time()\n",
        "    elapsed_time=(end_time-start_time)                        \n",
        "    print(\"Train %d epochs, %d sec\"%(EPOCHS,elapsed_time))\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "def just_evaluate(X,y):  # give me validation set\n",
        "    best_model=keras.models.load_model(bestname)\n",
        "    scores = best_model.evaluate(X, y, verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Train on RNA length-based slice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fNo6sn9KdH",
        "outputId": "3ab6b404-af3e-48b0-e32b-418c810db733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#      A    B    C     D     E     F\n",
        "# 200, 500, 750, 1000, 1500, 3000, 30000 \n",
        "print(\"Load data from files.\")\n",
        "nc_seq=load_fasta(NC_FILENAME,0)\n",
        "pc_seq=load_fasta(PC_FILENAME,1)\n",
        "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "def get_x_and_y(train_set,minlen,maxlen):\n",
        "  subset=make_slice(train_set,minlen,maxlen)\n",
        "  (X_set,y_set)=make_kmers(maxlen,subset)\n",
        "  print(\"Shape of X is \"+str(X_set.shape))\n",
        "  L=len(X_set)\n",
        "  T=int(0.80*L+0.5)\n",
        "  print(\"Total %d, Train portion %d\"%(L,T))\n",
        "  X_train=X_set[:T]\n",
        "  y_train=y_set[:T]\n",
        "  X_valid=X_set[T:]\n",
        "  y_valid=y_set[T:]\n",
        "  return (X_train,y_train,X_valid,y_valid)\n",
        "\n",
        "MINLEN=200\n",
        "MAXLEN=700\n",
        "(X_train,y_train,X_valid,y_valid)=get_x_and_y(train_set,MINLEN,MAXLEN)\n",
        "print(\"Loaded\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Shape of X is (10501, 700)\n",
            "Total 10501, Train portion 8401\n",
            "Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "5ec7e46b-2c8c-4f07-f5c0-58f383f59c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print (\"Train on \",MINLEN,\"-\",MAXLEN)\n",
        "just_train(X_train,y_train)  \n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on  200 - 700\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 4)           260       \n",
            "_________________________________________________________________\n",
            "gru_16 (GRU)                 (None, 4)                 120       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 385\n",
            "Trainable params: 385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FIT\n",
            "Epoch 1/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.9211INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 15s 59ms/step - loss: 0.3851 - accuracy: 0.9211\n",
            "Epoch 2/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9268INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 59ms/step - loss: 0.2607 - accuracy: 0.9268\n",
            "Epoch 3/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2602 - accuracy: 0.9268\n",
            "Epoch 4/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2592 - accuracy: 0.9268\n",
            "Epoch 5/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2585 - accuracy: 0.9268\n",
            "Epoch 6/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2579 - accuracy: 0.9268\n",
            "Epoch 7/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2560 - accuracy: 0.9268\n",
            "Epoch 8/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2558 - accuracy: 0.9268\n",
            "Epoch 9/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.9269INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 64ms/step - loss: 0.2556 - accuracy: 0.9269\n",
            "Epoch 10/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2543 - accuracy: 0.9269\n",
            "Epoch 11/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.9273INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 60ms/step - loss: 0.2531 - accuracy: 0.9273\n",
            "Epoch 12/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2522 - accuracy: 0.9272\n",
            "Epoch 13/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2508 - accuracy: 0.9272\n",
            "Epoch 14/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2480 - accuracy: 0.9273\n",
            "Epoch 15/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2453 - accuracy: 0.9273\n",
            "Epoch 16/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9276INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 64ms/step - loss: 0.2364 - accuracy: 0.9276\n",
            "Epoch 17/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2308 - accuracy: 0.9274\n",
            "Epoch 18/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2312 - accuracy: 0.9273\n",
            "Epoch 19/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2273 - accuracy: 0.9272\n",
            "Epoch 20/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2207 - accuracy: 0.9274\n",
            "Epoch 21/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2204 - accuracy: 0.9274\n",
            "Epoch 22/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9280INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 59ms/step - loss: 0.2167 - accuracy: 0.9280\n",
            "Epoch 23/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2143 - accuracy: 0.9276\n",
            "Epoch 24/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2145 - accuracy: 0.9277\n",
            "Epoch 25/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2125 - accuracy: 0.9280\n",
            "Epoch 26/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9286INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 65ms/step - loss: 0.2146 - accuracy: 0.9286\n",
            "Epoch 27/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2136 - accuracy: 0.9280\n",
            "Epoch 28/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2117 - accuracy: 0.9283\n",
            "Epoch 29/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2076 - accuracy: 0.9282\n",
            "Epoch 30/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9287INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 60ms/step - loss: 0.2089 - accuracy: 0.9287\n",
            "Epoch 31/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2106 - accuracy: 0.9279\n",
            "Epoch 32/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9306INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 60ms/step - loss: 0.2060 - accuracy: 0.9306\n",
            "Epoch 33/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2058 - accuracy: 0.9291\n",
            "Epoch 34/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2046 - accuracy: 0.9302\n",
            "Epoch 35/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2060 - accuracy: 0.9300\n",
            "Epoch 36/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2025 - accuracy: 0.9294\n",
            "Epoch 37/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2056 - accuracy: 0.9299\n",
            "Epoch 38/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9314INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 65ms/step - loss: 0.2017 - accuracy: 0.9314\n",
            "Epoch 39/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2026 - accuracy: 0.9313\n",
            "Epoch 40/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2023 - accuracy: 0.9298\n",
            "Epoch 41/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9317INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 15s 59ms/step - loss: 0.1994 - accuracy: 0.9317\n",
            "Epoch 42/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2010 - accuracy: 0.9306\n",
            "Epoch 43/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2005 - accuracy: 0.9313\n",
            "Epoch 44/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.9320INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 63ms/step - loss: 0.1987 - accuracy: 0.9320\n",
            "Epoch 45/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1982 - accuracy: 0.9307\n",
            "Epoch 46/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9330INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 15s 58ms/step - loss: 0.2000 - accuracy: 0.9330\n",
            "Epoch 47/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1982 - accuracy: 0.9327\n",
            "Epoch 48/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1989 - accuracy: 0.9323\n",
            "Epoch 49/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.9354INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 15s 59ms/step - loss: 0.1965 - accuracy: 0.9354\n",
            "Epoch 50/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1955 - accuracy: 0.9325\n",
            "Epoch 51/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1958 - accuracy: 0.9325\n",
            "Epoch 52/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1977 - accuracy: 0.9335\n",
            "Epoch 53/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1960 - accuracy: 0.9324\n",
            "Epoch 54/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1976 - accuracy: 0.9325\n",
            "Epoch 55/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1972 - accuracy: 0.9320\n",
            "Epoch 56/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1956 - accuracy: 0.9320\n",
            "Epoch 57/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1968 - accuracy: 0.9345\n",
            "Epoch 58/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1965 - accuracy: 0.9335\n",
            "Epoch 59/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1957 - accuracy: 0.9324\n",
            "Epoch 60/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1955 - accuracy: 0.9337\n",
            "Epoch 61/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1956 - accuracy: 0.9342\n",
            "Epoch 62/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1950 - accuracy: 0.9354\n",
            "Epoch 63/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1946 - accuracy: 0.9320\n",
            "Epoch 64/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1962 - accuracy: 0.9347\n",
            "Epoch 65/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1924 - accuracy: 0.9345\n",
            "Epoch 66/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1955 - accuracy: 0.9335\n",
            "Epoch 67/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1938 - accuracy: 0.9339\n",
            "Epoch 68/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1952 - accuracy: 0.9333\n",
            "Epoch 69/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1946 - accuracy: 0.9325\n",
            "Epoch 70/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1935 - accuracy: 0.9330\n",
            "Epoch 71/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1924 - accuracy: 0.9349\n",
            "Epoch 72/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9357INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 65ms/step - loss: 0.1936 - accuracy: 0.9357\n",
            "Epoch 73/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1956 - accuracy: 0.9329\n",
            "Epoch 74/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1911 - accuracy: 0.9354\n",
            "Epoch 75/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1928 - accuracy: 0.9344\n",
            "Epoch 76/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1941 - accuracy: 0.9339\n",
            "Epoch 77/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1901 - accuracy: 0.9356\n",
            "Epoch 78/100\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.1930 - accuracy: 0.9336\n",
            "Epoch 79/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1940 - accuracy: 0.9313\n",
            "Epoch 80/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1939 - accuracy: 0.9352\n",
            "Epoch 81/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1933 - accuracy: 0.9352\n",
            "Epoch 82/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1910 - accuracy: 0.9338\n",
            "Epoch 83/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1930 - accuracy: 0.9339\n",
            "Epoch 84/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1957 - accuracy: 0.9333\n",
            "Epoch 85/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9362INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 16s 59ms/step - loss: 0.1910 - accuracy: 0.9362\n",
            "Epoch 86/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1938 - accuracy: 0.9327\n",
            "Epoch 87/100\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9367INFO:tensorflow:Assets written to: /content/drive/My Drive/data/GRU240.best/assets\n",
            "263/263 [==============================] - 17s 64ms/step - loss: 0.1932 - accuracy: 0.9367\n",
            "Epoch 88/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1919 - accuracy: 0.9350\n",
            "Epoch 89/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1926 - accuracy: 0.9344\n",
            "Epoch 90/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1928 - accuracy: 0.9343\n",
            "Epoch 91/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1888 - accuracy: 0.9352\n",
            "Epoch 92/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1907 - accuracy: 0.9339\n",
            "Epoch 93/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1907 - accuracy: 0.9348\n",
            "Epoch 94/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1924 - accuracy: 0.9350\n",
            "Epoch 95/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1918 - accuracy: 0.9352\n",
            "Epoch 96/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1932 - accuracy: 0.9336\n",
            "Epoch 97/100\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1925 - accuracy: 0.9335\n",
            "Epoch 98/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1895 - accuracy: 0.9336\n",
            "Epoch 99/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1907 - accuracy: 0.9343\n",
            "Epoch 100/100\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.1916 - accuracy: 0.9339\n",
            "Train 100 epochs, 913 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0As2pLvQJXm",
        "outputId": "fdc36a6b-457d-40c6-852d-2dc9bd488701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (\"Evaluate on A\")\n",
        "(X_train,y_train,X_valid_A,y_valid_A)=get_x_and_y(train_set,200,700)\n",
        "just_evaluate(X_valid_A,y_valid_A) \n",
        "(X_valid_A,y_valid_A)=(None,None)\n",
        "print (\"Evaluate on B\")\n",
        "(X_train,y_train,X_valid_B,y_valid_B)=get_x_and_y(train_set,700,900)\n",
        "just_evaluate(X_valid_B,y_valid_B)  \n",
        "(X_valid_B,y_valid_B)=(None,None)\n",
        "print (\"Evaluate on C\")\n",
        "(X_train,y_train,X_valid_C,y_valid_C)=get_x_and_y(train_set,900,1200)\n",
        "just_evaluate(X_valid_C,y_valid_C)  \n",
        "(X_valid_C,y_valid_C)=(None,None)\n",
        "print (\"Evaluate on D\")\n",
        "(X_train,y_train,X_valid_D,y_valid_D)=get_x_and_y(train_set,1200,1700)\n",
        "just_evaluate(X_valid_D,y_valid_D)  \n",
        "(X_valid_D,y_valid_D)=(None,None)\n",
        "print (\"Evaluate on E\")\n",
        "(X_train,y_train,X_valid_E,y_valid_E)=get_x_and_y(train_set,1700,2500)\n",
        "just_evaluate(X_valid_E,y_valid_E)  \n",
        "(X_valid_E,y_valid_E)=(None,None)\n",
        "print (\"Evaluate on F\")\n",
        "(X_train,y_train,X_valid_F,y_valid_F)=get_x_and_y(train_set,2500,30000)\n",
        "just_evaluate(X_valid_F,y_valid_F) \n",
        "(X_valid_F,y_valid_F)=(None,None) \n",
        "\n",
        "print (\"Done\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on A\n",
            "Shape of X is (10501, 700)\n",
            "Total 10501, Train portion 8401\n",
            "accuracy: 16.62%\n",
            "Evaluate on B\n",
            "Shape of X is (4148, 900)\n",
            "Total 4148, Train portion 3318\n",
            "accuracy: 50.60%\n",
            "Evaluate on C\n",
            "Shape of X is (3636, 1200)\n",
            "Total 3636, Train portion 2909\n",
            "accuracy: 69.60%\n",
            "Evaluate on D\n",
            "Shape of X is (3942, 1700)\n",
            "Total 3942, Train portion 3154\n",
            "accuracy: 77.16%\n",
            "Evaluate on E\n",
            "Shape of X is (4395, 2500)\n",
            "Total 4395, Train portion 3516\n",
            "accuracy: 82.25%\n",
            "Evaluate on F\n",
            "Shape of X is (5438, 30000)\n",
            "Total 5438, Train portion 4350\n",
            "accuracy: 79.60%\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}