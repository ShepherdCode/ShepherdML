{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVjzLkNimqS8"
   },
   "source": [
    "# GRU 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "ubTxCruBmqS-",
    "outputId": "fd00113c-6a93-46ad-9f73-497b0e5e41d5"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#PATH='/content/drive/'\n",
    "#drive.mount(PATH)\n",
    "#DATAPATH=PATH+'My Drive/data/'\n",
    "#PC_FILENAME = DATAPATH+'pcRNA.fasta'\n",
    "#NC_FILENAME = DATAPATH+'ncRNA.fasta'\n",
    "PC_FILENAME = 'pcRNA.fasta'\n",
    "NC_FILENAME = 'ncRNA.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7OrrqZOfmqTF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=100\n",
    "SPLITS=1\n",
    "K=1\n",
    "EMBED_DIMEN=16\n",
    "FILENAME='GRU102'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Jl4LG19mqTK"
   },
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kffm79SEmqTL"
   },
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Uoj6Nc3tmqTQ"
   },
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cn1oP6rcmqTa"
   },
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    vocabulary_size=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "\n",
    "    neurons = 32\n",
    "    rnn = keras.models.Sequential()\n",
    "    embed_layer = keras.layers.Embedding(\n",
    "        vocabulary_size,EMBED_DIMEN,input_length=maxlen);\n",
    "    rnn1_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(neurons, return_sequences=True, dropout=0.50, \n",
    "            input_shape=[maxlen,dimen]))\n",
    "    rnn2_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(neurons, dropout=0.50, return_sequences=True))\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    dense1_layer = keras.layers.Dense(neurons,activation=act,dtype=dt)\n",
    "    dense2_layer = keras.layers.Dense(neurons,activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,activation=act,dtype=dt)\n",
    "\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    rnn.add(rnn2_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7xpthbwcmqTe"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    rnn2=None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        start_time=time.time()\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "        end_time=time.time()\n",
    "        elapsed_time=(end_time-start_time)\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs, %d sec\"%(fold,eps,elapsed_time))\n",
    "                      \n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "    return rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5E_UIKJEmqTh"
   },
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "Dwd6l1s8mqTn",
    "outputId": "40080e35-404c-424a-f1b5-dfbbf9c8677c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9089</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>6070</td>\n",
       "      <td>1</td>\n",
       "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>18550</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3387</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>6410</td>\n",
       "      <td>1</td>\n",
       "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7641</td>\n",
       "      <td>1</td>\n",
       "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14109</td>\n",
       "      <td>0</td>\n",
       "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...   \n",
       "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...   \n",
       "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...   \n",
       "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...   \n",
       "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...   \n",
       "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...   \n",
       "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...   \n",
       "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...   \n",
       "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...   \n",
       "\n",
       "       seqlen  \n",
       "1280      348  \n",
       "9088      534  \n",
       "6069      592  \n",
       "18549     945  \n",
       "15027    4382  \n",
       "...       ...  \n",
       "3386      578  \n",
       "6495      562  \n",
       "6409      740  \n",
       "7640     3156  \n",
       "14108     466  \n",
       "\n",
       "[30290 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta(NC_FILENAME,0)\n",
    "pc_seq=load_fasta(PC_FILENAME,1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3KW8eUOmqTs",
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_evesETdmqTs",
    "outputId": "fd3775f6-979c-404d-f3c1-b92ac8770355",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [200 - 1000)\n",
      "original (30290, 4)\n",
      "no short (30290, 4)\n",
      "no long, no short (8879, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(8879, 1)\n",
      "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
      "Name: 1280, dtype: object\n",
      "348\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[1 3 4 ... 0 0 0]\n",
      " [1 3 1 ... 0 0 0]\n",
      " [3 1 2 ... 0 0 0]\n",
      " ...\n",
      " [3 2 1 ... 0 0 0]\n",
      " [4 3 1 ... 0 0 0]\n",
      " [3 1 1 ... 0 0 0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 16)          80        \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 31,665\n",
      "Trainable params: 31,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/100\n",
      "222/222 [==============================] - 438s 2s/step - loss: 0.6768 - accuracy: 0.5775 - val_loss: 0.6866 - val_accuracy: 0.5712\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 452s 2s/step - loss: 0.6597 - accuracy: 0.6092 - val_loss: 0.6264 - val_accuracy: 0.6680\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 501s 2s/step - loss: 0.6507 - accuracy: 0.6229 - val_loss: 0.6732 - val_accuracy: 0.5852\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 420s 2s/step - loss: 0.6525 - accuracy: 0.6157 - val_loss: 0.6399 - val_accuracy: 0.6286\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - 417s 2s/step - loss: 0.6345 - accuracy: 0.6408 - val_loss: 0.6558 - val_accuracy: 0.6390\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 430s 2s/step - loss: 0.6107 - accuracy: 0.6686 - val_loss: 0.6292 - val_accuracy: 0.6496\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 429s 2s/step - loss: 0.6032 - accuracy: 0.6807 - val_loss: 0.6063 - val_accuracy: 0.6789\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 449s 2s/step - loss: 0.5916 - accuracy: 0.6856 - val_loss: 0.6161 - val_accuracy: 0.6647\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - 418s 2s/step - loss: 0.5825 - accuracy: 0.6946 - val_loss: 0.5846 - val_accuracy: 0.6905\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 376s 2s/step - loss: 0.5773 - accuracy: 0.6965 - val_loss: 0.5836 - val_accuracy: 0.6921\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5850 - accuracy: 0.6925 - val_loss: 0.6244 - val_accuracy: 0.6545\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 371s 2s/step - loss: 0.5961 - accuracy: 0.6815 - val_loss: 0.6009 - val_accuracy: 0.6758\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - 354s 2s/step - loss: 0.5847 - accuracy: 0.6887 - val_loss: 0.5840 - val_accuracy: 0.6928\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 368s 2s/step - loss: 0.5724 - accuracy: 0.6988 - val_loss: 0.5800 - val_accuracy: 0.6982\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5706 - accuracy: 0.7015 - val_loss: 0.5757 - val_accuracy: 0.7021\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 376s 2s/step - loss: 0.5674 - accuracy: 0.7011 - val_loss: 0.5915 - val_accuracy: 0.6820\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - 360s 2s/step - loss: 0.5621 - accuracy: 0.7059 - val_loss: 0.5733 - val_accuracy: 0.7073\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.5600 - accuracy: 0.7082 - val_loss: 0.5677 - val_accuracy: 0.7087\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 370s 2s/step - loss: 0.5568 - accuracy: 0.7107 - val_loss: 0.5748 - val_accuracy: 0.6984\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5543 - accuracy: 0.7109 - val_loss: 0.5668 - val_accuracy: 0.7046\n",
      "Epoch 21/100\n",
      "222/222 [==============================] - 367s 2s/step - loss: 0.5515 - accuracy: 0.7135 - val_loss: 0.5734 - val_accuracy: 0.6997\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 348s 2s/step - loss: 0.5493 - accuracy: 0.7147 - val_loss: 0.5699 - val_accuracy: 0.6986\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 353s 2s/step - loss: 0.5439 - accuracy: 0.7185 - val_loss: 0.5670 - val_accuracy: 0.7074\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 347s 2s/step - loss: 0.5474 - accuracy: 0.7145 - val_loss: 0.5831 - val_accuracy: 0.6882\n",
      "Epoch 25/100\n",
      "222/222 [==============================] - 341s 2s/step - loss: 0.5407 - accuracy: 0.7213 - val_loss: 0.5595 - val_accuracy: 0.7121\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 374s 2s/step - loss: 0.5404 - accuracy: 0.7192 - val_loss: 0.5740 - val_accuracy: 0.6946\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 362s 2s/step - loss: 0.5431 - accuracy: 0.7169 - val_loss: 0.5581 - val_accuracy: 0.7089\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 389s 2s/step - loss: 0.5375 - accuracy: 0.7231 - val_loss: 0.5569 - val_accuracy: 0.7164\n",
      "Epoch 29/100\n",
      "222/222 [==============================] - 367s 2s/step - loss: 0.5380 - accuracy: 0.7251 - val_loss: 0.5506 - val_accuracy: 0.7215\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 365s 2s/step - loss: 0.5347 - accuracy: 0.7255 - val_loss: 0.5539 - val_accuracy: 0.7137\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 369s 2s/step - loss: 0.5346 - accuracy: 0.7253 - val_loss: 0.5580 - val_accuracy: 0.7105\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 379s 2s/step - loss: 0.5338 - accuracy: 0.7286 - val_loss: 0.5480 - val_accuracy: 0.7207\n",
      "Epoch 33/100\n",
      "222/222 [==============================] - 370s 2s/step - loss: 0.5316 - accuracy: 0.7265 - val_loss: 0.5570 - val_accuracy: 0.7161\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 382s 2s/step - loss: 0.5288 - accuracy: 0.7307 - val_loss: 0.5474 - val_accuracy: 0.7284\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 388s 2s/step - loss: 0.5282 - accuracy: 0.7274 - val_loss: 0.5683 - val_accuracy: 0.7032\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 380s 2s/step - loss: 0.5279 - accuracy: 0.7304 - val_loss: 0.5456 - val_accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.5275 - accuracy: 0.7311 - val_loss: 0.5560 - val_accuracy: 0.7070\n",
      "Epoch 38/100\n",
      "222/222 [==============================] - 365s 2s/step - loss: 0.5253 - accuracy: 0.7313 - val_loss: 0.5448 - val_accuracy: 0.7206\n",
      "Epoch 39/100\n",
      "222/222 [==============================] - 368s 2s/step - loss: 0.5252 - accuracy: 0.7327 - val_loss: 0.5472 - val_accuracy: 0.7266\n",
      "Epoch 40/100\n",
      "222/222 [==============================] - 425s 2s/step - loss: 0.5229 - accuracy: 0.7364 - val_loss: 0.5455 - val_accuracy: 0.7204\n",
      "Epoch 41/100\n",
      "222/222 [==============================] - 453s 2s/step - loss: 0.5210 - accuracy: 0.7363 - val_loss: 0.5457 - val_accuracy: 0.7245\n",
      "Epoch 42/100\n",
      "222/222 [==============================] - 466s 2s/step - loss: 0.5230 - accuracy: 0.7359 - val_loss: 0.5474 - val_accuracy: 0.7208\n",
      "Epoch 43/100\n",
      "222/222 [==============================] - 431s 2s/step - loss: 0.5198 - accuracy: 0.7387 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 44/100\n",
      "222/222 [==============================] - 344s 2s/step - loss: 0.5215 - accuracy: 0.7346 - val_loss: 0.5420 - val_accuracy: 0.7245\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 334s 2s/step - loss: 0.5168 - accuracy: 0.7443 - val_loss: 0.5389 - val_accuracy: 0.7298\n",
      "Epoch 46/100\n",
      "222/222 [==============================] - 333s 1s/step - loss: 0.5189 - accuracy: 0.7372 - val_loss: 0.5434 - val_accuracy: 0.7284\n",
      "Epoch 47/100\n",
      "222/222 [==============================] - 334s 2s/step - loss: 0.5208 - accuracy: 0.7363 - val_loss: 0.5690 - val_accuracy: 0.7009\n",
      "Epoch 48/100\n",
      "222/222 [==============================] - 332s 1s/step - loss: 0.5153 - accuracy: 0.7379 - val_loss: 0.5531 - val_accuracy: 0.7130\n",
      "Epoch 49/100\n",
      "222/222 [==============================] - 334s 2s/step - loss: 0.5186 - accuracy: 0.7393 - val_loss: 0.5364 - val_accuracy: 0.7272\n",
      "Epoch 50/100\n",
      "222/222 [==============================] - 338s 2s/step - loss: 0.5145 - accuracy: 0.7405 - val_loss: 0.5327 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "222/222 [==============================] - 335s 2s/step - loss: 0.5143 - accuracy: 0.7428 - val_loss: 0.5436 - val_accuracy: 0.7264\n",
      "Epoch 52/100\n",
      "222/222 [==============================] - 351s 2s/step - loss: 0.5134 - accuracy: 0.7446 - val_loss: 0.5539 - val_accuracy: 0.7116\n",
      "Epoch 53/100\n",
      "222/222 [==============================] - 337s 2s/step - loss: 0.5110 - accuracy: 0.7439 - val_loss: 0.5366 - val_accuracy: 0.7315\n",
      "Epoch 54/100\n",
      "222/222 [==============================] - 345s 2s/step - loss: 0.5116 - accuracy: 0.7452 - val_loss: 0.5339 - val_accuracy: 0.7329\n",
      "Epoch 55/100\n",
      "222/222 [==============================] - 364s 2s/step - loss: 0.5103 - accuracy: 0.7443 - val_loss: 0.5342 - val_accuracy: 0.7382\n",
      "Epoch 56/100\n",
      "222/222 [==============================] - 420s 2s/step - loss: 0.5086 - accuracy: 0.7507 - val_loss: 0.5282 - val_accuracy: 0.7371\n",
      "Epoch 57/100\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.5098 - accuracy: 0.7455 - val_loss: 0.5262 - val_accuracy: 0.7413\n",
      "Epoch 58/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5072 - accuracy: 0.7465 - val_loss: 0.5304 - val_accuracy: 0.7365\n",
      "Epoch 59/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5049 - accuracy: 0.7526 - val_loss: 0.5458 - val_accuracy: 0.7209\n",
      "Epoch 60/100\n",
      "222/222 [==============================] - 380s 2s/step - loss: 0.5020 - accuracy: 0.7511 - val_loss: 0.5762 - val_accuracy: 0.7066\n",
      "Epoch 61/100\n",
      "222/222 [==============================] - 382s 2s/step - loss: 0.5018 - accuracy: 0.7518 - val_loss: 0.5393 - val_accuracy: 0.7300\n",
      "Epoch 62/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.5013 - accuracy: 0.7544 - val_loss: 0.5223 - val_accuracy: 0.7406\n",
      "Epoch 63/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.4984 - accuracy: 0.7528 - val_loss: 0.5317 - val_accuracy: 0.7324\n",
      "Epoch 64/100\n",
      "222/222 [==============================] - 372s 2s/step - loss: 0.4959 - accuracy: 0.7570 - val_loss: 0.5198 - val_accuracy: 0.7446\n",
      "Epoch 65/100\n",
      "222/222 [==============================] - 391s 2s/step - loss: 0.4914 - accuracy: 0.7572 - val_loss: 0.5250 - val_accuracy: 0.7408\n",
      "Epoch 66/100\n",
      "222/222 [==============================] - 404s 2s/step - loss: 0.4922 - accuracy: 0.7586 - val_loss: 0.5182 - val_accuracy: 0.7445\n",
      "Epoch 67/100\n",
      "222/222 [==============================] - 390s 2s/step - loss: 0.4886 - accuracy: 0.7604 - val_loss: 0.5139 - val_accuracy: 0.7481\n",
      "Epoch 68/100\n",
      "222/222 [==============================] - 394s 2s/step - loss: 0.4891 - accuracy: 0.7606 - val_loss: 0.5150 - val_accuracy: 0.7465\n",
      "Epoch 69/100\n",
      "222/222 [==============================] - 389s 2s/step - loss: 0.4857 - accuracy: 0.7644 - val_loss: 0.5169 - val_accuracy: 0.7390\n",
      "Epoch 70/100\n",
      "222/222 [==============================] - 562s 3s/step - loss: 0.4815 - accuracy: 0.7650 - val_loss: 0.5045 - val_accuracy: 0.7520\n",
      "Epoch 71/100\n",
      "222/222 [==============================] - 27925s 126s/step - loss: 0.4778 - accuracy: 0.7700 - val_loss: 0.5109 - val_accuracy: 0.7458\n",
      "Epoch 72/100\n",
      "222/222 [==============================] - 354s 2s/step - loss: 0.4733 - accuracy: 0.7707 - val_loss: 0.5067 - val_accuracy: 0.7474\n",
      "Epoch 73/100\n",
      "222/222 [==============================] - 344s 2s/step - loss: 0.4703 - accuracy: 0.7761 - val_loss: 0.5199 - val_accuracy: 0.7401\n",
      "Epoch 74/100\n",
      "222/222 [==============================] - 354s 2s/step - loss: 0.4743 - accuracy: 0.7693 - val_loss: 0.4952 - val_accuracy: 0.7577\n",
      "Epoch 75/100\n",
      "222/222 [==============================] - 417s 2s/step - loss: 0.4638 - accuracy: 0.7751 - val_loss: 0.5034 - val_accuracy: 0.7517\n",
      "Epoch 76/100\n",
      "222/222 [==============================] - 428s 2s/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7520\n",
      "Epoch 77/100\n",
      "222/222 [==============================] - 419s 2s/step - loss: 0.4618 - accuracy: 0.7775 - val_loss: 0.4946 - val_accuracy: 0.7571\n",
      "Epoch 78/100\n",
      "222/222 [==============================] - 418s 2s/step - loss: 0.4542 - accuracy: 0.7855 - val_loss: 0.5004 - val_accuracy: 0.7538\n",
      "Epoch 79/100\n",
      "222/222 [==============================] - 387s 2s/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7499\n",
      "Epoch 80/100\n",
      "222/222 [==============================] - 340s 2s/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7525\n",
      "Epoch 81/100\n",
      "222/222 [==============================] - 360s 2s/step - loss: 0.4478 - accuracy: 0.7885 - val_loss: 0.4767 - val_accuracy: 0.7665\n",
      "Epoch 82/100\n",
      "222/222 [==============================] - 397s 2s/step - loss: 0.4439 - accuracy: 0.7880 - val_loss: 0.5101 - val_accuracy: 0.7444\n",
      "Epoch 83/100\n",
      "222/222 [==============================] - 377s 2s/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4859 - val_accuracy: 0.7622\n",
      "Epoch 84/100\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.4364 - accuracy: 0.7933 - val_loss: 0.4909 - val_accuracy: 0.7614\n",
      "Epoch 85/100\n",
      "222/222 [==============================] - 385s 2s/step - loss: 0.4352 - accuracy: 0.7949 - val_loss: 0.4999 - val_accuracy: 0.7503\n",
      "Epoch 86/100\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.4433 - accuracy: 0.7906 - val_loss: 0.4627 - val_accuracy: 0.7749\n",
      "Epoch 87/100\n",
      "222/222 [==============================] - 368s 2s/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.4717 - val_accuracy: 0.7700\n",
      "Epoch 88/100\n",
      "222/222 [==============================] - 424s 2s/step - loss: 0.4282 - accuracy: 0.7968 - val_loss: 0.4623 - val_accuracy: 0.7789\n",
      "Epoch 89/100\n",
      "222/222 [==============================] - 370s 2s/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.4765 - val_accuracy: 0.7693\n",
      "Epoch 90/100\n",
      "222/222 [==============================] - 371s 2s/step - loss: 0.4209 - accuracy: 0.8038 - val_loss: 0.4778 - val_accuracy: 0.7596\n",
      "Epoch 91/100\n",
      "222/222 [==============================] - 368s 2s/step - loss: 0.4179 - accuracy: 0.8039 - val_loss: 0.4664 - val_accuracy: 0.7766\n",
      "Epoch 92/100\n",
      "222/222 [==============================] - 331s 1s/step - loss: 0.4146 - accuracy: 0.8066 - val_loss: 0.4746 - val_accuracy: 0.7672\n",
      "Epoch 93/100\n",
      "222/222 [==============================] - 330s 1s/step - loss: 0.4137 - accuracy: 0.8043 - val_loss: 0.4628 - val_accuracy: 0.7676\n",
      "Epoch 94/100\n",
      "222/222 [==============================] - 343s 2s/step - loss: 0.4066 - accuracy: 0.8100 - val_loss: 0.4475 - val_accuracy: 0.7882\n",
      "Epoch 95/100\n",
      "222/222 [==============================] - 408s 2s/step - loss: 0.4072 - accuracy: 0.8102 - val_loss: 0.4523 - val_accuracy: 0.7822\n",
      "Epoch 96/100\n",
      "222/222 [==============================] - 408s 2s/step - loss: 0.4012 - accuracy: 0.8153 - val_loss: 0.4503 - val_accuracy: 0.7782\n",
      "Epoch 97/100\n",
      "222/222 [==============================] - 373s 2s/step - loss: 0.3985 - accuracy: 0.8140 - val_loss: 0.4452 - val_accuracy: 0.7819\n",
      "Epoch 98/100\n",
      "222/222 [==============================] - 380s 2s/step - loss: 0.4045 - accuracy: 0.8093 - val_loss: 0.4394 - val_accuracy: 0.7863\n",
      "Epoch 99/100\n",
      "222/222 [==============================] - 383s 2s/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.4587 - val_accuracy: 0.7821\n",
      "Epoch 100/100\n",
      "222/222 [==============================] - 383s 2s/step - loss: 0.3940 - accuracy: 0.8179 - val_loss: 0.4349 - val_accuracy: 0.7919\n",
      "Fold 1, 100 epochs, 65940 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.19%\n",
      "\n",
      "Validation core mean 79.19% (+/- 0.00%)\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: GRU102.short.model/assets\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model1=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model1.save(FILENAME+'.short.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw1F0iw9mqTv"
   },
   "source": [
    "## Len 1K-2Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xwRg1mcHmqTw",
    "outputId": "94fbf037-d175-4810-d116-3e6938af6411",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [1000 - 2000)\n",
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[3 3 2 ... 0 0 0]\n",
      " [4 3 1 ... 0 0 0]\n",
      " [2 3 3 ... 0 0 0]\n",
      " ...\n",
      " [3 3 4 ... 0 0 0]\n",
      " [1 3 2 ... 0 0 0]\n",
      " [3 4 3 ... 0 0 0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 16)          80        \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 2000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 2000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 31,665\n",
      "Trainable params: 31,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 327s 4s/step - loss: 0.6650 - accuracy: 0.6184 - val_loss: 0.6698 - val_accuracy: 0.6039\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 300s 4s/step - loss: 0.6564 - accuracy: 0.6220 - val_loss: 0.6489 - val_accuracy: 0.6039\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 304s 4s/step - loss: 0.6519 - accuracy: 0.6228 - val_loss: 0.6473 - val_accuracy: 0.6150\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 317s 4s/step - loss: 0.6496 - accuracy: 0.6223 - val_loss: 0.6521 - val_accuracy: 0.6039\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 322s 4s/step - loss: 0.6502 - accuracy: 0.6221 - val_loss: 0.6416 - val_accuracy: 0.6039\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 307s 4s/step - loss: 0.6468 - accuracy: 0.6200 - val_loss: 0.6485 - val_accuracy: 0.6431\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 318s 4s/step - loss: 0.6407 - accuracy: 0.6396 - val_loss: 0.6318 - val_accuracy: 0.6513\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 314s 4s/step - loss: 0.6377 - accuracy: 0.6281 - val_loss: 0.6259 - val_accuracy: 0.6283\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 667s 8s/step - loss: 0.6333 - accuracy: 0.6383 - val_loss: 0.6265 - val_accuracy: 0.6451\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 900s 11s/step - loss: 0.6163 - accuracy: 0.6569 - val_loss: 0.6070 - val_accuracy: 0.6702\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 678s 8s/step - loss: 0.6223 - accuracy: 0.6258 - val_loss: 0.6488 - val_accuracy: 0.6039\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 771s 9s/step - loss: 0.6330 - accuracy: 0.6118 - val_loss: 0.6703 - val_accuracy: 0.6039\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 339s 4s/step - loss: 0.6637 - accuracy: 0.6221 - val_loss: 0.6698 - val_accuracy: 0.6039\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 282s 3s/step - loss: 0.6599 - accuracy: 0.6221 - val_loss: 0.6624 - val_accuracy: 0.6039\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 278s 3s/step - loss: 0.6430 - accuracy: 0.6274 - val_loss: 0.6173 - val_accuracy: 0.6290\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 296s 3s/step - loss: 0.6290 - accuracy: 0.6230 - val_loss: 0.6109 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 305s 4s/step - loss: 0.6209 - accuracy: 0.6258 - val_loss: 0.6014 - val_accuracy: 0.6666\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 328s 4s/step - loss: 0.6079 - accuracy: 0.6470 - val_loss: 0.6105 - val_accuracy: 0.6340\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 337s 4s/step - loss: 0.5991 - accuracy: 0.6689 - val_loss: 0.5798 - val_accuracy: 0.6887\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 323s 4s/step - loss: 0.6018 - accuracy: 0.6669 - val_loss: 0.5854 - val_accuracy: 0.6869\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 295s 3s/step - loss: 0.5947 - accuracy: 0.6645 - val_loss: 0.5684 - val_accuracy: 0.6957\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 317s 4s/step - loss: 0.5822 - accuracy: 0.6822 - val_loss: 0.6498 - val_accuracy: 0.6275\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 310s 4s/step - loss: 0.5926 - accuracy: 0.6818 - val_loss: 0.5678 - val_accuracy: 0.6942\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 612s 7s/step - loss: 0.5899 - accuracy: 0.6762 - val_loss: 0.5819 - val_accuracy: 0.6702\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 912s 11s/step - loss: 0.5885 - accuracy: 0.6730 - val_loss: 0.5675 - val_accuracy: 0.6948\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 565s 7s/step - loss: 0.5784 - accuracy: 0.6830 - val_loss: 0.5659 - val_accuracy: 0.7076\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 304s 4s/step - loss: 0.5788 - accuracy: 0.6939 - val_loss: 0.5735 - val_accuracy: 0.6897\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 289s 3s/step - loss: 0.6776 - accuracy: 0.6224 - val_loss: 0.6598 - val_accuracy: 0.6098\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 287s 3s/step - loss: 0.6534 - accuracy: 0.6254 - val_loss: 0.6431 - val_accuracy: 0.6201\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 289s 3s/step - loss: 0.6288 - accuracy: 0.6340 - val_loss: 0.6013 - val_accuracy: 0.6675\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 276s 3s/step - loss: 0.6157 - accuracy: 0.6531 - val_loss: 0.5944 - val_accuracy: 0.6755\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 274s 3s/step - loss: 0.6059 - accuracy: 0.6631 - val_loss: 0.6148 - val_accuracy: 0.6609\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 285s 3s/step - loss: 0.6000 - accuracy: 0.6720 - val_loss: 0.6008 - val_accuracy: 0.6817\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 657s 8s/step - loss: 0.5975 - accuracy: 0.6719 - val_loss: 0.5899 - val_accuracy: 0.6732\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 697s 8s/step - loss: 0.6003 - accuracy: 0.6769 - val_loss: 0.5738 - val_accuracy: 0.6895\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 820s 10s/step - loss: 0.5900 - accuracy: 0.6814 - val_loss: 0.5791 - val_accuracy: 0.6889\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 973s 11s/step - loss: 0.5890 - accuracy: 0.6890 - val_loss: 0.6294 - val_accuracy: 0.6606\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 728s 9s/step - loss: 0.5834 - accuracy: 0.6899 - val_loss: 0.5877 - val_accuracy: 0.6912\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 1109s 13s/step - loss: 0.5791 - accuracy: 0.6884 - val_loss: 0.5672 - val_accuracy: 0.7088\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 1266s 15s/step - loss: 0.5768 - accuracy: 0.6928 - val_loss: 0.5775 - val_accuracy: 0.7049\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 902s 11s/step - loss: 0.5723 - accuracy: 0.7009 - val_loss: 0.5662 - val_accuracy: 0.7158\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 488s 6s/step - loss: 0.5698 - accuracy: 0.7039 - val_loss: 0.7007 - val_accuracy: 0.6420\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 359s 4s/step - loss: 0.6336 - accuracy: 0.6538 - val_loss: 0.5884 - val_accuracy: 0.6928\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 337s 4s/step - loss: 0.5823 - accuracy: 0.6918 - val_loss: 0.5732 - val_accuracy: 0.7072\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 311s 4s/step - loss: 0.5735 - accuracy: 0.6984 - val_loss: 0.5717 - val_accuracy: 0.7192\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 284s 3s/step - loss: 0.5702 - accuracy: 0.7031 - val_loss: 0.5640 - val_accuracy: 0.7225\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 273s 3s/step - loss: 0.5730 - accuracy: 0.7004 - val_loss: 0.5721 - val_accuracy: 0.7106\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 272s 3s/step - loss: 0.5655 - accuracy: 0.7061 - val_loss: 0.5622 - val_accuracy: 0.7135\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 272s 3s/step - loss: 0.5654 - accuracy: 0.7110 - val_loss: 0.5541 - val_accuracy: 0.7170\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5618 - accuracy: 0.7116 - val_loss: 0.5541 - val_accuracy: 0.7186\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 263s 3s/step - loss: 0.5583 - accuracy: 0.7135 - val_loss: 0.5543 - val_accuracy: 0.7237\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 263s 3s/step - loss: 0.5609 - accuracy: 0.7146 - val_loss: 0.5613 - val_accuracy: 0.7224\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 264s 3s/step - loss: 0.5539 - accuracy: 0.7212 - val_loss: 0.5520 - val_accuracy: 0.7187\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 267s 3s/step - loss: 0.5548 - accuracy: 0.7206 - val_loss: 0.5456 - val_accuracy: 0.7243\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 263s 3s/step - loss: 0.5556 - accuracy: 0.7152 - val_loss: 0.5470 - val_accuracy: 0.7204\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 282s 3s/step - loss: 0.5518 - accuracy: 0.7239 - val_loss: 0.5644 - val_accuracy: 0.7192\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 318s 4s/step - loss: 0.5459 - accuracy: 0.7281 - val_loss: 0.5533 - val_accuracy: 0.7203\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 327s 4s/step - loss: 0.5514 - accuracy: 0.7214 - val_loss: 0.5460 - val_accuracy: 0.7223\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 356s 4s/step - loss: 0.5488 - accuracy: 0.7232 - val_loss: 0.5501 - val_accuracy: 0.7188\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 383s 5s/step - loss: 0.5504 - accuracy: 0.7253 - val_loss: 0.5613 - val_accuracy: 0.7187\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 425s 5s/step - loss: 0.5500 - accuracy: 0.7277 - val_loss: 0.5597 - val_accuracy: 0.7130\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 403s 5s/step - loss: 0.5518 - accuracy: 0.7225 - val_loss: 0.5429 - val_accuracy: 0.7223\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 677s 8s/step - loss: 0.5391 - accuracy: 0.7333 - val_loss: 0.5474 - val_accuracy: 0.7232\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 1058s 12s/step - loss: 0.5392 - accuracy: 0.7338 - val_loss: 0.5434 - val_accuracy: 0.7287\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 1114s 13s/step - loss: 0.5420 - accuracy: 0.7302 - val_loss: 0.5421 - val_accuracy: 0.7191\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 771s 9s/step - loss: 0.5419 - accuracy: 0.7331 - val_loss: 0.5345 - val_accuracy: 0.7347\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 623s 7s/step - loss: 0.5347 - accuracy: 0.7331 - val_loss: 0.5428 - val_accuracy: 0.7246\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 310s 4s/step - loss: 0.5365 - accuracy: 0.7361 - val_loss: 0.5419 - val_accuracy: 0.7282\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 298s 4s/step - loss: 0.5384 - accuracy: 0.7372 - val_loss: 0.5415 - val_accuracy: 0.7220\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 284s 3s/step - loss: 0.5314 - accuracy: 0.7393 - val_loss: 0.5356 - val_accuracy: 0.7275\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 289s 3s/step - loss: 0.5300 - accuracy: 0.7390 - val_loss: 0.5398 - val_accuracy: 0.7199\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 317s 4s/step - loss: 0.5298 - accuracy: 0.7394 - val_loss: 0.5329 - val_accuracy: 0.7283\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 294s 3s/step - loss: 0.5331 - accuracy: 0.7387 - val_loss: 0.5410 - val_accuracy: 0.7280\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 293s 3s/step - loss: 0.5275 - accuracy: 0.7427 - val_loss: 0.5423 - val_accuracy: 0.7231\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 335s 4s/step - loss: 0.5225 - accuracy: 0.7502 - val_loss: 0.5538 - val_accuracy: 0.7164\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 310s 4s/step - loss: 0.5219 - accuracy: 0.7499 - val_loss: 0.5318 - val_accuracy: 0.7309\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 283s 3s/step - loss: 0.5246 - accuracy: 0.7450 - val_loss: 0.5340 - val_accuracy: 0.7242\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 270s 3s/step - loss: 0.5153 - accuracy: 0.7512 - val_loss: 0.5427 - val_accuracy: 0.7202\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 273s 3s/step - loss: 0.5285 - accuracy: 0.7443 - val_loss: 0.5324 - val_accuracy: 0.7265\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 270s 3s/step - loss: 0.5167 - accuracy: 0.7471 - val_loss: 0.5311 - val_accuracy: 0.7303\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 336s 4s/step - loss: 0.5312 - accuracy: 0.7365 - val_loss: 0.5363 - val_accuracy: 0.7305\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 366s 4s/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5640 - val_accuracy: 0.7042\n",
      "Epoch 83/100\n",
      "37/85 [============>.................] - ETA: 3:16 - loss: 0.5381 - accuracy: 0.7330"
     ]
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model2=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model2.save(FILENAME+'.medium.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaFKdlJ3mqTz"
   },
   "source": [
    "## Len 2K-3Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uDUUlKuqmqT0",
    "outputId": "73dc8b7d-284f-4624-8758-75535624ee73"
   },
   "outputs": [],
   "source": [
    "MINLEN=2000\n",
    "MAXLEN=3000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model3=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model3.save(FILENAME+'.long.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Skqq7LKXmqT4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW619OmCmqT7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GRU_102.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
