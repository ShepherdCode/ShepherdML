{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep CNN \n",
    "In notebook 13, an RNN did pretty well using 3 RNN layers of 16 nodes each.\n",
    "Here, we try Conv1D configured to look at 3-mers.\n",
    "Since CNN expects images of same dimension, we'll try padding sequences with N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.keras.backend.set_floatx('float32')  # save RAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and encode the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ncRNA.fasta\n",
      "Load pcRNA.fasta\n",
      "Encoder categories\n",
      "Ecode the non-coding sequences\n",
      "shape: (3761, 2000, 5)\n",
      "element 0 is a sequence: \n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "element 0,0 is one letter: [0. 0. 0. 0. 1.]\n",
      "Encode the protein-coding sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5864, 2000, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_SEQ_LEN=200\n",
    "MIN_SEQ_LEN=1000  ### use this for testing\n",
    "MAX_SEQ_LEN=25000 ### this screens 4 outliers in the complete dataset\n",
    "MAX_SEQ_LEN=2000  ### we use this to reduce training RAM and CPU during testing\n",
    "DEFLINE='>'\n",
    "ncfile='ncRNA.fasta' \n",
    "pcfile='pcRNA.fasta' \n",
    "#ncfile='tiny.ncRNA.fasta' # 10 seqs for faster debugging\n",
    "#pcfile='tiny.pcRNA.fasta' \n",
    "\n",
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Returned structure is ndarray of ndarray i.e no python lists inside.\n",
    "def load_fasta(filename):\n",
    "    seqs=[]\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE and len(line)>=MIN_SEQ_LEN and len(line)<=MAX_SEQ_LEN:\n",
    "                line=line.rstrip()\n",
    "                pad_len = MAX_SEQ_LEN-len(line)\n",
    "                pad_chars = 'N' * pad_len\n",
    "                line = line + pad_chars\n",
    "                chars=np.array(list(line))\n",
    "                seqs.append(chars.reshape(-1, 1)) # reshaped changes (any,) to (any,1)\n",
    "    nparray=np.array(seqs)\n",
    "    return nparray\n",
    "\n",
    "print(\"Load \"+ncfile)\n",
    "nc_seqs = load_fasta(ncfile)\n",
    "print(\"Load \"+pcfile)\n",
    "pc_seqs = load_fasta(pcfile)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "#seq=tf.reshape(nc_seqs[0],shape=(-1, 1)) # tensor flow version\n",
    "seq=nc_seqs[0].reshape(-1, 1)\n",
    "encoder.fit(seq)\n",
    "print(\"Encoder categories\")\n",
    "encoder.categories_\n",
    "\n",
    "print(\"Ecode the non-coding sequences\")\n",
    "nc_list=[]\n",
    "for seq in nc_seqs:\n",
    "    encoded=encoder.transform(seq)  \n",
    "    nc_list.append(encoded)\n",
    "    \n",
    "nc_all=np.array(nc_list) # .reshape(-1,1)\n",
    "print(\"shape: \"+str(nc_all.shape))\n",
    "print(\"element 0 is a sequence: \\n\"+str(nc_all[0]))\n",
    "print(\"element 0,0 is one letter: \"+str(nc_all[0][0]))\n",
    "\n",
    "print(\"Encode the protein-coding sequences\")\n",
    "pc_list=[]\n",
    "for seq in pc_seqs:\n",
    "    encoded=encoder.transform(seq)\n",
    "    pc_list.append(encoded)\n",
    "\n",
    "pc_all=np.array(pc_list) # .reshape(-1,1)\n",
    "pc_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of sequences, shape of labels\n",
      "shape of train\n",
      "(7700, 2000, 5) (7700,)\n",
      "shape of test\n",
      "(1925, 2000, 5) (1925,)\n",
      "Convert numpy array to python 3D array\n",
      "Partition = 6160\n",
      "Partition train/validation\n",
      "Lengths of train,valid\n",
      "(6160, 1540)\n"
     ]
    }
   ],
   "source": [
    "nc_labels=np.zeros(shape=(17711))\n",
    "pc_labels=np.ones(shape=(20152))\n",
    "#nc_labels=np.zeros(shape=(10))  # fast debugging\n",
    "#pc_labels=np.ones(shape=(10))\n",
    "\n",
    "#nc_labeled=np.concatenate((nc_all,nc_labels),axis=1)\n",
    "#pc_labeled=np.concatenate((pc_all,pc_labels),axis=1)\n",
    "all_seqs=np.concatenate((nc_all,pc_all),axis=0)\n",
    "all_labels=np.concatenate((nc_labels,pc_labels),axis=0)\n",
    "\n",
    "print(\"shape of sequences, shape of labels\")\n",
    "all_seqs.shape,all_labels.shape\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "for train_index,test_index in splitter.split(all_seqs):\n",
    "    train_seqs =   all_seqs[train_index]\n",
    "    train_labels = all_labels[train_index]\n",
    "    test_seqs =    all_seqs[test_index]\n",
    "    test_labels =  all_labels[test_index]\n",
    " \n",
    "print(\"shape of train\")\n",
    "print(train_seqs.shape,train_labels.shape)\n",
    "print(\"shape of test\")\n",
    "print(test_seqs.shape,test_labels.shape)\n",
    "\n",
    "print(\"Convert numpy array to python 3D array\")\n",
    "def numpy_to_python_3D(np_seqs):\n",
    "    one_set = []\n",
    "    tlen = len(np_seqs)\n",
    "    for i in range(tlen): # for every sequence in set\n",
    "        one_seq = []\n",
    "        slen = len(np_seqs[i])\n",
    "        for j in range(slen): # for ever letter in sequence\n",
    "            one_letter=np_seqs[i][j]\n",
    "            one_seq.append(one_letter)\n",
    "        one_set.append(one_seq)\n",
    "    return one_set\n",
    "train_seqs = numpy_to_python_3D(train_seqs)\n",
    "test_seqs = numpy_to_python_3D(test_seqs)\n",
    "train_labels = train_labels.tolist()\n",
    "test_labels = test_labels.tolist()\n",
    "\n",
    "# Now that values are shuffled, partition gives random sample.\n",
    "data_size=len(train_seqs)\n",
    "PARTITION=int(data_size*0.8)\n",
    "print(\"Partition = \"+str(PARTITION))\n",
    "\n",
    "print(\"Partition train/validation\")\n",
    "X_train=train_seqs[:PARTITION]\n",
    "X_valid=train_seqs[PARTITION:]\n",
    "y_train=train_labels[:PARTITION]\n",
    "y_valid=train_labels[PARTITION:]\n",
    "print(\"Lengths of train,valid\")\n",
    "print((len(X_train),len(X_valid)))\n",
    "\n",
    "# Free memory for the next step\n",
    "nc_seqs=None\n",
    "pc_seqs=None\n",
    "all_seqs=None\n",
    "nc_labels=None\n",
    "pc_labels=None\n",
    "train_seqs=None\n",
    "train_labels=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert to tensors\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(6160, 2000, 5)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(6160,)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1540, 2000, 5)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1540,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert to tensors\")\n",
    "X_train = tf.constant(X_train)  \n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "print(type(y_train))\n",
    "print(y_train.shape)\n",
    "X_valid = tf.constant(X_valid)\n",
    "print(type(X_valid))\n",
    "print(X_valid.shape)\n",
    "y_valid = tf.convert_to_tensor(y_valid)\n",
    "print(type(y_valid))\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n",
      "Build the training environment\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2000, 64)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8192128   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,570,881\n",
      "Trainable params: 8,570,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build the model\")\n",
    "HOTS=4+1  # one hot encoding of ACGT+N\n",
    "cnn2 = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64,kernel_size=3,activation=\"relu\",padding=\"SAME\",\n",
    "    input_shape=[MAX_SEQ_LEN,HOTS]),\n",
    "    keras.layers.MaxPooling1D(2),\n",
    "    keras.layers.Conv1D(128,3,activation=\"relu\",padding=\"same\"),\n",
    "    keras.layers.Conv1D(128,3,activation=\"relu\",padding=\"same\"),\n",
    "    keras.layers.MaxPooling1D(2),   \n",
    "    keras.layers.Conv1D(256,3,activation=\"relu\",padding=\"same\"),\n",
    "    keras.layers.Conv1D(256,3,activation=\"relu\",padding=\"same\"),\n",
    "    keras.layers.MaxPooling1D(2), \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128,activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64,activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),    \n",
    "    keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "print(\"Build the training environment\")\n",
    "cnn2.compile(loss=\"binary_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the model\n",
      "Epoch 1/5\n",
      "193/193 [==============================] - 158s 816ms/step - loss: 0.0573 - accuracy: 0.9937 - val_loss: 1.5521e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "193/193 [==============================] - 134s 694ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 8.0682e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "193/193 [==============================] - 145s 753ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 1.3710e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "193/193 [==============================] - 153s 791ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 3.8956e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "193/193 [==============================] - 149s 773ms/step - loss: 6.1907e-04 - accuracy: 1.0000 - val_loss: 1.5308e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train the model\")\n",
    "history = cnn2.fit(X_train,y_train,epochs=5,validation_data=(X_valid,y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize training history.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Visualize training history.\")\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources.\n",
    "[Working with RNNs](https://keras.io/guides/working_with_rnns/).\n",
    "[Recurrent Neural Networks with Keras](https://www.tensorflow.org/guide/keras/rnn#rnns_with_listdict_inputs_or_nested_inputs).\n",
    "Function tf.convert_to_tensor [docs](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor).\n",
    "Function tf.reshape [docs](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "Ragged Tensors [tutorial](https://www.tensorflow.org/guide/tensor#ragged_tensors)\n",
    "and [docs](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#documenting_raggedtensor_shapes_2) and [module](https://www.tensorflow.org/api_docs/python/tf/ragged).\n",
    "Incredible speedup for convert to tensor by sirfz on [stackoverflow](https://stackoverflow.com/questions/44353509/tensorflow-tf-constant-initializer-is-very-slow).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
