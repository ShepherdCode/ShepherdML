{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFXUwj5sKlBa"
   },
   "source": [
    "# RNN on RNA K-mers\n",
    "\n",
    "Extract every K-mer for K=3.\n",
    "Apply one-hot encoding.\n",
    "Convert to ragged tensors.\n",
    "Train with 3-deep RNN.\n",
    "\n",
    "Previous runs exhausted RAM.\n",
    "This version trains the same model additively on small batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF0oFz5oKlBj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.keras.backend.set_floatx('float32')  # save RAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHTgt2mcKlBs"
   },
   "source": [
    "Load and encode the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "SHgYYvUPKlBt",
    "outputId": "a1728f02-612d-4f95-b630-02571f7f9b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ncRNA.fasta\n",
      "Load pcRNA.fasta\n",
      "Encoder categories\n",
      "[array(['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA',\n",
      "       'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC',\n",
      "       'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG',\n",
      "       'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT',\n",
      "       'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA',\n",
      "       'GTC', 'GTG', 'GTT', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC',\n",
      "       'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG',\n",
      "       'TTT'], dtype='<U3')]\n",
      "Ecode the non-coding sequences\n",
      "shape: (17711,)\n",
      "sequence 0 starts \n",
      "[['TCA']\n",
      " ['CAT']\n",
      " ['ATC']\n",
      " ['TCA']\n",
      " ['CAG']\n",
      " ['AGT']\n",
      " ['GTC']]\n",
      "element 0 encoding: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Encode the protein-coding sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20152,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_SEQ_LEN=200   ### by definition, lncRNA have min len 200\n",
    "#MIN_SEQ_LEN=1000  ### we use this to reduce training RAM and CPU\n",
    "MAX_SEQ_LEN=25000 ### this screens 4 outliers in the complete dataset\n",
    "#MAX_SEQ_LEN=2000  ### we use this to reduce training RAM and CPU\n",
    "DEFLINE='>'\n",
    "ncfile='ncRNA.fasta' \n",
    "pcfile='pcRNA.fasta' \n",
    "#ncfile='tiny.ncRNA.fasta' # 10 seqs for faster debugging\n",
    "#pcfile='tiny.pcRNA.fasta' # 10 seqs for faster debugging\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "## !ls drive/'My Drive'/'Colab Notebooks'/*\n",
    "#ncfile='drive/My Drive/Colab Notebooks/ncRNA.fasta'\n",
    "#pcfile='drive/My Drive/Colab Notebooks/pcRNA.fasta'\n",
    "\n",
    "K=3   # K-mer length = word length\n",
    "\n",
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Returned structure is ndarray of ndarray i.e no python lists inside.\n",
    "def load_fasta(filename):\n",
    "    seqs=[]\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE and len(line)>=MIN_SEQ_LEN and len(line)<=MAX_SEQ_LEN:\n",
    "                line=line.rstrip()\n",
    "                linelen=len(line)\n",
    "                kmers=[]\n",
    "                for i in range(linelen-K+1): # e.g. k=3,|line=4| => range=2 so i={0,1}\n",
    "                    kmer=line[i:i+K]\n",
    "                    kmers.append(kmer)\n",
    "                kmers=np.array(kmers)\n",
    "                seqs.append(kmers.reshape(-1, 1)) # reshaped changes (any,) to (any,1)\n",
    "    nparray=np.array(seqs)\n",
    "    return nparray\n",
    "\n",
    "print(\"Load \"+ncfile)\n",
    "nc_seqs = load_fasta(ncfile)\n",
    "print(\"Load \"+pcfile)\n",
    "pc_seqs = load_fasta(pcfile)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "#seq=tf.reshape(nc_seqs[0],shape=(-1, 1)) # tensor flow version\n",
    "seq=nc_seqs[0].reshape(-1, 1)\n",
    "encoder.fit(seq)\n",
    "print(\"Encoder categories\")\n",
    "print(str(encoder.categories_))\n",
    "\n",
    "print(\"Ecode the non-coding sequences\")\n",
    "nc_list=[]\n",
    "for seq in nc_seqs:\n",
    "    encoded=encoder.transform(seq)  \n",
    "    nc_list.append(encoded)\n",
    "    \n",
    "nc_all=np.array(nc_list) # .reshape(-1,1)\n",
    "print(\"shape: \"+str(nc_all.shape))\n",
    "print(\"sequence 0 starts \")\n",
    "print(nc_seqs[0][:7])\n",
    "print(\"element 0 encoding: \")\n",
    "print(nc_all[0][:5])\n",
    "\n",
    "print(\"Encode the protein-coding sequences\")\n",
    "pc_list=[]\n",
    "for seq in pc_seqs:\n",
    "    encoded=encoder.transform(seq)\n",
    "    pc_list.append(encoded)\n",
    "\n",
    "pc_all=np.array(pc_list) # .reshape(-1,1)\n",
    "pc_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvMpBuH0KlB8"
   },
   "source": [
    "Create train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8tbhs-U-KlB8",
    "outputId": "e44dbf08-14ed-4c7b-f77d-bffe8977d9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of sequences, shape of labels\n",
      "shape of train\n",
      "(30290,) (30290,)\n",
      "shape of test\n",
      "(7573,) (7573,)\n",
      "Convert numpy array to python 3D array\n",
      "Partition = 24232\n",
      "Partition train/validation\n",
      "Lengths of train,valid\n",
      "(24232, 6058)\n",
      "Free memory.\n"
     ]
    }
   ],
   "source": [
    "nc_labels=np.zeros(shape=(17711))\n",
    "pc_labels=np.ones(shape=(20152))\n",
    "#nc_labels=np.zeros(shape=(10))  # fast debugging\n",
    "#pc_labels=np.ones(shape=(10))\n",
    "\n",
    "#nc_labeled=np.concatenate((nc_all,nc_labels),axis=1)\n",
    "#pc_labeled=np.concatenate((pc_all,pc_labels),axis=1)\n",
    "all_seqs=np.concatenate((nc_all,pc_all),axis=0)\n",
    "all_labels=np.concatenate((nc_labels,pc_labels),axis=0)\n",
    "\n",
    "print(\"shape of sequences, shape of labels\")\n",
    "all_seqs.shape,all_labels.shape\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "for train_index,test_index in splitter.split(all_seqs):\n",
    "    train_seqs =   all_seqs[train_index]\n",
    "    train_labels = all_labels[train_index]\n",
    "    test_seqs =    all_seqs[test_index]\n",
    "    test_labels =  all_labels[test_index]\n",
    " \n",
    "print(\"shape of train\")\n",
    "print(train_seqs.shape,train_labels.shape)\n",
    "print(\"shape of test\")\n",
    "print(test_seqs.shape,test_labels.shape)\n",
    "\n",
    "print(\"Convert numpy array to python 3D array\")\n",
    "def numpy_to_python_3D(np_seqs):\n",
    "    one_set = []\n",
    "    tlen = len(np_seqs)\n",
    "    for i in range(tlen): # for every sequence in set\n",
    "        one_seq = []\n",
    "        slen = len(np_seqs[i])\n",
    "        for j in range(slen): # for ever letter in sequence\n",
    "            one_letter=np_seqs[i][j]\n",
    "            one_seq.append(one_letter)\n",
    "        one_set.append(one_seq)\n",
    "    return one_set\n",
    "train_seqs = numpy_to_python_3D(train_seqs)\n",
    "test_seqs = numpy_to_python_3D(test_seqs)\n",
    "train_labels = train_labels.tolist()\n",
    "test_labels = test_labels.tolist()\n",
    "\n",
    "# Now that values are shuffled, partition gives random sample.\n",
    "data_size=len(train_seqs)\n",
    "PARTITION=int(data_size*0.8)\n",
    "print(\"Partition = \"+str(PARTITION))\n",
    "\n",
    "print(\"Partition train/validation\")\n",
    "X_train=train_seqs[:PARTITION]\n",
    "X_valid=train_seqs[PARTITION:]\n",
    "y_train=train_labels[:PARTITION]\n",
    "y_valid=train_labels[PARTITION:]\n",
    "print(\"Lengths of train,valid\")\n",
    "print((len(X_train),len(X_valid)))\n",
    "\n",
    "print(\"Free memory.\")\n",
    "nc_seqs=None\n",
    "pc_seqs=None\n",
    "all_seqs=None\n",
    "nc_labels=None\n",
    "pc_labels=None\n",
    "train_seqs=None\n",
    "train_labels=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-2yAOndKlCE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n",
      "Build the training environment\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 1)                 66        \n",
      "=================================================================\n",
      "Total params: 24,834\n",
      "Trainable params: 24,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build the model\")\n",
    "seq_len=None  # none indicates variable length\n",
    "input_features=4**K   # 64 DNA K-mers at K=3\n",
    "rnn2 = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True, input_shape=[seq_len,input_features]),\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1),\n",
    "])\n",
    "\n",
    "print(\"Build the training environment\")\n",
    "bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "rnn2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop: additively train the model in small batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch of RNA lengths 0 to 1000\n",
      "Convert to tensors\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "BATCHES=6\n",
    "# batch max: 1K, 2K, 4K, 8K, 16K, 32K\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch %d\"%epoch)\n",
    "    batch_max = 0\n",
    "    for batch in range(BATCHES):\n",
    "        batch_min = batch_max\n",
    "        batch_max = 1000 * (2**batch)\n",
    "        print(\"Batch of RNA lengths %d to %d\"%(batch_min,batch_max))\n",
    "        X_batch_train = []\n",
    "        y_batch_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            L = len(X_train[i])\n",
    "            if L>batch_min and L<=batch_max:\n",
    "                X_batch_train.append(X_train[i])\n",
    "                y_batch_train.append(y_train[i])\n",
    "        X_batch_valid = []\n",
    "        y_batch_valid = []\n",
    "        for i in range(len(X_valid)):\n",
    "            L = len(X_valid[i])\n",
    "            if L>batch_min and L<=batch_max:\n",
    "                X_batch_valid.append(X_valid[i])\n",
    "                y_batch_valid.append(y_valid[i])\n",
    "            \n",
    "        print(\"Convert to tensors\")\n",
    "        tensor = tf.ragged.constant(X_batch_train)\n",
    "        X_batch_train = tensor\n",
    "        tensor=None\n",
    "        print(type(X_batch_train))\n",
    "        print(X_batch_train.shape)\n",
    "        tensor = tf.convert_to_tensor(y_batch_train)\n",
    "        y_batch_train = tensor\n",
    "        tensor=None\n",
    "        print(type(y_batch_train))\n",
    "        print(y_batch_train.shape)\n",
    "        tensor = tf.ragged.constant(X_batch_valid)\n",
    "        X_batch_valid=tensor\n",
    "        tensor=None\n",
    "        print(type(X_batch_valid))\n",
    "        print(X_batch_valid.shape)\n",
    "        tensor = tf.convert_to_tensor(y_batch_valid)\n",
    "        y_batch_valid = tensor\n",
    "        tensor=None\n",
    "        print(type(y_batch_valid))\n",
    "        print(y_batch_valid.shape)\n",
    "        \n",
    "        print(\"Train the model\")\n",
    "        history = rnn2.fit(X_batch_train,y_batch_train,epochs=1,\n",
    "                           validation_data=(X_batch_valid,y_batch_valid))\n",
    "\n",
    "        print(\"Visualize training history.\")\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBoVjg06KlCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGVmufeoKlCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quH4crn8KlCR"
   },
   "source": [
    "Resources.\n",
    "[Working with RNNs](https://keras.io/guides/working_with_rnns/).\n",
    "[Recurrent Neural Networks with Keras](https://www.tensorflow.org/guide/keras/rnn#rnns_with_listdict_inputs_or_nested_inputs).\n",
    "Function tf.convert_to_tensor [docs](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor).\n",
    "Function tf.reshape [docs](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "Ragged Tensors [tutorial](https://www.tensorflow.org/guide/tensor#ragged_tensors)\n",
    "and [docs](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#documenting_raggedtensor_shapes_2) and [module](https://www.tensorflow.org/api_docs/python/tf/ragged).\n",
    "Incredible speedup for convert to tensor by sirfz on [stackoverflow](https://stackoverflow.com/questions/44353509/tensorflow-tf-constant-initializer-is-very-slow).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QeTNy7HKlCT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lncRNA_14_Kmers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
