{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>seqname</th>\n",
       "      <th>AAAA</th>\n",
       "      <th>AAAC</th>\n",
       "      <th>AAAG</th>\n",
       "      <th>AAAT</th>\n",
       "      <th>AACA</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACG</th>\n",
       "      <th>AACT</th>\n",
       "      <th>...</th>\n",
       "      <th>TTCG</th>\n",
       "      <th>TTCT</th>\n",
       "      <th>TTGA</th>\n",
       "      <th>TTGC</th>\n",
       "      <th>TTGG</th>\n",
       "      <th>TTGT</th>\n",
       "      <th>TTTA</th>\n",
       "      <th>TTTC</th>\n",
       "      <th>TTTG</th>\n",
       "      <th>TTTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000261061</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000254837</td>\n",
       "      <td>87</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000282851</td>\n",
       "      <td>105</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000255650</td>\n",
       "      <td>108</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000163597</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          seqname  AAAA  AAAC  AAAG  AAAT  AACA  AACC  AACG  AACT  \\\n",
       "0      1  ENSG00000261061    31     5     2    13     6     5     0     5   \n",
       "1      1  ENSG00000254837    87    19    28    42    31     9     1    15   \n",
       "2      1  ENSG00000282851   105    29    43    51    48    23     2    23   \n",
       "3      1  ENSG00000255650   108    32    51    55    55    25     3    26   \n",
       "4      1  ENSG00000163597   133    47    74    80    65    39     8    42   \n",
       "\n",
       "   ...  TTCG  TTCT  TTGA  TTGC  TTGG  TTGT  TTTA  TTTC  TTTG  TTTT  \n",
       "0  ...     0     2     5     5     2     4     2     3     4     7  \n",
       "1  ...     1    15    13    13     6    14    17    11    10    30  \n",
       "2  ...     3    21    21    20    14    27    28    23    22    62  \n",
       "3  ...     3    24    21    21    19    30    28    28    25    83  \n",
       "4  ...     6    45    37    32    37    61    66    55    51   169  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data.\n",
    "# Since the classes are unequal, we don't risk random sampling from full set.\n",
    "# Instead, keep them separate until we make the train/test split.\n",
    "infile_pos='score-positive.4mer.features.csv'\n",
    "infile_neg='score-negative.4mer.features.csv'\n",
    "infile_zero='score-zero.4mer.features.csv'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "raw_pos = pd.read_csv(infile_pos,header=0)\n",
    "raw_neg = pd.read_csv(infile_neg,header=0)\n",
    "raw_zero = pd.read_csv(infile_zero,header=0)\n",
    "raw_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 258), (577, 258), (405, 258))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pos.shape, raw_neg.shape, raw_zero.shape\n",
    "# All matrices have columns for 4^4 = 256 k-mers plus label plus seqname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3962417414158951"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is imbalanced: 170/577/405.\n",
    "# What is the probability of correct classification by random?\n",
    "total=170+577+405\n",
    "prob_random_guess_is_correct=pow(170/total,2)+pow(577/total,2)+pow(405/total,2)\n",
    "prob_random_guess_is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 258), (136, 258), (34, 258))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_train_test(dataset,train_portion):    \n",
    "    # Use pandas sample() to randomize the order (i.e. random sample without replacement).\n",
    "    # Side note. Data frame can be randomized while keeping header in place.\n",
    "    # This is repeatable with 42.\n",
    "    middle = int(len(dataset)*train_portion)\n",
    "    random = dataset.sample(frac=1,random_state=42)\n",
    "    train_set = random[:middle]\n",
    "    test_set = random[middle:]\n",
    "    return train_set,test_set\n",
    "TRAIN_PORTION=0.8\n",
    "\n",
    "train_pos , test_pos = split_train_test(raw_pos,TRAIN_PORTION)\n",
    "train_neg , test_neg = split_train_test(raw_neg,TRAIN_PORTION)\n",
    "train_zero , test_zero = split_train_test(raw_zero,TRAIN_PORTION)\n",
    "\n",
    "raw_pos.shape, train_pos.shape, test_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Geron book recommends this (or StrattifiedShuffleSplit) \n",
    "# but we could not make it work. \n",
    "\n",
    "#from sklearn.model_selection import ShuffleSplit\n",
    "#splitter=ShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "#for train_index,test_index in splitter.split(rawpos):\n",
    "#    train_pos = rawpos[train_index]\n",
    "#    test_pos = rawpos[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921, 258), (231, 258))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine and shuffle.\n",
    "train_sorted = pd.concat([train_pos, train_neg, train_zero],axis=0)\n",
    "train_set = train_sorted.sample(frac=1,random_state=17)\n",
    "\n",
    "test_sorted = pd.concat([test_pos, test_neg, test_zero],axis=0)\n",
    "test_set = test_sorted.sample(frac=1,random_state=17)\n",
    "\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_set['label']\n",
    "X_train_ID = train_set['seqname']\n",
    "X_train = train_set.drop(['label','seqname'],axis=1)\n",
    "X_train.shape\n",
    "X_train_ID.head()\n",
    "X_train.head()\n",
    "y_train.unique()\n",
    "# Try all the validators above to ensure we have what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling.\n",
    "# Effectively convert k-mer counts to k-mer frequencies.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaled = scaler.fit_transform(X_train)\n",
    "df = pd.DataFrame(scaled,columns=X_train.columns)\n",
    "# The above works but we don't want to standaridize each column (feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165     363946\n",
       "61      149219\n",
       "505    1239798\n",
       "195     455718\n",
       "28       68188\n",
       "        ...   \n",
       "37       95573\n",
       "220     516018\n",
       "29       84581\n",
       "421    1066593\n",
       "84      199374\n",
       "Length: 921, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to normalize each number by its row sum.\n",
    "X_train.head()\n",
    "X_train.sum(axis=1)\n",
    "# Row sums before normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165    1.0\n",
       "61     1.0\n",
       "505    1.0\n",
       "195    1.0\n",
       "28     1.0\n",
       "      ... \n",
       "37     1.0\n",
       "220    1.0\n",
       "29     1.0\n",
       "421    1.0\n",
       "84     1.0\n",
       "Length: 921, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/35678874/normalize-rows-of-pandas-data-frame-by-their-sums/35679163\n",
    "X_norm=X_train.div(X_train.sum(axis=1), axis=0)\n",
    "X_norm.sum(axis=1)\n",
    "# Row sums after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO Try min-max scaling and z-score scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAA</th>\n",
       "      <th>AAAC</th>\n",
       "      <th>AAAG</th>\n",
       "      <th>AAAT</th>\n",
       "      <th>AACA</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACG</th>\n",
       "      <th>AACT</th>\n",
       "      <th>AAGA</th>\n",
       "      <th>AAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>TTCG</th>\n",
       "      <th>TTCT</th>\n",
       "      <th>TTGA</th>\n",
       "      <th>TTGC</th>\n",
       "      <th>TTGG</th>\n",
       "      <th>TTGT</th>\n",
       "      <th>TTTA</th>\n",
       "      <th>TTTC</th>\n",
       "      <th>TTTG</th>\n",
       "      <th>TTTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.012296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.011171</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.010296</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.010735</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.012935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AAAA      AAAC      AAAG      AAAT      AACA      AACC      AACG  \\\n",
       "165  0.011397  0.004957  0.006232  0.007732  0.005144  0.003514  0.001003   \n",
       "61   0.011171  0.004899  0.006186  0.007506  0.004952  0.003404  0.001092   \n",
       "505  0.009708  0.004292  0.005560  0.006187  0.004473  0.003260  0.000906   \n",
       "195  0.010296  0.004465  0.005574  0.006276  0.004599  0.003285  0.000946   \n",
       "28   0.010735  0.004810  0.005851  0.007083  0.004869  0.003637  0.001012   \n",
       "\n",
       "         AACT      AAGA      AAGC  ...      TTCG      TTCT      TTGA  \\\n",
       "165  0.004209  0.006127  0.004034  ...  0.000800  0.006792  0.004556   \n",
       "61   0.003974  0.005804  0.004068  ...  0.000891  0.006474  0.004591   \n",
       "505  0.003681  0.005422  0.003890  ...  0.000955  0.006198  0.003885   \n",
       "195  0.003524  0.005462  0.003976  ...  0.000983  0.006081  0.003853   \n",
       "28   0.003622  0.005529  0.004106  ...  0.000792  0.006981  0.004429   \n",
       "\n",
       "         TTGC      TTGG      TTGT      TTTA      TTTC      TTTG      TTTT  \n",
       "165  0.003836  0.004734  0.004979  0.006399  0.006506  0.006603  0.012296  \n",
       "61   0.003733  0.004832  0.004792  0.006253  0.006454  0.006681  0.013021  \n",
       "505  0.003597  0.004584  0.004606  0.005311  0.005934  0.005870  0.010900  \n",
       "195  0.003597  0.004661  0.004573  0.005190  0.005933  0.005833  0.011200  \n",
       "28   0.003608  0.004517  0.004341  0.005719  0.006467  0.006423  0.012935  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm  # starting now, each step must be repeated on X_test\n",
    "X_norm[:5]\n",
    "# Review the data before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165    0\n",
       "61     0\n",
       "505   -1\n",
       "195   -1\n",
       "28     0\n",
       "139    0\n",
       "45     0\n",
       "77     0\n",
       "140    1\n",
       "374    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: try this with a numpy array to ensure model doesn't see the row id like 165.\n",
    "# Why is 195 a negative? Perhaps the number is the number after shuffle.\n",
    "y_train[:10]\n",
    "# Review the data before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50162866, 0.50162866, 0.49837134])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=40) \n",
    "sgd_accuracy=cross_val_score(sgd, X_norm, y_train, cv=3, scoring=\"accuracy\")\n",
    "sgd_accuracy\n",
    "# Accuracy is slightly better than chance (differs by class) using normalized data.\n",
    "# TO DO: try grid search to optimize hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.99674267])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=41)\n",
    "rfc_accuracy = cross_val_score(rfc,X_norm, y_train, cv=3, scoring=\"accuracy\")\n",
    "rfc_accuracy\n",
    "# Accuracy is perfect using normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99674267, 1.        , 0.98697068])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm_accuracy=cross_val_score(svm, X_norm, y_train, cv=3, scoring=\"accuracy\")\n",
    "svm_accuracy\n",
    "# Accuracy is nearly perfect using normalized data. How did that happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77198697, 0.7752443 , 0.7980456 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm_accuracy=cross_val_score(svm, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "svm_accuracy\n",
    "# Accuracy is still pretty good using not-normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00989822, 0.00431689, 0.00559997, ..., 0.00600105, 0.00595757,\n",
       "        0.01107305],\n",
       "       [0.00994656, 0.00431837, 0.00560762, ..., 0.00602272, 0.00597691,\n",
       "        0.01114138],\n",
       "       [0.01196311, 0.00480032, 0.00591872, ..., 0.00643394, 0.00575536,\n",
       "        0.01335796],\n",
       "       ...,\n",
       "       [0.01206515, 0.00529931, 0.00666697, ..., 0.00628469, 0.00657799,\n",
       "        0.0120256 ],\n",
       "       [0.01209814, 0.00526933, 0.0066422 , ..., 0.00584247, 0.00644671,\n",
       "        0.01176491],\n",
       "       [0.01195536, 0.00523076, 0.0065766 , ..., 0.00587824, 0.00649336,\n",
       "        0.01181661]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_norm, y_train) # train on the full set (not cross validation fraction)\n",
    "svm.dual_coef_\n",
    "svm.classes_\n",
    "svm.support_vectors_\n",
    "# No signs of trouble (e.g. if the first or last column were 100%, maybe it contained the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_train,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Maybe problem was easy given the zeros. \n",
    "# But we really want classes 1 and -1.\n",
    "# How would the model do on just the zeros forcing them to score as 1 or -1.\n",
    "# Or go back to the RNA and classify as + or - without a zero class.\n",
    "# The visual clustering provided visual intuition of but now we're getting down to individual cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare traditional ML to deep learning.\n",
    "# Not sure if we want feature selection, but it could extract k-mers indicative of biology.\n",
    "# Compare to other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the LncAtlas scores rather than 3 bins.\n",
    "# Try KNN on scores.\n",
    "# Try logistic regression. Try thresholds. Add inverse log as another feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What did LncADeep use if they didn't use the LncAtlas.\n",
    "# Try Google collaborate on cloud.\n",
    "# Can I use Xcede? \n",
    "# Price a desktop GPU?\n",
    "# 8-cluster GPU at WVU called Titan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the training score was 1, the model probably overfit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
