{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFXUwj5sKlBa"
   },
   "source": [
    "# RNN on RNA K-mers\n",
    "\n",
    "Extract every K-mer for K=3.\n",
    "Apply one-hot encoding.\n",
    "Convert to ragged tensors.\n",
    "Train with 3-deep RNN.\n",
    "\n",
    "Previous runs exhausted RAM.\n",
    "This version trains the same model additively on small batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF0oFz5oKlBj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.keras.backend.set_floatx('float32')  # save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-2yAOndKlCE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n",
      "Build the training environment\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 64)          8256      \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 1)                 66        \n",
      "=================================================================\n",
      "Total params: 24,834\n",
      "Trainable params: 24,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K=3   # K-mer length = word length\n",
    "\n",
    "def showtime():\n",
    "    now=datetime.now()\n",
    "    current=now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Time=\",current)\n",
    "\n",
    "showtime()\n",
    "print(\"Build the model\")\n",
    "seq_len=None  # none indicates variable length\n",
    "input_features=4**K   # 64 DNA K-mers at K=3\n",
    "rnn2 = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True, input_shape=[seq_len,input_features]),\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1),\n",
    "])\n",
    "\n",
    "showtime()\n",
    "print(\"Build the training environment\")\n",
    "bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "rnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "SHgYYvUPKlBt",
    "outputId": "a1728f02-612d-4f95-b630-02571f7f9b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ncRNA.fasta\n",
      "Encoder categories\n",
      "[array(['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA',\n",
      "       'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC',\n",
      "       'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG',\n",
      "       'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT',\n",
      "       'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA',\n",
      "       'GTC', 'GTG', 'GTT', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC',\n",
      "       'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG',\n",
      "       'TTT'], dtype='<U3')]\n"
     ]
    }
   ],
   "source": [
    "MIN_SEQ_LEN=200   ### by definition, lncRNA have min len 200\n",
    "#MIN_SEQ_LEN=1000  ### we use this to reduce training RAM and CPU\n",
    "MAX_SEQ_LEN=25000 ### this screens 4 outliers in the complete dataset\n",
    "#MAX_SEQ_LEN=2000  ### we use this to reduce training RAM and CPU\n",
    "DEFLINE='>'\n",
    "ncfile='ncRNA.fasta' \n",
    "pcfile='pcRNA.fasta' \n",
    "#ncfile='tiny.ncRNA.fasta' # 10 seqs for faster debugging\n",
    "#pcfile='tiny.pcRNA.fasta' # 10 seqs for faster debugging\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "## !ls drive/'My Drive'/'Colab Notebooks'/*\n",
    "#ncfile='drive/My Drive/Colab Notebooks/ncRNA.fasta'\n",
    "#pcfile='drive/My Drive/Colab Notebooks/pcRNA.fasta'\n",
    "\n",
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Returned structure is ndarray of ndarray i.e no python lists inside.\n",
    "def load_fasta(filename,min_len,max_len):\n",
    "    seqs=[]\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE and len(line)>min_len and len(line)<=max_len:\n",
    "                line=line.rstrip()\n",
    "                linelen=len(line)\n",
    "                kmers=[]\n",
    "                for i in range(linelen-K+1): # e.g. k=3,|line=4| => range=2 so i={0,1}\n",
    "                    kmer=line[i:i+K]\n",
    "                    kmers.append(kmer)\n",
    "                kmers=np.array(kmers)\n",
    "                seqs.append(kmers.reshape(-1, 1)) # reshaped changes (any,) to (any,1)\n",
    "    nparray=np.array(seqs)\n",
    "    return nparray\n",
    "\n",
    "showtime()\n",
    "print(\"Load \"+ncfile)\n",
    "nc_seqs = load_fasta(ncfile,MIN_SEQ_LEN,MAX_SEQ_LEN)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "#seq=tf.reshape(nc_seqs[0],shape=(-1, 1)) # tensor flow version\n",
    "seq=nc_seqs[0].reshape(-1, 1)\n",
    "encoder.fit(seq)\n",
    "print(\"Encoder categories\")\n",
    "print(str(encoder.categories_))\n",
    "nc_seqs = None\n",
    "seq=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop: additively train the model in small batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch 0\n",
      "Batch of RNA lengths 0 to 1000\n",
      "Load ncRNA.fasta\n",
      "Load pcRNA.fasta\n",
      "Ecode the non-coding sequences\n",
      "nc shape: (11415,)\n",
      "Encode the protein-coding sequences\n",
      "pc shape: (7270,)\n",
      "shape of sequences, shape of labels\n",
      "shape of train\n",
      "(14948,) (14948,)\n",
      "shape of test\n",
      "(3737,) (3737,)\n",
      "Convert numpy array to python 3D array\n",
      "Partition = 11958\n",
      "Partition train/validation\n",
      "Lengths of train,valid\n",
      "(11958, 2990)\n",
      "Free memory.\n",
      "Convert to tensors\n",
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "(11958, None, None)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(11958,)\n",
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "(2990, None, None)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(2990,)\n",
      "Train the model\n",
      "374/374 [==============================] - 497s 1s/step - loss: 3.1799 - accuracy: 0.5370 - val_loss: 2.0506 - val_accuracy: 0.5448\n",
      "Visualize training history.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Batch of RNA lengths 1000 to 2000\n",
      "Load ncRNA.fasta\n",
      "Load pcRNA.fasta\n",
      "Ecode the non-coding sequences\n",
      "nc shape: (3758,)\n",
      "Encode the protein-coding sequences\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b75102f9ab2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpc_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc_seqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mencoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    467\u001b[0m                                 dtype=self.dtype)\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mcsr_todense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "BATCHES=6\n",
    "# batch max: 1K, 2K, 4K, 8K, 16K, 32K\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch %d\"%epoch)\n",
    "    batch_max = 0\n",
    "    for batch in range(BATCHES):\n",
    "        showtime()\n",
    "        print (\"Batch %d\"%batch)\n",
    "        batch_min = batch_max\n",
    "        batch_max = 1000 * (2**batch)\n",
    "        print(\"Batch of RNA lengths %d to %d\"%(batch_min,batch_max))\n",
    "        \n",
    "        print(\"Load \"+ncfile)\n",
    "        nc_seqs = load_fasta(ncfile,batch_min,batch_max)\n",
    "        print(\"Load \"+pcfile)\n",
    "        pc_seqs = load_fasta(pcfile,batch_min,batch_max)\n",
    "\n",
    "        print(\"Ecode the non-coding sequences\")\n",
    "        nc_list=[]\n",
    "        for seq in nc_seqs:\n",
    "            encoded=encoder.transform(seq)  \n",
    "            nc_list.append(encoded)\n",
    "\n",
    "        nc_len=len(nc_list)\n",
    "        nc_all=np.array(nc_list) # .reshape(-1,1)\n",
    "        print(\"nc shape: \"+str(nc_all.shape))\n",
    "\n",
    "        print(\"Encode the protein-coding sequences\")\n",
    "        pc_list=[]\n",
    "        for seq in pc_seqs:\n",
    "            encoded=encoder.transform(seq)\n",
    "            pc_list.append(encoded)\n",
    "\n",
    "        pc_len=len(pc_list)\n",
    "        pc_all=np.array(pc_list) # .reshape(-1,1)\n",
    "        print(\"pc shape: \"+str(pc_all.shape))\n",
    "        \n",
    "        nc_labels=np.zeros(shape=(nc_len))\n",
    "        pc_labels=np.ones(shape=(pc_len))\n",
    "        all_seqs=np.concatenate((nc_all,pc_all),axis=0)\n",
    "        all_labels=np.concatenate((nc_labels,pc_labels),axis=0)\n",
    "\n",
    "        print(\"shape of sequences, shape of labels\")\n",
    "        all_seqs.shape,all_labels.shape\n",
    "\n",
    "        splitter = ShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "        for train_index,test_index in splitter.split(all_seqs):\n",
    "            train_seqs =   all_seqs[train_index]\n",
    "            train_labels = all_labels[train_index]\n",
    "            test_seqs =    all_seqs[test_index]\n",
    "            test_labels =  all_labels[test_index]\n",
    "\n",
    "        print(\"shape of train\")\n",
    "        print(train_seqs.shape,train_labels.shape)\n",
    "        print(\"shape of test\")\n",
    "        print(test_seqs.shape,test_labels.shape)\n",
    "\n",
    "        print(\"Convert numpy array to python 3D array\")\n",
    "        def numpy_to_python_3D(np_seqs):\n",
    "            one_set = []\n",
    "            tlen = len(np_seqs)\n",
    "            for i in range(tlen): # for every sequence in set\n",
    "                one_seq = []\n",
    "                slen = len(np_seqs[i])\n",
    "                for j in range(slen): # for ever letter in sequence\n",
    "                    one_letter=np_seqs[i][j]\n",
    "                    one_seq.append(one_letter)\n",
    "                one_set.append(one_seq)\n",
    "            return one_set\n",
    "        train_seqs = numpy_to_python_3D(train_seqs)\n",
    "        test_seqs = numpy_to_python_3D(test_seqs)\n",
    "        train_labels = train_labels.tolist()\n",
    "        test_labels = test_labels.tolist()\n",
    "\n",
    "        # Now that values are shuffled, partition gives random sample.\n",
    "        data_size=len(train_seqs)\n",
    "        PARTITION=int(data_size*0.8)\n",
    "        print(\"Partition = \"+str(PARTITION))\n",
    "\n",
    "        print(\"Partition train/validation\")\n",
    "        X_train=train_seqs[:PARTITION]\n",
    "        X_valid=train_seqs[PARTITION:]\n",
    "        y_train=train_labels[:PARTITION]\n",
    "        y_valid=train_labels[PARTITION:]\n",
    "        print(\"Lengths of train,valid\")\n",
    "        print((len(X_train),len(X_valid)))\n",
    "\n",
    "        print(\"Free memory.\")\n",
    "        nc_list=None\n",
    "        pc_list=None\n",
    "        nc_all=None\n",
    "        pc_all=None\n",
    "        nc_seqs=None\n",
    "        pc_seqs=None\n",
    "        all_seqs=None\n",
    "        nc_labels=None\n",
    "        pc_labels=None\n",
    "        train_seqs=None\n",
    "        train_labels=None\n",
    "\n",
    "        showtime()\n",
    "        print(\"Convert to tensors\")\n",
    "        tensor = tf.ragged.constant(X_train)\n",
    "        X_train = tensor\n",
    "        tensor=None\n",
    "        print(type(X_train))\n",
    "        print(X_train.shape)\n",
    "        tensor = tf.convert_to_tensor(y_train)\n",
    "        y_train = tensor\n",
    "        tensor=None\n",
    "        print(type(y_train))\n",
    "        print(y_train.shape)\n",
    "        tensor = tf.ragged.constant(X_valid)\n",
    "        X_valid=tensor\n",
    "        tensor=None\n",
    "        print(type(X_valid))\n",
    "        print(X_valid.shape)\n",
    "        tensor = tf.convert_to_tensor(y_valid)\n",
    "        y_valid = tensor\n",
    "        tensor=None\n",
    "        print(type(y_valid))\n",
    "        print(y_valid.shape)\n",
    "        \n",
    "        showtime()\n",
    "        print(\"Resume training the model\")\n",
    "        history = rnn2.fit(X_train,y_train,epochs=1,\n",
    "                           validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBoVjg06KlCJ"
   },
   "outputs": [],
   "source": [
    "# Loss 3.7 to 3.2, accuracy .5 to .53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGVmufeoKlCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quH4crn8KlCR"
   },
   "source": [
    "Resources.\n",
    "[Working with RNNs](https://keras.io/guides/working_with_rnns/).\n",
    "[Recurrent Neural Networks with Keras](https://www.tensorflow.org/guide/keras/rnn#rnns_with_listdict_inputs_or_nested_inputs).\n",
    "Function tf.convert_to_tensor [docs](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor).\n",
    "Function tf.reshape [docs](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "Ragged Tensors [tutorial](https://www.tensorflow.org/guide/tensor#ragged_tensors)\n",
    "and [docs](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#documenting_raggedtensor_shapes_2) and [module](https://www.tensorflow.org/api_docs/python/tf/ragged).\n",
    "Incredible speedup for convert to tensor by sirfz on [stackoverflow](https://stackoverflow.com/questions/44353509/tensorflow-tf-constant-initializer-is-very-slow).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QeTNy7HKlCT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lncRNA_14_Kmers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
