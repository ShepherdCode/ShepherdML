{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with OneHot tensor\n",
    "Combine three previous achievements.\n",
    "Still hold off on the stratified split.\n",
    "This time use tensors instead of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.keras.backend.set_floatx('float32')  # was 64, now we're running out of memory. make this 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from FASTA files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ncRNA.fasta\n",
      "Load pcRNA.fasta\n"
     ]
    }
   ],
   "source": [
    "MIN_SEQ_LEN=200\n",
    "MAX_SEQ_LEN=25000\n",
    "DEFLINE='>'\n",
    "ncfile='ncRNA.fasta' \n",
    "pcfile='pcRNA.fasta' \n",
    "#ncfile='tiny.ncRNA.fasta' # 10 seqs for faster debugging\n",
    "#pcfile='tiny.pcRNA.fasta' \n",
    "\n",
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Returned structure is ndarray of ndarray i.e no python lists inside.\n",
    "def load_fasta(filename):\n",
    "    seqs=[]\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE and len(line)>=MIN_SEQ_LEN and len(line)<=MAX_SEQ_LEN:\n",
    "                line=line.rstrip()\n",
    "                chars=np.array(list(line))\n",
    "                seqs.append(chars.reshape(-1, 1)) # reshaped changes (any,) to (any,1)\n",
    "    nparray=np.array(seqs)\n",
    "    return nparray\n",
    "\n",
    "print(\"Load \"+ncfile)\n",
    "nc_seqs = load_fasta(ncfile)\n",
    "print(\"Load \"+pcfile)\n",
    "pc_seqs = load_fasta(pcfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode DNA letters with 4-bit one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['A', 'C', 'G', 'T'], dtype='<U1')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "print(\"Fit\")\n",
    "#seq=tf.reshape(nc_seqs[0],shape=(-1, 1)) # tensor flow version\n",
    "seq=nc_seqs[0].reshape(-1, 1)\n",
    "encoder.fit(seq)\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded=encoder.transform(seq) # returns a numpy.ndarray\n",
    "print(type(encoded))\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-coding\n",
      "shape: (17711,)\n",
      "element 0 is a sequence: \n",
      "[[0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "element 0,0 is one letter: [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"non-coding\")\n",
    "nc_list=[]\n",
    "for seq in nc_seqs:\n",
    "    encoded=encoder.transform(seq)  \n",
    "    nc_list.append(encoded)\n",
    "    \n",
    "nc_all=np.array(nc_list) # .reshape(-1,1)\n",
    "print(\"shape: \"+str(nc_all.shape))\n",
    "print(\"element 0 is a sequence: \\n\"+str(nc_all[0]))\n",
    "print(\"element 0,0 is one letter: \"+str(nc_all[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein-coding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20152,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"protein-coding\")\n",
    "pc_list=[]\n",
    "for seq in pc_seqs:\n",
    "    encoded=encoder.transform(seq)\n",
    "    pc_list.append(encoded)\n",
    "\n",
    "pc_all=np.array(pc_list) # .reshape(-1,1)\n",
    "pc_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels. Create train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37863,), (37863,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_labels=np.zeros(shape=(17711))\n",
    "pc_labels=np.ones(shape=(20152))\n",
    "#nc_labels=np.zeros(shape=(10))  # fast debugging\n",
    "#pc_labels=np.ones(shape=(10))\n",
    "\n",
    "#nc_labeled=np.concatenate((nc_all,nc_labels),axis=1)\n",
    "#pc_labeled=np.concatenate((pc_all,pc_labels),axis=1)\n",
    "all_seqs=np.concatenate((nc_all,pc_all),axis=0)\n",
    "all_labels=np.concatenate((nc_labels,pc_labels),axis=0)\n",
    "\n",
    "all_seqs.shape,all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(30290,) (30290,)\n",
      "test\n",
      "(7573,) (7573,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "for train_index,test_index in splitter.split(all_seqs):\n",
    "    train_seqs =   all_seqs[train_index]\n",
    "    train_labels = all_labels[train_index]\n",
    "    test_seqs =    all_seqs[test_index]\n",
    "    test_labels =  all_labels[test_index]\n",
    " \n",
    "print(\"train\")\n",
    "print(train_seqs.shape,train_labels.shape)\n",
    "print(\"test\")\n",
    "print(test_seqs.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Xy data shape:\n",
      "(25000,) (25000,)\n",
      "Validation Xy data shape:\n",
      "(5290,) (5290,)\n",
      "train 0 is one sequence: \n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "train 0,0 is one letter: \n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Now that values are shuffled, partition gives random sample.\n",
    "PARTITION=25000 # full dataset, TO DO: compute this as % of input\n",
    "#PARTITION=8     # tiny data, fast debugging\n",
    "\n",
    "X_trainNP=train_seqs[:PARTITION]\n",
    "X_validNP=train_seqs[PARTITION:]\n",
    "y_trainNP=train_labels[:PARTITION]\n",
    "y_validNP=train_labels[PARTITION:]\n",
    "print(\"Training Xy data shape:\")\n",
    "print(X_trainNP.shape,y_trainNP.shape)\n",
    "print(\"Validation Xy data shape:\")\n",
    "print(X_validNP.shape,y_validNP.shape)\n",
    "print(\"train 0 is one sequence: \\n\"+str(X_trainNP[0]))\n",
    "print(\"train 0,0 is one letter: \\n\"+str(X_trainNP[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n",
      "[1 2 3]\n",
      "(8, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Side experiment.\n",
    "# X_trainNP was ( array o seqs ( array of onehot ( array of bits)))\n",
    "# We need to reshape this to 3D array.\n",
    "# Try this.\n",
    "ary_of_ary = np.array([[1,2,3], [4,5,6], [1,2,3], [4,5,6],[1,2,3], [4,5,6],[1,2,3], [4,5,6]])\n",
    "print(ary_of_ary.shape) \n",
    "print(ary_of_ary[0])\n",
    "b = np.reshape(ary_of_ary, (8, 3, -1)) \n",
    "print(b.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "(25000, None, None)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(25000,)\n",
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "(5290, None, None)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(5290,)\n"
     ]
    }
   ],
   "source": [
    "# The SimpleRNN won't accept our numpy arrays. Here is the error.\n",
    "# ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).\n",
    "\n",
    "# For variable length sequences, it seems we must use a TensorFlow Ragged Tensor, which is much slower.\n",
    "# https://www.tensorflow.org/guide/tensor#ragged_tensors\n",
    "\n",
    "X_train = tf.ragged.constant(X_trainNP)  # This takes a long time and hogs memory\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "y_train = tf.convert_to_tensor(y_trainNP)\n",
    "print(type(y_train))\n",
    "print(y_train.shape)\n",
    "X_valid = tf.ragged.constant(X_validNP)\n",
    "print(type(X_valid))\n",
    "print(X_valid.shape)\n",
    "y_valid = tf.convert_to_tensor(y_validNP)\n",
    "print(type(y_valid))\n",
    "print(y_valid.shape)\n",
    "\n",
    "# This page offers a speedup for a slightly different problem and I cannot understand it.\n",
    "# https://stackoverflow.com/questions/44353509/tensorflow-tf-constant-initializer-is-very-slow\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#documenting_raggedtensor_shapes_2\n",
    "# For example, the shape of a 3-D RaggedTensor that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as [num_sentences, (num_words), embedding_size].\n",
    "\n",
    "# We are seeing <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> (8, None, None, None)\n",
    "# Why do we get a 4D tensor for X? We need a 3D tensor for X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, None, 4)           36        \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_len=None  # none indicates variable length\n",
    "input_features=4  # one hot encoding of DNA means 4 categories\n",
    "rnn2 = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(4, return_sequences=True, input_shape=[seq_len,input_features]),\n",
    "    keras.layers.SimpleRNN(1),\n",
    "])\n",
    "bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "rnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "599/782 [=====================>........] - ETA: 35:59 - loss: 3.7287 - accuracy: 0.4856"
     ]
    }
   ],
   "source": [
    "history = rnn2.fit(X_train,y_train,epochs=5,validation_data=(X_valid,y_valid))\n",
    "# ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources.\n",
    "[Working with RNNs](https://keras.io/guides/working_with_rnns/).\n",
    "[Recurrent Neural Networks with Keras](https://www.tensorflow.org/guide/keras/rnn#rnns_with_listdict_inputs_or_nested_inputs).\n",
    "Function tf.convert_to_tensor [docs](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor).\n",
    "Function tf.reshape [docs](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "Ragged Tensors [tutorial](https://www.tensorflow.org/guide/tensor#ragged_tensors)\n",
    "and [docs](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#documenting_raggedtensor_shapes_2) and [module](https://www.tensorflow.org/api_docs/python/tf/ragged).\n",
    "Incredible speedup for convert to tensor by sirfz on [stackoverflow](https://stackoverflow.com/questions/44353509/tensorflow-tf-constant-initializer-is-very-slow).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
