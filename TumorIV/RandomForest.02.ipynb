{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Build on notebook 01 which prepared train and valid sets\n",
    "from the H&E Image.csv rows \n",
    "Here, train RF classifier in one round of CV.\n",
    "Result: 63% accuracy.\n",
    "Later, filter by RBC stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 06:21:32.592919\n",
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle X,y in tandem.\n",
    "from sklearn.utils import shuffle\n",
    "# The model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# This generates one split after shuffling. By default, not stratified.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# This does stratified K-fold cross-validation with no shuffling.\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.feature_selection import RFE\n",
    "#import joblib # used to dump/load sklearn models\n",
    "#from CellProfiler_Util import CP_Util\n",
    "#from RandomForestUtil import RF_Util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train and valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All patients ['B7_', 'B15', 'D1_', 'D5_', 'E7_', 'E9_', 'F9_', 'G3_', 'H13', 'I1_', 'I5_', 'I13', 'A3_', 'A5_', 'B13', 'C1_', 'C11', 'D3_', 'E5_', 'F3_', 'F7_', 'F11', 'F15', 'G15', 'H1_', 'H3_', 'H7_', 'H15']\n",
      "Count Ypos:Yneg 12 16\n",
      "Hold out these patients for validation in each cross-validation fold.\n",
      "Fold 0 pos, neg: ['F9_', 'H13', 'B15'] ['C1_', 'F3_', 'A5_', 'F15']\n",
      "Fold 1 pos, neg: ['B7_', 'D5_', 'E7_'] ['H3_', 'D3_', 'G15', 'F7_']\n",
      "Fold 2 pos, neg: ['I13', 'I5_', 'I1_'] ['C11', 'H7_', 'B13', 'E5_']\n",
      "Fold 3 pos, neg: ['G3_', 'E9_', 'D1_'] ['H15', 'F11', 'H1_', 'A3_']\n"
     ]
    }
   ],
   "source": [
    "# Prepare to divy up patches stratified by patient.\n",
    "DF_Ypos = ['B7_','B15','D1_','D5_','E7_','E9_','F9_','G3_','H13','I1_','I5_','I13']\n",
    "DF_Yneg = ['A3_','A5_','B13','C1_','C11','D3_','E5_','F3_','F7_','F11','F15','G15','H1_','H3_','H7_','H15']\n",
    "ALL_PATIENTS = DF_Ypos + DF_Yneg\n",
    "NUM_FOLDS=4  # because both sets have size = multiple of 4\n",
    "print('All patients',ALL_PATIENTS)\n",
    "print('Count Ypos:Yneg',len(DF_Ypos),len(DF_Yneg))\n",
    "print('Hold out these patients for validation in each cross-validation fold.')\n",
    "def make_folds():\n",
    "    rpos = shuffle(DF_Ypos)  # fix random state?\n",
    "    rneg = shuffle(DF_Yneg)  # fix random state?\n",
    "    folds_pos = [rpos[0:3],rpos[3:6],rpos[6:9],rpos[9:12]]\n",
    "    folds_neg = [rneg[0:4],rneg[4:8],rneg[8:12],rneg[12:16]]\n",
    "    for i in range(4):\n",
    "        print('Fold %d pos, neg:'%i,end=' ')\n",
    "        print(folds_pos[i],folds_neg[i])\n",
    "    return folds_pos,folds_neg\n",
    "Ypos_valid_patients,Yneg_valid_patients = make_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH='/home/jrm/Martinez/CellProfilerRuns/CP_20220705/'\n",
    "FILENAME='Process100_Image.csv'\n",
    "def load_patient(p):\n",
    "    filepath=BASE_PATH+p+'/'+FILENAME\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patients(fold):\n",
    "    train_patients = list(ALL_PATIENTS)  # this will shrink\n",
    "    valid_patients = []   # this will grow\n",
    "    for patient in Ypos_valid_patients[fold]:\n",
    "        train_patients.remove(patient)\n",
    "        valid_patients.append(patient)\n",
    "    for patient in Yneg_valid_patients[fold]:\n",
    "        train_patients.remove(patient)\n",
    "        valid_patients.append(patient)\n",
    "    return train_patients,valid_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv rows for one fold\n",
    "def load_fold(fold,train_patients,valid_patients):\n",
    "    X_train=None\n",
    "    y_train=None\n",
    "    X_valid=None\n",
    "    y_valid=None\n",
    "    for patient in train_patients:\n",
    "        df = load_patient(patient)\n",
    "        func = np.ones\n",
    "        if patient not in DF_Ypos:\n",
    "            func = np.zeros\n",
    "        if X_train is None:\n",
    "            X_train = df\n",
    "            y_train = func(len(df))\n",
    "        else:\n",
    "            X_train = pd.concat( (X_train,df) )\n",
    "            y_train = np.concatenate( (y_train, func(len(df))))\n",
    "    for patient in valid_patients:\n",
    "        df = load_patient(patient)\n",
    "        func = np.ones\n",
    "        if patient not in DF_Ypos:\n",
    "            func = np.zeros\n",
    "        if X_valid is None:\n",
    "            X_valid = df\n",
    "            y_valid = func(len(df))\n",
    "        else:\n",
    "            X_valid = pd.concat( (X_valid,df) )\n",
    "            y_valid = np.concatenate( (y_valid, func(len(df))))\n",
    "    return X_train,y_train,X_valid,y_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 train patients\n",
      "['B7_', 'D1_', 'D5_', 'E7_', 'E9_', 'G3_', 'I1_', 'I5_', 'I13', 'A3_', 'B13', 'C11', 'D3_', 'E5_', 'F7_', 'F11', 'G15', 'H1_', 'H3_', 'H7_', 'H15']\n",
      "Fold 0 valid patients\n",
      "['F9_', 'H13', 'B15', 'C1_', 'F3_', 'A5_', 'F15']\n",
      "Fold: 0 Patch Train set X: (5764, 5308) y: 5764\n",
      "Fold: 0 Patch Valid set X: (1958, 5308) y: 1958\n"
     ]
    }
   ],
   "source": [
    "fold = 0   # later do all folds\n",
    "train_patients,valid_patients = load_patients(fold)  \n",
    "print('Fold %d train patients'%fold)\n",
    "print(train_patients)\n",
    "print('Fold %d valid patients'%fold)\n",
    "print(valid_patients)\n",
    "\n",
    "X_train,y_train,X_valid,y_valid = load_fold(fold,train_patients,valid_patients)\n",
    "print('Fold:',fold,'Patch Train set X:',X_train.shape,'y:',len(y_train))\n",
    "print('Fold:',fold,'Patch Valid set X:',X_valid.shape,'y:',len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining nan values: 0\n",
      "Number of string columns: 0\n",
      "Number of infinite values: 0\n"
     ]
    }
   ],
   "source": [
    "# Expect nan for mean_RBC_diameter where #RBC=0\n",
    "X_train.fillna(0,inplace=True)\n",
    "X_valid.fillna(0,inplace=True)\n",
    "nan = X_train.isna().sum().sum()\n",
    "print('Number of remaining nan values:',nan)\n",
    "# Expect no strings in X\n",
    "temp_df=X_train.select_dtypes(include='object')\n",
    "print('Number of string columns:',len(temp_df.columns>0))\n",
    "# Expect no infinite values\n",
    "inf = np.isinf(X_train).values.sum()\n",
    "print('Number of infinite values:',inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 06:22:56.208891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 06:23:15.689934\n",
      "Accuracy: 62.512768130745656\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "y_pred = rfc.predict(X_valid)\n",
    "matches = np.count_nonzero(y_valid==y_pred)\n",
    "accuracy = 100.0 * matches / len(y_pred)  \n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 06:23:15.777522\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
