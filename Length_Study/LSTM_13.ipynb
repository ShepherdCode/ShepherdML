{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=10\n",
    "SPLITS=1\n",
    "K=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def subset(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,K,maxlen,eps):\n",
    "    cv_scores = []\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "        print(\"BUILD MODEL\")\n",
    "        vocabulary_size=4**K+1   # 64 DNA K-mers at K=3\n",
    "        embed_dimen=16\n",
    "\n",
    "        rnn2 = keras.models.Sequential()\n",
    "        embed_layer = keras.layers.Embedding(vocabulary_size,embed_dimen,input_length=maxlen);\n",
    "        #embed_layer = keras.layers.Embedding(input_dim=input_features, output_dim=embed_dimensions);\n",
    "        rnn1_layer = keras.layers.LSTM(16, return_sequences=True, \n",
    "                                   input_shape=[maxlen,embed_dimen])\n",
    "        rnn2_layer = keras.layers.LSTM(16, return_sequences=True)\n",
    "        rnn3_layer = keras.layers.LATM(16, return_sequences=True)\n",
    "        output_layer = keras.layers.SimpleRNN(1)\n",
    "\n",
    "        rnn2.add(embed_layer)\n",
    "        rnn2.add(rnn1_layer)\n",
    "        rnn2.add(rnn2_layer)\n",
    "        rnn2.add(rnn3_layer)\n",
    "        rnn2.add(output_layer)\n",
    "\n",
    "        bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        print(\"COMPILE\")\n",
    "        rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "        print(rnn2.summary())  # really only need this once\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "(X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(MINLEN,MAXLEN,train_set):\n",
    "    # Extract subset by length\n",
    "    print(\"Subset %d - %d\"%(MINLEN,MAXLEN))\n",
    "    train_set=subset(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 200 - 1000\n",
      "original (30290, 4)\n",
      "no short (30290, 4)\n",
      "no long, no short (8879, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(8879, 1)\n",
      "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
      "Name: 1280, dtype: object\n",
      "348\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[12 46 54 ...  0  0  0]\n",
      " [ 9 36 14 ...  0  0  0]\n",
      " [34  7 28 ...  0  0  0]\n",
      " ...\n",
      " [37 19  9 ...  0  0  0]\n",
      " [57 36 15 ...  0  0  0]\n",
      " [33  3 12 ...  0  0  0]]\n",
      "Split\n",
      "Train, validate\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "(X_TRAIN,y_TRAIN)=setup(MINLEN,MAXLEN,train_set)\n",
    "\n",
    "print (\"Split\")\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "for train_index,valid_index in splitter.split(X_TRAIN):\n",
    "    pass\n",
    "\n",
    "print (\"Train, validate\")\n",
    "X_train=X_TRAIN[train_index] # use iloc[] for dataframe\n",
    "y_train=y_TRAIN[train_index]\n",
    "X_valid=X_TRAIN[valid_index]\n",
    "y_valid=y_TRAIN[valid_index]\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD MODEL\n",
      "COMPILE\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1000, 16)          2112      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1000, 16)          2112      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1000, 16)          2112      \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 7,394\n",
      "Trainable params: 7,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"BUILD MODEL\")\n",
    "vocabulary_size=4**K+1   # 64 DNA K-mers at K=3\n",
    "embed_dimen=16\n",
    "maxlen=MAXLEN\n",
    "\n",
    "rnn2 = keras.models.Sequential()\n",
    "embed_layer = keras.layers.Embedding(vocabulary_size,embed_dimen,input_length=maxlen);\n",
    "#embed_layer = keras.layers.Embedding(input_dim=input_features, output_dim=embed_dimensions);\n",
    "rnn1_layer = keras.layers.LSTM(16, return_sequences=True, \n",
    "                           input_shape=[maxlen,embed_dimen])\n",
    "rnn2_layer = keras.layers.LSTM(16, return_sequences=True)\n",
    "rnn3_layer = keras.layers.LSTM(16, return_sequences=True)\n",
    "output_layer = keras.layers.SimpleRNN(1)\n",
    "\n",
    "rnn2.add(embed_layer)\n",
    "rnn2.add(rnn1_layer)\n",
    "rnn2.add(rnn2_layer)\n",
    "rnn2.add(rnn3_layer)\n",
    "rnn2.add(output_layer)\n",
    "\n",
    "bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "print(\"COMPILE\")\n",
    "rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "print(rnn2.summary())  # really only need this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT\n",
      "Epoch 1/3\n",
      "222/222 [==============================] - 389s 2s/step - loss: 0.8129 - accuracy: 0.5002 - val_loss: 0.6956 - val_accuracy: 0.5011\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 383s 2s/step - loss: 0.6953 - accuracy: 0.5033 - val_loss: 0.6946 - val_accuracy: 0.4983\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 384s 2s/step - loss: 0.6945 - accuracy: 0.5026 - val_loss: 0.6937 - val_accuracy: 0.5011\n"
     ]
    }
   ],
   "source": [
    "print(\"FIT\")\n",
    "eps=3\n",
    "# this is complaining about string to float\n",
    "history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "        epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "        validation_data=(X_valid,y_valid) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 1K-2Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "(X_train,y_train)=setup(MINLEN,MAXLEN,train_set)\n",
    "do_cross_validation(X_train,y_train,K,MAXLEN,EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 2K-3Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINLEN=2000\n",
    "MAXLEN=3000\n",
    "(X_train,y_train)=setup(MINLEN,MAXLEN,train_set)\n",
    "do_cross_validation(X_train,y_train,K,MAXLEN,EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
