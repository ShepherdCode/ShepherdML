{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN cross validation\n",
    "Classify pc vs nc RNA.\n",
    "\n",
    "Set aside the 20% test set, stratified by length.\n",
    "On the remaining 80%,\n",
    "perform 5-fold cross validation.\n",
    "\n",
    "Use K=3. (K=2 was run previously.)\n",
    "Test 1K-2K subsets of the data.\n",
    "Use RNN(16,16,16,1).\n",
    "\n",
    "To do: \n",
    "Masking the Ns.\n",
    "Either bidirectional RNN or try starting with the Ns.\n",
    "Handle end case of max len < num K-mers.\n",
    "K-mer embedding (like word2vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=10\n",
    "SPLITS=1\n",
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "K=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def subset(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,K,maxlen,eps):\n",
    "    cv_scores = []\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "        print(\"BUILD MODEL\")\n",
    "        seq_len=maxlen  # None indicates variable length\n",
    "        input_features=4**K+1   # 64 DNA K-mers at K=3\n",
    "        rnn2 = keras.models.Sequential([\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True, \n",
    "                                   input_shape=[seq_len,input_features]),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(1),\n",
    "        ])\n",
    "\n",
    "        bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        print(\"COMPILE\")\n",
    "        rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "        print(\"FIT\")\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_encoding_set(K,uniform_len):\n",
    "    all_possible=['A','C','G','T']\n",
    "    if K==2:\n",
    "        all_possible=['AA','AC','AG','AT','CA','CC','CG','CT','GA','GC','GG','GT','TA','TC','TG','TT']\n",
    "    else:\n",
    "        k=1\n",
    "        while k<K:\n",
    "            temp=[]\n",
    "            for kmer in all_possible:\n",
    "                temp.append(kmer+'A')\n",
    "                temp.append(kmer+'C')\n",
    "                temp.append(kmer+'G')\n",
    "                temp.append(kmer+'T')\n",
    "            k += 1\n",
    "            all_possible=temp\n",
    "    i=16\n",
    "    pad_kmer='N'*K\n",
    "    while i < uniform_len:\n",
    "        all_possible.append(pad_kmer)\n",
    "        i += 1\n",
    "    return all_possible\n",
    "\n",
    "def generate_all_kmers(K):\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    return shorter_kmers\n",
    "\n",
    "def train_encoder(kmers):\n",
    "    narray = np.array(kmers)\n",
    "    array2d = narray.reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "    encoder.fit(array2d)\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_kmers(data,K,uniform_len):\n",
    "    all_seqs=[]\n",
    "    pad_char='N'\n",
    "    pad_kmer=pad_char*K\n",
    "    # pad_kmer=None      # Prefer this to the above. Will it work? No. Encoder balks.\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            kmers.append(kmer)\n",
    "            i += 1\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_kmer)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "(X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n"
     ]
    }
   ],
   "source": [
    "# Extract subset by length\n",
    "train_set=subset(train_set,MINLEN,MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n"
     ]
    }
   ],
   "source": [
    "# One array to two: X and y\n",
    "(X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "# The returned values are Pandas dataframes.\n",
    "# print(X_train_all.shape,y_train_all.shape)\n",
    "# (X_train_all,y_train_all)\n",
    "# y: Pandas dataframe to Python list.\n",
    "# y_train_all=y_train_all.values.tolist()\n",
    "# The sequences lengths are bounded but not uniform.\n",
    "X_train_all\n",
    "print(type(X_train_all))\n",
    "print(X_train_all.shape)\n",
    "print(X_train_all.iloc[0])\n",
    "print(len(X_train_all.iloc[0]['sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit...\n",
      "[array(['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA',\n",
      "       'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC',\n",
      "       'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG',\n",
      "       'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT',\n",
      "       'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA',\n",
      "       'GTC', 'GTG', 'GTT', 'NNN', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA',\n",
      "       'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC',\n",
      "       'TTG', 'TTT'], dtype='<U3')]\n"
     ]
    }
   ],
   "source": [
    "# X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "X_train_kmers=strings_to_kmers(X_train_all,K,MAXLEN)\n",
    "# X: true 2D array (no more lists)\n",
    "X_train_kmers.shape\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "# This takes a long time and may not be complete.\n",
    "# We should fit to sequences that absolutely contain every possible K-mer.\n",
    "sample_data=generate_encoding_set(K,MAXLEN)\n",
    "sample=np.array(sample_data).reshape(-1, 1)\n",
    "print(\"fit...\")\n",
    "encoder.fit(sample)\n",
    "print(str(encoder.categories_))\n",
    "\n",
    "#X_train_reshape=X_train_numpy.reshape(-1, 1)\n",
    "#X_train_encoded=encoder.fit(X_train_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "(3368, 2000, 65)\n"
     ]
    }
   ],
   "source": [
    "print(\"transform...\")\n",
    "# From pandas dataframe to numpy to list to numpy\n",
    "print(type(X_train_kmers))\n",
    "num_seqs=len(X_train_kmers)\n",
    "tmp_seqs=[]\n",
    "for i in range(num_seqs):\n",
    "    kmer_sequence=X_train_kmers.iloc[i]\n",
    "    X1=encoder.transform(kmer_sequence.to_numpy().reshape(-1, 1))\n",
    "    tmp_seqs.append(X1)\n",
    "encoded_seqs=np.array(tmp_seqs)\n",
    "tmp_seqs=None\n",
    "X_train_kmers=None\n",
    "print(type(encoded_seqs))\n",
    "print(encoded_seqs.shape)\n",
    "#X_train_encoded=encoder.transform(X_train_kmers.to_numpy().reshape(-1, 1))  # FLATTENS\n",
    "#X_train_encoded  # LONG TIME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 207s 2s/step - loss: 0.7230 - accuracy: 0.6151 - val_loss: 0.6749 - val_accuracy: 0.6053\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 201s 2s/step - loss: 0.6984 - accuracy: 0.6255 - val_loss: 0.6745 - val_accuracy: 0.6039\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 210s 2s/step - loss: 0.6722 - accuracy: 0.6229 - val_loss: 0.6758 - val_accuracy: 0.6053\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 203s 2s/step - loss: 0.6779 - accuracy: 0.6169 - val_loss: 0.6817 - val_accuracy: 0.6068\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 196s 2s/step - loss: 0.6740 - accuracy: 0.6240 - val_loss: 0.6770 - val_accuracy: 0.6053\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 192s 2s/step - loss: 0.6849 - accuracy: 0.6210 - val_loss: 0.6853 - val_accuracy: 0.6053\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 251s 3s/step - loss: 0.6805 - accuracy: 0.6214 - val_loss: 0.6874 - val_accuracy: 0.6053\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.6730 - accuracy: 0.6251 - val_loss: 0.6716 - val_accuracy: 0.6053\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 212s 2s/step - loss: 0.6789 - accuracy: 0.6218 - val_loss: 0.6807 - val_accuracy: 0.6098\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 188s 2s/step - loss: 0.6757 - accuracy: 0.6266 - val_loss: 0.6730 - val_accuracy: 0.6053\n",
      "Fold 1, 10 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 60.53%\n",
      "\n",
      "Validation core mean 60.53% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "labels=y_train_all.to_numpy()\n",
    "do_cross_validation(encoded_seqs,labels,K,MAXLEN,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
