{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN cross validation\n",
    "Classify pc vs nc RNA.\n",
    "Use K=2,3,4.\n",
    "\n",
    "Set aside the 20% test set, stratified by length.\n",
    "On the remaining 80%,\n",
    "perform 5-fold cross validation.\n",
    "\n",
    "Test subsets of the data with RNN.\n",
    "To do: Read sequences (not K-mers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def prepare_data_set(data):\n",
    "    y_test=   data[['class']].copy()\n",
    "    X_test=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X_test,y_test)\n",
    "\n",
    "def subset(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(data,K,uniform_len):\n",
    "    all_seqs=[]\n",
    "    pad_char='N'\n",
    "    pad_kmer=pad_char*K\n",
    "    for seq in data['sequence']:\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        for i in range(seqlen-K+1):\n",
    "            kmer=seq[i:i+K]\n",
    "            kmers.append(kmer)\n",
    "        for i in range(uniform_len):\n",
    "            kmer=pad_kmer\n",
    "            kmers.append(kmer)\n",
    "        all_seqs.append(kmers)\n",
    "    return all_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,K):\n",
    "    cv_scores = []\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "    fold=0\n",
    "    eps=100\n",
    "    splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X.iloc[train_index]\n",
    "        y_train=y.iloc[train_index]\n",
    "        X_valid=X.iloc[valid_index]\n",
    "        y_valid=y.iloc[valid_index]\n",
    "        mlp = keras.models.Sequential([\n",
    "            keras.layers.LayerNormalization(trainable=False),\n",
    "            keras.layers.Dense(32, activation=act,dtype=dt),\n",
    "            keras.layers.Dense(32, activation=act,dtype=dt),\n",
    "            keras.layers.Dense(1,  activation=act,dtype=dt)\n",
    "        ])\n",
    "        seq_len=None  # none indicates variable length\n",
    "        input_features=4**K   # 64 DNA K-mers at K=3\n",
    "        rnn2 = keras.models.Sequential([\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True, \n",
    "                                   input_shape=[seq_len,input_features]),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(1),\n",
    "        ])\n",
    "\n",
    "        bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=0,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = mlp.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (mlp.metrics_names[1], scores[1]*100))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "(X_test,y_test)=prepare_data_set(test_set)\n",
    "train_set=subset(train_set,MINLEN,MAXLEN)\n",
    "(X_train_all,y_train_all)=prepare_data_set(train_set)\n",
    "print(X_train_all.shape,y_train_all.shape)\n",
    "#X_train_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(K):\n",
    "    shorter_kmers=['']\n",
    "    longer_kmers=[]\n",
    "    for i in range(K):\n",
    "        print(i)\n",
    "        for mer in shorter_kmers:\n",
    "            print(mer)\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "        print(shorter_kmers)\n",
    "    return longer_kmers\n",
    "    #encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "train_encoder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1e8aa807b3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pandas dataframes to Python lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_kmers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAXLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-c30e0e0ea224>\u001b[0m in \u001b[0;36mmake_kmers\u001b[0;34m(data, K, uniform_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpad_char\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpad_kmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_char\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mseqlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mkmers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Pandas dataframes to Python lists.\n",
    "K=2\n",
    "X_train_all=make_kmers(X_train_all,K,MAXLEN)\n",
    "y_train_all=y_train_all.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "#encoder = train_encoder(K)\n",
    "#seq=nc_seqs[0].reshape(-1, 1)  # expects 2D array\n",
    "#encoder.fit(X_train_all)\n",
    "#print(\"Encoder categories\")\n",
    "#print(str(encoder.categories_))\n",
    "\n",
    "\n",
    "#do_cross_validation(X_train_all,y_train_all,K):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_mer = read_features('ncRNA.4mer.features.csv','pcRNA.4mer.features.csv')\n",
    "rna_mer = subset(rna_mer,1000,2000)\n",
    "(train_set,test_set)=make_train_test(rna_mer)\n",
    "(X_test,y_test)=prepare_test_set(test_set)\n",
    "(X_train_all,y_train_all)=prepare_train_set(train_set)\n",
    "print(X_train_all.shape,y_train_all.shape)\n",
    "do_cross_validation(X_train_all,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
