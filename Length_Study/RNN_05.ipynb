{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN cross validation\n",
    "Classify pc vs nc RNA.\n",
    "Use K=2,3,4.\n",
    "\n",
    "Set aside the 20% test set, stratified by length.\n",
    "On the remaining 80%,\n",
    "perform 5-fold cross validation.\n",
    "\n",
    "Test subsets of the data with RNN.\n",
    "To do: Read sequences (not K-mers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def prepare_data_set(data):\n",
    "    y_test=   data[['class']].copy()\n",
    "    X_test=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X_test,y_test)\n",
    "\n",
    "def subset(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,K):\n",
    "    cv_scores = []\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "    fold=0\n",
    "    eps=100\n",
    "    splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X.iloc[train_index]\n",
    "        y_train=y.iloc[train_index]\n",
    "        X_valid=X.iloc[valid_index]\n",
    "        y_valid=y.iloc[valid_index]\n",
    "        mlp = keras.models.Sequential([\n",
    "            keras.layers.LayerNormalization(trainable=False),\n",
    "            keras.layers.Dense(32, activation=act,dtype=dt),\n",
    "            keras.layers.Dense(32, activation=act,dtype=dt),\n",
    "            keras.layers.Dense(1,  activation=act,dtype=dt)\n",
    "        ])\n",
    "        seq_len=None  # none indicates variable length\n",
    "        input_features=4**K   # 64 DNA K-mers at K=3\n",
    "        rnn2 = keras.models.Sequential([\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True, \n",
    "                                   input_shape=[seq_len,input_features]),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(16, return_sequences=True),\n",
    "            keras.layers.SimpleRNN(1),\n",
    "        ])\n",
    "\n",
    "        bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        rnn2.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=0,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = mlp.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (mlp.metrics_names[1], scores[1]*100))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_kmers(K):\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    return shorter_kmers\n",
    "\n",
    "def train_encoder(kmers):\n",
    "    narray = np.array(kmers)\n",
    "    array2d = narray.reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "    encoder.fit(array2d)\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12641</th>\n",
       "      <td>12642</td>\n",
       "      <td>1</td>\n",
       "      <td>GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>2972</td>\n",
       "      <td>1</td>\n",
       "      <td>TGACATGGGCAGAGTTTCTCTTGCCCTTAAAGTCTTACTTTCCACT...</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>1942</td>\n",
       "      <td>1</td>\n",
       "      <td>CGGTGCCACAGGGACGAGGCCTGGAGAGCAGTCGCTCCTAGAACCG...</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "      <td>CGCCCGCGAGGGGCCGGGGTCGGGGCCGCCGGGGCCATGCGCGCGG...</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16687</th>\n",
       "      <td>16688</td>\n",
       "      <td>0</td>\n",
       "      <td>GTTCTTTAGTAGAAGGATAACATGACATAGCAGGAATAATACTGCC...</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>9273</td>\n",
       "      <td>1</td>\n",
       "      <td>AGCGAGCCCTGCGGCCGCCGGAGCAGCTCCCGCGGCGGAGCAGGAG...</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>3123</td>\n",
       "      <td>0</td>\n",
       "      <td>AGAGGCAGCGCTGGCGTTGGAGAGTGATGGCGGCATGGCGGTGCGG...</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1516</td>\n",
       "      <td>0</td>\n",
       "      <td>GGTGAACTCACATAGATTCAGAAAGCAGGGATTCAGGAACAAGGAA...</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10982</th>\n",
       "      <td>10983</td>\n",
       "      <td>0</td>\n",
       "      <td>AGCATCAGACTAGCCCCTGAGAGCCAAAAACTGTTTGCCTTTCAGT...</td>\n",
       "      <td>1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10776</th>\n",
       "      <td>10777</td>\n",
       "      <td>0</td>\n",
       "      <td>GTGTTTTGACGTCGGCGGTGCCCGCGTTCCGCGCCGAGTAACGGTC...</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3368 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "12641   12642      1  GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...   \n",
       "2971     2972      1  TGACATGGGCAGAGTTTCTCTTGCCCTTAAAGTCTTACTTTCCACT...   \n",
       "1941     1942      1  CGGTGCCACAGGGACGAGGCCTGGAGAGCAGTCGCTCCTAGAACCG...   \n",
       "2258     2259      1  CGCCCGCGAGGGGCCGGGGTCGGGGCCGCCGGGGCCATGCGCGCGG...   \n",
       "16687   16688      0  GTTCTTTAGTAGAAGGATAACATGACATAGCAGGAATAATACTGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "9272     9273      1  AGCGAGCCCTGCGGCCGCCGGAGCAGCTCCCGCGGCGGAGCAGGAG...   \n",
       "3122     3123      0  AGAGGCAGCGCTGGCGTTGGAGAGTGATGGCGGCATGGCGGTGCGG...   \n",
       "1515     1516      0  GGTGAACTCACATAGATTCAGAAAGCAGGGATTCAGGAACAAGGAA...   \n",
       "10982   10983      0  AGCATCAGACTAGCCCCTGAGAGCCAAAAACTGTTTGCCTTTCAGT...   \n",
       "10776   10777      0  GTGTTTTGACGTCGGCGGTGCCCGCGTTCCGCGCCGAGTAACGGTC...   \n",
       "\n",
       "       seqlen  \n",
       "12641    1338  \n",
       "2971     1454  \n",
       "1941     1721  \n",
       "2258     1550  \n",
       "16687    1889  \n",
       "...       ...  \n",
       "9272     1808  \n",
       "3122     1317  \n",
       "1515     1445  \n",
       "10982    1638  \n",
       "10776    1469  \n",
       "\n",
       "[3368 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "(X_test,y_test)=prepare_data_set(test_set)\n",
    "train_set=subset(train_set,MINLEN,MAXLEN)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                sequence\n",
       " 12641  GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
       " 2971   TGACATGGGCAGAGTTTCTCTTGCCCTTAAAGTCTTACTTTCCACT...\n",
       " 1941   CGGTGCCACAGGGACGAGGCCTGGAGAGCAGTCGCTCCTAGAACCG...\n",
       " 2258   CGCCCGCGAGGGGCCGGGGTCGGGGCCGCCGGGGCCATGCGCGCGG...\n",
       " 16687  GTTCTTTAGTAGAAGGATAACATGACATAGCAGGAATAATACTGCC...\n",
       " ...                                                  ...\n",
       " 9272   AGCGAGCCCTGCGGCCGCCGGAGCAGCTCCCGCGGCGGAGCAGGAG...\n",
       " 3122   AGAGGCAGCGCTGGCGTTGGAGAGTGATGGCGGCATGGCGGTGCGG...\n",
       " 1515   GGTGAACTCACATAGATTCAGAAAGCAGGGATTCAGGAACAAGGAA...\n",
       " 10982  AGCATCAGACTAGCCCCTGAGAGCCAAAAACTGTTTGCCTTTCAGT...\n",
       " 10776  GTGTTTTGACGTCGGCGGTGCCCGCGTTCCGCGCCGAGTAACGGTC...\n",
       " \n",
       " [3368 rows x 1 columns],\n",
       "        class\n",
       " 12641      1\n",
       " 2971       1\n",
       " 1941       1\n",
       " 2258       1\n",
       " 16687      0\n",
       " ...      ...\n",
       " 9272       1\n",
       " 3122       0\n",
       " 1515       0\n",
       " 10982      0\n",
       " 10776      0\n",
       " \n",
       " [3368 rows x 1 columns])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_all,y_train_all)=prepare_data_set(train_set)\n",
    "#print(X_train_all.shape,y_train_all.shape)\n",
    "(X_train_all,y_train_all)\n",
    "# y: Pandas dataframe to Python list.\n",
    "# y_train_all=y_train_all.values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(data,K,uniform_len):\n",
    "    all_seqs=[]\n",
    "    pad_char='N'\n",
    "    pad_kmer=pad_char*K\n",
    "    # pad_kmer=None      # Prefer this to the above. Will it work? No. Encoder balks.\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            kmers.append(kmer)\n",
    "            i += 1\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_kmer)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    return all_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "encoder=train_encoder(generate_all_kmers(2))\n",
    "\n",
    "# X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "X_train_kmers=make_kmers(X_train_all,K,MAXLEN)\n",
    "\n",
    "# X: true 2D array (no more lists)\n",
    "X_train_2D=pd.DataFrame(X_train_kmers) \n",
    "X_train_2D.shape\n",
    "#X_train_reshape=X_train_numpy.reshape(-1, 1)\n",
    "#X_train_encoded=encoder.fit(X_train_numpy)\n",
    "X_train_encoded=encoder.fit(X_train_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#encoder = train_encoder(K)\n",
    "#seq=nc_seqs[0].reshape(-1, 1)  # expects 2D array\n",
    "#encoder.fit(X_train_all)\n",
    "#print(\"Encoder categories\")\n",
    "#print(str(encoder.categories_))\n",
    "\n",
    "\n",
    "#do_cross_validation(X_train_all,y_train_all,K):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer sequence, K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
