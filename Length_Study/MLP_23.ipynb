{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP cross validation\n",
    "\n",
    "Start with MLP 08.\n",
    "Includes K=3 bag of words.\n",
    "Includes cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LayerNormalization\n",
    "\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx(dt)\n",
    "\n",
    "EPOCHS=10\n",
    "SPLITS=1\n",
    "K=3\n",
    "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "EMBED_DIMEN=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frequencies(Xin):\n",
    "    # Input:  numpy X(numseq,seqlen)  list of vectors of kmerval where val0=NNN,val1=AAA,etc. \n",
    "    # Output: numpy X(numseq,65)    list of frequencies of 0,1,etc.\n",
    "    Xout=[]\n",
    "    VOCABULARY_SIZE= 4**K + 1  # plus one for 'NNN'\n",
    "    for seq in Xin:\n",
    "        freqs =[0] * VOCABULARY_SIZE\n",
    "        total = 0\n",
    "        for kmerval in seq:\n",
    "            freqs[kmerval] += 1\n",
    "            total += 1\n",
    "        for c in range(VOCABULARY_SIZE):\n",
    "            freqs[c] = freqs[c]/total\n",
    "        Xout.append(freqs)\n",
    "    Xnum = np.asarray(Xout)\n",
    "    return (Xnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    act=\"sigmoid\"\n",
    "\n",
    "    embed_layer  = keras.layers.Embedding(\n",
    "        VOCABULARY_SIZE,EMBED_DIMEN,input_length=maxlen);\n",
    "    \n",
    "    dense1_layer = keras.layers.Dense(32, activation=act,dtype=dt)\n",
    "    dense2_layer = keras.layers.Dense(32, activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,  activation=act,dtype=dt)\n",
    "\n",
    "    mlp = keras.models.Sequential()\n",
    "    mlp.add(embed_layer)\n",
    "    mlp.add(dense1_layer)\n",
    "    mlp.add(dense2_layer)\n",
    "    mlp.add(output_layer)\n",
    "    \n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    mlp.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9089</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>6070</td>\n",
       "      <td>1</td>\n",
       "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>18550</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3387</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>6410</td>\n",
       "      <td>1</td>\n",
       "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7641</td>\n",
       "      <td>1</td>\n",
       "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14109</td>\n",
       "      <td>0</td>\n",
       "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...   \n",
       "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...   \n",
       "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...   \n",
       "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...   \n",
       "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...   \n",
       "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...   \n",
       "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...   \n",
       "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...   \n",
       "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...   \n",
       "\n",
       "       seqlen  \n",
       "1280      348  \n",
       "9088      534  \n",
       "6069      592  \n",
       "18549     945  \n",
       "15027    4382  \n",
       "...       ...  \n",
       "3386      578  \n",
       "6495      562  \n",
       "6409      740  \n",
       "7640     3156  \n",
       "14108     466  \n",
       "\n",
       "[30290 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 200-1Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile the model\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000, 32)          544       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 2,673\n",
      "Trainable params: 2,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [1000 - 2000)\n",
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[42 39 27 ...  0  0  0]\n",
      " [57 34  5 ...  0  0  0]\n",
      " [27 44 47 ...  0  0  0]\n",
      " ...\n",
      " [44 47 57 ...  0  0  0]\n",
      " [10 37 20 ...  0  0  0]\n",
      " [47 60 48 ...  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.332 , 0.0295, 0.0105, ..., 0.015 , 0.0175, 0.0385],\n",
       "       [0.274 , 0.038 , 0.012 , ..., 0.02  , 0.014 , 0.0205],\n",
       "       [0.1405, 0.0215, 0.0095, ..., 0.018 , 0.0105, 0.034 ],\n",
       "       ...,\n",
       "       [0.2785, 0.0195, 0.0145, ..., 0.0135, 0.0155, 0.022 ],\n",
       "       [0.182 , 0.0205, 0.0145, ..., 0.008 , 0.013 , 0.0135],\n",
       "       [0.2665, 0.025 , 0.012 , ..., 0.0135, 0.014 , 0.0285]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "\n",
    "X_train=make_frequencies(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2000) for input Tensor(\"embedding_1_input:0\", shape=(None, 2000), dtype=float32), but it was called on an input with incompatible shape (None, 65).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2000) for input Tensor(\"embedding_1_input:0\", shape=(None, 2000), dtype=float32), but it was called on an input with incompatible shape (None, 65).\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.6224WARNING:tensorflow:Model was constructed with shape (None, 2000) for input Tensor(\"embedding_1_input:0\", shape=(None, 2000), dtype=float32), but it was called on an input with incompatible shape (None, 65).\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.6641 - accuracy: 0.6221 - val_loss: 0.6719 - val_accuracy: 0.6039\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.6647 - accuracy: 0.6221 - val_loss: 0.6722 - val_accuracy: 0.6039\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.6640 - accuracy: 0.6221 - val_loss: 0.6714 - val_accuracy: 0.6039\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 1s 8ms/step - loss: 0.6637 - accuracy: 0.6221 - val_loss: 0.6716 - val_accuracy: 0.6039\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.6221 - val_loss: 0.6715 - val_accuracy: 0.6039\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.6636 - accuracy: 0.6221 - val_loss: 0.6748 - val_accuracy: 0.6039\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 0.6642 - accuracy: 0.6221 - val_loss: 0.6729 - val_accuracy: 0.6039\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 0.6646 - accuracy: 0.6221 - val_loss: 0.6766 - val_accuracy: 0.6039\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.6221 - val_loss: 0.6739 - val_accuracy: 0.6039\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 0.6643 - accuracy: 0.6221 - val_loss: 0.6728 - val_accuracy: 0.6039\n",
      "Fold 1, 10 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 60.39%\n",
      "\n",
      "Validation core mean 60.39% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "print (\"Cross valiation\")\n",
    "do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
