{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional GRU\n",
    "\n",
    "Same as GRU 20 but more epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=200\n",
    "SPLITS=1\n",
    "K=3\n",
    "EMBED_DIMEN=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    vocabulary_size=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "\n",
    "    rnn = keras.models.Sequential()\n",
    "    embed_layer = keras.layers.Embedding(\n",
    "        vocabulary_size,EMBED_DIMEN,input_length=maxlen);\n",
    "    rnn1_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(32, return_sequences=True, dropout=0.50, \n",
    "            input_shape=[maxlen,dimen]))\n",
    "    rnn2_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(32, dropout=0.50, return_sequences=True))\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    dense1_layer = keras.layers.Dense(32,activation=act,dtype=dt)\n",
    "    dense2_layer = keras.layers.Dense(32,activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,activation=act,dtype=dt)\n",
    "\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    rnn.add(rnn2_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    rnn2=None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "    return rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9089</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>6070</td>\n",
       "      <td>1</td>\n",
       "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>18550</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3387</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>6410</td>\n",
       "      <td>1</td>\n",
       "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7641</td>\n",
       "      <td>1</td>\n",
       "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14109</td>\n",
       "      <td>0</td>\n",
       "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...   \n",
       "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...   \n",
       "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...   \n",
       "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...   \n",
       "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...   \n",
       "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...   \n",
       "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...   \n",
       "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...   \n",
       "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...   \n",
       "\n",
       "       seqlen  \n",
       "1280      348  \n",
       "9088      534  \n",
       "6069      592  \n",
       "18549     945  \n",
       "15027    4382  \n",
       "...       ...  \n",
       "3386      578  \n",
       "6495      562  \n",
       "6409      740  \n",
       "7640     3156  \n",
       "14108     466  \n",
       "\n",
       "[30290 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [200 - 1000)\n",
      "original (30290, 4)\n",
      "no short (30290, 4)\n",
      "no long, no short (8879, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(8879, 1)\n",
      "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
      "Name: 1280, dtype: object\n",
      "348\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[12 46 54 ...  0  0  0]\n",
      " [ 9 36 14 ...  0  0  0]\n",
      " [34  7 28 ...  0  0  0]\n",
      " ...\n",
      " [37 19  9 ...  0  0  0]\n",
      " [57 36 15 ...  0  0  0]\n",
      " [33  3 12 ...  0  0  0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 32,625\n",
      "Trainable params: 32,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/200\n",
      "222/222 [==============================] - 295s 1s/step - loss: 0.6717 - accuracy: 0.5903 - val_loss: 0.6468 - val_accuracy: 0.6417\n",
      "Epoch 2/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.6336 - accuracy: 0.6524 - val_loss: 0.6269 - val_accuracy: 0.6614\n",
      "Epoch 3/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.6101 - accuracy: 0.6797 - val_loss: 0.5920 - val_accuracy: 0.7004\n",
      "Epoch 4/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.5514 - accuracy: 0.7282 - val_loss: 0.5245 - val_accuracy: 0.7409\n",
      "Epoch 5/200\n",
      "222/222 [==============================] - 292s 1s/step - loss: 0.5159 - accuracy: 0.7501 - val_loss: 0.4787 - val_accuracy: 0.7702\n",
      "Epoch 6/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.4732 - accuracy: 0.7825 - val_loss: 0.4931 - val_accuracy: 0.7718\n",
      "Epoch 7/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.4578 - accuracy: 0.7864 - val_loss: 0.4574 - val_accuracy: 0.7872\n",
      "Epoch 8/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4494 - accuracy: 0.7938 - val_loss: 0.4475 - val_accuracy: 0.7894\n",
      "Epoch 9/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.4502 - accuracy: 0.7895 - val_loss: 0.4577 - val_accuracy: 0.7836\n",
      "Epoch 10/200\n",
      "222/222 [==============================] - 297s 1s/step - loss: 0.4431 - accuracy: 0.7955 - val_loss: 0.4364 - val_accuracy: 0.7902\n",
      "Epoch 11/200\n",
      "222/222 [==============================] - 291s 1s/step - loss: 0.4429 - accuracy: 0.7966 - val_loss: 0.5291 - val_accuracy: 0.7400\n",
      "Epoch 12/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4352 - accuracy: 0.8039 - val_loss: 0.4575 - val_accuracy: 0.7870\n",
      "Epoch 13/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4321 - accuracy: 0.8036 - val_loss: 0.4516 - val_accuracy: 0.7825\n",
      "Epoch 14/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4330 - accuracy: 0.8021 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
      "Epoch 15/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.4262 - accuracy: 0.8020 - val_loss: 0.4359 - val_accuracy: 0.7879\n",
      "Epoch 16/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.4319 - accuracy: 0.8015 - val_loss: 0.4268 - val_accuracy: 0.7955\n",
      "Epoch 17/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.4228 - accuracy: 0.8069 - val_loss: 0.4475 - val_accuracy: 0.8019\n",
      "Epoch 18/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4208 - accuracy: 0.8121 - val_loss: 0.4712 - val_accuracy: 0.7767\n",
      "Epoch 19/200\n",
      "222/222 [==============================] - 283s 1s/step - loss: 0.4990 - accuracy: 0.7631 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
      "Epoch 20/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.5063 - accuracy: 0.7633 - val_loss: 0.4672 - val_accuracy: 0.7945\n",
      "Epoch 21/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.4646 - accuracy: 0.7885 - val_loss: 0.4534 - val_accuracy: 0.7958\n",
      "Epoch 22/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.4434 - accuracy: 0.7994 - val_loss: 0.4329 - val_accuracy: 0.8004\n",
      "Epoch 23/200\n",
      "222/222 [==============================] - 283s 1s/step - loss: 0.4428 - accuracy: 0.7945 - val_loss: 0.4455 - val_accuracy: 0.7965\n",
      "Epoch 24/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4315 - accuracy: 0.8037 - val_loss: 0.4698 - val_accuracy: 0.7809\n",
      "Epoch 25/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4243 - accuracy: 0.8107 - val_loss: 0.4325 - val_accuracy: 0.7980\n",
      "Epoch 26/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.4185 - accuracy: 0.8118 - val_loss: 0.4527 - val_accuracy: 0.7918\n",
      "Epoch 27/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.4233 - accuracy: 0.8080 - val_loss: 0.4447 - val_accuracy: 0.7949\n",
      "Epoch 28/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.4202 - accuracy: 0.8085 - val_loss: 0.4281 - val_accuracy: 0.8014\n",
      "Epoch 29/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.4156 - accuracy: 0.8124 - val_loss: 0.4261 - val_accuracy: 0.8114\n",
      "Epoch 30/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4155 - accuracy: 0.8107 - val_loss: 0.4332 - val_accuracy: 0.8027\n",
      "Epoch 31/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4130 - accuracy: 0.8144 - val_loss: 0.4216 - val_accuracy: 0.8062\n",
      "Epoch 32/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4084 - accuracy: 0.8146 - val_loss: 0.4177 - val_accuracy: 0.8091\n",
      "Epoch 33/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4034 - accuracy: 0.8170 - val_loss: 0.4253 - val_accuracy: 0.8054\n",
      "Epoch 34/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4076 - accuracy: 0.8152 - val_loss: 0.4292 - val_accuracy: 0.8029\n",
      "Epoch 35/200\n",
      "222/222 [==============================] - 294s 1s/step - loss: 0.4075 - accuracy: 0.8143 - val_loss: 0.4160 - val_accuracy: 0.8123\n",
      "Epoch 36/200\n",
      "222/222 [==============================] - 282s 1s/step - loss: 0.4114 - accuracy: 0.8129 - val_loss: 0.4161 - val_accuracy: 0.8098\n",
      "Epoch 37/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3985 - accuracy: 0.8204 - val_loss: 0.4183 - val_accuracy: 0.8104\n",
      "Epoch 38/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.4015 - accuracy: 0.8168 - val_loss: 0.4114 - val_accuracy: 0.8152\n",
      "Epoch 39/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3987 - accuracy: 0.8190 - val_loss: 0.4120 - val_accuracy: 0.8109\n",
      "Epoch 40/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3970 - accuracy: 0.8220 - val_loss: 0.4240 - val_accuracy: 0.7980\n",
      "Epoch 41/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3946 - accuracy: 0.8203 - val_loss: 0.4195 - val_accuracy: 0.8098\n",
      "Epoch 42/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.3971 - accuracy: 0.8204 - val_loss: 0.4319 - val_accuracy: 0.8118\n",
      "Epoch 43/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3936 - accuracy: 0.8193 - val_loss: 0.4143 - val_accuracy: 0.8025\n",
      "Epoch 44/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3934 - accuracy: 0.8201 - val_loss: 0.4088 - val_accuracy: 0.8203\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 274s 1s/step - loss: 0.3953 - accuracy: 0.8189 - val_loss: 0.4178 - val_accuracy: 0.8196\n",
      "Epoch 46/200\n",
      "222/222 [==============================] - 281s 1s/step - loss: 0.3853 - accuracy: 0.8282 - val_loss: 0.4131 - val_accuracy: 0.8156\n",
      "Epoch 47/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.3862 - accuracy: 0.8227 - val_loss: 0.4098 - val_accuracy: 0.8094\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - 293s 1s/step - loss: 0.3837 - accuracy: 0.8259 - val_loss: 0.4070 - val_accuracy: 0.8147\n",
      "Epoch 49/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3899 - accuracy: 0.8189 - val_loss: 0.4032 - val_accuracy: 0.8216\n",
      "Epoch 50/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3835 - accuracy: 0.8275 - val_loss: 0.4441 - val_accuracy: 0.7984\n",
      "Epoch 51/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3797 - accuracy: 0.8300 - val_loss: 0.4019 - val_accuracy: 0.8200\n",
      "Epoch 52/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3791 - accuracy: 0.8287 - val_loss: 0.4115 - val_accuracy: 0.8049\n",
      "Epoch 53/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3862 - accuracy: 0.8263 - val_loss: 0.4082 - val_accuracy: 0.8189\n",
      "Epoch 54/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3812 - accuracy: 0.8283 - val_loss: 0.4012 - val_accuracy: 0.8213\n",
      "Epoch 55/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3767 - accuracy: 0.8331 - val_loss: 0.4042 - val_accuracy: 0.8122\n",
      "Epoch 56/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3727 - accuracy: 0.8323 - val_loss: 0.4001 - val_accuracy: 0.8192\n",
      "Epoch 57/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3779 - accuracy: 0.8289 - val_loss: 0.3966 - val_accuracy: 0.8213\n",
      "Epoch 58/200\n",
      "222/222 [==============================] - 284s 1s/step - loss: 0.3717 - accuracy: 0.8331 - val_loss: 0.3902 - val_accuracy: 0.8270\n",
      "Epoch 59/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3737 - accuracy: 0.8290 - val_loss: 0.3941 - val_accuracy: 0.8173\n",
      "Epoch 60/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.3716 - accuracy: 0.8323 - val_loss: 0.3977 - val_accuracy: 0.8226\n",
      "Epoch 61/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.3648 - accuracy: 0.8387 - val_loss: 0.3913 - val_accuracy: 0.8269\n",
      "Epoch 62/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3665 - accuracy: 0.8344 - val_loss: 0.3957 - val_accuracy: 0.8228\n",
      "Epoch 63/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3653 - accuracy: 0.8386 - val_loss: 0.4045 - val_accuracy: 0.8243\n",
      "Epoch 64/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3671 - accuracy: 0.8328 - val_loss: 0.3941 - val_accuracy: 0.8270\n",
      "Epoch 65/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3686 - accuracy: 0.8314 - val_loss: 0.3864 - val_accuracy: 0.8294\n",
      "Epoch 66/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3585 - accuracy: 0.8377 - val_loss: 0.4235 - val_accuracy: 0.8025\n",
      "Epoch 67/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3612 - accuracy: 0.8381 - val_loss: 0.4168 - val_accuracy: 0.8167\n",
      "Epoch 68/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.3666 - accuracy: 0.8354 - val_loss: 0.3889 - val_accuracy: 0.8294\n",
      "Epoch 69/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3572 - accuracy: 0.8411 - val_loss: 0.4114 - val_accuracy: 0.8079\n",
      "Epoch 70/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3582 - accuracy: 0.8377 - val_loss: 0.3901 - val_accuracy: 0.8273\n",
      "Epoch 71/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3555 - accuracy: 0.8423 - val_loss: 0.4538 - val_accuracy: 0.7764\n",
      "Epoch 72/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3558 - accuracy: 0.8423 - val_loss: 0.3979 - val_accuracy: 0.8170\n",
      "Epoch 73/200\n",
      "222/222 [==============================] - 279s 1s/step - loss: 0.3528 - accuracy: 0.8408 - val_loss: 0.3886 - val_accuracy: 0.8316\n",
      "Epoch 74/200\n",
      "222/222 [==============================] - 280s 1s/step - loss: 0.3546 - accuracy: 0.8429 - val_loss: 0.4494 - val_accuracy: 0.7963\n",
      "Epoch 75/200\n",
      "222/222 [==============================] - 280s 1s/step - loss: 0.3533 - accuracy: 0.8417 - val_loss: 0.3850 - val_accuracy: 0.8322\n",
      "Epoch 76/200\n",
      "222/222 [==============================] - 293s 1s/step - loss: 0.3477 - accuracy: 0.8447 - val_loss: 0.3877 - val_accuracy: 0.8297\n",
      "Epoch 77/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.3480 - accuracy: 0.8458 - val_loss: 0.4114 - val_accuracy: 0.8019\n",
      "Epoch 78/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3508 - accuracy: 0.8446 - val_loss: 0.3910 - val_accuracy: 0.8294\n",
      "Epoch 79/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3565 - accuracy: 0.8406 - val_loss: 0.3965 - val_accuracy: 0.8172\n",
      "Epoch 80/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3514 - accuracy: 0.8408 - val_loss: 0.3905 - val_accuracy: 0.8355\n",
      "Epoch 81/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3442 - accuracy: 0.8487 - val_loss: 0.3898 - val_accuracy: 0.8327\n",
      "Epoch 82/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3551 - accuracy: 0.8394 - val_loss: 0.3880 - val_accuracy: 0.8330\n",
      "Epoch 83/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3439 - accuracy: 0.8470 - val_loss: 0.4162 - val_accuracy: 0.8066\n",
      "Epoch 84/200\n",
      "222/222 [==============================] - 285s 1s/step - loss: 0.3413 - accuracy: 0.8480 - val_loss: 0.4008 - val_accuracy: 0.8251\n",
      "Epoch 85/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.3448 - accuracy: 0.8465 - val_loss: 0.4022 - val_accuracy: 0.8272\n",
      "Epoch 86/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3400 - accuracy: 0.8494 - val_loss: 0.3771 - val_accuracy: 0.8381\n",
      "Epoch 87/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3356 - accuracy: 0.8510 - val_loss: 0.3819 - val_accuracy: 0.8398\n",
      "Epoch 88/200\n",
      "222/222 [==============================] - 283s 1s/step - loss: 0.3382 - accuracy: 0.8488 - val_loss: 0.3767 - val_accuracy: 0.8409\n",
      "Epoch 89/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3368 - accuracy: 0.8522 - val_loss: 0.3845 - val_accuracy: 0.8410\n",
      "Epoch 90/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3389 - accuracy: 0.8457 - val_loss: 0.3723 - val_accuracy: 0.8392\n",
      "Epoch 91/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3393 - accuracy: 0.8499 - val_loss: 0.3828 - val_accuracy: 0.8434\n",
      "Epoch 92/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3328 - accuracy: 0.8523 - val_loss: 0.3809 - val_accuracy: 0.8404\n",
      "Epoch 93/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.3314 - accuracy: 0.8547 - val_loss: 0.3774 - val_accuracy: 0.8445\n",
      "Epoch 94/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3324 - accuracy: 0.8559 - val_loss: 0.3908 - val_accuracy: 0.8329\n",
      "Epoch 95/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3323 - accuracy: 0.8529 - val_loss: 0.3829 - val_accuracy: 0.8410\n",
      "Epoch 96/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3322 - accuracy: 0.8507 - val_loss: 0.3769 - val_accuracy: 0.8416\n",
      "Epoch 97/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3286 - accuracy: 0.8548 - val_loss: 0.3928 - val_accuracy: 0.8272\n",
      "Epoch 98/200\n",
      "222/222 [==============================] - 279s 1s/step - loss: 0.3252 - accuracy: 0.8560 - val_loss: 0.3927 - val_accuracy: 0.8405\n",
      "Epoch 99/200\n",
      "222/222 [==============================] - 282s 1s/step - loss: 0.3319 - accuracy: 0.8511 - val_loss: 0.3715 - val_accuracy: 0.8433\n",
      "Epoch 100/200\n",
      "222/222 [==============================] - 281s 1s/step - loss: 0.3259 - accuracy: 0.8564 - val_loss: 0.3748 - val_accuracy: 0.8439\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 292s 1s/step - loss: 0.3258 - accuracy: 0.8539 - val_loss: 0.3819 - val_accuracy: 0.8402\n",
      "Epoch 102/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3195 - accuracy: 0.8603 - val_loss: 0.3923 - val_accuracy: 0.8327\n",
      "Epoch 103/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3189 - accuracy: 0.8594 - val_loss: 0.3875 - val_accuracy: 0.8403\n",
      "Epoch 104/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3178 - accuracy: 0.8590 - val_loss: 0.3674 - val_accuracy: 0.8454\n",
      "Epoch 105/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3219 - accuracy: 0.8587 - val_loss: 0.3739 - val_accuracy: 0.8474\n",
      "Epoch 106/200\n",
      "222/222 [==============================] - 290s 1s/step - loss: 0.3201 - accuracy: 0.8621 - val_loss: 0.3692 - val_accuracy: 0.8459\n",
      "Epoch 107/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3152 - accuracy: 0.8621 - val_loss: 0.3624 - val_accuracy: 0.8458\n",
      "Epoch 108/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3148 - accuracy: 0.8628 - val_loss: 0.3725 - val_accuracy: 0.8385\n",
      "Epoch 109/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3127 - accuracy: 0.8659 - val_loss: 0.3763 - val_accuracy: 0.8413\n",
      "Epoch 110/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3092 - accuracy: 0.8643 - val_loss: 0.3697 - val_accuracy: 0.8441\n",
      "Epoch 111/200\n",
      "222/222 [==============================] - 294s 1s/step - loss: 0.3135 - accuracy: 0.8634 - val_loss: 0.3685 - val_accuracy: 0.8413\n",
      "Epoch 112/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3050 - accuracy: 0.8678 - val_loss: 0.3838 - val_accuracy: 0.8383\n",
      "Epoch 113/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3073 - accuracy: 0.8649 - val_loss: 0.3734 - val_accuracy: 0.8446\n",
      "Epoch 114/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3127 - accuracy: 0.8640 - val_loss: 0.3769 - val_accuracy: 0.8421\n",
      "Epoch 115/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.3033 - accuracy: 0.8689 - val_loss: 0.3990 - val_accuracy: 0.8280\n",
      "Epoch 116/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.3056 - accuracy: 0.8657 - val_loss: 0.3625 - val_accuracy: 0.8482\n",
      "Epoch 117/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.2977 - accuracy: 0.8680 - val_loss: 0.3765 - val_accuracy: 0.8471\n",
      "Epoch 118/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.2991 - accuracy: 0.8735 - val_loss: 0.3724 - val_accuracy: 0.8379\n",
      "Epoch 119/200\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.3094 - accuracy: 0.8665 - val_loss: 0.3361 - val_accuracy: 0.8573\n",
      "Epoch 120/200\n",
      "222/222 [==============================] - 288s 1s/step - loss: 0.3022 - accuracy: 0.8710 - val_loss: 0.3644 - val_accuracy: 0.8516\n",
      "Epoch 121/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.2925 - accuracy: 0.8718 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
      "Epoch 122/200\n",
      "222/222 [==============================] - 287s 1s/step - loss: 0.2893 - accuracy: 0.8764 - val_loss: 0.3266 - val_accuracy: 0.8607\n",
      "Epoch 123/200\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.2963 - accuracy: 0.8728 - val_loss: 0.3517 - val_accuracy: 0.8491\n",
      "Epoch 124/200\n",
      "222/222 [==============================] - 280s 1s/step - loss: 0.3242 - accuracy: 0.8612 - val_loss: 0.3159 - val_accuracy: 0.8663\n",
      "Epoch 125/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3459 - accuracy: 0.8487 - val_loss: 0.3616 - val_accuracy: 0.8386\n",
      "Epoch 126/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3388 - accuracy: 0.8488 - val_loss: 0.3678 - val_accuracy: 0.8404\n",
      "Epoch 127/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3253 - accuracy: 0.8605 - val_loss: 0.3457 - val_accuracy: 0.8495\n",
      "Epoch 128/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3286 - accuracy: 0.8586 - val_loss: 0.3725 - val_accuracy: 0.8317\n",
      "Epoch 129/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3191 - accuracy: 0.8602 - val_loss: 0.3593 - val_accuracy: 0.8416\n",
      "Epoch 130/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3125 - accuracy: 0.8642 - val_loss: 0.3340 - val_accuracy: 0.8542\n",
      "Epoch 131/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3156 - accuracy: 0.8619 - val_loss: 0.3645 - val_accuracy: 0.8377\n",
      "Epoch 132/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3205 - accuracy: 0.8605 - val_loss: 0.3552 - val_accuracy: 0.8418\n",
      "Epoch 133/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3072 - accuracy: 0.8677 - val_loss: 0.3208 - val_accuracy: 0.8611\n",
      "Epoch 134/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3127 - accuracy: 0.8656 - val_loss: 0.3128 - val_accuracy: 0.8667\n",
      "Epoch 135/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3229 - accuracy: 0.8611 - val_loss: 0.3699 - val_accuracy: 0.8390\n",
      "Epoch 136/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.3330 - accuracy: 0.8515 - val_loss: 0.3521 - val_accuracy: 0.8416\n",
      "Epoch 137/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3316 - accuracy: 0.8557 - val_loss: 0.3492 - val_accuracy: 0.8460\n",
      "Epoch 138/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3277 - accuracy: 0.8556 - val_loss: 0.3743 - val_accuracy: 0.8316\n",
      "Epoch 139/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3447 - accuracy: 0.8449 - val_loss: 0.3654 - val_accuracy: 0.8396\n",
      "Epoch 140/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3263 - accuracy: 0.8567 - val_loss: 0.3620 - val_accuracy: 0.8381\n",
      "Epoch 141/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3223 - accuracy: 0.8580 - val_loss: 0.3411 - val_accuracy: 0.8503\n",
      "Epoch 142/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3209 - accuracy: 0.8591 - val_loss: 0.3375 - val_accuracy: 0.8527\n",
      "Epoch 143/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3170 - accuracy: 0.8660 - val_loss: 0.3457 - val_accuracy: 0.8531\n",
      "Epoch 144/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.3188 - accuracy: 0.8641 - val_loss: 0.3430 - val_accuracy: 0.8459\n",
      "Epoch 145/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3263 - accuracy: 0.8625 - val_loss: 0.3500 - val_accuracy: 0.8476\n",
      "Epoch 146/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3235 - accuracy: 0.8587 - val_loss: 0.3541 - val_accuracy: 0.8399\n",
      "Epoch 147/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3260 - accuracy: 0.8566 - val_loss: 0.3774 - val_accuracy: 0.8315\n",
      "Epoch 148/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3170 - accuracy: 0.8616 - val_loss: 0.3436 - val_accuracy: 0.8542\n",
      "Epoch 149/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.3035 - accuracy: 0.8695 - val_loss: 0.3321 - val_accuracy: 0.8546\n",
      "Epoch 150/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.2986 - accuracy: 0.8735 - val_loss: 0.3238 - val_accuracy: 0.8632\n",
      "Epoch 151/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2915 - accuracy: 0.8757 - val_loss: 0.3217 - val_accuracy: 0.8652\n",
      "Epoch 152/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3063 - accuracy: 0.8699 - val_loss: 0.3506 - val_accuracy: 0.8511\n",
      "Epoch 153/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3099 - accuracy: 0.8660 - val_loss: 0.3458 - val_accuracy: 0.8488\n",
      "Epoch 154/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3103 - accuracy: 0.8655 - val_loss: 0.3408 - val_accuracy: 0.8491\n",
      "Epoch 155/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3125 - accuracy: 0.8651 - val_loss: 0.3354 - val_accuracy: 0.8558\n",
      "Epoch 156/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3012 - accuracy: 0.8715 - val_loss: 0.3424 - val_accuracy: 0.8552\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 273s 1s/step - loss: 0.3113 - accuracy: 0.8652 - val_loss: 0.3510 - val_accuracy: 0.8455\n",
      "Epoch 158/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 0.3473 - val_accuracy: 0.8514\n",
      "Epoch 159/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.3008 - accuracy: 0.8720 - val_loss: 0.3492 - val_accuracy: 0.8540\n",
      "Epoch 160/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.2994 - accuracy: 0.8707 - val_loss: 0.3354 - val_accuracy: 0.8572\n",
      "Epoch 161/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2947 - accuracy: 0.8710 - val_loss: 0.3512 - val_accuracy: 0.8437\n",
      "Epoch 162/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2923 - accuracy: 0.8705 - val_loss: 0.3431 - val_accuracy: 0.8570\n",
      "Epoch 163/200\n",
      "222/222 [==============================] - 282s 1s/step - loss: 0.2856 - accuracy: 0.8774 - val_loss: 0.3927 - val_accuracy: 0.8257\n",
      "Epoch 164/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.2830 - accuracy: 0.8787 - val_loss: 0.3429 - val_accuracy: 0.8479\n",
      "Epoch 165/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2811 - accuracy: 0.8811 - val_loss: 0.3336 - val_accuracy: 0.8560\n",
      "Epoch 166/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2812 - accuracy: 0.8767 - val_loss: 0.3256 - val_accuracy: 0.8618\n",
      "Epoch 167/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2800 - accuracy: 0.8797 - val_loss: 0.3461 - val_accuracy: 0.8511\n",
      "Epoch 168/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2757 - accuracy: 0.8831 - val_loss: 0.2990 - val_accuracy: 0.8781\n",
      "Epoch 169/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2884 - accuracy: 0.8793 - val_loss: 0.3531 - val_accuracy: 0.8365\n",
      "Epoch 170/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2909 - accuracy: 0.8748 - val_loss: 0.3324 - val_accuracy: 0.8540\n",
      "Epoch 171/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2817 - accuracy: 0.8801 - val_loss: 0.3386 - val_accuracy: 0.8577\n",
      "Epoch 172/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2906 - accuracy: 0.8720 - val_loss: 0.3287 - val_accuracy: 0.8583\n",
      "Epoch 173/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2737 - accuracy: 0.8837 - val_loss: 0.3252 - val_accuracy: 0.8678\n",
      "Epoch 174/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.2695 - accuracy: 0.8862 - val_loss: 0.3354 - val_accuracy: 0.8624\n",
      "Epoch 175/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2765 - accuracy: 0.8824 - val_loss: 0.3612 - val_accuracy: 0.8416\n",
      "Epoch 176/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.2828 - accuracy: 0.8778 - val_loss: 0.3409 - val_accuracy: 0.8513\n",
      "Epoch 177/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2825 - accuracy: 0.8801 - val_loss: 0.3327 - val_accuracy: 0.8506\n",
      "Epoch 178/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2728 - accuracy: 0.8836 - val_loss: 0.3352 - val_accuracy: 0.8502\n",
      "Epoch 179/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2712 - accuracy: 0.8854 - val_loss: 0.3358 - val_accuracy: 0.8618\n",
      "Epoch 180/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2683 - accuracy: 0.8851 - val_loss: 0.3378 - val_accuracy: 0.8582\n",
      "Epoch 181/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2583 - accuracy: 0.8916 - val_loss: 0.2913 - val_accuracy: 0.8744\n",
      "Epoch 182/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2735 - accuracy: 0.8863 - val_loss: 0.3417 - val_accuracy: 0.8540\n",
      "Epoch 183/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2868 - accuracy: 0.8740 - val_loss: 0.3419 - val_accuracy: 0.8576\n",
      "Epoch 184/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2784 - accuracy: 0.8827 - val_loss: 0.3355 - val_accuracy: 0.8567\n",
      "Epoch 185/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2827 - accuracy: 0.8810 - val_loss: 0.3557 - val_accuracy: 0.8420\n",
      "Epoch 186/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.3027 - accuracy: 0.8673 - val_loss: 0.3717 - val_accuracy: 0.8419\n",
      "Epoch 187/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.3097 - accuracy: 0.8641 - val_loss: 0.3684 - val_accuracy: 0.8454\n",
      "Epoch 188/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2989 - accuracy: 0.8722 - val_loss: 0.3486 - val_accuracy: 0.8527\n",
      "Epoch 189/200\n",
      "222/222 [==============================] - 277s 1s/step - loss: 0.2870 - accuracy: 0.8764 - val_loss: 0.3477 - val_accuracy: 0.8588\n",
      "Epoch 190/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2887 - accuracy: 0.8760 - val_loss: 0.3339 - val_accuracy: 0.8642\n",
      "Epoch 191/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2729 - accuracy: 0.8871 - val_loss: 0.3361 - val_accuracy: 0.8644\n",
      "Epoch 192/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2733 - accuracy: 0.8840 - val_loss: 0.3409 - val_accuracy: 0.8634\n",
      "Epoch 193/200\n",
      "222/222 [==============================] - 273s 1s/step - loss: 0.2741 - accuracy: 0.8828 - val_loss: 0.3794 - val_accuracy: 0.8373\n",
      "Epoch 194/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2670 - accuracy: 0.8859 - val_loss: 0.3160 - val_accuracy: 0.8689\n",
      "Epoch 195/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2627 - accuracy: 0.8906 - val_loss: 0.3563 - val_accuracy: 0.8454\n",
      "Epoch 196/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.2595 - accuracy: 0.8937 - val_loss: 0.3267 - val_accuracy: 0.8624\n",
      "Epoch 197/200\n",
      "222/222 [==============================] - 276s 1s/step - loss: 0.2618 - accuracy: 0.8899 - val_loss: 0.3284 - val_accuracy: 0.8545\n",
      "Epoch 198/200\n",
      "222/222 [==============================] - 275s 1s/step - loss: 0.2665 - accuracy: 0.8887 - val_loss: 0.3586 - val_accuracy: 0.8487\n",
      "Epoch 199/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2596 - accuracy: 0.8907 - val_loss: 0.3908 - val_accuracy: 0.8407\n",
      "Epoch 200/200\n",
      "222/222 [==============================] - 274s 1s/step - loss: 0.2561 - accuracy: 0.8931 - val_loss: 0.3204 - val_accuracy: 0.8678\n",
      "Fold 1, 200 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.78%\n",
      "\n",
      "Validation core mean 86.78% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model1=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 1K-2Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [1000 - 2000)\n",
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[42 39 27 ...  0  0  0]\n",
      " [57 34  5 ...  0  0  0]\n",
      " [27 44 47 ...  0  0  0]\n",
      " ...\n",
      " [44 47 57 ...  0  0  0]\n",
      " [10 37 20 ...  0  0  0]\n",
      " [47 60 48 ...  0  0  0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 16)          1040      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 2000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 2000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 32,625\n",
      "Trainable params: 32,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/200\n",
      "85/85 [==============================] - 250s 3s/step - loss: 0.6930 - accuracy: 0.5684 - val_loss: 0.6706 - val_accuracy: 0.6039\n",
      "Epoch 2/200\n",
      "85/85 [==============================] - 251s 3s/step - loss: 0.6602 - accuracy: 0.6229 - val_loss: 0.6609 - val_accuracy: 0.6130\n",
      "Epoch 3/200\n",
      "85/85 [==============================] - 251s 3s/step - loss: 0.6527 - accuracy: 0.6252 - val_loss: 0.6499 - val_accuracy: 0.6214\n",
      "Epoch 4/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.6478 - accuracy: 0.6275 - val_loss: 0.6397 - val_accuracy: 0.6159\n",
      "Epoch 5/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.6141 - accuracy: 0.6719 - val_loss: 0.5875 - val_accuracy: 0.7002\n",
      "Epoch 6/200\n",
      "85/85 [==============================] - 245s 3s/step - loss: 0.5971 - accuracy: 0.6984 - val_loss: 0.5765 - val_accuracy: 0.7096\n",
      "Epoch 7/200\n",
      "85/85 [==============================] - 237s 3s/step - loss: 0.5801 - accuracy: 0.6960 - val_loss: 0.5686 - val_accuracy: 0.7089\n",
      "Epoch 8/200\n",
      "85/85 [==============================] - 231s 3s/step - loss: 0.5854 - accuracy: 0.7007 - val_loss: 0.5530 - val_accuracy: 0.7254\n",
      "Epoch 9/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.5503 - accuracy: 0.7271 - val_loss: 0.5214 - val_accuracy: 0.7420\n",
      "Epoch 10/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.6068 - accuracy: 0.7006 - val_loss: 0.5856 - val_accuracy: 0.7144\n",
      "Epoch 11/200\n",
      "85/85 [==============================] - 233s 3s/step - loss: 0.6000 - accuracy: 0.6922 - val_loss: 0.6433 - val_accuracy: 0.6038\n",
      "Epoch 12/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.5802 - accuracy: 0.6876 - val_loss: 0.5724 - val_accuracy: 0.7011\n",
      "Epoch 13/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.5247 - accuracy: 0.7442 - val_loss: 0.4957 - val_accuracy: 0.7748\n",
      "Epoch 14/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.5038 - accuracy: 0.7594 - val_loss: 0.5380 - val_accuracy: 0.7366\n",
      "Epoch 15/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4858 - accuracy: 0.7769 - val_loss: 0.4532 - val_accuracy: 0.7959\n",
      "Epoch 16/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4692 - accuracy: 0.7849 - val_loss: 0.4524 - val_accuracy: 0.7923\n",
      "Epoch 17/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.4583 - accuracy: 0.7900 - val_loss: 0.5276 - val_accuracy: 0.7556\n",
      "Epoch 18/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.4626 - accuracy: 0.7879 - val_loss: 0.4199 - val_accuracy: 0.8193\n",
      "Epoch 19/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.4472 - accuracy: 0.7962 - val_loss: 0.4146 - val_accuracy: 0.8192\n",
      "Epoch 20/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4273 - accuracy: 0.8127 - val_loss: 0.4006 - val_accuracy: 0.8259\n",
      "Epoch 21/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4238 - accuracy: 0.8140 - val_loss: 0.3969 - val_accuracy: 0.8237\n",
      "Epoch 22/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4247 - accuracy: 0.8043 - val_loss: 0.3950 - val_accuracy: 0.8256\n",
      "Epoch 23/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4130 - accuracy: 0.8149 - val_loss: 0.3958 - val_accuracy: 0.8237\n",
      "Epoch 24/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.4071 - accuracy: 0.8195 - val_loss: 0.3895 - val_accuracy: 0.8262\n",
      "Epoch 25/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4066 - accuracy: 0.8185 - val_loss: 0.3877 - val_accuracy: 0.8272\n",
      "Epoch 26/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3946 - accuracy: 0.8252 - val_loss: 0.3805 - val_accuracy: 0.8304\n",
      "Epoch 27/200\n",
      "85/85 [==============================] - 231s 3s/step - loss: 0.4054 - accuracy: 0.8221 - val_loss: 0.4557 - val_accuracy: 0.7845\n",
      "Epoch 28/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.4132 - accuracy: 0.8177 - val_loss: 0.4047 - val_accuracy: 0.8090\n",
      "Epoch 29/200\n",
      "85/85 [==============================] - 231s 3s/step - loss: 0.3946 - accuracy: 0.8270 - val_loss: 0.4342 - val_accuracy: 0.8057\n",
      "Epoch 30/200\n",
      "85/85 [==============================] - 243s 3s/step - loss: 0.4030 - accuracy: 0.8232 - val_loss: 0.3767 - val_accuracy: 0.8341\n",
      "Epoch 31/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3994 - accuracy: 0.8247 - val_loss: 0.3875 - val_accuracy: 0.8241\n",
      "Epoch 32/200\n",
      "85/85 [==============================] - 246s 3s/step - loss: 0.3912 - accuracy: 0.8275 - val_loss: 0.3722 - val_accuracy: 0.8317\n",
      "Epoch 33/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.3843 - accuracy: 0.8319 - val_loss: 0.3684 - val_accuracy: 0.8354\n",
      "Epoch 34/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.3693 - val_accuracy: 0.8324\n",
      "Epoch 35/200\n",
      "85/85 [==============================] - 246s 3s/step - loss: 0.3772 - accuracy: 0.8409 - val_loss: 0.3657 - val_accuracy: 0.8359\n",
      "Epoch 36/200\n",
      "85/85 [==============================] - 250s 3s/step - loss: 0.4053 - accuracy: 0.8209 - val_loss: 0.3861 - val_accuracy: 0.8271\n",
      "Epoch 37/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3846 - accuracy: 0.8334 - val_loss: 0.3864 - val_accuracy: 0.8215\n",
      "Epoch 38/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3854 - accuracy: 0.8262 - val_loss: 0.3854 - val_accuracy: 0.8168\n",
      "Epoch 39/200\n",
      "85/85 [==============================] - 250s 3s/step - loss: 0.3810 - accuracy: 0.8342 - val_loss: 0.4286 - val_accuracy: 0.8001\n",
      "Epoch 40/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3844 - accuracy: 0.8303 - val_loss: 0.3732 - val_accuracy: 0.8270\n",
      "Epoch 41/200\n",
      "85/85 [==============================] - 251s 3s/step - loss: 0.3810 - accuracy: 0.8347 - val_loss: 0.3963 - val_accuracy: 0.8157\n",
      "Epoch 42/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3837 - accuracy: 0.8342 - val_loss: 0.3695 - val_accuracy: 0.8257\n",
      "Epoch 43/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3749 - accuracy: 0.8399 - val_loss: 0.3747 - val_accuracy: 0.8362\n",
      "Epoch 44/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3782 - accuracy: 0.8328 - val_loss: 0.3661 - val_accuracy: 0.8377\n",
      "Epoch 45/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3741 - accuracy: 0.8411 - val_loss: 0.3712 - val_accuracy: 0.8362\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 232s 3s/step - loss: 0.3746 - accuracy: 0.8400 - val_loss: 0.3591 - val_accuracy: 0.8435\n",
      "Epoch 47/200\n",
      "85/85 [==============================] - 237s 3s/step - loss: 0.3721 - accuracy: 0.8415 - val_loss: 0.3646 - val_accuracy: 0.8489\n",
      "Epoch 48/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.3769 - accuracy: 0.8342 - val_loss: 0.3532 - val_accuracy: 0.8502\n",
      "Epoch 49/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3664 - accuracy: 0.8438 - val_loss: 0.3522 - val_accuracy: 0.8393\n",
      "Epoch 50/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3722 - accuracy: 0.8379 - val_loss: 0.3523 - val_accuracy: 0.8486\n",
      "Epoch 51/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3698 - accuracy: 0.8409 - val_loss: 0.3577 - val_accuracy: 0.8491\n",
      "Epoch 52/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3619 - accuracy: 0.8441 - val_loss: 0.3498 - val_accuracy: 0.8426\n",
      "Epoch 53/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3815 - accuracy: 0.8363 - val_loss: 0.3586 - val_accuracy: 0.8357\n",
      "Epoch 54/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3744 - accuracy: 0.8384 - val_loss: 0.3525 - val_accuracy: 0.8441\n",
      "Epoch 55/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3782 - accuracy: 0.8367 - val_loss: 0.3490 - val_accuracy: 0.8492\n",
      "Epoch 56/200\n",
      "85/85 [==============================] - 244s 3s/step - loss: 0.3692 - accuracy: 0.8359 - val_loss: 0.3598 - val_accuracy: 0.8358\n",
      "Epoch 57/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3600 - accuracy: 0.8478 - val_loss: 0.3737 - val_accuracy: 0.8301\n",
      "Epoch 58/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3682 - accuracy: 0.8427 - val_loss: 0.3570 - val_accuracy: 0.8364\n",
      "Epoch 59/200\n",
      "85/85 [==============================] - 239s 3s/step - loss: 0.3620 - accuracy: 0.8444 - val_loss: 0.3653 - val_accuracy: 0.8310\n",
      "Epoch 60/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3558 - accuracy: 0.8522 - val_loss: 0.3424 - val_accuracy: 0.8519\n",
      "Epoch 61/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3636 - accuracy: 0.8424 - val_loss: 0.3532 - val_accuracy: 0.8404\n",
      "Epoch 62/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3639 - accuracy: 0.8441 - val_loss: 0.3449 - val_accuracy: 0.8467\n",
      "Epoch 63/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.3558 - accuracy: 0.8515 - val_loss: 0.3701 - val_accuracy: 0.8282\n",
      "Epoch 64/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3604 - accuracy: 0.8495 - val_loss: 0.3648 - val_accuracy: 0.8386\n",
      "Epoch 65/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3633 - accuracy: 0.8454 - val_loss: 0.3631 - val_accuracy: 0.8342\n",
      "Epoch 66/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3664 - accuracy: 0.8430 - val_loss: 0.3626 - val_accuracy: 0.8343\n",
      "Epoch 67/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3618 - accuracy: 0.8417 - val_loss: 0.3448 - val_accuracy: 0.8454\n",
      "Epoch 68/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3723 - accuracy: 0.8368 - val_loss: 0.3509 - val_accuracy: 0.8404\n",
      "Epoch 69/200\n",
      "85/85 [==============================] - 233s 3s/step - loss: 0.3535 - accuracy: 0.8490 - val_loss: 0.3410 - val_accuracy: 0.8491\n",
      "Epoch 70/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.3560 - accuracy: 0.8510 - val_loss: 0.3399 - val_accuracy: 0.8494\n",
      "Epoch 71/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3530 - accuracy: 0.8498 - val_loss: 0.3444 - val_accuracy: 0.8422\n",
      "Epoch 72/200\n",
      "85/85 [==============================] - 233s 3s/step - loss: 0.3531 - accuracy: 0.8474 - val_loss: 0.3399 - val_accuracy: 0.8508\n",
      "Epoch 73/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3600 - accuracy: 0.8444 - val_loss: 0.3642 - val_accuracy: 0.8365\n",
      "Epoch 74/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3499 - accuracy: 0.8523 - val_loss: 0.3388 - val_accuracy: 0.8499\n",
      "Epoch 75/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3501 - accuracy: 0.8524 - val_loss: 0.3370 - val_accuracy: 0.8473\n",
      "Epoch 76/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3504 - accuracy: 0.8516 - val_loss: 0.4148 - val_accuracy: 0.8150\n",
      "Epoch 77/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3421 - accuracy: 0.8558 - val_loss: 0.3442 - val_accuracy: 0.8526\n",
      "Epoch 78/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3520 - accuracy: 0.8548 - val_loss: 0.3429 - val_accuracy: 0.8519\n",
      "Epoch 79/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3495 - accuracy: 0.8514 - val_loss: 0.3714 - val_accuracy: 0.8272\n",
      "Epoch 80/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3591 - accuracy: 0.8462 - val_loss: 0.3394 - val_accuracy: 0.8494\n",
      "Epoch 81/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3428 - accuracy: 0.8606 - val_loss: 0.3394 - val_accuracy: 0.8525\n",
      "Epoch 82/200\n",
      "85/85 [==============================] - 249s 3s/step - loss: 0.3497 - accuracy: 0.8563 - val_loss: 0.3493 - val_accuracy: 0.8461\n",
      "Epoch 83/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3436 - accuracy: 0.8558 - val_loss: 0.3385 - val_accuracy: 0.8546\n",
      "Epoch 84/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3411 - accuracy: 0.8557 - val_loss: 0.3808 - val_accuracy: 0.8307\n",
      "Epoch 85/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3423 - accuracy: 0.8610 - val_loss: 0.3467 - val_accuracy: 0.8421\n",
      "Epoch 86/200\n",
      "85/85 [==============================] - 244s 3s/step - loss: 0.3470 - accuracy: 0.8471 - val_loss: 0.3338 - val_accuracy: 0.8570\n",
      "Epoch 87/200\n",
      "85/85 [==============================] - 239s 3s/step - loss: 0.3440 - accuracy: 0.8535 - val_loss: 0.3357 - val_accuracy: 0.8558\n",
      "Epoch 88/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3417 - accuracy: 0.8570 - val_loss: 0.3405 - val_accuracy: 0.8574\n",
      "Epoch 89/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3503 - accuracy: 0.8520 - val_loss: 0.3479 - val_accuracy: 0.8404\n",
      "Epoch 90/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3451 - accuracy: 0.8531 - val_loss: 0.3433 - val_accuracy: 0.8528\n",
      "Epoch 91/200\n",
      "85/85 [==============================] - 233s 3s/step - loss: 0.3511 - accuracy: 0.8518 - val_loss: 0.4011 - val_accuracy: 0.8150\n",
      "Epoch 92/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3486 - accuracy: 0.8534 - val_loss: 0.3672 - val_accuracy: 0.8399\n",
      "Epoch 93/200\n",
      "85/85 [==============================] - 231s 3s/step - loss: 0.3439 - accuracy: 0.8535 - val_loss: 0.3315 - val_accuracy: 0.8558\n",
      "Epoch 94/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3451 - accuracy: 0.8576 - val_loss: 0.3782 - val_accuracy: 0.8210\n",
      "Epoch 95/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3461 - accuracy: 0.8499 - val_loss: 0.3353 - val_accuracy: 0.8600\n",
      "Epoch 96/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3400 - accuracy: 0.8567 - val_loss: 0.3473 - val_accuracy: 0.8487\n",
      "Epoch 97/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3373 - accuracy: 0.8563 - val_loss: 0.3361 - val_accuracy: 0.8589\n",
      "Epoch 98/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3452 - accuracy: 0.8537 - val_loss: 0.3301 - val_accuracy: 0.8593\n",
      "Epoch 99/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.3414 - accuracy: 0.8579 - val_loss: 0.3619 - val_accuracy: 0.8295\n",
      "Epoch 100/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3420 - accuracy: 0.8539 - val_loss: 0.3877 - val_accuracy: 0.8206\n",
      "Epoch 101/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3403 - accuracy: 0.8574 - val_loss: 0.3808 - val_accuracy: 0.8227\n",
      "Epoch 102/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3335 - accuracy: 0.8628 - val_loss: 0.3461 - val_accuracy: 0.8468\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 241s 3s/step - loss: 0.3360 - accuracy: 0.8570 - val_loss: 0.3308 - val_accuracy: 0.8597\n",
      "Epoch 104/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3418 - accuracy: 0.8548 - val_loss: 0.3407 - val_accuracy: 0.8602\n",
      "Epoch 105/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3408 - accuracy: 0.8537 - val_loss: 0.4198 - val_accuracy: 0.8008\n",
      "Epoch 106/200\n",
      "85/85 [==============================] - 246s 3s/step - loss: 0.3405 - accuracy: 0.8552 - val_loss: 0.3284 - val_accuracy: 0.8700\n",
      "Epoch 107/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3338 - accuracy: 0.8621 - val_loss: 0.3346 - val_accuracy: 0.8595\n",
      "Epoch 108/200\n",
      "85/85 [==============================] - 249s 3s/step - loss: 0.3346 - accuracy: 0.8613 - val_loss: 0.4021 - val_accuracy: 0.8231\n",
      "Epoch 109/200\n",
      "85/85 [==============================] - 249s 3s/step - loss: 0.3372 - accuracy: 0.8583 - val_loss: 0.3337 - val_accuracy: 0.8632\n",
      "Epoch 110/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3337 - accuracy: 0.8620 - val_loss: 0.3995 - val_accuracy: 0.8183\n",
      "Epoch 111/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3385 - accuracy: 0.8598 - val_loss: 0.3514 - val_accuracy: 0.8452\n",
      "Epoch 112/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3253 - accuracy: 0.8627 - val_loss: 0.3385 - val_accuracy: 0.8533\n",
      "Epoch 113/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3311 - accuracy: 0.8582 - val_loss: 0.3703 - val_accuracy: 0.8315\n",
      "Epoch 114/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3361 - accuracy: 0.8561 - val_loss: 0.3452 - val_accuracy: 0.8424\n",
      "Epoch 115/200\n",
      "85/85 [==============================] - 243s 3s/step - loss: 0.3406 - accuracy: 0.8576 - val_loss: 0.3345 - val_accuracy: 0.8586\n",
      "Epoch 116/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3290 - accuracy: 0.8645 - val_loss: 0.3752 - val_accuracy: 0.8208\n",
      "Epoch 117/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3312 - accuracy: 0.8580 - val_loss: 0.3537 - val_accuracy: 0.8348\n",
      "Epoch 118/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3251 - accuracy: 0.8609 - val_loss: 0.4638 - val_accuracy: 0.7796\n",
      "Epoch 119/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3271 - accuracy: 0.8650 - val_loss: 0.3789 - val_accuracy: 0.8198\n",
      "Epoch 120/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3324 - accuracy: 0.8586 - val_loss: 0.3813 - val_accuracy: 0.8177\n",
      "Epoch 121/200\n",
      "85/85 [==============================] - 244s 3s/step - loss: 0.3473 - accuracy: 0.8509 - val_loss: 0.3379 - val_accuracy: 0.8538\n",
      "Epoch 122/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3261 - accuracy: 0.8620 - val_loss: 0.3605 - val_accuracy: 0.8309\n",
      "Epoch 123/200\n",
      "85/85 [==============================] - 245s 3s/step - loss: 0.3224 - accuracy: 0.8653 - val_loss: 0.3371 - val_accuracy: 0.8509\n",
      "Epoch 124/200\n",
      "85/85 [==============================] - 236s 3s/step - loss: 0.3213 - accuracy: 0.8638 - val_loss: 0.3286 - val_accuracy: 0.8600\n",
      "Epoch 125/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.3250 - accuracy: 0.8653 - val_loss: 0.3465 - val_accuracy: 0.8476\n",
      "Epoch 126/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3370 - accuracy: 0.8598 - val_loss: 0.3462 - val_accuracy: 0.8451\n",
      "Epoch 127/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3316 - accuracy: 0.8649 - val_loss: 0.3427 - val_accuracy: 0.8498\n",
      "Epoch 128/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3188 - accuracy: 0.8609 - val_loss: 0.3360 - val_accuracy: 0.8538\n",
      "Epoch 129/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3167 - accuracy: 0.8700 - val_loss: 0.3353 - val_accuracy: 0.8547\n",
      "Epoch 130/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3222 - accuracy: 0.8619 - val_loss: 0.3845 - val_accuracy: 0.8171\n",
      "Epoch 131/200\n",
      "85/85 [==============================] - 237s 3s/step - loss: 0.3190 - accuracy: 0.8676 - val_loss: 0.3400 - val_accuracy: 0.8539\n",
      "Epoch 132/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3230 - accuracy: 0.8671 - val_loss: 0.3367 - val_accuracy: 0.8505\n",
      "Epoch 133/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3323 - accuracy: 0.8602 - val_loss: 0.3272 - val_accuracy: 0.8630\n",
      "Epoch 134/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3266 - accuracy: 0.8627 - val_loss: 0.3278 - val_accuracy: 0.8594\n",
      "Epoch 135/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3163 - accuracy: 0.8703 - val_loss: 0.3273 - val_accuracy: 0.8592\n",
      "Epoch 136/200\n",
      "85/85 [==============================] - 246s 3s/step - loss: 0.3177 - accuracy: 0.8679 - val_loss: 0.3264 - val_accuracy: 0.8610\n",
      "Epoch 137/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3215 - accuracy: 0.8618 - val_loss: 0.3379 - val_accuracy: 0.8599\n",
      "Epoch 138/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.3223 - accuracy: 0.8624 - val_loss: 0.3271 - val_accuracy: 0.8572\n",
      "Epoch 139/200\n",
      "85/85 [==============================] - 246s 3s/step - loss: 0.3085 - accuracy: 0.8708 - val_loss: 0.3530 - val_accuracy: 0.8381\n",
      "Epoch 140/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.3222 - accuracy: 0.8619 - val_loss: 0.3567 - val_accuracy: 0.8456\n",
      "Epoch 141/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3177 - accuracy: 0.8710 - val_loss: 0.3872 - val_accuracy: 0.8179\n",
      "Epoch 142/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3066 - accuracy: 0.8724 - val_loss: 0.3435 - val_accuracy: 0.8497\n",
      "Epoch 143/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3259 - accuracy: 0.8601 - val_loss: 0.3603 - val_accuracy: 0.8409\n",
      "Epoch 144/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3259 - accuracy: 0.8644 - val_loss: 0.3304 - val_accuracy: 0.8567\n",
      "Epoch 145/200\n",
      "85/85 [==============================] - 244s 3s/step - loss: 0.3090 - accuracy: 0.8772 - val_loss: 0.3365 - val_accuracy: 0.8541\n",
      "Epoch 146/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3107 - accuracy: 0.8700 - val_loss: 0.3383 - val_accuracy: 0.8540\n",
      "Epoch 147/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3170 - accuracy: 0.8672 - val_loss: 0.3668 - val_accuracy: 0.8316\n",
      "Epoch 148/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3142 - accuracy: 0.8678 - val_loss: 0.4031 - val_accuracy: 0.8166\n",
      "Epoch 149/200\n",
      "85/85 [==============================] - 234s 3s/step - loss: 0.3284 - accuracy: 0.8603 - val_loss: 0.4043 - val_accuracy: 0.8134\n",
      "Epoch 150/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3168 - accuracy: 0.8666 - val_loss: 0.3516 - val_accuracy: 0.8370\n",
      "Epoch 151/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3108 - accuracy: 0.8701 - val_loss: 0.3349 - val_accuracy: 0.8545\n",
      "Epoch 152/200\n",
      "85/85 [==============================] - 248s 3s/step - loss: 0.3050 - accuracy: 0.8743 - val_loss: 0.3755 - val_accuracy: 0.8331\n",
      "Epoch 153/200\n",
      "85/85 [==============================] - 247s 3s/step - loss: 0.3100 - accuracy: 0.8755 - val_loss: 0.5512 - val_accuracy: 0.7835\n",
      "Epoch 154/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.3216 - accuracy: 0.8635 - val_loss: 0.4370 - val_accuracy: 0.8033\n",
      "Epoch 155/200\n",
      "85/85 [==============================] - 239s 3s/step - loss: 0.3127 - accuracy: 0.8653 - val_loss: 0.3317 - val_accuracy: 0.8572\n",
      "Epoch 156/200\n",
      "85/85 [==============================] - 239s 3s/step - loss: 0.3095 - accuracy: 0.8721 - val_loss: 0.3579 - val_accuracy: 0.8394\n",
      "Epoch 157/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.2948 - accuracy: 0.8772 - val_loss: 0.3882 - val_accuracy: 0.8198\n",
      "Epoch 158/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3157 - accuracy: 0.8673 - val_loss: 0.3352 - val_accuracy: 0.8552\n",
      "Epoch 159/200\n",
      "85/85 [==============================] - 240s 3s/step - loss: 0.3068 - accuracy: 0.8714 - val_loss: 0.3530 - val_accuracy: 0.8411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "85/85 [==============================] - 242s 3s/step - loss: 0.3051 - accuracy: 0.8703 - val_loss: 0.3552 - val_accuracy: 0.8375\n",
      "Epoch 161/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.2957 - accuracy: 0.8836 - val_loss: 0.3675 - val_accuracy: 0.8314\n",
      "Epoch 162/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.2981 - accuracy: 0.8779 - val_loss: 0.3322 - val_accuracy: 0.8610\n",
      "Epoch 163/200\n",
      "85/85 [==============================] - 241s 3s/step - loss: 0.2972 - accuracy: 0.8756 - val_loss: 0.3313 - val_accuracy: 0.8634\n",
      "Epoch 164/200\n",
      "85/85 [==============================] - 236s 3s/step - loss: 0.3031 - accuracy: 0.8726 - val_loss: 0.3670 - val_accuracy: 0.8411\n",
      "Epoch 165/200\n",
      "85/85 [==============================] - 232s 3s/step - loss: 0.3032 - accuracy: 0.8711 - val_loss: 0.3659 - val_accuracy: 0.8316\n",
      "Epoch 166/200\n",
      "85/85 [==============================] - 238s 3s/step - loss: 0.2982 - accuracy: 0.8778 - val_loss: 0.3335 - val_accuracy: 0.8555\n",
      "Epoch 167/200\n",
      "85/85 [==============================] - 234s 3s/step - loss: 0.2919 - accuracy: 0.8811 - val_loss: 0.3391 - val_accuracy: 0.8517\n",
      "Epoch 168/200\n",
      "85/85 [==============================] - 231s 3s/step - loss: 0.3032 - accuracy: 0.8718 - val_loss: 0.3369 - val_accuracy: 0.8490\n",
      "Epoch 169/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.2889 - accuracy: 0.8814 - val_loss: 0.3391 - val_accuracy: 0.8473\n",
      "Epoch 170/200\n",
      "85/85 [==============================] - 229s 3s/step - loss: 0.2949 - accuracy: 0.8761 - val_loss: 0.3400 - val_accuracy: 0.8493\n",
      "Epoch 171/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.3068 - accuracy: 0.8669 - val_loss: 0.3644 - val_accuracy: 0.8442\n",
      "Epoch 172/200\n",
      "85/85 [==============================] - 230s 3s/step - loss: 0.2976 - accuracy: 0.8767 - val_loss: 0.3314 - val_accuracy: 0.8519\n",
      "Epoch 173/200\n",
      "39/85 [============>.................] - ETA: 2:02 - loss: 0.2947 - accuracy: 0.8749"
     ]
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model2=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 2K-3Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINLEN=2000\n",
    "MAXLEN=3000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model3=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
