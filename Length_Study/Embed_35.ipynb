{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional GRU\n",
    "\n",
    "Same as GRU 33 with K=5 but one more layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For the manual cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=200\n",
    "SPLITS=1\n",
    "K=5\n",
    "EMBED_DIMEN=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    vocabulary_size=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "    act=\"sigmoid\"\n",
    "    dt='float32'\n",
    "\n",
    "    rnn = keras.models.Sequential()\n",
    "    embed_layer = keras.layers.Embedding(\n",
    "        vocabulary_size,EMBED_DIMEN,input_length=maxlen);\n",
    "    rnn1_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(32, return_sequences=True, dropout=0.50, \n",
    "            input_shape=[maxlen,dimen]))\n",
    "    rnn2_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(32, return_sequences=True, dropout=0.50, \n",
    "            input_shape=[maxlen,dimen]))\n",
    "    rnn3_layer = keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(32, dropout=0.50, return_sequences=True))\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    dense1_layer = keras.layers.Dense(32,activation=act,dtype=dt)\n",
    "    dense2_layer = keras.layers.Dense(32,activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,activation=act,dtype=dt)\n",
    "\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    rnn.add(rnn2_layer)\n",
    "    rnn.add(rnn3_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    rnn2=None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "    return rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    print(type(X_train_all))\n",
    "    print(X_train_all.shape)\n",
    "    print(X_train_all.iloc[0])\n",
    "    print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    print(type(X_train_kmers))\n",
    "    print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9089</td>\n",
       "      <td>0</td>\n",
       "      <td>CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>6070</td>\n",
       "      <td>1</td>\n",
       "      <td>AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>18550</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>15028</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3387</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>6410</td>\n",
       "      <td>1</td>\n",
       "      <td>GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7641</td>\n",
       "      <td>1</td>\n",
       "      <td>ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...</td>\n",
       "      <td>3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14109</td>\n",
       "      <td>0</td>\n",
       "      <td>GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30290 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seqnum  class                                           sequence  \\\n",
       "1280     1281      0  AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...   \n",
       "9088     9089      0  CAGCTCCTGGGATGGCCTCACCTGAGGAGACTCTTGGGCCTTGGCA...   \n",
       "6069     6070      1  AGATCTAGGGATGGGGATGGGGAGGAGAAGTGGGAATGGGAAATTG...   \n",
       "18549   18550      1  GACGTCTCCCGCGGGCGTCGGCAGGGTCGGCGGCGTCGGCAGCAGT...   \n",
       "15027   15028      1  GAGCGCGCGAGCCGGGCCCGGAGCGCACGCCGCCGCCGCCACCGCC...   \n",
       "...       ...    ...                                                ...   \n",
       "3386     3387      0  TTTATGTGGATTGTCTGTCTCATGCTTGTTTCACCAGGGTAGTTAC...   \n",
       "6495     6496      0  ATAATGGGAAACTAAGGGCAAGTTCTCATGTTCCTGGTCCTGGCTT...   \n",
       "6409     6410      1  GGGTTTATTACTACTGAAGGAAGAACGTGAGTAGGTTAGGATTTCG...   \n",
       "7640     7641      1  ACAGCTGTGTTTGGCTGCAGGGCCAAGAGCGCTGTCAAGAAGACCC...   \n",
       "14108   14109      0  GAAGTGATTGCAAGTTCAGCAGCATGAAACTGCTCTTTATCCGTGC...   \n",
       "\n",
       "       seqlen  \n",
       "1280      348  \n",
       "9088      534  \n",
       "6069      592  \n",
       "18549     945  \n",
       "15027    4382  \n",
       "...       ...  \n",
       "3386      578  \n",
       "6495      562  \n",
       "6409      740  \n",
       "7640     3156  \n",
       "14108     466  \n",
       "\n",
       "[30290 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "nc_seq=load_fasta('ncRNA.fasta',0)\n",
    "pc_seq=load_fasta('pcRNA.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [200 - 1000)\n",
      "original (30290, 4)\n",
      "no short (30290, 4)\n",
      "no long, no short (8879, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(8879, 1)\n",
      "sequence    AGTCCCTCCCCAGCCCAGCAGTCCCTCCAGGCTACATCCAGGAGAC...\n",
      "Name: 1280, dtype: object\n",
      "348\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[182 726 856 ...   0   0   0]\n",
      " [142 568 221 ...   0   0   0]\n",
      " [540 110 440 ...   0   0   0]\n",
      " ...\n",
      " [585 292 144 ...   0   0   0]\n",
      " [911 569 225 ...   0   0   0]\n",
      " [524  47 185 ...   0   0   0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 16)          16400     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 66,801\n",
      "Trainable params: 66,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/200\n",
      "222/222 [==============================] - 515s 2s/step - loss: 0.6694 - accuracy: 0.5894 - val_loss: 0.6147 - val_accuracy: 0.6929\n",
      "Epoch 2/200\n",
      "222/222 [==============================] - 502s 2s/step - loss: 0.6626 - accuracy: 0.6077 - val_loss: 0.6781 - val_accuracy: 0.5613\n",
      "Epoch 3/200\n",
      "222/222 [==============================] - 495s 2s/step - loss: 0.6031 - accuracy: 0.6792 - val_loss: 0.5011 - val_accuracy: 0.7700\n",
      "Epoch 4/200\n",
      "222/222 [==============================] - 500s 2s/step - loss: 0.4479 - accuracy: 0.7989 - val_loss: 0.4282 - val_accuracy: 0.8171\n",
      "Epoch 5/200\n",
      "222/222 [==============================] - 501s 2s/step - loss: 0.3858 - accuracy: 0.8330 - val_loss: 0.4224 - val_accuracy: 0.8163\n",
      "Epoch 6/200\n",
      "222/222 [==============================] - 491s 2s/step - loss: 0.3566 - accuracy: 0.8494 - val_loss: 0.4014 - val_accuracy: 0.8299\n",
      "Epoch 7/200\n",
      "222/222 [==============================] - 488s 2s/step - loss: 0.3505 - accuracy: 0.8528 - val_loss: 0.3931 - val_accuracy: 0.8224\n",
      "Epoch 8/200\n",
      "222/222 [==============================] - 487s 2s/step - loss: 0.3379 - accuracy: 0.8592 - val_loss: 0.3836 - val_accuracy: 0.8357\n",
      "Epoch 9/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.3334 - accuracy: 0.8632 - val_loss: 0.3871 - val_accuracy: 0.8359\n",
      "Epoch 10/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.3215 - accuracy: 0.8654 - val_loss: 0.3899 - val_accuracy: 0.8289\n",
      "Epoch 11/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.3152 - accuracy: 0.8693 - val_loss: 0.3772 - val_accuracy: 0.8327\n",
      "Epoch 12/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.3119 - accuracy: 0.8705 - val_loss: 0.3875 - val_accuracy: 0.8253\n",
      "Epoch 13/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.3212 - accuracy: 0.8652 - val_loss: 0.3778 - val_accuracy: 0.8316\n",
      "Epoch 14/200\n",
      "222/222 [==============================] - 498s 2s/step - loss: 0.3072 - accuracy: 0.8707 - val_loss: 0.3751 - val_accuracy: 0.8323\n",
      "Epoch 15/200\n",
      "222/222 [==============================] - 568s 3s/step - loss: 0.3009 - accuracy: 0.8768 - val_loss: 0.3712 - val_accuracy: 0.8323\n",
      "Epoch 16/200\n",
      "222/222 [==============================] - 642s 3s/step - loss: 0.3024 - accuracy: 0.8755 - val_loss: 0.3748 - val_accuracy: 0.8309\n",
      "Epoch 17/200\n",
      "222/222 [==============================] - 496s 2s/step - loss: 0.2962 - accuracy: 0.8788 - val_loss: 0.3911 - val_accuracy: 0.8230\n",
      "Epoch 18/200\n",
      "222/222 [==============================] - 499s 2s/step - loss: 0.2955 - accuracy: 0.8778 - val_loss: 0.3712 - val_accuracy: 0.8311\n",
      "Epoch 19/200\n",
      "222/222 [==============================] - 488s 2s/step - loss: 0.2936 - accuracy: 0.8834 - val_loss: 0.3745 - val_accuracy: 0.8315\n",
      "Epoch 20/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2916 - accuracy: 0.8834 - val_loss: 0.3751 - val_accuracy: 0.8279\n",
      "Epoch 21/200\n",
      "222/222 [==============================] - 495s 2s/step - loss: 0.2917 - accuracy: 0.8809 - val_loss: 0.3754 - val_accuracy: 0.8334\n",
      "Epoch 22/200\n",
      "222/222 [==============================] - 495s 2s/step - loss: 0.2820 - accuracy: 0.8888 - val_loss: 0.3868 - val_accuracy: 0.8276\n",
      "Epoch 23/200\n",
      "222/222 [==============================] - 491s 2s/step - loss: 0.2839 - accuracy: 0.8834 - val_loss: 0.3836 - val_accuracy: 0.8276\n",
      "Epoch 24/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2792 - accuracy: 0.8876 - val_loss: 0.3828 - val_accuracy: 0.8268\n",
      "Epoch 25/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2782 - accuracy: 0.8872 - val_loss: 0.3822 - val_accuracy: 0.8321\n",
      "Epoch 26/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2741 - accuracy: 0.8927 - val_loss: 0.4363 - val_accuracy: 0.7978\n",
      "Epoch 27/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2711 - accuracy: 0.8917 - val_loss: 0.3892 - val_accuracy: 0.8242\n",
      "Epoch 28/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.2646 - accuracy: 0.8972 - val_loss: 0.3832 - val_accuracy: 0.8288\n",
      "Epoch 29/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2645 - accuracy: 0.8960 - val_loss: 0.4006 - val_accuracy: 0.8248\n",
      "Epoch 30/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2583 - accuracy: 0.8990 - val_loss: 0.3788 - val_accuracy: 0.8319\n",
      "Epoch 31/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2524 - accuracy: 0.9018 - val_loss: 0.3924 - val_accuracy: 0.8250\n",
      "Epoch 32/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2525 - accuracy: 0.9025 - val_loss: 0.4425 - val_accuracy: 0.8050\n",
      "Epoch 33/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2475 - accuracy: 0.9028 - val_loss: 0.3948 - val_accuracy: 0.8284\n",
      "Epoch 34/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2544 - accuracy: 0.8999 - val_loss: 0.3861 - val_accuracy: 0.8265\n",
      "Epoch 35/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2416 - accuracy: 0.9079 - val_loss: 0.4055 - val_accuracy: 0.8259\n",
      "Epoch 36/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2358 - accuracy: 0.9110 - val_loss: 0.4225 - val_accuracy: 0.8243\n",
      "Epoch 37/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2393 - accuracy: 0.9086 - val_loss: 0.3969 - val_accuracy: 0.8188\n",
      "Epoch 38/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2408 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8186\n",
      "Epoch 39/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2384 - accuracy: 0.9087 - val_loss: 0.4370 - val_accuracy: 0.8119\n",
      "Epoch 40/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2292 - accuracy: 0.9133 - val_loss: 0.4116 - val_accuracy: 0.8150\n",
      "Epoch 41/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2233 - accuracy: 0.9162 - val_loss: 0.4423 - val_accuracy: 0.8224\n",
      "Epoch 42/200\n",
      "222/222 [==============================] - 480s 2s/step - loss: 0.2246 - accuracy: 0.9148 - val_loss: 0.4067 - val_accuracy: 0.8271\n",
      "Epoch 43/200\n",
      "222/222 [==============================] - 488s 2s/step - loss: 0.2165 - accuracy: 0.9185 - val_loss: 0.4284 - val_accuracy: 0.8210\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 481s 2s/step - loss: 0.2204 - accuracy: 0.9177 - val_loss: 0.4344 - val_accuracy: 0.8167\n",
      "Epoch 45/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2174 - accuracy: 0.9205 - val_loss: 0.4203 - val_accuracy: 0.8138\n",
      "Epoch 46/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2174 - accuracy: 0.9162 - val_loss: 0.4404 - val_accuracy: 0.8215\n",
      "Epoch 47/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2176 - accuracy: 0.9201 - val_loss: 0.4266 - val_accuracy: 0.8250\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2156 - accuracy: 0.9193 - val_loss: 0.4344 - val_accuracy: 0.8222\n",
      "Epoch 49/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2054 - accuracy: 0.9226 - val_loss: 0.4314 - val_accuracy: 0.8235\n",
      "Epoch 50/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2135 - accuracy: 0.9202 - val_loss: 0.4065 - val_accuracy: 0.8254\n",
      "Epoch 51/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2075 - accuracy: 0.9227 - val_loss: 0.4378 - val_accuracy: 0.8190\n",
      "Epoch 52/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.2110 - accuracy: 0.9204 - val_loss: 0.4286 - val_accuracy: 0.8220\n",
      "Epoch 53/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1976 - accuracy: 0.9266 - val_loss: 0.4408 - val_accuracy: 0.8217\n",
      "Epoch 54/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.2107 - accuracy: 0.9217 - val_loss: 0.4312 - val_accuracy: 0.8154\n",
      "Epoch 55/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.2010 - accuracy: 0.9243 - val_loss: 0.4918 - val_accuracy: 0.8074\n",
      "Epoch 56/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1996 - accuracy: 0.9265 - val_loss: 0.4866 - val_accuracy: 0.8110\n",
      "Epoch 57/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1963 - accuracy: 0.9283 - val_loss: 0.4414 - val_accuracy: 0.8214\n",
      "Epoch 58/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.1934 - accuracy: 0.9273 - val_loss: 0.4860 - val_accuracy: 0.8093\n",
      "Epoch 59/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1881 - accuracy: 0.9300 - val_loss: 0.4709 - val_accuracy: 0.8137\n",
      "Epoch 60/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1859 - accuracy: 0.9306 - val_loss: 0.4798 - val_accuracy: 0.8105\n",
      "Epoch 61/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1833 - accuracy: 0.9323 - val_loss: 0.4749 - val_accuracy: 0.8136\n",
      "Epoch 62/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.1861 - accuracy: 0.9328 - val_loss: 0.4406 - val_accuracy: 0.8118\n",
      "Epoch 63/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1784 - accuracy: 0.9362 - val_loss: 0.4694 - val_accuracy: 0.8149\n",
      "Epoch 64/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1795 - accuracy: 0.9340 - val_loss: 0.4917 - val_accuracy: 0.8094\n",
      "Epoch 65/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.1843 - accuracy: 0.9304 - val_loss: 0.4465 - val_accuracy: 0.8141\n",
      "Epoch 66/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.1746 - accuracy: 0.9360 - val_loss: 0.4836 - val_accuracy: 0.8157\n",
      "Epoch 67/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1754 - accuracy: 0.9371 - val_loss: 0.4464 - val_accuracy: 0.8158\n",
      "Epoch 68/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1848 - accuracy: 0.9323 - val_loss: 0.4792 - val_accuracy: 0.8116\n",
      "Epoch 69/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1713 - accuracy: 0.9399 - val_loss: 0.4850 - val_accuracy: 0.8131\n",
      "Epoch 70/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1731 - accuracy: 0.9360 - val_loss: 0.4694 - val_accuracy: 0.8165\n",
      "Epoch 71/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1694 - accuracy: 0.9399 - val_loss: 0.4944 - val_accuracy: 0.8036\n",
      "Epoch 72/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1727 - accuracy: 0.9360 - val_loss: 0.4853 - val_accuracy: 0.8076\n",
      "Epoch 73/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1710 - accuracy: 0.9361 - val_loss: 0.5109 - val_accuracy: 0.8094\n",
      "Epoch 74/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1671 - accuracy: 0.9391 - val_loss: 0.5217 - val_accuracy: 0.8057\n",
      "Epoch 75/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1732 - accuracy: 0.9368 - val_loss: 0.5149 - val_accuracy: 0.8103\n",
      "Epoch 76/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1669 - accuracy: 0.9389 - val_loss: 0.5358 - val_accuracy: 0.8056\n",
      "Epoch 77/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1642 - accuracy: 0.9404 - val_loss: 0.4901 - val_accuracy: 0.8165\n",
      "Epoch 78/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1625 - accuracy: 0.9429 - val_loss: 0.5328 - val_accuracy: 0.8092\n",
      "Epoch 79/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1594 - accuracy: 0.9425 - val_loss: 0.5017 - val_accuracy: 0.8065\n",
      "Epoch 80/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.1609 - accuracy: 0.9402 - val_loss: 0.5385 - val_accuracy: 0.8001\n",
      "Epoch 81/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1587 - accuracy: 0.9444 - val_loss: 0.5114 - val_accuracy: 0.8073\n",
      "Epoch 82/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1675 - accuracy: 0.9385 - val_loss: 0.4817 - val_accuracy: 0.8010\n",
      "Epoch 83/200\n",
      "222/222 [==============================] - 480s 2s/step - loss: 0.1571 - accuracy: 0.9463 - val_loss: 0.5263 - val_accuracy: 0.8019\n",
      "Epoch 84/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1557 - accuracy: 0.9462 - val_loss: 0.5252 - val_accuracy: 0.8048\n",
      "Epoch 85/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1513 - accuracy: 0.9458 - val_loss: 0.5066 - val_accuracy: 0.8059\n",
      "Epoch 86/200\n",
      "222/222 [==============================] - 480s 2s/step - loss: 0.1527 - accuracy: 0.9467 - val_loss: 0.5094 - val_accuracy: 0.8107\n",
      "Epoch 87/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1546 - accuracy: 0.9462 - val_loss: 0.5006 - val_accuracy: 0.8102\n",
      "Epoch 88/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.1440 - accuracy: 0.9512 - val_loss: 0.5260 - val_accuracy: 0.8125\n",
      "Epoch 89/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1531 - accuracy: 0.9443 - val_loss: 0.5061 - val_accuracy: 0.8140\n",
      "Epoch 90/200\n",
      "222/222 [==============================] - 482s 2s/step - loss: 0.1540 - accuracy: 0.9459 - val_loss: 0.5256 - val_accuracy: 0.8091\n",
      "Epoch 91/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1442 - accuracy: 0.9522 - val_loss: 0.5258 - val_accuracy: 0.8138\n",
      "Epoch 92/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.1466 - accuracy: 0.9483 - val_loss: 0.5208 - val_accuracy: 0.8138\n",
      "Epoch 93/200\n",
      "222/222 [==============================] - 548s 2s/step - loss: 0.1451 - accuracy: 0.9502 - val_loss: 0.5257 - val_accuracy: 0.8109\n",
      "Epoch 94/200\n",
      "222/222 [==============================] - 558s 3s/step - loss: 0.1421 - accuracy: 0.9513 - val_loss: 0.5568 - val_accuracy: 0.8075\n",
      "Epoch 95/200\n",
      "222/222 [==============================] - 591s 3s/step - loss: 0.1450 - accuracy: 0.9489 - val_loss: 0.5713 - val_accuracy: 0.8056\n",
      "Epoch 96/200\n",
      "222/222 [==============================] - 495s 2s/step - loss: 0.1510 - accuracy: 0.9469 - val_loss: 0.5617 - val_accuracy: 0.8072\n",
      "Epoch 97/200\n",
      "222/222 [==============================] - 495s 2s/step - loss: 0.1343 - accuracy: 0.9528 - val_loss: 0.5393 - val_accuracy: 0.8077\n",
      "Epoch 98/200\n",
      "222/222 [==============================] - 481s 2s/step - loss: 0.1423 - accuracy: 0.9500 - val_loss: 0.5515 - val_accuracy: 0.8111\n",
      "Epoch 99/200\n",
      "222/222 [==============================] - 478s 2s/step - loss: 0.1457 - accuracy: 0.9474 - val_loss: 0.5152 - val_accuracy: 0.8101\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 481s 2s/step - loss: 0.1374 - accuracy: 0.9545 - val_loss: 0.6012 - val_accuracy: 0.8100\n",
      "Epoch 101/200\n",
      "222/222 [==============================] - 488s 2s/step - loss: 0.1380 - accuracy: 0.9520 - val_loss: 0.5548 - val_accuracy: 0.8062\n",
      "Epoch 102/200\n",
      "222/222 [==============================] - 498s 2s/step - loss: 0.1389 - accuracy: 0.9526 - val_loss: 0.5618 - val_accuracy: 0.8072\n",
      "Epoch 103/200\n",
      "222/222 [==============================] - 500s 2s/step - loss: 0.1347 - accuracy: 0.9525 - val_loss: 0.5476 - val_accuracy: 0.8068\n",
      "Epoch 104/200\n",
      "222/222 [==============================] - 547s 2s/step - loss: 0.1293 - accuracy: 0.9562 - val_loss: 0.5828 - val_accuracy: 0.8064\n",
      "Epoch 105/200\n",
      "222/222 [==============================] - 525s 2s/step - loss: 0.1338 - accuracy: 0.9538 - val_loss: 0.5429 - val_accuracy: 0.8076\n",
      "Epoch 106/200\n",
      "222/222 [==============================] - 556s 3s/step - loss: 0.1290 - accuracy: 0.9554 - val_loss: 0.5861 - val_accuracy: 0.8011\n",
      "Epoch 107/200\n",
      "222/222 [==============================] - 527s 2s/step - loss: 0.1315 - accuracy: 0.9535 - val_loss: 0.5837 - val_accuracy: 0.8026\n",
      "Epoch 108/200\n",
      "222/222 [==============================] - 530s 2s/step - loss: 0.1288 - accuracy: 0.9572 - val_loss: 0.5929 - val_accuracy: 0.8010\n",
      "Epoch 109/200\n",
      "222/222 [==============================] - 552s 2s/step - loss: 0.1303 - accuracy: 0.9544 - val_loss: 0.5552 - val_accuracy: 0.8037\n",
      "Epoch 110/200\n",
      "222/222 [==============================] - 511s 2s/step - loss: 0.1280 - accuracy: 0.9544 - val_loss: 0.5871 - val_accuracy: 0.8095\n",
      "Epoch 111/200\n",
      "222/222 [==============================] - 501s 2s/step - loss: 0.1309 - accuracy: 0.9556 - val_loss: 0.6076 - val_accuracy: 0.8026\n",
      "Epoch 112/200\n",
      "222/222 [==============================] - 496s 2s/step - loss: 0.1270 - accuracy: 0.9571 - val_loss: 0.6111 - val_accuracy: 0.8040\n",
      "Epoch 113/200\n",
      "222/222 [==============================] - 498s 2s/step - loss: 0.1239 - accuracy: 0.9564 - val_loss: 0.6081 - val_accuracy: 0.8023\n",
      "Epoch 114/200\n",
      "222/222 [==============================] - 503s 2s/step - loss: 0.1226 - accuracy: 0.9574 - val_loss: 0.6136 - val_accuracy: 0.8056\n",
      "Epoch 115/200\n",
      "222/222 [==============================] - 501s 2s/step - loss: 0.1242 - accuracy: 0.9579 - val_loss: 0.6099 - val_accuracy: 0.8033\n",
      "Epoch 116/200\n",
      "222/222 [==============================] - 496s 2s/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.5765 - val_accuracy: 0.8069\n",
      "Epoch 117/200\n",
      "222/222 [==============================] - 489s 2s/step - loss: 0.1310 - accuracy: 0.9566 - val_loss: 0.5834 - val_accuracy: 0.7960\n",
      "Epoch 118/200\n",
      "222/222 [==============================] - 507s 2s/step - loss: 0.1218 - accuracy: 0.9594 - val_loss: 0.5976 - val_accuracy: 0.8032\n",
      "Epoch 119/200\n",
      "222/222 [==============================] - 502s 2s/step - loss: 0.1287 - accuracy: 0.9541 - val_loss: 0.5955 - val_accuracy: 0.8089\n",
      "Epoch 120/200\n",
      "222/222 [==============================] - 496s 2s/step - loss: 0.1111 - accuracy: 0.9619 - val_loss: 0.6653 - val_accuracy: 0.7950\n",
      "Epoch 121/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.1156 - accuracy: 0.9631 - val_loss: 0.6151 - val_accuracy: 0.8096\n",
      "Epoch 122/200\n",
      "222/222 [==============================] - 487s 2s/step - loss: 0.1130 - accuracy: 0.9610 - val_loss: 0.6688 - val_accuracy: 0.7975\n",
      "Epoch 123/200\n",
      "222/222 [==============================] - 511s 2s/step - loss: 0.1209 - accuracy: 0.9584 - val_loss: 0.6041 - val_accuracy: 0.8038\n",
      "Epoch 124/200\n",
      "222/222 [==============================] - 519s 2s/step - loss: 0.1127 - accuracy: 0.9618 - val_loss: 0.5855 - val_accuracy: 0.8072\n",
      "Epoch 125/200\n",
      "222/222 [==============================] - 518s 2s/step - loss: 0.1100 - accuracy: 0.9622 - val_loss: 0.6508 - val_accuracy: 0.7986\n",
      "Epoch 126/200\n",
      "222/222 [==============================] - 544s 2s/step - loss: 0.1114 - accuracy: 0.9619 - val_loss: 0.6465 - val_accuracy: 0.7961\n",
      "Epoch 127/200\n",
      "222/222 [==============================] - 509s 2s/step - loss: 0.1148 - accuracy: 0.9606 - val_loss: 0.6564 - val_accuracy: 0.8009\n",
      "Epoch 128/200\n",
      "222/222 [==============================] - 504s 2s/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.6170 - val_accuracy: 0.8008\n",
      "Epoch 129/200\n",
      "222/222 [==============================] - 564s 3s/step - loss: 0.1047 - accuracy: 0.9655 - val_loss: 0.6654 - val_accuracy: 0.7960\n",
      "Epoch 130/200\n",
      "222/222 [==============================] - 563s 3s/step - loss: 0.1131 - accuracy: 0.9612 - val_loss: 0.6854 - val_accuracy: 0.7969\n",
      "Epoch 131/200\n",
      "222/222 [==============================] - 566s 3s/step - loss: 0.1093 - accuracy: 0.9639 - val_loss: 0.6338 - val_accuracy: 0.7972\n",
      "Epoch 132/200\n",
      "222/222 [==============================] - 549s 2s/step - loss: 0.1143 - accuracy: 0.9607 - val_loss: 0.6221 - val_accuracy: 0.8018\n",
      "Epoch 133/200\n",
      "222/222 [==============================] - 506s 2s/step - loss: 0.1070 - accuracy: 0.9651 - val_loss: 0.6260 - val_accuracy: 0.8056\n",
      "Epoch 134/200\n",
      "222/222 [==============================] - 523s 2s/step - loss: 0.1022 - accuracy: 0.9665 - val_loss: 0.6304 - val_accuracy: 0.8048\n",
      "Epoch 135/200\n",
      "222/222 [==============================] - 564s 3s/step - loss: 0.1073 - accuracy: 0.9663 - val_loss: 0.6493 - val_accuracy: 0.8022\n",
      "Epoch 136/200\n",
      "222/222 [==============================] - 559s 3s/step - loss: 0.1092 - accuracy: 0.9637 - val_loss: 0.6725 - val_accuracy: 0.8014\n",
      "Epoch 137/200\n",
      "222/222 [==============================] - 512s 2s/step - loss: 0.1048 - accuracy: 0.9654 - val_loss: 0.5877 - val_accuracy: 0.8022\n",
      "Epoch 138/200\n",
      "222/222 [==============================] - 517s 2s/step - loss: 0.0977 - accuracy: 0.9674 - val_loss: 0.7385 - val_accuracy: 0.7902\n",
      "Epoch 139/200\n",
      "222/222 [==============================] - 515s 2s/step - loss: 0.1058 - accuracy: 0.9643 - val_loss: 0.6328 - val_accuracy: 0.7986\n",
      "Epoch 140/200\n",
      "222/222 [==============================] - 528s 2s/step - loss: 0.1058 - accuracy: 0.9653 - val_loss: 0.7111 - val_accuracy: 0.7916\n",
      "Epoch 141/200\n",
      "222/222 [==============================] - 512s 2s/step - loss: 0.1058 - accuracy: 0.9657 - val_loss: 0.6939 - val_accuracy: 0.7960\n",
      "Epoch 142/200\n",
      "222/222 [==============================] - 508s 2s/step - loss: 0.1070 - accuracy: 0.9638 - val_loss: 0.6388 - val_accuracy: 0.8025\n",
      "Epoch 143/200\n",
      "222/222 [==============================] - 514s 2s/step - loss: 0.0988 - accuracy: 0.9681 - val_loss: 0.6376 - val_accuracy: 0.7944\n",
      "Epoch 144/200\n",
      "222/222 [==============================] - 503s 2s/step - loss: 0.1048 - accuracy: 0.9649 - val_loss: 0.6744 - val_accuracy: 0.7974\n",
      "Epoch 145/200\n",
      "222/222 [==============================] - 518s 2s/step - loss: 0.1042 - accuracy: 0.9653 - val_loss: 0.6141 - val_accuracy: 0.8107\n",
      "Epoch 146/200\n",
      "222/222 [==============================] - 525s 2s/step - loss: 0.1049 - accuracy: 0.9646 - val_loss: 0.6121 - val_accuracy: 0.8077\n",
      "Epoch 147/200\n",
      "222/222 [==============================] - 693s 3s/step - loss: 0.0954 - accuracy: 0.9693 - val_loss: 0.6463 - val_accuracy: 0.8038\n",
      "Epoch 148/200\n",
      "222/222 [==============================] - 909s 4s/step - loss: 0.1023 - accuracy: 0.9666 - val_loss: 0.6365 - val_accuracy: 0.7950\n",
      "Epoch 149/200\n",
      "222/222 [==============================] - 921s 4s/step - loss: 0.1060 - accuracy: 0.9648 - val_loss: 0.6680 - val_accuracy: 0.8056\n",
      "Epoch 150/200\n",
      "222/222 [==============================] - 1036s 5s/step - loss: 0.0991 - accuracy: 0.9667 - val_loss: 0.6265 - val_accuracy: 0.8017\n",
      "Epoch 151/200\n",
      "222/222 [==============================] - 1032s 5s/step - loss: 0.1049 - accuracy: 0.9623 - val_loss: 0.6963 - val_accuracy: 0.7983\n",
      "Epoch 152/200\n",
      "222/222 [==============================] - 1000s 5s/step - loss: 0.0934 - accuracy: 0.9702 - val_loss: 0.6769 - val_accuracy: 0.8003\n",
      "Epoch 153/200\n",
      "222/222 [==============================] - 526s 2s/step - loss: 0.0988 - accuracy: 0.9673 - val_loss: 0.6885 - val_accuracy: 0.8036\n",
      "Epoch 154/200\n",
      "222/222 [==============================] - 496s 2s/step - loss: 0.0916 - accuracy: 0.9705 - val_loss: 0.6750 - val_accuracy: 0.8074\n",
      "Epoch 155/200\n",
      "222/222 [==============================] - 490s 2s/step - loss: 0.0909 - accuracy: 0.9699 - val_loss: 0.6664 - val_accuracy: 0.7987\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 485s 2s/step - loss: 0.0979 - accuracy: 0.9683 - val_loss: 0.6910 - val_accuracy: 0.8021\n",
      "Epoch 157/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.0897 - accuracy: 0.9698 - val_loss: 0.6877 - val_accuracy: 0.7986\n",
      "Epoch 158/200\n",
      "222/222 [==============================] - 505s 2s/step - loss: 0.0928 - accuracy: 0.9695 - val_loss: 0.6602 - val_accuracy: 0.7994\n",
      "Epoch 159/200\n",
      "222/222 [==============================] - 510s 2s/step - loss: 0.0878 - accuracy: 0.9720 - val_loss: 0.7205 - val_accuracy: 0.7992\n",
      "Epoch 160/200\n",
      "222/222 [==============================] - 504s 2s/step - loss: 0.0946 - accuracy: 0.9693 - val_loss: 0.6610 - val_accuracy: 0.8026\n",
      "Epoch 161/200\n",
      "222/222 [==============================] - 500s 2s/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 0.6487 - val_accuracy: 0.8040\n",
      "Epoch 162/200\n",
      "222/222 [==============================] - 543s 2s/step - loss: 0.0921 - accuracy: 0.9711 - val_loss: 0.7055 - val_accuracy: 0.7998\n",
      "Epoch 163/200\n",
      "222/222 [==============================] - 517s 2s/step - loss: 0.0884 - accuracy: 0.9705 - val_loss: 0.7107 - val_accuracy: 0.7957\n",
      "Epoch 164/200\n",
      "222/222 [==============================] - 588s 3s/step - loss: 0.0942 - accuracy: 0.9697 - val_loss: 0.7131 - val_accuracy: 0.7996\n",
      "Epoch 165/200\n",
      "222/222 [==============================] - 991s 4s/step - loss: 0.0841 - accuracy: 0.9737 - val_loss: 0.7369 - val_accuracy: 0.7918\n",
      "Epoch 166/200\n",
      "222/222 [==============================] - 1012s 5s/step - loss: 0.0838 - accuracy: 0.9751 - val_loss: 0.6918 - val_accuracy: 0.7983\n",
      "Epoch 167/200\n",
      "222/222 [==============================] - 1002s 5s/step - loss: 0.0927 - accuracy: 0.9707 - val_loss: 0.6860 - val_accuracy: 0.8037\n",
      "Epoch 168/200\n",
      "222/222 [==============================] - 1066s 5s/step - loss: 0.0838 - accuracy: 0.9739 - val_loss: 0.6901 - val_accuracy: 0.8021\n",
      "Epoch 169/200\n",
      "222/222 [==============================] - 869s 4s/step - loss: 0.0945 - accuracy: 0.9691 - val_loss: 0.6463 - val_accuracy: 0.8080\n",
      "Epoch 170/200\n",
      "222/222 [==============================] - 796s 4s/step - loss: 0.0837 - accuracy: 0.9724 - val_loss: 0.7399 - val_accuracy: 0.8054\n",
      "Epoch 171/200\n",
      "222/222 [==============================] - 1119s 5s/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 0.6311 - val_accuracy: 0.8068\n",
      "Epoch 172/200\n",
      "222/222 [==============================] - 1050s 5s/step - loss: 0.0848 - accuracy: 0.9728 - val_loss: 0.6979 - val_accuracy: 0.8036\n",
      "Epoch 173/200\n",
      "222/222 [==============================] - 1161s 5s/step - loss: 0.0884 - accuracy: 0.9711 - val_loss: 0.7072 - val_accuracy: 0.8034\n",
      "Epoch 174/200\n",
      "222/222 [==============================] - 972s 4s/step - loss: 0.0834 - accuracy: 0.9748 - val_loss: 0.7182 - val_accuracy: 0.7971\n",
      "Epoch 175/200\n",
      "222/222 [==============================] - 573s 3s/step - loss: 0.0805 - accuracy: 0.9751 - val_loss: 0.7073 - val_accuracy: 0.7996\n",
      "Epoch 176/200\n",
      "222/222 [==============================] - 569s 3s/step - loss: 0.0852 - accuracy: 0.9720 - val_loss: 0.6896 - val_accuracy: 0.7998\n",
      "Epoch 177/200\n",
      "222/222 [==============================] - 493s 2s/step - loss: 0.0788 - accuracy: 0.9753 - val_loss: 0.8532 - val_accuracy: 0.7857\n",
      "Epoch 178/200\n",
      "222/222 [==============================] - 518s 2s/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 0.6974 - val_accuracy: 0.8024\n",
      "Epoch 179/200\n",
      "222/222 [==============================] - 502s 2s/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.7373 - val_accuracy: 0.7996\n",
      "Epoch 180/200\n",
      "222/222 [==============================] - 499s 2s/step - loss: 0.0850 - accuracy: 0.9725 - val_loss: 0.7468 - val_accuracy: 0.7984\n",
      "Epoch 181/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.0854 - accuracy: 0.9715 - val_loss: 0.6706 - val_accuracy: 0.8030\n",
      "Epoch 182/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.7290 - val_accuracy: 0.7910\n",
      "Epoch 183/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0796 - accuracy: 0.9749 - val_loss: 0.6967 - val_accuracy: 0.8012\n",
      "Epoch 184/200\n",
      "222/222 [==============================] - 487s 2s/step - loss: 0.0864 - accuracy: 0.9712 - val_loss: 0.7201 - val_accuracy: 0.7993\n",
      "Epoch 185/200\n",
      "222/222 [==============================] - 488s 2s/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 0.6932 - val_accuracy: 0.8007\n",
      "Epoch 186/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0892 - accuracy: 0.9716 - val_loss: 0.6913 - val_accuracy: 0.8034\n",
      "Epoch 187/200\n",
      "222/222 [==============================] - 483s 2s/step - loss: 0.0851 - accuracy: 0.9726 - val_loss: 0.7223 - val_accuracy: 0.7997\n",
      "Epoch 188/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.6588 - val_accuracy: 0.8029\n",
      "Epoch 189/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.0850 - accuracy: 0.9699 - val_loss: 0.7319 - val_accuracy: 0.8000\n",
      "Epoch 190/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0770 - accuracy: 0.9752 - val_loss: 0.6975 - val_accuracy: 0.8034\n",
      "Epoch 191/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0809 - accuracy: 0.9734 - val_loss: 0.6688 - val_accuracy: 0.8126\n",
      "Epoch 192/200\n",
      "222/222 [==============================] - 487s 2s/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.6618 - val_accuracy: 0.8068\n",
      "Epoch 193/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.0857 - accuracy: 0.9731 - val_loss: 0.7338 - val_accuracy: 0.8036\n",
      "Epoch 194/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.0748 - accuracy: 0.9761 - val_loss: 0.7067 - val_accuracy: 0.8089\n",
      "Epoch 195/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.0772 - accuracy: 0.9766 - val_loss: 0.7037 - val_accuracy: 0.8108\n",
      "Epoch 196/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.0834 - accuracy: 0.9729 - val_loss: 0.6828 - val_accuracy: 0.8042\n",
      "Epoch 197/200\n",
      "222/222 [==============================] - 486s 2s/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.7135 - val_accuracy: 0.8097\n",
      "Epoch 198/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.7224 - val_accuracy: 0.8058\n",
      "Epoch 199/200\n",
      "222/222 [==============================] - 484s 2s/step - loss: 0.0750 - accuracy: 0.9766 - val_loss: 0.7144 - val_accuracy: 0.8104\n",
      "Epoch 200/200\n",
      "222/222 [==============================] - 485s 2s/step - loss: 0.0727 - accuracy: 0.9782 - val_loss: 0.6789 - val_accuracy: 0.8131\n",
      "Fold 1, 200 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 81.31%\n",
      "\n",
      "Validation core mean 81.31% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model1=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 1K-2Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [1000 - 2000)\n",
      "original (30290, 4)\n",
      "no short (9273, 4)\n",
      "no long, no short (3368, 4)\n",
      "Sequence to Kmer\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3368, 1)\n",
      "sequence    GGCGGGGTCGACTGACGGTAACGGGGCAGAGAGGCTGTTCGCAGAG...\n",
      "Name: 12641, dtype: object\n",
      "1338\n",
      "transform...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[667 619 427 ...   0   0   0]\n",
      " [901 532  79 ...   0   0   0]\n",
      " [431 698 742 ...   0   0   0]\n",
      " ...\n",
      " [697 737 898 ...   0   0   0]\n",
      " [148 590 309 ...   0   0   0]\n",
      " [752 960 768 ...   0   0   0]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 16)          16400     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 2000, 64)          9600      \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 2000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 2000, 64)          18816     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2000, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 66,801\n",
      "Trainable params: 66,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/200\n",
      "85/85 [==============================] - 431s 5s/step - loss: 0.6628 - accuracy: 0.6223 - val_loss: 0.6747 - val_accuracy: 0.6121\n",
      "Epoch 2/200\n",
      "85/85 [==============================] - 408s 5s/step - loss: 0.6393 - accuracy: 0.6291 - val_loss: 0.6956 - val_accuracy: 0.4177\n",
      "Epoch 3/200\n",
      "85/85 [==============================] - 397s 5s/step - loss: 0.6653 - accuracy: 0.6215 - val_loss: 0.6656 - val_accuracy: 0.6170\n",
      "Epoch 4/200\n",
      "85/85 [==============================] - 396s 5s/step - loss: 0.6450 - accuracy: 0.6271 - val_loss: 0.7380 - val_accuracy: 0.6039\n",
      "Epoch 5/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6654 - accuracy: 0.6264 - val_loss: 0.6721 - val_accuracy: 0.6046\n",
      "Epoch 6/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6615 - accuracy: 0.6297 - val_loss: 0.6725 - val_accuracy: 0.6038\n",
      "Epoch 7/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6558 - accuracy: 0.6388 - val_loss: 0.6668 - val_accuracy: 0.6180\n",
      "Epoch 8/200\n",
      "85/85 [==============================] - 390s 5s/step - loss: 0.6627 - accuracy: 0.6248 - val_loss: 0.6704 - val_accuracy: 0.6060\n",
      "Epoch 9/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6619 - accuracy: 0.6265 - val_loss: 0.6672 - val_accuracy: 0.6134\n",
      "Epoch 10/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6513 - accuracy: 0.6420 - val_loss: 0.6727 - val_accuracy: 0.6040\n",
      "Epoch 11/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6629 - accuracy: 0.6228 - val_loss: 0.6713 - val_accuracy: 0.6041\n",
      "Epoch 12/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6623 - accuracy: 0.6238 - val_loss: 0.6705 - val_accuracy: 0.6065\n",
      "Epoch 13/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6428 - accuracy: 0.6561 - val_loss: 0.5987 - val_accuracy: 0.7109\n",
      "Epoch 14/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6338 - accuracy: 0.6648 - val_loss: 0.6156 - val_accuracy: 0.6956\n",
      "Epoch 15/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6446 - accuracy: 0.6553 - val_loss: 0.6809 - val_accuracy: 0.6104\n",
      "Epoch 16/200\n",
      "85/85 [==============================] - 385s 5s/step - loss: 0.6422 - accuracy: 0.6547 - val_loss: 0.6706 - val_accuracy: 0.6053\n",
      "Epoch 17/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6395 - accuracy: 0.6580 - val_loss: 0.6695 - val_accuracy: 0.6113\n",
      "Epoch 18/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6437 - accuracy: 0.6480 - val_loss: 0.6658 - val_accuracy: 0.6097\n",
      "Epoch 19/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6377 - accuracy: 0.6592 - val_loss: 0.6680 - val_accuracy: 0.6142\n",
      "Epoch 20/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6377 - accuracy: 0.6599 - val_loss: 0.6688 - val_accuracy: 0.6126\n",
      "Epoch 21/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6350 - accuracy: 0.6681 - val_loss: 0.6600 - val_accuracy: 0.6289\n",
      "Epoch 22/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6376 - accuracy: 0.6607 - val_loss: 0.6704 - val_accuracy: 0.6172\n",
      "Epoch 23/200\n",
      "85/85 [==============================] - 385s 5s/step - loss: 0.6389 - accuracy: 0.6659 - val_loss: 0.6699 - val_accuracy: 0.6187\n",
      "Epoch 24/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6388 - accuracy: 0.6612 - val_loss: 0.6688 - val_accuracy: 0.6217\n",
      "Epoch 25/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6393 - accuracy: 0.6605 - val_loss: 0.6779 - val_accuracy: 0.6083\n",
      "Epoch 26/200\n",
      "85/85 [==============================] - 385s 5s/step - loss: 0.6586 - accuracy: 0.6308 - val_loss: 0.6706 - val_accuracy: 0.6083\n",
      "Epoch 27/200\n",
      "85/85 [==============================] - 390s 5s/step - loss: 0.6508 - accuracy: 0.6400 - val_loss: 0.6745 - val_accuracy: 0.6128\n",
      "Epoch 28/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6531 - accuracy: 0.6385 - val_loss: 0.6696 - val_accuracy: 0.6113\n",
      "Epoch 29/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6517 - accuracy: 0.6410 - val_loss: 0.6675 - val_accuracy: 0.6172\n",
      "Epoch 30/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6493 - accuracy: 0.6440 - val_loss: 0.6714 - val_accuracy: 0.6157\n",
      "Epoch 31/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6465 - accuracy: 0.6469 - val_loss: 0.6690 - val_accuracy: 0.6187\n",
      "Epoch 32/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6389 - accuracy: 0.6542 - val_loss: 0.6719 - val_accuracy: 0.6172\n",
      "Epoch 33/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6417 - accuracy: 0.6528 - val_loss: 0.6729 - val_accuracy: 0.6172\n",
      "Epoch 34/200\n",
      "85/85 [==============================] - 385s 5s/step - loss: 0.6417 - accuracy: 0.6523 - val_loss: 0.6696 - val_accuracy: 0.6172\n",
      "Epoch 35/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6414 - accuracy: 0.6518 - val_loss: 0.6712 - val_accuracy: 0.6172\n",
      "Epoch 36/200\n",
      "85/85 [==============================] - 391s 5s/step - loss: 0.6416 - accuracy: 0.6514 - val_loss: 0.6757 - val_accuracy: 0.6172\n",
      "Epoch 37/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6636 - accuracy: 0.6236 - val_loss: 0.6720 - val_accuracy: 0.6039\n",
      "Epoch 38/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6709 - accuracy: 0.6157 - val_loss: 0.6757 - val_accuracy: 0.6039\n",
      "Epoch 39/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6634 - accuracy: 0.6221 - val_loss: 0.6748 - val_accuracy: 0.6039\n",
      "Epoch 40/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6642 - accuracy: 0.6221 - val_loss: 0.6730 - val_accuracy: 0.6039\n",
      "Epoch 41/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6635 - accuracy: 0.6221 - val_loss: 0.6724 - val_accuracy: 0.6039\n",
      "Epoch 42/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6636 - accuracy: 0.6221 - val_loss: 0.6719 - val_accuracy: 0.6039\n",
      "Epoch 43/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6640 - accuracy: 0.6221 - val_loss: 0.6720 - val_accuracy: 0.6039\n",
      "Epoch 44/200\n",
      "85/85 [==============================] - 386s 5s/step - loss: 0.6636 - accuracy: 0.6221 - val_loss: 0.6714 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6638 - accuracy: 0.6221 - val_loss: 0.6723 - val_accuracy: 0.6039\n",
      "Epoch 46/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6638 - accuracy: 0.6221 - val_loss: 0.6743 - val_accuracy: 0.6039\n",
      "Epoch 47/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6638 - accuracy: 0.6221 - val_loss: 0.6715 - val_accuracy: 0.6039\n",
      "Epoch 48/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6634 - accuracy: 0.6221 - val_loss: 0.6720 - val_accuracy: 0.6039\n",
      "Epoch 49/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6635 - accuracy: 0.6221 - val_loss: 0.6732 - val_accuracy: 0.6039\n",
      "Epoch 50/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6638 - accuracy: 0.6221 - val_loss: 0.6714 - val_accuracy: 0.6039\n",
      "Epoch 51/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6637 - accuracy: 0.6221 - val_loss: 0.6719 - val_accuracy: 0.6039\n",
      "Epoch 52/200\n",
      "85/85 [==============================] - 388s 5s/step - loss: 0.6637 - accuracy: 0.6221 - val_loss: 0.6714 - val_accuracy: 0.6039\n",
      "Epoch 53/200\n",
      "85/85 [==============================] - 387s 5s/step - loss: 0.6638 - accuracy: 0.6221 - val_loss: 0.6728 - val_accuracy: 0.6039\n",
      "Epoch 54/200\n",
      "85/85 [==============================] - 389s 5s/step - loss: 0.6639 - accuracy: 0.6221 - val_loss: 0.6715 - val_accuracy: 0.6039\n",
      "Epoch 55/200\n",
      "85/85 [==============================] - 395s 5s/step - loss: 0.6643 - accuracy: 0.6221 - val_loss: 0.6721 - val_accuracy: 0.6039\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-19a7aef3762d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print this only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross valiation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAXLEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBED_DIMEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-51edad3141b6>\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, eps, maxlen, dimen)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FIT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# this is complaining about string to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# verbose=1 for ascii art, verbose=0 for none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 validation_data=(X_valid,y_valid) )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MINLEN=1000\n",
    "MAXLEN=2000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model2=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Len 2K-3Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINLEN=2000\n",
    "MAXLEN=3000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model3=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('EMB35.Short.model')\n",
    "model2.save('EMB35.Medium.model')\n",
    "model3.save('EMB35.Long.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('EMB35.Short.model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
