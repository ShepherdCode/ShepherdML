{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation using Quadratic Distriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.metrics import zero_one_loss, confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daily_2060_S3.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathR='data/ChunkedData_R/'\n",
    "pathN='data/ChunkedData_NR/'\n",
    "filesR = listdir(pathR)\n",
    "filesN = listdir(pathN)\n",
    "filesR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one CSV file. Drop the date column.\n",
    "def file_mean (filepath):\n",
    "    mydata = pd.read_csv(filepath)\n",
    "    # Drop the date column.\n",
    "    mydata = mydata.drop('Date',axis=1) \n",
    "    # Transpose column of mean values into a row.\n",
    "    mymean = mydata.mean(axis=0).to_frame().T\n",
    "    return mymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directory of CSV files. Retain only one row per file = column averages.\n",
    "def mean_per_file (directory):\n",
    "    files = listdir(directory)\n",
    "    means = pd.DataFrame()\n",
    "    for fp in files:\n",
    "        dfp = directory+fp\n",
    "        m = file_mean(dfp)\n",
    "        # Let Pandas number the rows sequentially.\n",
    "        means = means.append(m,ignore_index=True)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansR = mean_per_file(pathR)\n",
    "meansN = mean_per_file(pathN)\n",
    "meansAll = pd.concat((meansR,meansN),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(positives,negatives):\n",
    "    rows = positives.shape[0]\n",
    "    labelsP = pd.DataFrame(np.ones(rows,dtype=np.int8))  # one = positive = blue\n",
    "    rows = negatives.shape[0]\n",
    "    labelsN = pd.DataFrame(np.zeros(rows,dtype=np.int8))  # zero = negative = red\n",
    "    labelsAll = pd.concat((labelsP,labelsN),ignore_index=True)\n",
    "    return labelsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAll = make_labels(meansR,meansN)\n",
    "print(labelsAll.shape)\n",
    "#print(labelsAll.T)\n",
    "y1d = labelsAll.values.ravel() # required for sklearn models\n",
    "y1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_question_features(X,scale=True):\n",
    "    c = X.columns[:13] # Excel columns B-N\n",
    "    z = X[c]\n",
    "    if scale:\n",
    "        s = StandardScaler()\n",
    "        z = s.fit_transform(z)\n",
    "    return z\n",
    "def make_physiol_features(X,scale=True):\n",
    "    c = X.columns[249:] # Excel columns IQ-IZ\n",
    "    z = X[c]\n",
    "    if scale:\n",
    "        s = StandardScaler()\n",
    "        z = s.fit_transform(z)\n",
    "    return z\n",
    "def make_all_features(X,scale=True):\n",
    "    c = X.columns \n",
    "    z = X[c]\n",
    "    if scale:\n",
    "        s = StandardScaler()\n",
    "        z = s.fit_transform(z)\n",
    "    return z\n",
    "X_questionFeatures = make_question_features(meansAll)\n",
    "X_physiolFeatures = make_physiol_features(meansAll)\n",
    "X_allFeatures = make_all_features(meansAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_val(model,splits,X,y,verbose=False):\n",
    "    skf = StratifiedKFold(n_splits=splits, random_state=456, shuffle=True)\n",
    "    confusion = np.zeros(shape=[2,2],dtype=np.int8)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train,y_train = X[train_index],y[train_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        X_test,y_test = X[test_index],y[test_index]\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Labels attribute says generate all 4 counts even if none of any category.\n",
    "        # https://stackoverflow.com/questions/46229965/how-to-make-sklearn-metrics-confusion-matrix-to-always-return-tp-tn-fp-fn\n",
    "        cf = confusion_matrix(y_test,y_pred,labels=[0,1])\n",
    "        confusion = np.add(confusion,cf)\n",
    "        if verbose:\n",
    "            ba = balanced_accuracy_score(y_test,y_pred)\n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            # unintuitive order but from documentation\n",
    "            tn, fp, fn, tp = cf.ravel() \n",
    "            print(\" Array indices. Train:\",train_index, \" Test:\",test_index)\n",
    "            print(\"  y_test=\",y_test,\" y_pred=\",y_pred)\n",
    "            print(\"  acc=%.2f ba=%.2f tp=%d fp=%d fn=%d tn=%d\"%(acc,ba,tp,fp,fn,tn))\n",
    "    return confusion\n",
    "def print_confusion(label1,cm1,label2,cm2):\n",
    "    tn, fp, fn, tp = cm1.ravel()\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    tpr = tp / (tp+fn)\n",
    "    tnr = tn / (tn+fp)\n",
    "    bal = (tpr+tnr)/2\n",
    "    f1 = (2*tp)/(2*tp+fp+fn)\n",
    "    TL=' tp fp | %2d %2d | acc=%.2f'%(tp,fp,acc)\n",
    "    BL=' fn tn | %2d %2d | bal=%.2f'%(fn,tn,bal)\n",
    "    tn, fp, fn, tp = cm2.ravel()\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    tpr = tp / (tp+fn)\n",
    "    tnr = tn / (tn+fp)\n",
    "    bal = (tpr+tnr)/2\n",
    "    f1 = (2*tp)/(2*tp+fp+fn)\n",
    "    TR=' tp fp | %2d %2d | acc=%.2f'%(tp,fp,acc)\n",
    "    BR=' fn tn | %2d %2d | bal=%.2f'%(fn,tn,bal)\n",
    "    print(\"%-30s %-30s\"%(label1,label2))\n",
    "    print(\"%-30s %-30s\"%(TL,TR))\n",
    "    print(\"%-30s %-30s\"%(BL,BR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose validation run\n",
      " Array indices. Train: [ 0  2  3  5  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 25 26 27 28\n",
      " 30 31 33 34 35 36 37 38]  Test: [ 1  4  6 16 24 29 32 39]\n",
      "  y_test= [1 1 1 0 0 0 0 0]  y_pred= [1 1 1 0 0 0 0 0]\n",
      "  acc=1.00 ba=1.00 tp=3 fp=0 fn=0 tn=5\n",
      " Array indices. Train: [ 0  1  2  3  4  6  7  8 10 11 13 14 15 16 17 18 20 21 23 24 25 26 27 29\n",
      " 31 32 34 35 36 37 38 39]  Test: [ 5  9 12 19 22 28 30 33]\n",
      "  y_test= [1 1 1 0 0 0 0 0]  y_pred= [0 1 1 0 0 0 0 0]\n",
      "  acc=0.88 ba=0.83 tp=2 fp=0 fn=1 tn=5\n",
      " Array indices. Train: [ 1  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 21 22 23 24 25 26 28 29\n",
      " 30 31 32 33 35 36 37 39]  Test: [ 0  2  3 18 20 27 34 38]\n",
      "  y_test= [1 1 1 0 0 0 0 0]  y_pred= [1 0 1 1 0 0 0 0]\n",
      "  acc=0.75 ba=0.73 tp=2 fp=1 fn=1 tn=4\n",
      " Array indices. Train: [ 0  1  2  3  4  5  6  8  9 11 12 14 15 16 18 19 20 22 24 25 27 28 29 30\n",
      " 32 33 34 35 36 37 38 39]  Test: [ 7 10 13 17 21 23 26 31]\n",
      "  y_test= [1 1 1 0 0 0 0 0]  y_pred= [1 0 0 0 1 1 0 0]\n",
      "  acc=0.50 ba=0.47 tp=1 fp=2 fn=2 tn=3\n",
      " Array indices. Train: [ 0  1  2  3  4  5  6  7  9 10 12 13 16 17 18 19 20 21 22 23 24 26 27 28\n",
      " 29 30 31 32 33 34 38 39]  Test: [ 8 11 14 15 25 35 36 37]\n",
      "  y_test= [1 1 0 0 0 0 0 0]  y_pred= [1 1 0 0 0 0 0 0]\n",
      "  acc=1.00 ba=1.00 tp=2 fp=0 fn=0 tn=6\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return LinearDiscriminantAnalysis(solver='lsqr')\n",
    "print(\"Verbose validation run\")\n",
    "confusion = do_cross_val(get_model(),5,X_questionFeatures, y1d, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis with 5-fold Cross Validation\n",
      "QuestionFeatures               PhysiolFeatures               \n",
      " tp fp | 10  3 | acc=0.82       tp fp |  9  6 | acc=0.72     \n",
      " fn tn |  4 23 | bal=0.80       fn tn |  5 20 | bal=0.71     \n",
      "Linear Discriminant Analysis with 10-fold Cross Validation\n",
      "QuestionFeatures               PhysiolFeatures               \n",
      " tp fp |  9  4 | acc=0.78       tp fp |  9  5 | acc=0.75     \n",
      " fn tn |  5 22 | bal=0.74       fn tn |  5 21 | bal=0.73     \n",
      "Linear Discriminant Analysis with 20-fold Cross Validation\n",
      "QuestionFeatures               PhysiolFeatures               \n",
      " tp fp | 11  3 | acc=0.85       tp fp |  9  7 | acc=0.70     \n",
      " fn tn |  3 23 | bal=0.84       fn tn |  5 19 | bal=0.69     \n",
      "Linear Discriminant Analysis with All Features\n",
      "5-fold CV                      10-fold CV                    \n",
      " tp fp |  8 16 | acc=0.45       tp fp |  5 12 | acc=0.47     \n",
      " fn tn |  6 10 | bal=0.48       fn tn |  9 14 | bal=0.45     \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# Supress sklearn warnings that test set has zero instances of one category.\n",
    "\n",
    "print(\"Linear Discriminant Analysis with 5-fold Cross Validation\")\n",
    "confusionQ=do_cross_val(get_model(),5,X_questionFeatures, y1d)\n",
    "confusionP=do_cross_val(get_model(),5,X_physiolFeatures, y1d)\n",
    "print_confusion(\"QuestionFeatures\",confusionQ,\"PhysiolFeatures\",confusionP)\n",
    "\n",
    "print(\"Linear Discriminant Analysis with 10-fold Cross Validation\")\n",
    "confusionQ=do_cross_val(get_model(),10,X_questionFeatures, y1d)\n",
    "confusionP=do_cross_val(get_model(),10,X_physiolFeatures, y1d)\n",
    "print_confusion(\"QuestionFeatures\",confusionQ,\"PhysiolFeatures\",confusionP)\n",
    "\n",
    "print(\"Linear Discriminant Analysis with 20-fold Cross Validation\")\n",
    "confusionQ=do_cross_val(get_model(),20,X_questionFeatures, y1d)\n",
    "confusionP=do_cross_val(get_model(),20,X_physiolFeatures, y1d)\n",
    "print_confusion(\"QuestionFeatures\",confusionQ,\"PhysiolFeatures\",confusionP)\n",
    "\n",
    "print(\"Linear Discriminant Analysis with All Features\")\n",
    "confusion5=do_cross_val(get_model(),5,X_allFeatures, y1d)\n",
    "confusion10=do_cross_val(get_model(),10,X_allFeatures, y1d)\n",
    "print_confusion(\"5-fold CV\",confusion5,\"10-fold CV\",confusion10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
