{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Data\n",
    "HW #2 Part 1 - Dimensionality Reduction.  \n",
    "Use one summary vector per patient, specifically the monthly average per patient.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Patient files are in one of two directories: R or NR.  \n",
    "Each patient is represented by one CSV file.  \n",
    "Each row of each CSV contains readings from one day.    \n",
    "Here, we load each patient average across all days.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  files of type R\n",
      "26  files of type N\n"
     ]
    }
   ],
   "source": [
    "pathR='data/ChunkedData_R/'\n",
    "pathN='data/ChunkedData_NR/'\n",
    "filesR = listdir(pathR)\n",
    "filesN = listdir(pathN)\n",
    "print(len(filesR),\" files of type R\")\n",
    "print(len(filesN),\" files of type N\")\n",
    "CLASS_SEPARATOR=13  # data[:13] vs data[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one CSV file. \n",
    "# Create a Pandas data frame.\n",
    "# Drop the date column.\n",
    "def file_mean (filepath):\n",
    "    mydata = pd.read_csv(filepath)\n",
    "    # Drop the date column.\n",
    "    mydata = mydata.drop('Date',axis=1) \n",
    "    # Transpose column of mean values into a row.\n",
    "    mymean = mydata.mean(axis=0).to_frame().T\n",
    "    return mymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directory of CSV files (R or NR). \n",
    "# Create one dataframe representing all files.\n",
    "# Retain only one row per file = column averages.\n",
    "def mean_per_file (directory):\n",
    "    files = listdir(directory)\n",
    "    means = pd.DataFrame()\n",
    "    for fp in files:\n",
    "        dfp = directory+fp\n",
    "        m = file_mean(dfp)\n",
    "        # Let Pandas number the rows sequentially.\n",
    "        means = means.append(m,ignore_index=True)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morning_Question1</th>\n",
       "      <th>Morning_Question2</th>\n",
       "      <th>Morning_Question3</th>\n",
       "      <th>Morning_Question4</th>\n",
       "      <th>Morning_Question5</th>\n",
       "      <th>Morning_Question6</th>\n",
       "      <th>Afternoon_Question1</th>\n",
       "      <th>Afternoon_Question2</th>\n",
       "      <th>Afternoon_Question3</th>\n",
       "      <th>Afternoon_Question4</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_var</th>\n",
       "      <th>HR_std</th>\n",
       "      <th>HR_sk</th>\n",
       "      <th>HR_ku</th>\n",
       "      <th>Stress_mean</th>\n",
       "      <th>Stress_var</th>\n",
       "      <th>Stress_std</th>\n",
       "      <th>Stress_sk</th>\n",
       "      <th>Stress_ku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.771630</td>\n",
       "      <td>2.704766</td>\n",
       "      <td>3.684239</td>\n",
       "      <td>3.427975</td>\n",
       "      <td>2.393328</td>\n",
       "      <td>4.368998</td>\n",
       "      <td>3.686286</td>\n",
       "      <td>3.513472</td>\n",
       "      <td>2.736801</td>\n",
       "      <td>2.429426</td>\n",
       "      <td>...</td>\n",
       "      <td>79.327247</td>\n",
       "      <td>168.022421</td>\n",
       "      <td>12.358672</td>\n",
       "      <td>0.787483</td>\n",
       "      <td>0.662993</td>\n",
       "      <td>30.629987</td>\n",
       "      <td>449.669255</td>\n",
       "      <td>20.457643</td>\n",
       "      <td>0.917550</td>\n",
       "      <td>0.612431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.339235</td>\n",
       "      <td>1.115521</td>\n",
       "      <td>1.206275</td>\n",
       "      <td>1.113369</td>\n",
       "      <td>0.893719</td>\n",
       "      <td>0.702195</td>\n",
       "      <td>1.221645</td>\n",
       "      <td>1.272435</td>\n",
       "      <td>1.147496</td>\n",
       "      <td>1.152266</td>\n",
       "      <td>...</td>\n",
       "      <td>3.769125</td>\n",
       "      <td>61.278871</td>\n",
       "      <td>2.289319</td>\n",
       "      <td>0.272895</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>4.683535</td>\n",
       "      <td>105.003775</td>\n",
       "      <td>2.483785</td>\n",
       "      <td>0.268648</td>\n",
       "      <td>0.824843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>74.539412</td>\n",
       "      <td>85.912121</td>\n",
       "      <td>9.195755</td>\n",
       "      <td>0.280961</td>\n",
       "      <td>-0.283663</td>\n",
       "      <td>23.014433</td>\n",
       "      <td>264.873317</td>\n",
       "      <td>15.284160</td>\n",
       "      <td>0.290027</td>\n",
       "      <td>-0.820974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.956981</td>\n",
       "      <td>2.169643</td>\n",
       "      <td>3.302760</td>\n",
       "      <td>2.539577</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>3.958128</td>\n",
       "      <td>2.908279</td>\n",
       "      <td>3.087662</td>\n",
       "      <td>1.551724</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>...</td>\n",
       "      <td>77.465143</td>\n",
       "      <td>104.751713</td>\n",
       "      <td>9.907677</td>\n",
       "      <td>0.591312</td>\n",
       "      <td>0.244217</td>\n",
       "      <td>28.117668</td>\n",
       "      <td>386.597363</td>\n",
       "      <td>18.933233</td>\n",
       "      <td>0.804227</td>\n",
       "      <td>0.240722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.857759</td>\n",
       "      <td>2.393939</td>\n",
       "      <td>3.928480</td>\n",
       "      <td>3.847222</td>\n",
       "      <td>2.064394</td>\n",
       "      <td>4.403941</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.772727</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>78.904839</td>\n",
       "      <td>172.698871</td>\n",
       "      <td>12.686409</td>\n",
       "      <td>0.808753</td>\n",
       "      <td>0.448019</td>\n",
       "      <td>29.403302</td>\n",
       "      <td>442.825365</td>\n",
       "      <td>20.723560</td>\n",
       "      <td>0.986197</td>\n",
       "      <td>0.782005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.435737</td>\n",
       "      <td>3.758621</td>\n",
       "      <td>4.419540</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.423701</td>\n",
       "      <td>4.979167</td>\n",
       "      <td>4.713362</td>\n",
       "      <td>4.326149</td>\n",
       "      <td>3.772727</td>\n",
       "      <td>3.607955</td>\n",
       "      <td>...</td>\n",
       "      <td>79.905215</td>\n",
       "      <td>214.698339</td>\n",
       "      <td>14.061540</td>\n",
       "      <td>1.040887</td>\n",
       "      <td>1.121867</td>\n",
       "      <td>32.695160</td>\n",
       "      <td>533.173782</td>\n",
       "      <td>22.052479</td>\n",
       "      <td>1.072589</td>\n",
       "      <td>0.855014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.448276</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.035714</td>\n",
       "      <td>3.962963</td>\n",
       "      <td>...</td>\n",
       "      <td>89.492347</td>\n",
       "      <td>258.342542</td>\n",
       "      <td>15.626514</td>\n",
       "      <td>1.102250</td>\n",
       "      <td>2.221792</td>\n",
       "      <td>39.126304</td>\n",
       "      <td>616.333657</td>\n",
       "      <td>24.128994</td>\n",
       "      <td>1.329738</td>\n",
       "      <td>2.395604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Morning_Question1  Morning_Question2  Morning_Question3  \\\n",
       "count          14.000000          14.000000          14.000000   \n",
       "mean            2.771630           2.704766           3.684239   \n",
       "std             1.339235           1.115521           1.206275   \n",
       "min             1.000000           1.000000           1.000000   \n",
       "25%             1.956981           2.169643           3.302760   \n",
       "50%             2.857759           2.393939           3.928480   \n",
       "75%             3.435737           3.758621           4.419540   \n",
       "max             5.000000           4.448276           5.000000   \n",
       "\n",
       "       Morning_Question4  Morning_Question5  Morning_Question6  \\\n",
       "count          14.000000          14.000000          14.000000   \n",
       "mean            3.427975           2.393328           4.368998   \n",
       "std             1.113369           0.893719           0.702195   \n",
       "min             1.310345           1.517241           2.517241   \n",
       "25%             2.539577           1.972222           3.958128   \n",
       "50%             3.847222           2.064394           4.403941   \n",
       "75%             4.000000           2.423701           4.979167   \n",
       "max             5.000000           5.000000           5.000000   \n",
       "\n",
       "       Afternoon_Question1  Afternoon_Question2  Afternoon_Question3  \\\n",
       "count            14.000000            14.000000            14.000000   \n",
       "mean              3.686286             3.513472             2.736801   \n",
       "std               1.221645             1.272435             1.147496   \n",
       "min               1.000000             1.000000             1.000000   \n",
       "25%               2.908279             3.087662             1.551724   \n",
       "50%               4.000000             3.772727             3.000000   \n",
       "75%               4.713362             4.326149             3.772727   \n",
       "max               5.000000             5.000000             4.035714   \n",
       "\n",
       "       Afternoon_Question4  ...    HR_mean      HR_var     HR_std      HR_sk  \\\n",
       "count            14.000000  ...  14.000000   14.000000  14.000000  14.000000   \n",
       "mean              2.429426  ...  79.327247  168.022421  12.358672   0.787483   \n",
       "std               1.152266  ...   3.769125   61.278871   2.289319   0.272895   \n",
       "min               1.000000  ...  74.539412   85.912121   9.195755   0.280961   \n",
       "25%               1.310345  ...  77.465143  104.751713   9.907677   0.591312   \n",
       "50%               2.214286  ...  78.904839  172.698871  12.686409   0.808753   \n",
       "75%               3.607955  ...  79.905215  214.698339  14.061540   1.040887   \n",
       "max               3.962963  ...  89.492347  258.342542  15.626514   1.102250   \n",
       "\n",
       "           HR_ku  Stress_mean  Stress_var  Stress_std  Stress_sk  Stress_ku  \n",
       "count  14.000000    14.000000   14.000000   14.000000  14.000000  14.000000  \n",
       "mean    0.662993    30.629987  449.669255   20.457643   0.917550   0.612431  \n",
       "std     0.669500     4.683535  105.003775    2.483785   0.268648   0.824843  \n",
       "min    -0.283663    23.014433  264.873317   15.284160   0.290027  -0.820974  \n",
       "25%     0.244217    28.117668  386.597363   18.933233   0.804227   0.240722  \n",
       "50%     0.448019    29.403302  442.825365   20.723560   0.986197   0.782005  \n",
       "75%     1.121867    32.695160  533.173782   22.052479   1.072589   0.855014  \n",
       "max     2.221792    39.126304  616.333657   24.128994   1.329738   2.395604  \n",
       "\n",
       "[8 rows x 259 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansR = mean_per_file(pathR)\n",
    "meansR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morning_Question1</th>\n",
       "      <th>Morning_Question2</th>\n",
       "      <th>Morning_Question3</th>\n",
       "      <th>Morning_Question4</th>\n",
       "      <th>Morning_Question5</th>\n",
       "      <th>Morning_Question6</th>\n",
       "      <th>Afternoon_Question1</th>\n",
       "      <th>Afternoon_Question2</th>\n",
       "      <th>Afternoon_Question3</th>\n",
       "      <th>Afternoon_Question4</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_var</th>\n",
       "      <th>HR_std</th>\n",
       "      <th>HR_sk</th>\n",
       "      <th>HR_ku</th>\n",
       "      <th>Stress_mean</th>\n",
       "      <th>Stress_var</th>\n",
       "      <th>Stress_std</th>\n",
       "      <th>Stress_sk</th>\n",
       "      <th>Stress_ku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.982123</td>\n",
       "      <td>2.888846</td>\n",
       "      <td>4.235503</td>\n",
       "      <td>3.537182</td>\n",
       "      <td>2.198923</td>\n",
       "      <td>4.308005</td>\n",
       "      <td>4.279549</td>\n",
       "      <td>4.207332</td>\n",
       "      <td>3.086296</td>\n",
       "      <td>2.498761</td>\n",
       "      <td>...</td>\n",
       "      <td>76.611583</td>\n",
       "      <td>159.975591</td>\n",
       "      <td>11.960036</td>\n",
       "      <td>0.683127</td>\n",
       "      <td>0.560790</td>\n",
       "      <td>30.689241</td>\n",
       "      <td>401.670527</td>\n",
       "      <td>18.861560</td>\n",
       "      <td>0.781198</td>\n",
       "      <td>1.112729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.295793</td>\n",
       "      <td>1.195432</td>\n",
       "      <td>0.749181</td>\n",
       "      <td>1.094154</td>\n",
       "      <td>1.225848</td>\n",
       "      <td>0.605677</td>\n",
       "      <td>0.759156</td>\n",
       "      <td>0.893941</td>\n",
       "      <td>1.475356</td>\n",
       "      <td>1.406318</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441676</td>\n",
       "      <td>81.101585</td>\n",
       "      <td>2.960623</td>\n",
       "      <td>0.284105</td>\n",
       "      <td>0.898365</td>\n",
       "      <td>8.503527</td>\n",
       "      <td>182.846846</td>\n",
       "      <td>5.082146</td>\n",
       "      <td>0.532732</td>\n",
       "      <td>1.924766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.241379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>2.655172</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>67.782868</td>\n",
       "      <td>56.488793</td>\n",
       "      <td>7.377522</td>\n",
       "      <td>0.122072</td>\n",
       "      <td>-0.705049</td>\n",
       "      <td>14.546611</td>\n",
       "      <td>104.996084</td>\n",
       "      <td>9.509846</td>\n",
       "      <td>-0.290844</td>\n",
       "      <td>-1.149331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.648348</td>\n",
       "      <td>2.206897</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.969109</td>\n",
       "      <td>1.086207</td>\n",
       "      <td>3.758621</td>\n",
       "      <td>3.612069</td>\n",
       "      <td>3.810345</td>\n",
       "      <td>1.140445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.879550</td>\n",
       "      <td>101.738931</td>\n",
       "      <td>9.844374</td>\n",
       "      <td>0.526519</td>\n",
       "      <td>-0.145713</td>\n",
       "      <td>27.099043</td>\n",
       "      <td>239.313772</td>\n",
       "      <td>14.858416</td>\n",
       "      <td>0.493503</td>\n",
       "      <td>-0.113687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.465517</td>\n",
       "      <td>3.155093</td>\n",
       "      <td>4.162835</td>\n",
       "      <td>3.885776</td>\n",
       "      <td>2.035714</td>\n",
       "      <td>4.275223</td>\n",
       "      <td>4.431034</td>\n",
       "      <td>4.362069</td>\n",
       "      <td>3.716236</td>\n",
       "      <td>2.379310</td>\n",
       "      <td>...</td>\n",
       "      <td>76.319784</td>\n",
       "      <td>129.058084</td>\n",
       "      <td>11.141028</td>\n",
       "      <td>0.696458</td>\n",
       "      <td>0.353699</td>\n",
       "      <td>30.683653</td>\n",
       "      <td>449.767037</td>\n",
       "      <td>20.611773</td>\n",
       "      <td>0.745404</td>\n",
       "      <td>0.254687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.982759</td>\n",
       "      <td>3.913793</td>\n",
       "      <td>4.965517</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.017241</td>\n",
       "      <td>4.913793</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.721675</td>\n",
       "      <td>...</td>\n",
       "      <td>79.833627</td>\n",
       "      <td>206.797720</td>\n",
       "      <td>13.810337</td>\n",
       "      <td>0.879722</td>\n",
       "      <td>1.252244</td>\n",
       "      <td>37.073748</td>\n",
       "      <td>534.976423</td>\n",
       "      <td>22.557086</td>\n",
       "      <td>1.016159</td>\n",
       "      <td>2.623001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.931034</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.654594</td>\n",
       "      <td>375.786266</td>\n",
       "      <td>18.950565</td>\n",
       "      <td>1.223495</td>\n",
       "      <td>2.095290</td>\n",
       "      <td>48.321463</td>\n",
       "      <td>738.938880</td>\n",
       "      <td>26.660994</td>\n",
       "      <td>1.915858</td>\n",
       "      <td>5.422677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Morning_Question1  Morning_Question2  Morning_Question3  \\\n",
       "count          26.000000          26.000000          26.000000   \n",
       "mean            2.982123           2.888846           4.235503   \n",
       "std             1.295793           1.195432           0.749181   \n",
       "min             1.000000           1.000000           2.241379   \n",
       "25%             1.648348           2.206897           4.000000   \n",
       "50%             3.465517           3.155093           4.162835   \n",
       "75%             3.982759           3.913793           4.965517   \n",
       "max             4.931034           4.555556           5.000000   \n",
       "\n",
       "       Morning_Question4  Morning_Question5  Morning_Question6  \\\n",
       "count          26.000000          26.000000          26.000000   \n",
       "mean            3.537182           2.198923           4.308005   \n",
       "std             1.094154           1.225848           0.605677   \n",
       "min             1.000000           1.000000           3.375000   \n",
       "25%             2.969109           1.086207           3.758621   \n",
       "50%             3.885776           2.035714           4.275223   \n",
       "75%             4.000000           3.017241           4.913793   \n",
       "max             5.000000           5.000000           5.000000   \n",
       "\n",
       "       Afternoon_Question1  Afternoon_Question2  Afternoon_Question3  \\\n",
       "count            26.000000            26.000000            26.000000   \n",
       "mean              4.279549             4.207332             3.086296   \n",
       "std               0.759156             0.893941             1.475356   \n",
       "min               2.655172             1.965517             1.000000   \n",
       "25%               3.612069             3.810345             1.140445   \n",
       "50%               4.431034             4.362069             3.716236   \n",
       "75%               5.000000             5.000000             4.000000   \n",
       "max               5.000000             5.000000             5.000000   \n",
       "\n",
       "       Afternoon_Question4  ...    HR_mean      HR_var     HR_std      HR_sk  \\\n",
       "count            26.000000  ...  26.000000   26.000000  26.000000  26.000000   \n",
       "mean              2.498761  ...  76.611583  159.975591  11.960036   0.683127   \n",
       "std               1.406318  ...   5.441676   81.101585   2.960623   0.284105   \n",
       "min               1.000000  ...  67.782868   56.488793   7.377522   0.122072   \n",
       "25%               1.000000  ...  72.879550  101.738931   9.844374   0.526519   \n",
       "50%               2.379310  ...  76.319784  129.058084  11.141028   0.696458   \n",
       "75%               3.721675  ...  79.833627  206.797720  13.810337   0.879722   \n",
       "max               5.000000  ...  87.654594  375.786266  18.950565   1.223495   \n",
       "\n",
       "           HR_ku  Stress_mean  Stress_var  Stress_std  Stress_sk  Stress_ku  \n",
       "count  26.000000    26.000000   26.000000   26.000000  26.000000  26.000000  \n",
       "mean    0.560790    30.689241  401.670527   18.861560   0.781198   1.112729  \n",
       "std     0.898365     8.503527  182.846846    5.082146   0.532732   1.924766  \n",
       "min    -0.705049    14.546611  104.996084    9.509846  -0.290844  -1.149331  \n",
       "25%    -0.145713    27.099043  239.313772   14.858416   0.493503  -0.113687  \n",
       "50%     0.353699    30.683653  449.767037   20.611773   0.745404   0.254687  \n",
       "75%     1.252244    37.073748  534.976423   22.557086   1.016159   2.623001  \n",
       "max     2.095290    48.321463  738.938880   26.660994   1.915858   5.422677  \n",
       "\n",
       "[8 rows x 259 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansN = mean_per_file(pathN)\n",
    "meansN.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansAll = pd.concat((meansR,meansN),ignore_index=True)\n",
    "meansAll.shape\n",
    "meansR = None\n",
    "meansN = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data (R and NR) into one data frame.\n",
    "# Label R = positive = 1 = blue.\n",
    "# Label NR = negative = 0 = red.\n",
    "def make_labels(positives,negatives):\n",
    "    rows = positives.shape[0]\n",
    "    labelsP = pd.DataFrame(np.ones(rows,dtype=np.int8))  # one = blue\n",
    "    rows = negatives.shape[0]\n",
    "    labelsN = pd.DataFrame(np.zeros(rows,dtype=np.int8))  # zero = red\n",
    "    labelsAll = pd.concat((labelsP,labelsN),ignore_index=True)\n",
    "    return labelsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-02609bcc4b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeansR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeansN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a8a14bc7e7bc>\u001b[0m in \u001b[0;36mmake_labels\u001b[0;34m(positives, negatives)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Label NR = negative = 0 = red.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlabelsP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# one = blue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "labels_df = make_labels(meansR,meansN)\n",
    "labels_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and covariance\n",
    "Normalize by subtracting the column mean from every column value.  \n",
    "Since columns have widely different numerical ranges,   \n",
    "also normalize by making each column have unit variance.  \n",
    "Note: without normalization, the covariance plot would be all black except for the few features with large absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by shifting the mean to zero and scaling to unit variance.\n",
    "def scale_features(X):\n",
    "    s = StandardScaler()\n",
    "    z = s.fit_transform(X)\n",
    "    return z\n",
    "scaledMeans = scale_features(meansAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covariance(X):\n",
    "    cv=X.T.dot(X)/len(X)\n",
    "    plt.imshow(cv, cmap='hot', interpolation='nearest')\n",
    "    plt.show()\n",
    "plot_covariance(scaledMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "PCA is an example of unsupervised learning.\n",
    "PCA does dimensionality reduction by a linear transformation\n",
    "to orthogonal axes where each successive axis \n",
    "captures most of the remaining variance.  \n",
    "\n",
    "It is important to normalize first.\n",
    "Otherwise, most variance will be explained by those columns with large absoulte values.\n",
    "That was our mistake in HW #1, when 67% of variance was explained by PC1.  \n",
    "We will examine prinicpal components 1, 2, 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_PC_variance_explained(model):\n",
    "    # Assumes at least 3 principal components, or else crashes.\n",
    "    e1,e2,e3=model.explained_variance_ratio_[:3]*100.0\n",
    "    print(\"Variance explained by PC1=%.2f%% PC2=%.2f%% PC3=%.2f%%\"%(e1,e2,e3))\n",
    "def show_PC_eigenvalues(model):\n",
    "    e1,e2,e3=model.lambdas_[:3]\n",
    "    print(\"Eigenvalues EV1=%.2f EV2=%.2f EV3=%.2f\"%(e1,e2,e3))\n",
    "def construct_PCA():\n",
    "    # Use the PCA class from sklearn.\n",
    "    # Linear dimensionality reduction using Singular Value Decomposition.\n",
    "    # This is unsupervised learning (but we'll use labels for visualization).\n",
    "    # Every transform returns a COPY of the data; see copy parameter.\n",
    "    # Does centering (setting mean = 0); no way to disable this.\n",
    "    # Does not do scaling (setting variance = 1); no way to enable this.\n",
    "    # Does NOT do whitening (setting variance = covariance = 1); see whitening parameter.\n",
    "    # When n_components = None, PCA uses min(features,instances).\n",
    "    # Can also be set to 'mle' or min percent of variance to explain.\n",
    "    model = PCA()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA of total feature space:\")\n",
    "pca=construct_PCA()\n",
    "pca.fit(scaledMeans)\n",
    "show_PC_variance_explained(pca)\n",
    "P_transformed=pca.fit_transform(scaledMeans)\n",
    "print(\"Shape of transformed data\",P_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)\n",
    "LDA is a classification algorithm. \n",
    "LDA is an example of supervised learning.\n",
    "LDA finds a linear decision boundary.\n",
    "\n",
    "LDA can be used for dimensionality reduction.\n",
    "It projects the data onto some number of axes \n",
    "that most discriminate between the classes.\n",
    "The maximum number of dimensions is n_classes-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_LDA():\n",
    "    # A classifier with a linear decision boundary, \n",
    "    # generated by fitting class conditional densities \n",
    "    # to the data and using Bayes’ rule.\n",
    "    # Assumes a Gaussian density for each class.\n",
    "    # Assumes that all classes share the same covariance matrix.\n",
    "    # Solver = 'svd' (default), 'lsqr', or 'eigen'.\n",
    "    # By default, priors are inferred from inputs.\n",
    "    # By default, n_components = None, and LDA uses min(features,classes-1).  \n",
    "    # It is possible to ask LDA for the means, classes, priors,\n",
    "    # variance explained, decision boundary line, and within-class covariance.\n",
    "    return LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must use ravel() to convert shape (40,1) to (40,).\n",
    "labels_ravel=np.ravel(labels_df)\n",
    "lda=construct_LDA()\n",
    "training = cross_validate(lda, scaledMeans, labels_ravel, cv=5)\n",
    "training['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA of total feature space:\")\n",
    "lda.fit(scaledMeans,labels_ravel)\n",
    "# The linear decision boundary is a (n_features)-dimensional vector.\n",
    "print(\"Shape of decision boundary\",lda.coef_.shape)\n",
    "L_transformed = lda.transform(scaledMeans)\n",
    "# The transformed data is (n_classes-1)-dimensional i.e. 1D.\n",
    "print(\"Shape of transformed data\",L_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW2.1.a: Comparison of PCA vs LDA\n",
    "The LDA has more information, specifically, the labels.\n",
    "Also, since we have only two classes, the LDA must perform maximum separation on one axis.\n",
    "Thus, it is not surprising that the LDA achieves greater separation \n",
    "compared to the first principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(10,2)) \n",
    "ax1 = fig1.add_subplot(121)\n",
    "ax1.set_title('PCA first axis')\n",
    "# Extract list of PC1 coordinate for each of 40 intances.\n",
    "pc1_coords = [c[0] for c in P_transformed]\n",
    "ax1.hist(pc1_coords[:CLASS_SEPARATOR],histtype='step',color='blue') \n",
    "ax1.hist(pc1_coords[CLASS_SEPARATOR:],histtype='step',color='red')  \n",
    "ax2 = fig1.add_subplot(122)\n",
    "ax2.set_title('LDA first axis')\n",
    "ax2.hist(L_transformed[:CLASS_SEPARATOR],histtype='step',color='blue') \n",
    "ax2.hist(L_transformed[CLASS_SEPARATOR:],histtype='step',color='red')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW2.1.b: Discussion of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA (transformed,labels):  \n",
    "    lims=[-5,5]  #  Use this if defaults don't work:   ax1d.set_xlim(lims)\n",
    "    fig = plt.figure(figsize=(10,3))\n",
    "    #pc1,pc2,pc3 = np.split(transformed,3,axis=1)  # crashes if n_components != 3\n",
    "    pc1 = [c[0] for c in transformed]\n",
    "    pc2 = [c[1] for c in transformed]\n",
    "    pc3 = [c[2] for c in transformed]\n",
    "    # Plot first PC as histogram\n",
    "    ax1d = fig.add_subplot(131)\n",
    "    ax1d.set_title('First PC')\n",
    "    ax1d.hist(pc1[:CLASS_SEPARATOR],histtype='step',color='blue')  \n",
    "    ax1d.hist(pc1[CLASS_SEPARATOR:],histtype='step',color='red')  \n",
    "    # Plot first 2 PCs in 2D. \n",
    "    ax2d = fig.add_subplot(132)\n",
    "    ax2d.set_title('First 2 PCs')\n",
    "    ax2d.scatter(pc1,pc2,c=labels,cmap=mycmap)\n",
    "    # Plot first 3 PCs in 3D.\n",
    "    ax3d = fig.add_subplot(133,projection='3d')\n",
    "    ax3d.set_title('First 3 PCs')\n",
    "    ax3d.scatter(pc1,pc2,pc3,c=labels,cmap=mycmap)\n",
    "    # Output to screen.\n",
    "    plt.show()\n",
    "plot_PCA(P_transformed,labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scree(model):\n",
    "    pc_values = np.arange(model.n_components_) + 1\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "    plt.plot(pc_values, model.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Proportion of Variance Explained')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "plot_scree(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Principal components (count,dimensions):\",pca.components_.shape)\n",
    "\n",
    "print(\"Additional variance explained, per principal component (first 10):\")\n",
    "for pc in range(0,10):\n",
    "    print(\"%d=%.3f \"%(pc+1,pca.explained_variance_ratio_[pc]),end=\" \")\n",
    "print()\n",
    "\n",
    "print(\"Cumulative variance explained, per principal component (first 10):\")\n",
    "sum = 0.0\n",
    "for pc in range(0,10):\n",
    "    sum += pca.explained_variance_ratio_[pc]\n",
    "    print(\"%d=%.3f \"%(pc+1,sum),end=\" \")\n",
    "print()\n",
    "\n",
    "def print_top_ten_features(pc,cols,cmps):\n",
    "    NUM=10\n",
    "    print(\"PC%d top ten features\"%pc)\n",
    "    n_features=len(cols)\n",
    "    mylist=[]\n",
    "    for i in range(0,n_features):\n",
    "        name = cols[i]\n",
    "        weight = cmps[pc-1][i]\n",
    "        triple = (i,name,np.abs(weight))   \n",
    "        mylist.append(triple)\n",
    "    myary = np.array(mylist,dtype=[('index',int),('name','S30'),('weight',float)])\n",
    "    sorted = np.sort(myary,order='weight')\n",
    "    for i in range(1,NUM+1):\n",
    "        val = sorted[-i]  # start at end and work to front\n",
    "        print(\"  # %3i (%30s) %7.4f\"%(val[0],val[1],val[2]))\n",
    "print_top_ten_features(1,meansAll.columns,pca.components_)\n",
    "print_top_ten_features(2,meansAll.columns,pca.components_)\n",
    "print_top_ten_features(3,meansAll.columns,pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansAll.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
