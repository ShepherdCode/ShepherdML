{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Data - LSTM\n",
    "HW #2 Part 2 - Timeseries.  \n",
    "Use all rows per patient from about 30 consecutive days.\n",
    "Standardize all of it.\n",
    "Train LSTM classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data structures and scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathR='data/ChunkedData_R/'\n",
    "pathN='data/chunkedData_NR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "labels_list = []\n",
    "features_df = pd.DataFrame()\n",
    "NUM_PATIENTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one CSV file. \n",
    "# Load global lists\n",
    "def load_patient (filepath,cohort,patient_name):\n",
    "    global labels_df\n",
    "    global features_df\n",
    "    one_patient = pd.read_csv(filepath)\n",
    "    rows,cols = one_patient.shape\n",
    "    features_df = features_df.append(one_patient)\n",
    "    for rec in range(0,rows):\n",
    "        one_label=(cohort,patient_name,one_patient.loc[rec]['Date'])\n",
    "        labels_list.append(one_label)\n",
    "\n",
    "# Read directory of CSV files (R or NR). \n",
    "# Given directory, load all the patients in that directory.\n",
    "# We use filenames as patient names.\n",
    "def load_cohort (cohort,directory):\n",
    "    global NUM_PATIENTS\n",
    "    file_names = listdir(directory)\n",
    "    NUM_PATIENTS = 0\n",
    "    for fp in file_names:\n",
    "        dfp = directory+fp\n",
    "        one_name = fp.split('.')[0]  # strip away .csv suffix\n",
    "        one_name = one_name[6:]    # strip away Daily_ prefix\n",
    "        one_patient = load_patient(dfp,cohort,one_name)\n",
    "        NUM_PATIENTS += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_cohort('R',pathR)\n",
    "load_cohort('N',pathN)\n",
    "features_df = features_df.drop('Date',axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by shifting the mean to zero and scaling to unit variance.\n",
    "# Subtract the mean and divide by the std.dev: z = (x - u) / s\n",
    "def scale_features(df):\n",
    "    scaled = StandardScaler().fit_transform(df.values)\n",
    "    scaled_df = pd.DataFrame(scaled, index=df.index, columns=df.columns)\n",
    "    return scaled_df\n",
    "scaled_features = scale_features(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns 3-tuple (cohort,name,date)\n",
    "def patient_by_index(ndx):\n",
    "    prev_name='XXX'\n",
    "    name_index=-1\n",
    "    for i in range(0,len(labels_list)):\n",
    "        (cohort,name,date)=labels_list[i]\n",
    "        if not name == prev_name:\n",
    "            prev_name = name\n",
    "            name_index = name_index+1\n",
    "        if name_index == ndx:\n",
    "            return (cohort,name,date)\n",
    "    return None\n",
    "    \n",
    "# Returns dataframe for one patient [n_dates,n_features]\n",
    "def features_by_patient_index(ndx):\n",
    "    prev_name='XXX'\n",
    "    name_index=-1\n",
    "    min=1000000\n",
    "    max=-1\n",
    "    for i in range(0,len(labels_list)):\n",
    "        (cohort,name,date)=labels_list[i]\n",
    "        if not name == prev_name:\n",
    "            prev_name = name\n",
    "            name_index = name_index+1\n",
    "        if name_index == ndx:\n",
    "            if i<min:\n",
    "                min=i\n",
    "            if i>max:\n",
    "                max=i\n",
    "    one_p = features_df.iloc[min:max+1]\n",
    "    return (one_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of {1=R,0=NR}\n",
    "def get_all_cohorts():\n",
    "    all = []\n",
    "    for i in range(0,len(labels_list)):\n",
    "        (cohort,name,date) = patient_by_index(i)\n",
    "        y = 0\n",
    "        if cohort=='R':\n",
    "            y=1\n",
    "        all.append(y)\n",
    "    return all\n",
    "\n",
    "# Returns list of list of list:\n",
    "# list of all patients, \n",
    "# where each patient is a list of daily records,\n",
    "# where record is a list of 259 feature values.\n",
    "def get_all_patients():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient number: 1\n",
      "Patient cohort, name, start date: ('R', '2027_S2', '2020-03-12')\n",
      "Num records: 29\n",
      "Num columns: 259\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "ndx=1\n",
    "my_feat = features_by_patient_index(ndx)\n",
    "print(\"Patient number:\",ndx)\n",
    "print(\"Patient cohort, name, start date:\",patient_by_index(ndx))\n",
    "print(\"Num records:\",len(my_feat))\n",
    "print(\"Num columns:\",len(features_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM=32\n",
    "NEURONS=32\n",
    "def build_model():\n",
    "    #embed_layer = keras.layers.Embedding(\n",
    "    #    input_dim=INPUT_DIM, output_dim=EMBED_DIM, mask_zero=True)\n",
    "    rnn1_layer = keras.layers.LSTM(NEURONS, return_sequences=True, \n",
    "          input_shape=[None,259,]) # shape=[dates,features,none]=[29,259,]\n",
    "    rnn2_layer = keras.layers.LSTM(NEURONS, return_sequences=False)\n",
    "    dense1_layer = keras.layers.Dense(NEURONS)\n",
    "    dense2_layer = keras.layers.Dense(NEURONS)\n",
    "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ann = keras.models.Sequential()\n",
    "    #ann.add(embed_layer)\n",
    "    ann.add(rnn1_layer)\n",
    "    ann.add(rnn2_layer)\n",
    "    ann.add(dense1_layer)\n",
    "    ann.add(dense2_layer)\n",
    "    ann.add(output_layer)\n",
    "    compiled = compile_model(ann)\n",
    "    return compiled\n",
    "\n",
    "# Default weight initializers.\n",
    "# Keras Dense default = Glorot aka Xavier uniform initializer\n",
    "\n",
    "def compile_model(model):\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    model.compile(loss=bc, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "if False:\n",
    "    t1=[4,2,6]\n",
    "    t2=[7,1,3]\n",
    "    t3=[5,5,0]\n",
    "    t4=[9,3,6]\n",
    "    p1=[t1,t2,t3,t4]\n",
    "    data=[p1,p1]\n",
    "    data\n",
    "    # samples, timesteps, features\n",
    "    # for this demo, set rnn layer 1 input shape to       input_shape=[4,3,]\n",
    "    INPUT_DIM=3\n",
    "    lstm = build_model()\n",
    "    lstm = compile_model(lstm)\n",
    "    lstm.summary()\n",
    "    lstm.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 32)          37376     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 47,841\n",
      "Trainable params: 47,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM=len(features_df.columns)\n",
    "lstm = build_model()\n",
    "lstm = compile_model(lstm)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient number: 1\n",
      "Patient cohort, name, start date: ('R', '2027_S2', '2020-03-12')\n",
      "Num records: 29\n",
      "Num columns: 259\n",
      "<class 'list'>\n",
      "29\n",
      "<class 'list'>\n",
      "259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48673052],\n",
       "       [0.48673052]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndx=1\n",
    "my_feat = features_by_patient_index(ndx)\n",
    "print(\"Patient number:\",ndx)\n",
    "print(\"Patient cohort, name, start date:\",patient_by_index(ndx))\n",
    "print(\"Num records:\",len(my_feat))\n",
    "print(\"Num columns:\",INPUT_DIM)\n",
    "p1=features_by_patient_index(1)\n",
    "list1=p1.values.tolist()\n",
    "print(type(list1))\n",
    "print(len(list1))\n",
    "print(type(list1[0]))\n",
    "print(len(list1[0]))\n",
    "data=[list1,list1]\n",
    "lstm.predict(data)\n",
    "# When n_dates = None, prediction is 0.54342705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 0.6935 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec872e6190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[0,1]\n",
    "lstm.fit(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions(model_outs):\n",
    "    preds=[]\n",
    "    for x in model_outs:\n",
    "        y = 0\n",
    "        if x[0]>=0.5:\n",
    "            y=1\n",
    "        preds.append(y)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output=lstm.predict(data)\n",
    "predicted=convert_predictions(model_output)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(labels,predicted)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
