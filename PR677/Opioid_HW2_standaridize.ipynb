{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Data - Standardize Timeseries\n",
    "HW #2 Part 2 - Timeseries.  \n",
    "Use all rows per patient from about 30 consecutive days.\n",
    "Standardize all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Input characteristics: \n",
    "Patient files are in one of two directories: R or NR.\n",
    "Each patient is represented by one CSV file.\n",
    "Each row of each CSV contains readings from one day.\n",
    "Days are in order and mostly sequential (at least one day is missing in one patient).\n",
    "Most patients have 30 days but some have less.\n",
    "\n",
    "Loaded data structure characteristics:\n",
    "Labels columns for cohort (R or NR), patient (2005_S3), date.\n",
    "Labels rows are num_cohorts * num_patients * num_dates.\n",
    "Features columns are measurements without dates.\n",
    "Features rows are same as Labels rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  files of type R\n",
      "26  files of type N\n"
     ]
    }
   ],
   "source": [
    "pathR='data/ChunkedData_R/'\n",
    "pathN='data/chunkedData_NR/'\n",
    "filesR = listdir(pathR)\n",
    "filesN = listdir(pathN)\n",
    "print(len(filesR),\" files of type R\")\n",
    "print(len(filesN),\" files of type N\")\n",
    "CLASS_SEPARATOR=13  # data[:13] vs data[13:]\n",
    "WITH_VARIANCE_COLUMNS=True   # Use mean and variance per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list=[]\n",
    "features_list=[]\n",
    "# Read one CSV file. \n",
    "# Load global lists\n",
    "def load_patient (filepath,cohort,patient_name):\n",
    "    patient_recs = pd.read_csv(filepath)\n",
    "    rows,cols = patient_recs.shape\n",
    "    print(rows,cols)\n",
    "    for r in range(0,rows):\n",
    "        record = patient_recs.iloc[r]\n",
    "        dt=record['Date']\n",
    "        label = (cohort,patient_name,dt)\n",
    "        labels_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('N', '2002_S1', '2020-01-03'),\n",
       " ('N', '2002_S1', '2020-01-04'),\n",
       " ('N', '2002_S1', '2020-01-05'),\n",
       " ('N', '2002_S1', '2020-01-06'),\n",
       " ('N', '2002_S1', '2020-01-07'),\n",
       " ('N', '2002_S1', '2020-01-08'),\n",
       " ('N', '2002_S1', '2020-01-09'),\n",
       " ('N', '2002_S1', '2020-01-10'),\n",
       " ('N', '2002_S1', '2020-01-11'),\n",
       " ('N', '2002_S1', '2020-01-12'),\n",
       " ('N', '2002_S1', '2020-01-13'),\n",
       " ('N', '2002_S1', '2020-01-14'),\n",
       " ('N', '2002_S1', '2020-01-15'),\n",
       " ('N', '2002_S1', '2020-01-16'),\n",
       " ('N', '2002_S1', '2020-01-17'),\n",
       " ('N', '2002_S1', '2020-01-18'),\n",
       " ('N', '2002_S1', '2020-01-19'),\n",
       " ('N', '2002_S1', '2020-01-20'),\n",
       " ('N', '2002_S1', '2020-01-21'),\n",
       " ('N', '2002_S1', '2020-01-22'),\n",
       " ('N', '2002_S1', '2020-01-23'),\n",
       " ('N', '2002_S1', '2020-01-24'),\n",
       " ('N', '2002_S1', '2020-01-25'),\n",
       " ('N', '2002_S1', '2020-01-26'),\n",
       " ('N', '2002_S1', '2020-01-27'),\n",
       " ('N', '2002_S1', '2020-01-28'),\n",
       " ('N', '2002_S1', '2020-01-29'),\n",
       " ('N', '2002_S1', '2020-01-30'),\n",
       " ('N', '2002_S1', '2020-01-31')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_patient('data/chunkedData_NR/Daily_2002_S1.csv','N','2002_S1')\n",
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directory of CSV files (R or NR). \n",
    "# Given directory, load all the patients in that directory.\n",
    "# We use filenames as patient names.\n",
    "def load_cohort (directory):\n",
    "    file_names = listdir(directory)\n",
    "    patient_names = []\n",
    "    patient_records = []\n",
    "    for fp in file_names:\n",
    "        dfp = directory+fp\n",
    "        one_patient = load_patient(dfp)\n",
    "        one_name = fp.split('.')[0]  # strip away .csv suffix\n",
    "        one_name = one_name[6:]    # strip away Daily_ prefix\n",
    "        patient_names.append(one_name)\n",
    "        patient_records.append(one_patient)\n",
    "    return patient_names,patient_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesR,dataR = load_cohort(pathR)\n",
    "namesN,dataN = load_cohort(pathN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients (R,N,total): 14 26 40\n"
     ]
    }
   ],
   "source": [
    "dataAll = dataR + dataN\n",
    "rowsR = len(dataR)\n",
    "rowsN = len(dataN)\n",
    "rowsAll = len(dataAll)\n",
    "print(\"Number of patients (R,N,total):\",rowsR,rowsN,rowsAll)\n",
    "\n",
    "# Visit all patients in order.\n",
    "# Either print the dates or remove the dates.\n",
    "#for p in range(rowsAll):\n",
    "#    patient_recs = dataAll[p]\n",
    "#    #print(patient_recs['Date'])\n",
    "#    patient_recs.drop(['Date'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume timeseries records are equally spaced at one per day.\n",
    "This is mostly true with a few abberations.\n",
    "For example, R patient 2060_S3 is missing the record between 2020-06-01 and 2020-06-03.\n",
    "\n",
    "We will align all patient records by measuring days-since-start.\n",
    "We will ignore the specific dates which can be in different months for different patients.\n",
    "Thus, we are assuming month of year has no effect on the response variable R/NR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and covariance\n",
    "Normalize by subtracting the column mean from every column value.  \n",
    "Since columns have widely different numerical ranges,   \n",
    "also normalize by making each column have unit variance.  \n",
    "Note: without normalization, the covariance plot would be all black except for the few features with large absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meansAll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-06b00d6aa6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscaledMeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeansAll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeansAll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meansAll' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize features by shifting the mean to zero and scaling to unit variance.\n",
    "# Subtract the mean and divide by the std.dev: z = (x - u) / s\n",
    "def scale_features(X):\n",
    "    s = StandardScaler()\n",
    "    z = s.fit_transform(X)\n",
    "    return z\n",
    "scaledMeans = scale_features(meansAll)\n",
    "column_names = meansAll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Names:\")\n",
    "print(column_names)\n",
    "print(\"Scaled Means & Variances:\")\n",
    "scaledMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathR = None\n",
    "pathN = None\n",
    "filesR = None\n",
    "filesN = None\n",
    "meansR = None\n",
    "meansN = None\n",
    "meansAll = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
