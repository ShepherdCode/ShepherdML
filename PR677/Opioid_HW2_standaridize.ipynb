{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Data - Standardize Timeseries\n",
    "HW #2 Part 2 - Timeseries.  \n",
    "Use all rows per patient from about 30 consecutive days.\n",
    "Standardize all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Input characteristics: \n",
    "Patient files are in one of two directories: R or NR.\n",
    "Each patient is represented by one CSV file.\n",
    "Each row of each CSV contains readings from one day.\n",
    "Days are in order and mostly sequential (at least one day is missing in one patient).\n",
    "Most patients have 30 days but some have less.\n",
    "\n",
    "Loaded data structure characteristics:\n",
    "Labels columns for cohort (R or NR), patient (2005_S3), date.\n",
    "Labels rows are num_cohorts * num_patients * num_dates.\n",
    "Features columns are measurements without dates.\n",
    "Features rows are same as Labels rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume timeseries records are equally spaced at one per day.\n",
    "This is mostly true with a few abberations.\n",
    "For example, R patient 2060_S3 is missing the record between 2020-06-01 and 2020-06-03.\n",
    "\n",
    "We will align all patient records by measuring days-since-start.\n",
    "We will ignore the specific dates which can be in different months for different patients.\n",
    "Thus, we are assuming month of year has no effect on the response variable R/NR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathR='data/ChunkedData_R/'\n",
    "pathN='data/chunkedData_NR/'\n",
    "CLASS_SEPARATOR=13  # data[:13] vs data[13:]\n",
    "WITH_VARIANCE_COLUMNS=True   # Use mean and variance per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_LIST = ['cohort','patient_name','date']\n",
    "labels_list = []\n",
    "features_df = pd.DataFrame()\n",
    "# Read one CSV file. \n",
    "# Load global lists\n",
    "def load_patient (filepath,cohort,patient_name):\n",
    "    global labels_df\n",
    "    global features_df\n",
    "    one_patient = pd.read_csv(filepath)\n",
    "    rows,cols = one_patient.shape\n",
    "    features_df = features_df.append(one_patient)\n",
    "    for rec in range(0,rows):\n",
    "        one_label=(cohort,patient_name,one_patient.loc[rec]['Date'])\n",
    "        labels_list.append(one_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directory of CSV files (R or NR). \n",
    "# Given directory, load all the patients in that directory.\n",
    "# We use filenames as patient names.\n",
    "def load_cohort (cohort,directory):\n",
    "    file_names = listdir(directory)\n",
    "    for fp in file_names:\n",
    "        dfp = directory+fp\n",
    "        one_name = fp.split('.')[0]  # strip away .csv suffix\n",
    "        one_name = one_name[6:]    # strip away Daily_ prefix\n",
    "        one_patient = load_patient(dfp,cohort,one_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  files of type R\n",
      "26  files of type N\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Morning_Question1</th>\n",
       "      <th>Morning_Question2</th>\n",
       "      <th>Morning_Question3</th>\n",
       "      <th>Morning_Question4</th>\n",
       "      <th>Morning_Question5</th>\n",
       "      <th>Morning_Question6</th>\n",
       "      <th>Afternoon_Question1</th>\n",
       "      <th>Afternoon_Question2</th>\n",
       "      <th>Afternoon_Question3</th>\n",
       "      <th>Afternoon_Question4</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_var</th>\n",
       "      <th>HR_std</th>\n",
       "      <th>HR_sk</th>\n",
       "      <th>HR_ku</th>\n",
       "      <th>Stress_mean</th>\n",
       "      <th>Stress_var</th>\n",
       "      <th>Stress_std</th>\n",
       "      <th>Stress_sk</th>\n",
       "      <th>Stress_ku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>74.290849</td>\n",
       "      <td>320.934322</td>\n",
       "      <td>17.914640</td>\n",
       "      <td>1.071010</td>\n",
       "      <td>0.770627</td>\n",
       "      <td>39.173780</td>\n",
       "      <td>769.416191</td>\n",
       "      <td>27.738352</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>-1.319960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>74.401459</td>\n",
       "      <td>308.214628</td>\n",
       "      <td>17.556042</td>\n",
       "      <td>1.327296</td>\n",
       "      <td>1.331250</td>\n",
       "      <td>38.691558</td>\n",
       "      <td>485.933870</td>\n",
       "      <td>22.043908</td>\n",
       "      <td>0.706097</td>\n",
       "      <td>-0.149387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>74.329967</td>\n",
       "      <td>292.800716</td>\n",
       "      <td>17.111421</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>0.316197</td>\n",
       "      <td>35.116129</td>\n",
       "      <td>880.102975</td>\n",
       "      <td>29.666530</td>\n",
       "      <td>0.565035</td>\n",
       "      <td>-1.181336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>77.153765</td>\n",
       "      <td>166.815153</td>\n",
       "      <td>12.915694</td>\n",
       "      <td>1.120305</td>\n",
       "      <td>3.849928</td>\n",
       "      <td>52.852547</td>\n",
       "      <td>349.389489</td>\n",
       "      <td>18.691963</td>\n",
       "      <td>-0.040921</td>\n",
       "      <td>-0.137957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>80.128234</td>\n",
       "      <td>197.631934</td>\n",
       "      <td>14.058163</td>\n",
       "      <td>1.264925</td>\n",
       "      <td>0.945865</td>\n",
       "      <td>45.834320</td>\n",
       "      <td>377.319680</td>\n",
       "      <td>19.424718</td>\n",
       "      <td>0.539156</td>\n",
       "      <td>-0.363470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Morning_Question1  Morning_Question2  Morning_Question3  Morning_Question4  \\\n",
       "0                  2                  2                  4                  4   \n",
       "1                  1                  2                  4                  4   \n",
       "2                  2                  1                  1                  4   \n",
       "3                  2                  2                  3                  4   \n",
       "4                  2                  2                  4                  4   \n",
       "\n",
       "   Morning_Question5  Morning_Question6  Afternoon_Question1  \\\n",
       "0                  3                  4                    4   \n",
       "1                  2                  4                    2   \n",
       "2                  4                  5                    4   \n",
       "3                  3                  4                    2   \n",
       "4                  3                  5                    4   \n",
       "\n",
       "   Afternoon_Question2  Afternoon_Question3  Afternoon_Question4  ...  \\\n",
       "0                    4                    4                    4  ...   \n",
       "1                    5                    5                    4  ...   \n",
       "2                    4                    4                    4  ...   \n",
       "3                    2                    3                    4  ...   \n",
       "4                    4                    4                    4  ...   \n",
       "\n",
       "     HR_mean      HR_var     HR_std     HR_sk     HR_ku  Stress_mean  \\\n",
       "0  74.290849  320.934322  17.914640  1.071010  0.770627    39.173780   \n",
       "1  74.401459  308.214628  17.556042  1.327296  1.331250    38.691558   \n",
       "2  74.329967  292.800716  17.111421  0.993076  0.316197    35.116129   \n",
       "3  77.153765  166.815153  12.915694  1.120305  3.849928    52.852547   \n",
       "4  80.128234  197.631934  14.058163  1.264925  0.945865    45.834320   \n",
       "\n",
       "   Stress_var  Stress_std  Stress_sk  Stress_ku  \n",
       "0  769.416191   27.738352   0.451429  -1.319960  \n",
       "1  485.933870   22.043908   0.706097  -0.149387  \n",
       "2  880.102975   29.666530   0.565035  -1.181336  \n",
       "3  349.389489   18.691963  -0.040921  -0.137957  \n",
       "4  377.319680   19.424718   0.539156  -0.363470  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(listdir(pathR)),\" files of type R\")\n",
    "load_cohort('R',pathR)\n",
    "print(len(listdir(pathN)),\" files of type N\")\n",
    "load_cohort('N',pathN)\n",
    "features_df = features_df.drop('Date',axis=1) \n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: 1004  like  ('R', '2060_S3', '2020-05-21')\n",
      "features: (1004, 259)\n"
     ]
    }
   ],
   "source": [
    "# Labels is a list of triples: cohort, patient name, test date.\n",
    "# Labels is just identifying info; no data.\n",
    "# Labels and Features are in one-to-one correspondence.\n",
    "print(\"labels:\",len(labels_list),\" like \",labels_list[0])\n",
    "# Features is a dataframe with named columns.\n",
    "# Features is just features; no identifying info.\n",
    "print(\"features:\",features_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and covariance\n",
    "Normalize by subtracting the column mean from every column value.  \n",
    "Since columns have widely different numerical ranges,   \n",
    "also normalize by making each column have unit variance.  \n",
    "Note: without normalization, the covariance plot would be all black except for the few features with large absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meansAll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-06b00d6aa6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscaledMeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeansAll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeansAll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meansAll' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize features by shifting the mean to zero and scaling to unit variance.\n",
    "# Subtract the mean and divide by the std.dev: z = (x - u) / s\n",
    "def scale_features(X):\n",
    "    s = StandardScaler()\n",
    "    z = s.fit_transform(X)\n",
    "    return z\n",
    "scaledMeans = scale_features(meansAll)\n",
    "column_names = meansAll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Names:\")\n",
    "print(column_names)\n",
    "print(\"Scaled Means & Variances:\")\n",
    "scaledMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathR = None\n",
    "pathN = None\n",
    "filesR = None\n",
    "filesN = None\n",
    "meansR = None\n",
    "meansN = None\n",
    "meansAll = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
