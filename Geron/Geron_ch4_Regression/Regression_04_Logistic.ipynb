{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression.\n",
    "# As binary classifier, outputs the probability that instance is in positive class.\n",
    "\n",
    "# The \"logit\" is the log-odds.\n",
    "# Logit(p) = log(p/(1-p)).\n",
    "# The \"logistic\" is found with sigmoid function.\n",
    "# Sigmoid(t) = 1 / (1 + e^(-t)).\n",
    "# Prob = sigmoid (XT*theta)\n",
    "# Prediction = {0 if prob<0.5, else 1}\n",
    "# Note: Logit ( Sigmoid ( t ) ) == t.\n",
    "\n",
    "# For a single training instance:\n",
    "# Cost (theta) = {-log(p) if y=1, -log(1-p) if y=0}\n",
    "# Examples: y=1, p=0.9, cost = 0.05 ; y=0, p=0.1, cost = 0.05\n",
    "#           y=1, p=0.1, cost = 1.00 ; y=0, p=0.9, cost = 1.00\n",
    "\n",
    "# Summed over the training set:\n",
    "# Cost (theta) = \"log loss\" = complicated, see Equation 4-17 on page 144.\n",
    "# No closed form solution.\n",
    "# Is confex so gradient descent finds global optimum.\n",
    "\n",
    "# Partial derivative (cost(theta)) w.r.t. weight j\n",
    "#    = (1/m)sum_over_m(sigmoid(thetaT*xi)-yi)*xji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target',\n",
       " 'frame',\n",
       " 'target_names',\n",
       " 'DESCR',\n",
       " 'feature_names',\n",
       " 'filename']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import flower data.\n",
    "# This is a minimum exploration using one feature to make a linear binary classifier.\n",
    "# This data could be explored further.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'][:5] # five features per flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=iris['data'][:,3:]  # use just last feature\n",
    "y=(iris['target']==2).astype(np.int)   # is it species 2 (out of 3)?\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg=LogisticRegression()  # default = regularization with L2 penalty\n",
    "reg.fit(X,y)\n",
    "# Book used predictions in a loop to find that 1.6 is the decision boundary.\n",
    "high_value=1.7\n",
    "low_value=1.5\n",
    "reg.predict([[high_value],[low_value]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
