{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Issues\n",
    "\n",
    "PCA is slow. PCA is a memory hog.\n",
    "\n",
    "Randomized PCA is faster. Incremental PCA uses less memory.\n",
    "\n",
    "PCA uses Singular Value Decomposition (SVD) \n",
    "to find each next optimal orthogonal axis.\n",
    "O(m*n^2 + n^3) for m instances and n features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09704664, 0.07095924, 0.06169089, 0.05389419, 0.04868797])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_pixels = 784\n",
    "X_train1D = X_train.reshape(X_train.shape[0],num_pixels)\n",
    "\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "pca1 = PCA(n_components=154,svd_solver='full')\n",
    "start = time.time()\n",
    "pca1.fit(X_train1D)\n",
    "done = time.time()\n",
    "elapsed1 = done-start\n",
    "explained1 = pca1.explained_variance_ratio_\n",
    "explained1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09704664, 0.07095924, 0.06169089, 0.05389419, 0.04868797])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2 = PCA(n_components=154,svd_solver='randomized')\n",
    "start = time.time()\n",
    "pca2.fit(X_train1D)\n",
    "done = time.time()\n",
    "elapsed2 = done-start\n",
    "explained2 = pca2.explained_variance_ratio_\n",
    "explained2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73472348e-15, 1.36002321e-15, 9.71445147e-16, 9.29811783e-16,\n",
       "       8.11850587e-16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hardly any difference in outputs!\n",
    "(explained1-explained2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.489128112792969, 8.100416898727417)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shaved 3 seconds off the clock!\n",
    "elapsed1,elapsed2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental PCA (IPCA)\n",
    "When the data is too large for RAM, use sklearn IncrementalPCA.\n",
    "\n",
    "### Solution 1: numpy mmap\n",
    "Use numpy.mmap(file) to map a file to memory.\n",
    "Then IncrementalPCA(batch_size=100) to load a few instances at a time.\n",
    "Then IncrementalPCA.fit() works as usual.\n",
    "\n",
    "### Solution 2: numpy array_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: numpy array_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import numpy as np\n",
    "\n",
    "ipca = IncrementalPCA(n_components=154)\n",
    "num_batches=100\n",
    "for X_batch in np.array_split(X_train1D,num_batches):\n",
    "    ipca.partial_fit(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09704663, 0.07095923, 0.06169087, 0.05389418, 0.04868795])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained3 = ipca.explained_variance_ratio_\n",
    "explained3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.85068449e-09, 1.37314708e-08, 1.68055410e-08, 1.91886324e-08,\n",
       "       2.41079584e-08])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the results are not EXACTLY the same as PCA, but pretty close.\n",
    "(explained1-explained3)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
