{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomness\n",
    "There are several aspects of randomness to be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Training Data\n",
    "\n",
    "What happens if you train an ANN on random data? Will it learn?\n",
    "\n",
    "There are many kinds of random data.\n",
    "* Real RNA sequences with the coding/non-coding labels scrambled.\n",
    "* Real RNA sequences with proper labels but scrambled sequence.\n",
    "* Real RNA sequences with proper labels with a few letters changed.\n",
    "\n",
    "Google explored this already.\n",
    "[arXiv](https://arxiv.org/pdf/1611.03530.pdf): UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION (unpublished paper by Google + Berkeley & MIT professors.\n",
    "Finding: \"Deep neural networks easily fit random labels.\"\n",
    "Of course, the network does not generalize to OTHER data,\n",
    "but for any training data, \n",
    "it can learn to predict all the random labels perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to a Random Predictor\n",
    "Before we get excited by a model that predicts with 80% accuracy,\n",
    "we should evaluate what a random predictor would do.\n",
    "\n",
    "On our impbalanced RNA training data (~10K non-coding vs ~5K protein-coding), a model could score 64% by saying non-coding in every case. \n",
    "This is uniform not random, but it takes a similar approach.\n",
    "\n",
    "Google made a big splash with NAS = Neural Architecture Search.\n",
    "They train a neural network to design neural networks for a certain task.\n",
    "Another group claims a random model works as well: \n",
    "[PMLR](http://proceedings.mlr.press/v115/li20c.html) \n",
    "Random Search and Reproducibility for Neural Architecture Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Data Selection\n",
    "Cells produce one to many RNA transcripts per DNA gene.\n",
    "The number of transcripts per gene reaches hundreds for a few outliers.\n",
    "If we train ANNs on all transcripts, do we bias toward high-count genes?\n",
    "If we use one transcript per gene, which one is most representative?\n",
    "The RNA study of Hill et al. used one random transcript per gene.\n",
    "The RNA study of Miller & Adjeroh used the median-length transcript per gene.\n",
    "We have shown that the difference is important;\n",
    "models trained on median transcripts have lower accuracy on all transcripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
