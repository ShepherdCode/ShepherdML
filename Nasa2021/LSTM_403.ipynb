{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_403.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShepherdCode/ShepherdML/blob/master/Nasa2021/LSTM_403.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# LSTM 403\n",
        "Start with LSTM 201 and modify it to use our updated code infrastructure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh6XplUvC0j0",
        "outputId": "f95d3108-f697-4cde-a769-325f3ccca9b2"
      },
      "source": [
        "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
        "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
        "MODEL_FILE='LSTM302'   # load not save!\n",
        "DATAPATH=''\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "NC_FILENAME = DATAPATH+NC_FILENAME\n",
        "PC_FILENAME = DATAPATH+PC_FILENAME\n",
        "MODEL_FILE=DATAPATH+MODEL_FILE\n",
        "\n",
        "EPOCHS=100\n",
        "SPLITS=1\n",
        "K=3\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=16\n",
        "NEURONS=16\n",
        "DROP=0.25\n",
        "ACT=\"tanh\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9TY3HK9ZklE",
        "outputId": "0cb88bed-33b7-46cc-eed5-2e717cf08ab9"
      },
      "source": [
        "# Load our own tools\n",
        "GITHUB = True\n",
        "if GITHUB:\n",
        "    #!pip install requests  # Uncomment this if necessary. Seems to be pre-installed.\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/ShepherdML/master/Strings/tools_fasta.py')\n",
        "    with open('tools_fasta.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "    # TO DO: delete the file after import\n",
        "import tools_fasta as tools\n",
        "tools.yahoo()  # If this prints \"Yahoo!\" the the import was successful.\n",
        "\n",
        "TOOLS_CHANGED = False   # set to True to re-run with a new version of tools\n",
        "if TOOLS_CHANGED:\n",
        "  from importlib import reload \n",
        "  tools=reload(tools)\n",
        "  print(dir(tools))   # run this to see EVERYTHING in the tools module"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yahoo!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def compile_model(model):\n",
        "    adam_default_learn_rate = 0.001\n",
        "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = adam_default_learn_rate*10,\n",
        "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
        "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "    alrd = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE...\")\n",
        "    #model.compile(loss=bc, optimizer=alrd, metrics=[\"accuracy\"])\n",
        "    model.compile(loss=bc, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return model\n",
        "\n",
        "def build_model():\n",
        "    embed_layer  = keras.layers.Embedding(\n",
        "        #VOCABULARY_SIZE, EMBED_DIMEN, input_length=1000, input_length=1000, mask_zero=True)\n",
        "        #input_dim=[None,VOCABULARY_SIZE], output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "        input_dim=VOCABULARY_SIZE, output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "    rnn1_layer = keras.layers.Bidirectional(\n",
        "      keras.layers.LSTM(NEURONS, return_sequences=True, \n",
        "          input_shape=[1000,EMBED_DIMEN], activation=ACT, dropout=DROP) )#bi\n",
        "    rnn2_layer = keras.layers.Bidirectional(\n",
        "      keras.layers.LSTM(NEURONS, return_sequences=False, \n",
        "        activation=ACT, dropout=DROP) )#bi\n",
        "    dense1_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    drop1_layer = keras.layers.Dropout(DROP)\n",
        "    dense2_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    drop2_layer = keras.layers.Dropout(DROP)\n",
        "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\", dtype=dt)\n",
        "    mlp = keras.models.Sequential()\n",
        "    mlp.add(embed_layer)\n",
        "    mlp.add(rnn1_layer)\n",
        "    mlp.add(rnn2_layer)\n",
        "    mlp.add(dense1_layer)\n",
        "    mlp.add(drop1_layer)\n",
        "    mlp.add(dense2_layer)\n",
        "    mlp.add(drop2_layer)\n",
        "    mlp.add(output_layer)\n",
        "    mlpc = compile_model(mlp)\n",
        "    return mlpc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "Partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "def make_slice(data_set,min_len,max_len):\n",
        "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
        "    return slice"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "def do_cross_validation(X,y,given_model):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        fold += 1\n",
        "        X_train=X[train_index] # use iloc[] for dataframe\n",
        "        y_train=y[train_index]\n",
        "        X_valid=X[valid_index]\n",
        "        y_valid=y[valid_index]        \n",
        "        # Avoid continually improving the same model.\n",
        "        model = compile_model(keras.models.clone_model(given_model))\n",
        "        bestname=MODEL_FILE+\".cv.\"+str(fold)+\".best\"\n",
        "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
        "            filepath=bestname, save_best_only=True, \n",
        "            monitor='val_accuracy', mode='max')]   \n",
        "        print(\"FIT\")\n",
        "        start_time=time.time()\n",
        "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                callbacks=mycallbacks,\n",
        "                validation_data=(X_valid,y_valid) )\n",
        "        end_time=time.time()\n",
        "        elapsed_time=(end_time-start_time)                        \n",
        "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0,1)\n",
        "        plt.show()\n",
        "        best_model=keras.models.load_model(bestname)\n",
        "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
        "        cv_scores.append(scores[1] * 100)  \n",
        "    print()\n",
        "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Train on RNA lengths 200-1Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8fNo6sn9KdH",
        "outputId": "86b33646-2cb2-4d15-d6ab-ac8bac4728ee"
      },
      "source": [
        "MINLEN=200\n",
        "MAXLEN=1000\n",
        "print(\"Load data from files.\")\n",
        "nc_seq=tools.load_fasta(NC_FILENAME,0)\n",
        "pc_seq=tools.load_fasta(PC_FILENAME,1)\n",
        "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "print(\"Ready: train_set\")\n",
        "#train_set\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "print (\"Data reshape\")\n",
        "(X_train,y_train)=tools.make_kmers(K,MAXLEN,subset)\n",
        "#print (\"Data prep\")\n",
        "#X_train=tools.make_frequencies(K,X_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Ready: train_set\n",
            "Data reshape\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1HuSs8ZbeL4",
        "outputId": "38a46599-9173-4bcc-d99c-01649786e838"
      },
      "source": [
        "print (\"Compile the model\")\n",
        "model=build_model()\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "model.save(MODEL_FILE+'.model')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          1040      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 32)          4224      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 32)                6272      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 12,353\n",
            "Trainable params: 12,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "baa894bf-928e-43aa-a939-4844bb712e25"
      },
      "source": [
        "print (\"Cross valiation\")\n",
        "do_cross_validation(X_train,y_train,model)  \n",
        "print (\"Done\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross valiation\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/100\n",
            "453/453 [==============================] - 81s 139ms/step - loss: 0.6233 - accuracy: 0.6681 - val_loss: 0.5548 - val_accuracy: 0.7300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.5661 - accuracy: 0.7190 - val_loss: 0.5594 - val_accuracy: 0.7182\n",
            "Epoch 3/100\n",
            "453/453 [==============================] - 59s 129ms/step - loss: 0.5594 - accuracy: 0.7205 - val_loss: 0.5159 - val_accuracy: 0.7616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/100\n",
            "453/453 [==============================] - 59s 129ms/step - loss: 0.5431 - accuracy: 0.7349 - val_loss: 0.5083 - val_accuracy: 0.7672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.5619 - accuracy: 0.7291 - val_loss: 0.5178 - val_accuracy: 0.7511\n",
            "Epoch 6/100\n",
            "453/453 [==============================] - 60s 131ms/step - loss: 0.5446 - accuracy: 0.7390 - val_loss: 0.5474 - val_accuracy: 0.6822\n",
            "Epoch 7/100\n",
            "453/453 [==============================] - 59s 129ms/step - loss: 0.6063 - accuracy: 0.6842 - val_loss: 0.5875 - val_accuracy: 0.7064\n",
            "Epoch 8/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.5957 - accuracy: 0.6915 - val_loss: 0.5496 - val_accuracy: 0.7349\n",
            "Epoch 9/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.5694 - accuracy: 0.7031 - val_loss: 0.6566 - val_accuracy: 0.6046\n",
            "Epoch 10/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.5750 - accuracy: 0.7073 - val_loss: 0.5088 - val_accuracy: 0.7610\n",
            "Epoch 11/100\n",
            "453/453 [==============================] - 60s 131ms/step - loss: 0.5303 - accuracy: 0.7481 - val_loss: 0.5125 - val_accuracy: 0.7623\n",
            "Epoch 12/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.5411 - accuracy: 0.7387 - val_loss: 0.5133 - val_accuracy: 0.7610\n",
            "Epoch 13/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.5340 - accuracy: 0.7372 - val_loss: 0.4324 - val_accuracy: 0.8007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.4755 - accuracy: 0.7798 - val_loss: 0.4518 - val_accuracy: 0.7790\n",
            "Epoch 15/100\n",
            "453/453 [==============================] - 58s 127ms/step - loss: 0.4637 - accuracy: 0.7763 - val_loss: 0.4241 - val_accuracy: 0.8001\n",
            "Epoch 16/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.4509 - accuracy: 0.7797 - val_loss: 0.4039 - val_accuracy: 0.8144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.4016 - val_accuracy: 0.8107\n",
            "Epoch 18/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.4127 - accuracy: 0.8173 - val_loss: 0.3828 - val_accuracy: 0.8237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.4110 - accuracy: 0.8199 - val_loss: 0.3730 - val_accuracy: 0.8281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.4155 - accuracy: 0.8162 - val_loss: 0.3930 - val_accuracy: 0.8318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.4002 - accuracy: 0.8238 - val_loss: 0.3720 - val_accuracy: 0.8262\n",
            "Epoch 22/100\n",
            "453/453 [==============================] - 60s 131ms/step - loss: 0.4028 - accuracy: 0.8266 - val_loss: 0.3660 - val_accuracy: 0.8324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3978 - accuracy: 0.8258 - val_loss: 0.3885 - val_accuracy: 0.8194\n",
            "Epoch 24/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3897 - accuracy: 0.8305 - val_loss: 0.3961 - val_accuracy: 0.8274\n",
            "Epoch 25/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.4024 - accuracy: 0.8250 - val_loss: 0.3725 - val_accuracy: 0.8343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.3967 - accuracy: 0.8249 - val_loss: 0.3788 - val_accuracy: 0.8268\n",
            "Epoch 27/100\n",
            "453/453 [==============================] - 61s 134ms/step - loss: 0.4038 - accuracy: 0.8242 - val_loss: 0.3790 - val_accuracy: 0.8231\n",
            "Epoch 28/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.3920 - accuracy: 0.8280 - val_loss: 0.3764 - val_accuracy: 0.8274\n",
            "Epoch 29/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3789 - accuracy: 0.8350 - val_loss: 0.3541 - val_accuracy: 0.8442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3815 - accuracy: 0.8355 - val_loss: 0.3716 - val_accuracy: 0.8355\n",
            "Epoch 31/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.3951 - accuracy: 0.8259 - val_loss: 0.3575 - val_accuracy: 0.8361\n",
            "Epoch 32/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3856 - accuracy: 0.8327 - val_loss: 0.3586 - val_accuracy: 0.8374\n",
            "Epoch 33/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3799 - accuracy: 0.8387 - val_loss: 0.3595 - val_accuracy: 0.8367\n",
            "Epoch 34/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3846 - accuracy: 0.8315 - val_loss: 0.3553 - val_accuracy: 0.8417\n",
            "Epoch 35/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3823 - accuracy: 0.8356 - val_loss: 0.3481 - val_accuracy: 0.8417\n",
            "Epoch 36/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3826 - accuracy: 0.8361 - val_loss: 0.3629 - val_accuracy: 0.8392\n",
            "Epoch 37/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.3669 - accuracy: 0.8399 - val_loss: 0.3647 - val_accuracy: 0.8355\n",
            "Epoch 38/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.3760 - accuracy: 0.8380 - val_loss: 0.3783 - val_accuracy: 0.8312\n",
            "Epoch 39/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.3679 - accuracy: 0.8396 - val_loss: 0.3572 - val_accuracy: 0.8343\n",
            "Epoch 40/100\n",
            "453/453 [==============================] - 60s 133ms/step - loss: 0.3639 - accuracy: 0.8456 - val_loss: 0.3458 - val_accuracy: 0.8436\n",
            "Epoch 41/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3709 - accuracy: 0.8462 - val_loss: 0.3513 - val_accuracy: 0.8405\n",
            "Epoch 42/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3667 - accuracy: 0.8410 - val_loss: 0.4003 - val_accuracy: 0.8237\n",
            "Epoch 43/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3626 - accuracy: 0.8476 - val_loss: 0.3455 - val_accuracy: 0.8423\n",
            "Epoch 44/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3699 - accuracy: 0.8397 - val_loss: 0.3453 - val_accuracy: 0.8510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/100\n",
            "453/453 [==============================] - 59s 129ms/step - loss: 0.3575 - accuracy: 0.8479 - val_loss: 0.3397 - val_accuracy: 0.8510\n",
            "Epoch 46/100\n",
            "453/453 [==============================] - 60s 132ms/step - loss: 0.3672 - accuracy: 0.8431 - val_loss: 0.3395 - val_accuracy: 0.8510\n",
            "Epoch 47/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.3605 - accuracy: 0.8531 - val_loss: 0.3373 - val_accuracy: 0.8554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3586 - accuracy: 0.8481 - val_loss: 0.3438 - val_accuracy: 0.8498\n",
            "Epoch 49/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3480 - accuracy: 0.8516 - val_loss: 0.3598 - val_accuracy: 0.8535\n",
            "Epoch 50/100\n",
            "453/453 [==============================] - 57s 127ms/step - loss: 0.3555 - accuracy: 0.8489 - val_loss: 0.3322 - val_accuracy: 0.8523\n",
            "Epoch 51/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3530 - accuracy: 0.8502 - val_loss: 0.3419 - val_accuracy: 0.8523\n",
            "Epoch 52/100\n",
            "453/453 [==============================] - 58s 129ms/step - loss: 0.3460 - accuracy: 0.8529 - val_loss: 0.3390 - val_accuracy: 0.8485\n",
            "Epoch 53/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3416 - accuracy: 0.8526 - val_loss: 0.3255 - val_accuracy: 0.8641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 54/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.3410 - accuracy: 0.8565 - val_loss: 0.3366 - val_accuracy: 0.8454\n",
            "Epoch 55/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3465 - accuracy: 0.8535 - val_loss: 0.3265 - val_accuracy: 0.8529\n",
            "Epoch 56/100\n",
            "453/453 [==============================] - 59s 131ms/step - loss: 0.3423 - accuracy: 0.8597 - val_loss: 0.3200 - val_accuracy: 0.8641\n",
            "Epoch 57/100\n",
            "453/453 [==============================] - 59s 129ms/step - loss: 0.3459 - accuracy: 0.8527 - val_loss: 0.3251 - val_accuracy: 0.8579\n",
            "Epoch 58/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3348 - accuracy: 0.8595 - val_loss: 0.3147 - val_accuracy: 0.8734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 59/100\n",
            "453/453 [==============================] - 56s 124ms/step - loss: 0.3417 - accuracy: 0.8546 - val_loss: 0.3157 - val_accuracy: 0.8628\n",
            "Epoch 60/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3361 - accuracy: 0.8606 - val_loss: 0.3165 - val_accuracy: 0.8696\n",
            "Epoch 61/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.3257 - accuracy: 0.8658 - val_loss: 0.3122 - val_accuracy: 0.8703\n",
            "Epoch 62/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.3324 - accuracy: 0.8595 - val_loss: 0.3221 - val_accuracy: 0.8622\n",
            "Epoch 63/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3287 - accuracy: 0.8624 - val_loss: 0.3140 - val_accuracy: 0.8734\n",
            "Epoch 64/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.3315 - accuracy: 0.8598 - val_loss: 0.3091 - val_accuracy: 0.8684\n",
            "Epoch 65/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3181 - accuracy: 0.8690 - val_loss: 0.3321 - val_accuracy: 0.8554\n",
            "Epoch 66/100\n",
            "453/453 [==============================] - 59s 130ms/step - loss: 0.3209 - accuracy: 0.8640 - val_loss: 0.3146 - val_accuracy: 0.8647\n",
            "Epoch 67/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3146 - accuracy: 0.8627 - val_loss: 0.3150 - val_accuracy: 0.8672\n",
            "Epoch 68/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3161 - accuracy: 0.8689 - val_loss: 0.3078 - val_accuracy: 0.8734\n",
            "Epoch 69/100\n",
            "453/453 [==============================] - 56s 125ms/step - loss: 0.3214 - accuracy: 0.8689 - val_loss: 0.3201 - val_accuracy: 0.8659\n",
            "Epoch 70/100\n",
            "453/453 [==============================] - 58s 127ms/step - loss: 0.3096 - accuracy: 0.8751 - val_loss: 0.3092 - val_accuracy: 0.8647\n",
            "Epoch 71/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3166 - accuracy: 0.8631 - val_loss: 0.3068 - val_accuracy: 0.8709\n",
            "Epoch 72/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3103 - accuracy: 0.8703 - val_loss: 0.3072 - val_accuracy: 0.8690\n",
            "Epoch 73/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3013 - accuracy: 0.8773 - val_loss: 0.3131 - val_accuracy: 0.8659\n",
            "Epoch 74/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3119 - accuracy: 0.8715 - val_loss: 0.3020 - val_accuracy: 0.8672\n",
            "Epoch 75/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3133 - accuracy: 0.8733 - val_loss: 0.3042 - val_accuracy: 0.8715\n",
            "Epoch 76/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3117 - accuracy: 0.8708 - val_loss: 0.2968 - val_accuracy: 0.8740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 77/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3035 - accuracy: 0.8756 - val_loss: 0.3036 - val_accuracy: 0.8771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 78/100\n",
            "453/453 [==============================] - 57s 127ms/step - loss: 0.3067 - accuracy: 0.8729 - val_loss: 0.3037 - val_accuracy: 0.8740\n",
            "Epoch 79/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3038 - accuracy: 0.8798 - val_loss: 0.3031 - val_accuracy: 0.8752\n",
            "Epoch 80/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.3032 - accuracy: 0.8767 - val_loss: 0.3136 - val_accuracy: 0.8653\n",
            "Epoch 81/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2983 - accuracy: 0.8785 - val_loss: 0.2985 - val_accuracy: 0.8715\n",
            "Epoch 82/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2991 - accuracy: 0.8806 - val_loss: 0.2987 - val_accuracy: 0.8740\n",
            "Epoch 83/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.2979 - accuracy: 0.8800 - val_loss: 0.3005 - val_accuracy: 0.8746\n",
            "Epoch 84/100\n",
            "453/453 [==============================] - 56s 125ms/step - loss: 0.2894 - accuracy: 0.8857 - val_loss: 0.3075 - val_accuracy: 0.8690\n",
            "Epoch 85/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.3018 - accuracy: 0.8756 - val_loss: 0.2952 - val_accuracy: 0.8727\n",
            "Epoch 86/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.2816 - accuracy: 0.8890 - val_loss: 0.3010 - val_accuracy: 0.8715\n",
            "Epoch 87/100\n",
            "453/453 [==============================] - 57s 127ms/step - loss: 0.2999 - accuracy: 0.8806 - val_loss: 0.3146 - val_accuracy: 0.8696\n",
            "Epoch 88/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2851 - accuracy: 0.8842 - val_loss: 0.3083 - val_accuracy: 0.8703\n",
            "Epoch 89/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.2930 - accuracy: 0.8810 - val_loss: 0.3038 - val_accuracy: 0.8727\n",
            "Epoch 90/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.2739 - accuracy: 0.8928 - val_loss: 0.3055 - val_accuracy: 0.8715\n",
            "Epoch 91/100\n",
            "453/453 [==============================] - 56s 124ms/step - loss: 0.2824 - accuracy: 0.8891 - val_loss: 0.3024 - val_accuracy: 0.8777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 92/100\n",
            "453/453 [==============================] - 56s 124ms/step - loss: 0.2815 - accuracy: 0.8870 - val_loss: 0.2947 - val_accuracy: 0.8746\n",
            "Epoch 93/100\n",
            "453/453 [==============================] - 55s 122ms/step - loss: 0.2833 - accuracy: 0.8859 - val_loss: 0.3015 - val_accuracy: 0.8696\n",
            "Epoch 94/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.2830 - accuracy: 0.8840 - val_loss: 0.2944 - val_accuracy: 0.8721\n",
            "Epoch 95/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2775 - accuracy: 0.8897 - val_loss: 0.3210 - val_accuracy: 0.8672\n",
            "Epoch 96/100\n",
            "453/453 [==============================] - 58s 128ms/step - loss: 0.2828 - accuracy: 0.8853 - val_loss: 0.3145 - val_accuracy: 0.8684\n",
            "Epoch 97/100\n",
            "453/453 [==============================] - 57s 127ms/step - loss: 0.2826 - accuracy: 0.8846 - val_loss: 0.2976 - val_accuracy: 0.8759\n",
            "Epoch 98/100\n",
            "453/453 [==============================] - 57s 125ms/step - loss: 0.2819 - accuracy: 0.8832 - val_loss: 0.3070 - val_accuracy: 0.8771\n",
            "Epoch 99/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2714 - accuracy: 0.8891 - val_loss: 0.2983 - val_accuracy: 0.8771\n",
            "Epoch 100/100\n",
            "453/453 [==============================] - 57s 126ms/step - loss: 0.2749 - accuracy: 0.8906 - val_loss: 0.3326 - val_accuracy: 0.8659\n",
            "Fold 1, 100 epochs, 6538 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 87.77%\n",
            "\n",
            "1-way Cross Validation mean 87.77% (+/- 0.00%)\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4fh2GI8beMQ"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}