{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojm_6E9f9Kcf"
   },
   "source": [
    "# CNN 303\n",
    "Try to use TensorFlow Keras [Conv1D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D).\n",
    "\n",
    "Follow this [tutorial](https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/) on MissingLink.ai\n",
    "\n",
    "One-hot encoding of individual nucleotides will provide the required feature vector, small though it will be. Use Keras [one-hot](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/one_hot)?\n",
    "\n",
    "Keras convolution layers do not take a [padding/masking](https://www.tensorflow.org/guide/keras/masking_and_padding) parameter.\n",
    "\n",
    "Relevant [paper](https://academic.oup.com/nargab/article/2/1/lqz024/5701461?login=true) uses Conv1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hh6XplUvC0j0",
    "outputId": "ccf442f0-a4ee-440e-80b0-9cba0821ac51"
   },
   "outputs": [],
   "source": [
    "NC_FILENAME='ncRNA.tiny50.fasta'\n",
    "PC_FILENAME='pcRNA.tiny50.fasta'\n",
    "MODEL_FILE='CNN303'  \n",
    "DATAPATH=''\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "NC_FILENAME = DATAPATH+NC_FILENAME\n",
    "PC_FILENAME = DATAPATH+PC_FILENAME\n",
    "MODEL_FILE=DATAPATH+MODEL_FILE\n",
    "\n",
    "EPOCHS=100\n",
    "SPLITS=1\n",
    "K=1\n",
    "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "EMBED_DIMEN=2\n",
    "FILTERS=16\n",
    "KERNEL=3\n",
    "NEURONS=16\n",
    "DROP=0.25\n",
    "ACT=\"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9TY3HK9ZklE",
    "outputId": "584b4e5d-c4da-4f1f-ab26-600ecc172bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo!\n"
     ]
    }
   ],
   "source": [
    "# Load our own tools\n",
    "GITHUB = True\n",
    "if GITHUB:\n",
    "    #!pip install requests  # Uncomment this if necessary. Seems to be pre-installed.\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/ShepherdML/master/Strings/tools_fasta.py')\n",
    "    with open('tools_fasta.py', 'w') as f:\n",
    "        f.write(r.text)\n",
    "    # TO DO: delete the file after import\n",
    "import tools_fasta as tools\n",
    "tools.yahoo()  # If this prints \"Yahoo!\" the the import was successful.\n",
    "\n",
    "TOOLS_CHANGED = False   # set to True to re-run with a new version of tools\n",
    "if TOOLS_CHANGED:\n",
    "  from importlib import reload \n",
    "  tools=reload(tools)\n",
    "  print(dir(tools))   # run this to see EVERYTHING in the tools module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VQY7aTj29Kch"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LayerNormalization\n",
    "import time\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once this works, move this to our tools library.\n",
    "def onehot(seqs): \n",
    "    # Input list of digits from alphabet {0..4} .\n",
    "    # Return array of (5-bit bit-vectors) \n",
    "    newX = []\n",
    "    vectors=[]\n",
    "    vectors.append([1,0,0,0,0]) # 0 = N\n",
    "    vectors.append([0,1,0,0,0]) # 1 = A\n",
    "    vectors.append([0,0,1,0,0]) # 2 = C\n",
    "    vectors.append([0,0,0,1,0]) # 3 = G\n",
    "    vectors.append([0,0,0,0,1]) # 4 = T\n",
    "    for seq in X_train:\n",
    "        letters=[]\n",
    "        for num in seq:\n",
    "            hot = vectors[num]\n",
    "            letters.append(hot)\n",
    "        newX.append(letters)\n",
    "    return np.asarray(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1I-O_qzw9Kco"
   },
   "outputs": [],
   "source": [
    "# Once this works, move this to our tools library.\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
    "    return slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7jcg6Wl9Kc2"
   },
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qLFNO1Xa9Kc3"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    adam_default_learn_rate = 0.001\n",
    "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = adam_default_learn_rate*10,\n",
    "        #decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "        decay_steps=10000, decay_rate=0.99, staircase=True)\n",
    "    # learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "    alrd = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    #model.compile(loss=bc, optimizer=alrd, metrics=[\"accuracy\"])\n",
    "    model.compile(loss=bc, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    #embed_layer  = keras.layers.Embedding(\n",
    "    #    input_dim=VOCABULARY_SIZE, output_dim=4, mask_zero=True)\n",
    "    SHAPE=(1000,5)  # 1000 time steps, 5 features\n",
    "    clayer1 = keras.layers.Conv1D(FILTERS,KERNEL,activation=ACT,padding=\"same\",\n",
    "                                 input_shape=SHAPE)\n",
    "    clayer2 = keras.layers.Conv1D(FILTERS,KERNEL,activation=ACT,padding=\"same\")\n",
    "    clayer3 = keras.layers.MaxPooling1D(2)\n",
    "    clayer4 = keras.layers.Conv1D(FILTERS,KERNEL,activation=ACT,padding=\"same\")\n",
    "    clayer5 = keras.layers.Conv1D(FILTERS,KERNEL,activation=ACT,padding=\"same\")\n",
    "    clayer6 = keras.layers.MaxPooling1D(2)\n",
    "    clayer7 = keras.layers.Flatten()\n",
    "\n",
    "    dlayer1 = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt, input_shape=[1000])\n",
    "    #dlayer1 = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
    "    dlayer2 = keras.layers.Dropout(DROP)\n",
    "    dlayer3 = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
    "    dlayer4 = keras.layers.Dropout(DROP)\n",
    "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\", dtype=dt)\n",
    "\n",
    "    cnn = keras.models.Sequential()\n",
    "    #cnn.add(embed_layer)\n",
    "    cnn.add(clayer1)\n",
    "    cnn.add(clayer2)\n",
    "    cnn.add(clayer3)\n",
    "    #cnn.add(clayer4)\n",
    "    #cnn.add(clayer5)\n",
    "    #cnn.add(clayer6)\n",
    "    cnn.add(clayer7)\n",
    "    cnn.add(dlayer1)\n",
    "    #cnn.add(dlayer2)\n",
    "    cnn.add(dlayer3)\n",
    "    #cnn.add(dlayer4)\n",
    "    cnn.add(output_layer)\n",
    "    mlpc = compile_model(cnn)\n",
    "    return mlpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdIS2utq9Kc9"
   },
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BVo4tbB_9Kc-"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,given_model):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        fold += 1\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]        \n",
    "        # Avoid continually improving the same model.\n",
    "        model = compile_model(keras.models.clone_model(given_model))\n",
    "        bestname=MODEL_FILE+\".cv.\"+str(fold)+\".best\"\n",
    "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
    "            filepath=bestname, save_best_only=True, \n",
    "            monitor='val_accuracy', mode='max')]   \n",
    "        print(\"FIT\")\n",
    "        start_time=time.time()\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                callbacks=mycallbacks,\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "        end_time=time.time()\n",
    "        elapsed_time=(end_time-start_time)                        \n",
    "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "        best_model=keras.models.load_model(bestname)\n",
    "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
    "        cv_scores.append(scores[1] * 100)  \n",
    "    print()\n",
    "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd3Wj_vI9KdP"
   },
   "source": [
    "## Train on RNA lengths 200-1Kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to do:\n",
    "Stop calling make_kmers() then onehot().\n",
    "We're only using make_kmers convert ACGT to 1234.\n",
    "Instead, write an RNA_to_onehot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8fNo6sn9KdH",
    "outputId": "f7652e68-a3e0-4ed4-8a91-884a906a4ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Ready: train_set\n",
      "Data reshape\n",
      "First sequence as ints\n",
      "[4 2 1 4 2 1 3 4 2 2 1 1 1 3 4 2 2 1 3 2 1 3 4 4 3 4 2 2 2 4 2 2 4 3 3 1 1\n",
      " 4 2 2 3 4 4 3 3 2 4 4 3 2 2 4 2 2 3 3 2 1 4 4 4 4 4 3 3 2 2 2 4 4 3 2 2 4\n",
      " 4 4 4 1 3 3 3 4 4 3 2 2 1 3 1 4 4 1 1 1 1 3 1 2 1 3 3 1 4 3 2 2 2 1 3 2 4\n",
      " 1 3 4 4 4 3 1 1 4 4 4 4 1 3 1 4 1 1 1 2 1 1 2 3 1 1 4 1 1 4 4 4 2 3 4 1 3\n",
      " 2 1 4 1 1 1 4 1 4 3 4 2 2 2 1 1 3 2 4 4 1 3 4 4 4 3 3 3 1 2 1 4 1 2 4 4 1\n",
      " 4 3 2 4 1 1 1 1 1 1 2 1 4 4 1 4 4 3 3 4 4 3 4 4 4 1 4 2 4 3 1 3 1 4 4 2 1\n",
      " 3 1 1 4 4 1 1 3 2 1 4 4 4 4 1 4 1 4 4 4 4 1 4 4 4 3 2 4 3 2 2 4 2 4 3 3 2\n",
      " 2 1 2 2 2 4 1 2 4 2 4 2 4 4 2 2 4 1 1 2 1 2 4 2 4 2 4 2 2 2 4 2 4 2 2 2 1\n",
      " 3 4 4 4 4 3 4 2 2 3 2 2 4 4 2 2 2 4 3 2 2 4 2 2 4 2 4 4 2 4 3 3 3 3 3 1 3\n",
      " 4 4 1 3 1 4 2 3 1 3 4 4 3 4 1 1 2 1 1 3 1 1 2 1 4 3 2 2 1 2 4 3 4 2 4 2 3\n",
      " 2 4 3 3 2 4 3 2 1 3 2 3 4 3 4 3 3 4 2 2 2 2 4 4 1 2 2 1 3 1 3 4 3 1 3 3 1\n",
      " 4 3 2 3 1 1 3 1 3 1 1 3 3 4 3 3 2 4 3 4 2 4 3 2 1 1 1 2 2 1 3 3 1 1 3 1 3\n",
      " 1 3 2 2 2 4 2 1 2 2 3 3 3 1 1 2 2 2 3 4 2 2 1 3 2 4 3 2 2 1 2 2 4 4 3 1 1\n",
      " 2 4 4 3 3 1 2 4 4 2 2 1 1 3 2 2 4 2 2 1 3 1 1 2 4 3 4 3 1 3 3 3 1 4 1 1 1\n",
      " 4 3 4 1 4 3 1 4 4 4 4 1 1 1 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "First sequence as onehot\n",
      "[[0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "print(\"Load data from files.\")\n",
    "nc_seq=tools.load_fasta(NC_FILENAME,0)\n",
    "pc_seq=tools.load_fasta(PC_FILENAME,1)\n",
    "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "print(\"Ready: train_set\")\n",
    "#train_set\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "print (\"Data reshape\")\n",
    "(X_train,y_train)=tools.make_kmers(K,MAXLEN,subset)\n",
    "# print(X_train.shape)\n",
    "print(\"First sequence as ints\")\n",
    "print(X_train[0])  \n",
    "X_train=onehot(X_train)\n",
    "print(\"First sequence as onehot\")\n",
    "print(X_train[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1HuSs8ZbeL4",
    "outputId": "2c104352-0458-4bb2-e88a-7cddfb10d962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile the model\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1000, 16)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 16)          784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                128016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 129,345\n",
      "Trainable params: 129,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Assets written to: data/CNN303.model/assets\n"
     ]
    }
   ],
   "source": [
    "print (\"Compile the model\")\n",
    "model=build_model()\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once\n",
    "model.save(MODEL_FILE+'.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mQ8eW5Rg9KdQ",
    "outputId": "dbf1fadc-a15e-46f8-e0d5-d37988351d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross valiation\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7142 - accuracy: 0.5991 - val_loss: 0.2389 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: data/CNN303.cv.1.best/assets\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5331 - accuracy: 0.7361 - val_loss: 0.2993 - val_accuracy: 0.9000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.5039 - accuracy: 0.7734 - val_loss: 0.3008 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4502 - accuracy: 0.8118 - val_loss: 0.3022 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4364 - accuracy: 0.8151 - val_loss: 0.2875 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3852 - accuracy: 0.8630 - val_loss: 0.2463 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3119 - accuracy: 0.8842 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2798 - accuracy: 0.8914 - val_loss: 0.2573 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2590 - accuracy: 0.8953 - val_loss: 0.2671 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2114 - accuracy: 0.9214 - val_loss: 0.2890 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1633 - accuracy: 0.9905 - val_loss: 0.3094 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 86ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9000\n",
      "Fold 1, 100 epochs, 23 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABEnUlEQVR4nO3deXyU1b3H8c+ZLZOdLJAAQRIBZQmbILhUxCrV1gW1F9G2LrRqva3aqtV6rW2ttbeLvbWbV6W9LlgVrUuL1rpdSNErgqDIDiJr2CH7Otu5f0wyBEjIECaZZPJ99zWvmXnWX45TvnPO88zzGGstIiIiEj+OeBcgIiLS2ymMRURE4kxhLCIiEmcKYxERkThTGIuIiMSZwlhERCTO2g1jY8zjxpi9xphVbcw3xpjfG2M2GmNWGGNOiX2ZIiIiiSuanvGTwAVHmf9FYFjT40bgkeMvS0REpPdoN4yttQuBsqMsMh2YY8M+APoYY/rHqkAREZFEF4tjxgOB7S3elzZNExERkSi4unJnxpgbCQ9lk5ycPGHQoEEx2a6jrg7nvv0E+udjPZ4j99vQgGvPXqzHDY4Ofv/w+8HlIpCff5zVgsdXRlJjOdbhJGTcx729WLKAiXcRCUDtGBtqx9hQO3aMNQ7qkw8O9IZCIRwdzRBgw4YN+621fVvfmbXtPoBCYFUb8x4Drmrxfj3Qv71tTpgwwcZKw4YNds3Jw23FvFdbnX9gztN2zcnDrW/Png7vY9f9P7XrTplgQ6FQh7dhK3da+8SF1v44w9qXbrC2oarj2+okCxYsiHcJCUHtGBtqx9hQO8bG8bYjsNS2kYmxGKaeB1zTdFb1aUCltXZXDLYbNffgwVhj8G3Z0up835YtOFJTcfVt/QtJNDxFRYRqawnu39+xDexZA4+eCTuWwaWPwOWzISm9w/WIiEjiaHeY2hjzHDAVyDXGlAI/BtwA1tpHgdeBLwEbgTpgVmcV2xaHx0MwJxvf5s2tzvdt3oynsBBjOj5Q4yksBKBx8+aOhfriR8HfADf+C/qe1OE6REQk8bQbxtbaq9qZb4Fvx6yiDgrm5R21Z5x8yvH9/DmpqDC8rc1bSJ006RiL88PaeXDyFxXEIiJyhIS5AlewXziM7WH3Zw41NODftQtPU5h2lKt/f0xSUpuBf1Sb/gX15VB8+XHVICIiiSlhwjiQl0eoro7A3r2HTPdt3QrWRoaZO8o4HHgGD25zKPyoVr8CSRkw9LzjqkFERBJTwoRxMD8PCA8jt9T8Pqmo6Lj34SkqOvYwDvhg3asw/EJwJR13DSIikngSJowD/foB4NtyaFg2v/cMHnzc+/AUFuIrLcX6/dGv9Nl8aKiEURqiFhGR1iVMGIf69MEkJ7faM3bl5eFITT3ufXiKCiEYxLe9NPqVVr8M3j5w4tTj3r+IiCSmhAljmo7pNh7WM27cshlPDIao4eBQd9QncfkbYN3rMOJicB15ZTARERFIpDAm3HNt2TO21uLbvAVP4fEPUcPB3xpHfdx449vgq4ZRl8Vk/yIikpgSK4wLC/GXlmJ9PgCC5eWEqqpicvIWgDMzE2d29hHHpdu06mVIyYGis2OyfxERSUwJFcZJRUUQCuHbHr6JVHMPNlbD1M3bOvy4dKt8tbDhDRhxCTi79H4cIiLSwyRUGHsOO6bb/Hy8vzE+ZB+Fg2mM5pjxhjfBX6cLfYiISLsSK4wPO6br27wZ3G7cA2N3e+WkoiKC+/cTrK4++oKrX4bUfjD4zJjtW0REElNChbEzPR1nbi6NTWHcuHkLnhNOwDidMdtHJPCP1jturIZP34ZRl4IjdvsWEZHElFBhDOFhZN+WrUA4MI/3mtRHbL95KPxoZ1SvfwMCDbrQh4iIRCXhwjip6ZKVNhDAt21bzM6kbuYZNAgcjqP3jFe/DOkDYNDkmO5bREQSU8KFsaewiGBZGQ1r14HfH9OTtwCMx4O7oCAyFH6E+grY+E7TEHXCNa+IiHSChEuL5mHpmpKSpvex7Rk376PNnzetfx2CPg1Ri4hI1BIvjAvD4Vu9YH7T+8KY7yOpsBDf1q3YUOjImatehswToGBizPcrIiKJKfHCuGAgOJ00rlmLIzMTZ1ZW7PdRVIStryewZ8+hM+rKYNOC8BC1MTHfr4iIJKaEC2Pj8eApKADCPVjTCaHY3Ps+4ozqda9BKKALfYiIyDFJuDCGg0PTnTFEDQePSx9xJa5VL0NWIfQf1yn7FRGRxJSYYdx00lZnnLwF4OrXD0dKyqEncdXuh80LwyduaYhaRESOQULewaCzw9gYg2dALjWvv8Tuze+FJzZWQUUqNFbABz/rlP12hfQdpex+7//iXUaPp3aMDbVjbKgdO8bhTaLf977XJftKyDBOnTyJpOHDSR4/rnN2ULGNtNRPKdvmpnJJ7cHpjgzY+z7Qc3vGXr+fSvfH8S6jx1M7xobaMTbUjh3jTEtTGB8PT2EhJ/7tlc7ZeCgEf/82fcc20vfRBZA1uHP2EyclJSVMnTo13mX0eGrH2FA7xobasftLyDDuVB/+OXxs+OLfJ1wQi4hIfCTkCVyd5sBn8PaPYOg0OOWaeFcjIiIJQmEcrVAQXrkJXElwyR90xrSIiMSMhqmjYS0s/DWULoHL/wQZ/eNdkYiIJBCFcXsaq+G122HlC1D8ZRg9I94ViYhIglEYH82uT+Cvs6B8M5zzAzjrDg1Pi4hIzCmM27LsKXj9e5CSC9e+BoVnxrsiERFJUArj1lTthH/cDoWfg397AlKy412RiIgkMJ1N3ZrFj4ENwcW/UxCLiEinUxgfrrEalj4BI6eH78AkIiLSyRTGh/voaWishDNuiXclIiLSSyiMWwoG4IP/hsFnwsAJ8a5GRER6CYVxS2v+BpXb4fSb412JiIj0IgrjZtbC+7+HnKFw0gXxrkZERHoRhXGzLe+FL/Jx+s3gULOIiEjXUeo0W/TH8AU+xl4Z70pERKSXURgDfPo2bHgDJt8E7uR4VyMiIr2MwriuDP5+M/QdAWfeGu9qRESkF9LlMP/5fajbD1+ZG75XsYiISBfr3T3jNfPCt0accicMGB/vakREpJfqvWFcsw9euw36jw3fGlFERCROeucwtbXwj9ugsQoufRWc7nhXJCIivVhUPWNjzAXGmPXGmI3GmLtbmX+CMWaBMeZjY8wKY8yXYl9qDK38K6x9Fc65B/JGxrsaERHp5doNY2OME3gY+CIwErjKGHN4gt0LvGCtHQ9cCfx3rAuNmapd8Pr3oGASnKGzp0VEJP6i6RlPAjZaazdZa33AXGD6YctYIKPpdSawM3YlxpC1MO8WCPjgskfB4Yx3RSIiIhhr7dEXMObfgAustdc3vb8amGytvbnFMv2Bt4AsIBU4z1q7rJVt3QjcCJCXlzdh7ty5sfo7qKmpIS0t7ajL9N/5FidveJhPh97AjoKLYrbvRBJNO0r71I6xoXaMDbVjbBxvO55zzjnLrLUTW5sXqxO4rgKetNb+lzHmdOBpY0yxtTbUciFr7WxgNsDEiRPt1KlTY7R7KCkp4ajbK98K7z8FhWcx7Cu/YpiuP92qdttRoqJ2jA21Y2yoHWOjM9sxmkTaAQxq8b6gaVpL3wBeALDWLgK8QG4sCoyJUAj+/m3AwPSHdSMIERHpVqJJpQ+BYcaYImOMh/AJWvMOW2YbcC6AMWYE4TDeF8tCj0vpEtjyLpz3Y8gaHO9qREREDtFuGFtrA8DNwJvAWsJnTa82xtxvjLmkabE7gBuMMZ8AzwHX2fYORnelbR+En0ddFt86REREWhHVMWNr7evA64dN+1GL12uAM2NbWgxtXwLZQyC1+4yci4iINEv8g6fWwvbFMGhyvCsRERFpVeKHcdmm8F2ZBp0a70pERERalfhhvH1J+Fk9YxER6aYSP4xLl0BSBvQdHu9KREREWpX4Ybx9CRRM1KUvRUSk20rsMG6ogj2rNUQtIiLdWmKH8Y6lgIVBk+JdiYiISJsSIoz/9vEObplfy77qxkNnbF8CGBjY6nW5RUREuoWECGOHw1Dtg4o636Ezti+GvFHgzWh9RRERkW4gIcI4K8UNQHmd/+DEUBBKl2qIWkREur0ECWMPAOUte8b71kFjlU7eEhGRbi8hwrhPU8/4kGHqyMU+1DMWEZHuLSHC+GDPuMUw9fYlkJILWUVxqkpERCQ6CRHGKR4nLnPYMHXzzSGMiV9hIiIiUUiIMDbGkOYxVDb3jGv3Q9lnGqIWEZEeISHCGCDN3aJnvPPj8HOBfl8sIiLdX8KEcarbHDxmXLEt/KzjxSIi0gMkTBineczBs6mrdoBxQnp+fIsSERGJQsKE8SE948odkN5fd2oSEZEeIWHCOM0d7hlba8M948yB8S5JREQkKokTxh7wBy21viBUlkKGwlhERHqGxAljd/j3xOU1jVC1Uz1jERHpMRIujGvKd0OwETIK4lyRiIhIdBImjFObwrhhf9PPmtQzFhGRHiJhwjjNEw5jf/n28AQdMxYRkR4iccK4qWdMZWn4OVPD1CIi0jMkTBinhu+iiKN6Jzg94Ts2iYiI9AAJE8YuhyE9yUVS3S7IGACOhPnTREQkwSVUYvVJdZPasFtnUouISI+SUGGcleIhw7dXZ1KLiEiPklhhnOwkK7hfZ1KLiEiPklBhfIK7Gich9YxFRKRHSawwdpWFX+iYsYiI9CAJFcb9TTiMA2n941yJiIhI9BIqjPvZ/QBUefLiXImIiEj0EiqMc4L7qLNJlIVS412KiIhI1BIqjDN8e9hls6ls8Me7FBERkaglVBinNOxlp82hvFZhLCIiPUdChXFS3S522RzK63zxLkVERCRqCRPGJhTAWbuHXWRTUaeesYiI9ByueBcQKx5fGQbLXnLIVM9YRER6kIQJY2/DwZ81hdQzFhGRHiRhwjipMRzGdcn9CahnLCIiPUjChbE/NZ869YxFRKQHSZgTuJIa90NSBklpWTqbWkREepSowtgYc4ExZr0xZqMx5u42lrnCGLPGGLPaGPNsbMtsn7chfOvErBS3zqYWEZEepd1hamOME3gYmAaUAh8aY+ZZa9e0WGYY8B/AmdbacmNMv84quC1Jjfshv4isFI96xiIi0qNE0zOeBGy01m6y1vqAucD0w5a5AXjYWlsOYK3dG9sy25fUGO4ZZ6a4aQyEqPcFu7oEERGRDokmjAcC21u8L22a1tJJwEnGmP8zxnxgjLkgVgVGxd+Ax18JmQVkpXgA1DsWEZEeI1ZnU7uAYcBUoABYaIwZba2taLmQMeZG4EaAvLw8SkpKYrLz5LpdTAbW7axmh9kAwNsL32dwhjMm2+9NampqYvbfpTdTO8aG2jE21I6x0ZntGE0Y7wAGtXhf0DStpVJgsbXWD2w2xmwgHM4ftlzIWjsbmA0wceJEO3Xq1A6WfZjNC2EJDJ98LhWM5o/LP2DYyLGcMTQ3NtvvRUpKSojZf5deTO0YG2rH2FA7xkZntmM0w9QfAsOMMUXGGA9wJTDvsGX+RrhXjDEml/Cw9abYldmOyqbvBhkth6l1RrWIiPQM7YaxtTYA3Ay8CawFXrDWrjbG3G+MuaRpsTeBA8aYNcAC4E5r7YHOKvoIeSPZMvgKyAz/tAl0zFhERHqOqI4ZW2tfB14/bNqPWry2wO1Nj67Xfyxbir5KoTuZTBM+i7pCYSwiIj1EwlyBq1mSy0mKx6lhahER6TESLowBXfhDRER6lIQM4z66JKaIiPQgCRnGWSkeHTMWEZEeIyHDWD1jERHpSRIyjHXMWEREepIEDWM3lfV+QiEb71JERETalZBh3CfFQ8hCVYOGqkVEpPtL0DBuvgqXwlhERLq/hAzj3LQkAHZV1Me5EhERkfYlZBiPO6EPTofh/c+67vLYIiIiHZWQYZzhdTN+UB/e/XRfvEsRERFpV0KGMcBZw/qyYkcl5bX6iZOIiHRvCRvGnxuWi7VoqFpERLq9hA3jsQWZpHtdGqoWEZFuL2HD2OV0cOaQXN79dD/h2y2LiIh0TwkbxgBnnZTLjop6Nu2vjXcpIiIibUrsMB7aF4D3Pt0f50pERETaltBhfEJOCoNzUnTcWEREurWEDmOAs4blsuizA/gCoXiXIiIi0qpeEMZ9qfUF+XhbebxLERERaVXCh/HpQ3JwOgzv6rixiIh0UwkfxhleN+MG9eHdjQpjERHpnhI+jCF83HhFaQUVdbo0poiIdD+9JIz7Yi0sWL833qWIiIgcoVeE8fhBfRiUncyLy0rjXYqIiMgRekUYOxyGfztlEO9/doDtZXXxLkdEROQQvSKMAb48YSAAL32k3rGIiHQvvSaMC7JSOHNILi8uKyUU0o0jRESk++g1YQwwY2IBpeX1fLBZ9zgWEZHuo1eF8fmj8kn3uvjrUg1Vi4hI99GrwtjrdnLJ2AH8c9Uuqhr88S5HREQE6GVhDDBj4iAa/CH+sWJXvEsREREBemEYjy3IZFi/NF5Yuj3epYiIiAC9MIyNMVwxcRAfb6tg497qeJcjIiLS+8IY4NLxA3E7DXMWbY13KSIiIr0zjPumJ3HpuIG8sHQ7ZbW6eYSIiMRXrwxjgBunnEiDP8TT6h2LiEic9dowHpaXzrnD+/HUoi3U+4LxLkdERHqxXhvGAN88ewhltT5eXKYzq0VEJH56dRifWpjF+BP68Kd3NxPU9apFRCROenUYG2P45pQhbCur441Vu+NdjoiI9FKueBcQb9NG5lGUm8qj//qML43OxxgT75LaVB+oZ33ZetaWrWVd2TrWl61nePZwbhp7E/mp+fEuT0REOqjXh7HTYbjhrBO555WVLNp0gDOG5Ma7pFZtqtjErDdnUdZQBkBWUhYn9jmReZ/N47VNr3H1yKv5evHXSfekx7lSERE5Vr0+jAEuP2Ugv3pzHS8uLe2WYby7djc3vn0jBsNDUx+iOLeYvJQ8jDGUVpfyx+V/5M8r/8yLG15kVvEsZpw0Q6EsItKDRHXM2BhzgTFmvTFmozHm7qMs92VjjDXGTIxdiZ3P63Zy7vA8/nfdXvzBULzLOURlYyU3vX0TNf4aHp32KOcNPo/81IPD6QXpBfzirF/wwkUvMDJnJA8te4jz/noev1zyS3bU7Ihz9SIiEo12e8bGGCfwMDANKAU+NMbMs9auOWy5dOA7wOLOKLSzfWFUHi99VMqSzWWcObR79I7rA/Xc/L83s616G4+e9yjDs4e3ueyInBE8Nu0x1h5Yy1NrnmLuurk8t+45Tso6CadxRpZLcacwpM8QhvYZGn5kDSXDk9EVf46ISLdiraXWX0u1r5oqXxWVjZWUNZZR0VBBeUM5ARvglvG3dEkt0QxTTwI2Wms3ARhj5gLTgTWHLfdT4JfAnTGtsItMGdYXr9vBW6t3d4swDtkQd/3rLj7Z9wm/PvvXTOo/Kar1RuSM4Bdn/YLvnvJdnlv3HOvL12M4eFJaVWMVf9/4d+oCdZFpBWkFjMgZwcickdgGyxQ7BYfp1Sfai0gP5A/5qWiooKyhjPLGcsobyilrKIs8yhvC0yoaw2Fb6askZNseDe2X0q9bhfFAoOVVMUqByS0XMMacAgyy1v7DGNMjwzjZ42TKsL68tWYP910yKu5nVb+x+Q1KSku469S7+ELhF455/fzUfG6bcFur86y17KrdxcaKjWwo38CaA2tYe2Atb299G4BX//4qV4+8motPvBivy3tcf4eISLQaAg1UNFZQ0VhBVWMVdYE66vx1kedqfzVVjVWRnmy1r5pqfzU1vhpqfDVU+1u/E5/DOOiT1IdsbzZZ3iyG9BlCVlIWmUmZZHgyyEjKCD97MsjyZpHlDc9zO9xd9rcba49+sQtjzL8BF1hrr296fzUw2Vp7c9N7BzAfuM5au8UYUwJ8z1q7tJVt3QjcCJCXlzdh7ty5MftDampqSEtLO65t/N8OP39a6ePHp3spynS2v0InCdgAD+x8AK/xclf/u7qsl1oXrGNZxTIW+Rax3bedNEcaZ6adycS0ieS79dOpYxGLz6OoHWOlM9rRWovf+qkP1VNv68PPLR4NoQYabWPk2W/9hGwIiyVEiIANRJatC9VRF6rDb/1H3afB4HV4STbJpDhSSHYkh987kkl2JJPqSCXNmUaaIy3ynO5MJ8WREpN/R4+3Hc8555xl1tpWz6mKpme8AxjU4n1B07Rm6UAxUNLUm8wH5hljLjk8kK21s4HZABMnTrRTp06N9m9oV0lJCce7vXF1Ph5f/Q77vQOZNbXt47Od7Zm1z3Bg2wEeOe8RPjfwc12675SSFO49+16W7VnGnDVzeGv7W7xZ9SZFmUWcd8J5nDv4XEZmj4z7yEF3F4vPo6gdY6WkpITTzzo93KNsrKLaX01joJGGYAMNgQYagg3U+mup9deGe5n+msj0+kA9DYHwc52/LvwcqKPGX0MgFDjqfg2GFHcKqa5UPE4PTqcTp3HiMA48Tg99PX3J8GSQ7kkn3Z1OH28f+iSFH5lJmaS4U0hxpZDsSibFnUKaOy2uh9A68/MYTRh/CAwzxhQRDuErga80z7TWVgKRg6xH6xl3d31SPEwuyuat1Xu48/z4hHGtv5bZK2YzKX8SZw44My41GGOYmD+RifkT2Vu3l/nb5vPO1nd4fNXj/Gnln8hLyWPqoKmcM+gcTs0/FY/TE5c6RXqTkA1R1lDGnto9lDeWU+OvodZXG35uOgnpkNdNoVrlq6KqoYrA1qMHZzOXw0WaO41kVzJelxev00uyK5kMTwb5qfkku5JJdiWT5k4jzZNGhieDNHdaOFA96ZFwTXWnkuxK1hf3KLUbxtbagDHmZuBNwAk8bq1dbYy5H1hqrZ3X2UV2pS+MzOO+V9ewaV8NJ/bt+uGxp1Y/RVlDGbdNuK1bfIj7pfTjyuFXcuXwKylvKKdkewkl20uY99k8nl//PCmuFMb0HUNxbjHFOcWMyh0V+Q20iIRZa6kL1FHZWEllYyV1gbpDepwNwYZDeqo1/hqqGqvCQeqrYl/dPvbU7cEfansYN9WdGg7IppDM9GZSkF5AmieN8t3lFA8tjgRlmjstErTNz6me8Pr6ch0fUV30w1r7OvD6YdN+1MayU4+/rPiZNiqf+15dw1tr9nDT2V0bxvvr9/Pk6ieZNngaxbnFXbrvaGR5s7hs2GVcNuwyGgINLNm9hIWlC1mxbwVPrnqSgA1/8/Y4POQm50YeA9IGUJhRSGFmIYMzBpPhySBgAwRC4Ufz2YwGgzEGg8FiaT6fIWRD4X+sgo00BBrwBX0EQgH8IT/+kB9f0BcZTqsP1OML+khzp5HlzYoMeXmcHhzGgdM4cTqcpLhSSPekk+RM0hcHaZO1Fn/If8hJRLWBWmp9teHnpmHdyElE/ppIr7T55KLmoeHm/39EI80d7nE2n2A0uu9opqVOIz8ln/zUfLK92ZHeZ6o7lRRXCk5H2+e5lJSUMHX01Bi0iHQWXYHrMAP7JDN6YCZvrd7NTWcP6dJ9z14xG1/Qx63jb+3S/XaE1+VlSsEUphRMAaAx2Mi6snWsObCGXbW7OFB/gH11+9hWvY1FuxZRH6iPc8Wtczlch5xFmZmUGTnLsuWwW7+UfgztM5Qsb1a8S5bDWGsP+TLW3MNs/pLW/L4x2EhjsPGQYG35uvlYaK2/9mDo+mvbPS7aLNmVTLo7nTTPkT3TPkl9yPRkRsI12Z0cORbaPByc5EyKPPQFsfdRGLfiCyPz+K+3N7C3qoF+GV3z054dNTv46/q/8uVhX6Yws7BL9hlLSc4kxvYdy9i+Y4+YF7Ih9tbtZWvVVrZUbqEuUIfL4cJpnJFn2/y/Fmf3N/eSHcZBkjMJr9NLkisJj8ODx+nB7XDjcrhwO90kOw/+o+Zxeqj2VR/8LWFjJf6Qn6ANErIhAqEA9YF6qnxV1PhqIj/2r2ysZGfNTtbsX0OVr4qGYMMRf0tuci5D+wxlUPog+iT1ifResr3ZFKQXUJBeQJIzqVPbuifxBX2Rn6o0t3Hkta+SWl8tvpCPxmAj/qCfxmAjvpAPfzA84lFWVcZv/vYbfEEf/pA/MpIStEGstQRtkIZAA5ZjvwWq1+k9eIJQi3DM8eaQ5kkjxZUSeW5eLsWdEjle2twrTXWnkuZJ69KfwUjiURi34vzifP7r7Q28vXYPX508uEv2+Zc1fwHghjE3dMn+upLDOMhPDQ+vTe4/uf0VYiAzKdwLGZzR8f9+vqAv8nvGXTW7+LTiUzZWbGRj+Ube3vo21b5qgjZ4yDoGQ7+UfqQH03nz3TfDf3dKPnmpeZFjdS1PcOkpPSBrLTX+msjvP5tDtbzx4AUUWgvdo42IuB1u0txph3zB8jg9kdfJ7mRMnWFA1gDcDnfk4TCOyMNpnHhd3sgXsRRXSuQLmdcZ7m029zqbv8wlu5LbHdYV6WoK41YM65dGUW4q/1y5u0vCuNpXzcufvswFRRfoVojdiMfpISc5h5zkHIoyizhj4BmHzG++lF6Vr4r99fvZXr2dbdXb2F61ndU7VrNszzL21u09IrCbJTmTIsfV+yb3jVyQIMubRbY3m7yUPPqn9qdfSr+YBoe1lkAoQF2g7pCrEpU1lnGg/kD40RB+bnkBhraOeRoMmUmZkePzeSl5nJR10iHTml83P2d4MqI607akpISpZ0+N2d8u0l0pjFthjOFLo/N59F+bOFDTSE5a5w47vvzpy9QF6rh65NWduh+JLWNM5PjggLQBjOk7JjKv+feIwVCQ/fX72Ve/LzIs3nymbPP0A/UH2FS5iWV7llHRWHHEkKvTOMlLySMzKTPS0/M6vTiMIzK0b7EEbABfMDzk6wv6Iie6BUIBAjaAP+iPHDs92iUAMzwZ5CTnkO3NZkifIW2GaqYnkz7ecLC6HPqnROR46P9Bbbhw9AAeXvAZb67ew1cmn9Bp+wmEAvxl7V84Nf9URuaM7LT9SHw4HU7yUvPIS82LavlgKEilr5Ky+jL21O1hZ+1OdtXsYmftTqp94Qs11AfqqWisIGiDOHBEjq07jZMkV1L45ylJHtzOpmPqDjdO48TtcJPkSooM3ya7ksnyZpHjzYn0yHO8ObidOvYp0tUUxm0Y0T+dE3NT+cfKnZ0axm9vfZvdtbv5weQfdNo+pOdwOpxke7PJ9mYzNGtovMsRkS6iW/O0wRjDhWP6s+izA+yvaeyUfVhreWr1UwzOGBz5iZCIiPQ+CuOjuHBMf0IW3li1u1O2//Hej1l9YDVXj7hatywUEenFlABHcXJeOkP7pfGPFbs6Zftz1swhMymTi4dc3CnbFxGRnkFhfBTGGC4c3Z/Fmw+wt/rIC0Acj+1V25m/bT5XnHQFKe6UmG5bRER6FoVxO5qHqt+M8VD1E6ufwOVwcdXwq2K6XRER6XkUxu04KS+dk/LSeC2GQ9X76vbxt41/Y/rQ6fRN6Ruz7YqISM+kMI7ChaMHsGRLGXurYjNU/fSapwnaIF8f9fWYbE9ERHo2hXEULhyTj7XwzxgMVVc2VvL8+uc5v/B8BmUMikF1IiLS0ymMozC0XzrD89Njclb13HVzqQvU8Y3ib8SgMhERSQQK4yhdUJzPh1vL2Ffd8QuA1AfqeWbtM0wpmMLJ2SfHsDoREenJFMZRuqA4PFT99po9Hd7Gy5++THljOdePvj6GlYmISE+nMI7SyXnpFOak8Mbqjh039gf9PLHqCU7pdwrj+42PcXUiItKTKYyjZIzh/OJ83t+4n8p6/zGvP3f9XPbU7VGvWEREjtArw9haS32g/pjXu2BUPoGQZf66YxuqXnNgDQ8te4izC87mcwM/d8z7FRGRxJaQt1AMhoL8387/Y2fNTvbX7z/icaDhAIFQgKtHXs2dE+/EGBPVdscW9CE/w8sbq3Zz2fiCqNap8dVw57/uJNubzQNnPhD1vkREpPdIyDAuKS3huwu+C4DDOMj2ZpPjzSE3JZehfYaSk5zDnro9PL3maXxBH/dMviequyY5HIbzR+Xx/NLt1PkCpHiO3nzWWu7/4H521Ozg8fMfp4+3Twz+OhERSTQJGcaLdy0m2ZXMq5e+Sm5yLk6H84hlrLX0S+nHE6uewB/y8+PTfxxVIJ9fnM9Ti7aycMM+Lijuf9RlX9n4Cv/c/E9uHX8rp+Sd0uG/R0REEltChvGHuz/klH6nkJea1+YyxhhuO+U2PA4Pj614jEAowP1n3N9qcLc0qTCbrBQ3b6zafdQw3li+kZ8v/jmn9T+Nb4zWBT5ERKRtCRfGZQ1lbKzYyIUnXtjussYYbh5/M26Hmz8u/yOFGYXcMOaGo67jcjqYNjKPf67cjS8QwuM6sjftD/q5+927SXGn8POzfh5Vj1tERHqvhEuJZXuWATAxb2LU63xz7DeZ3H8yL336Etbadpe/oDif6sYA73+2v9X5j3zyCOvL1/OTM35CbnJu1HWIiEjvlHBhvHT3UpJdyYzKHXVM610y5BJ21Ozg470ft7vsGUNySUty8UYrN45Yvnc5/7Pqf7h82OVMHTT1mGoQEZHeKeHC+MM9HzK+33jcDvcxrXfeCeeR7Epm3mfz2l3W63Zy3oh+/GPlLup8gcj0On8dP3jvB/RP7c+dE+885tpFRKR3SqgwLm8o59PyTzk1/9RjXjfFncJ5J5zHW1veojHY/s0gvnraYKobAvx9+c7ItN8s+w3bq7fz0zN/Spon7ZhrEBGR3imhwrgjx4tbunjIxVT7qynZXtLushMHZzE8P52n3t+CtZa3trzF8+uf55qR13Toy4CIiPReCRXGH+7+sEPHi5tNyp9Ev+R+vPrZq+0ua4zh2jMKWbd3D9966/vc8a87GJE9gltOuaVD+xYRkd4rscK4g8eLmzkdTi4cciHv7XiPA/UH2l2+T+560oc8xHu73+T60dfz9JeeJsmZ1KF9i4hI75UwYVwTrOHT8k87PETd7OITLyZog/xz8z+PutzvPvodd717O32ScmjYcjNXDf2mglhERDokYS76sbFxI8BxH68dljWMEdkjeHXTq3xt5NdaXWZL5RaeWPUEF514EV8/+W6m/eY9nl2yje+ed9Jx7VtEpCP8fj+lpaU0NDS0Oj8zM5O1a9d2cVWJJ9p29Hq9FBQU4HZHP0qbOGHcsDF8vDinY8eLW7p4yMX86sNfsbF8I0Ozhh4x/w8f/wGP08MdE+8gNzmTs0/qy7OLt/Htc4bidibMYIOI9BClpaWkp6dTWFjY6p3hqqurSU9Pj0NliSWadrTWcuDAAUpLSykqKop62wmTHJ82fMq4vuNwOzt2vLilLxZ9Eadx8pe1fzli3ur9q3lr61tcM/KayNW1rjl9MHurG3lz9ZEXARER6WwNDQ3k5OToFq3dgDGGnJycNkcp2pIQYVzRUMFO/86Y/aQoNzmXr4z4Ci99+hLPrH3mkHm//ei3ZCVlcd2o6yLTpp7cj0HZycxZtDUm+xcROVYK4u6jI/8tEiKMm39fHMvf994x4Q6mDprKL5f8kvnb5gOwaOciPtj1ATeMueGQi3o4HYarJp3Aks1lbD1QG7MaRER6irQ0XejoeCREGGcmZXJKyikxOV7czOlw8qspv2JUzii+v/D7rNi3gt9+9Fv6p/bnipOvOGL5S8cNxBh45eMdMatBRER6h4QI44n5E5nVd1ZMjhe3lOxK5g/n/oGc5By+/ubXWXNgDd8e9+1Wf8I0oE8ypxXl8MrHO6K685OISCKy1nLnnXdSXFzM6NGjef755wHYtWsXU6ZMYdy4cRQXF/Puu+8SDAa57rrrIss+9NBDca4+fhLmbOrOkpucy3+f999c/frVDEofxEUnXtTmspedMpC7XlzBR9sqmDA4qwurFBEJ+8mrq1mzs+qQacFgEKfT2eFtjhyQwY8vjm7k8eWXX2b58uV88skn7N+/n1NPPZUpU6bw7LPPcv755/ODH/yAYDBIXV0dy5cvZ8eOHaxatQqAioqKDtfY0yVEz7iznZh5In+b/jceP/9xnI62P9BfLM4nyeXgbxqqFpFe6r333uOqq67C6XSSl5fH2WefzYcffsipp57KE088wX333cfKlStJT0/nxBNPZNOmTdxyyy288cYbZGRkxLv8uFHPOEp9U/q2u0y6180XRuXz6oqd/PCikXhc+q4jIl2rtR5sd/id8ZQpU1i4cCH/+Mc/uO6667j99tu55ppr+OSTT3jzzTd59NFHeeGFF3j88cfjWme8KC1i7LLxA6io81Oyfm+8SxER6XJnnXUWzz//PMFgkH379rFw4UImTZrE1q1bycvL44YbbuD666/no48+Yv/+/YRCIb785S/zwAMP8NFHH8W7/LhRzzjGzhrWl5xUD698vIMvjMqPdzkiIl3qsssuY9GiRYwdOxZjDL/61a/Iz8/nqaee4sEHH8TtdpOWlsacOXPYsWMHs2bNIhQKAfDzn/88ztXHT1RhbIy5APgd4AT+bK39xWHzbweuBwLAPuDr1tpeeQUMt9PBxWMH8OzibVTW+clMie0Z3iIi3VFNTQ0QvuDFgw8+yIMPPnjI/GuvvZZrr732iPV6c2+4pXaHqY0xTuBh4IvASOAqY8zIwxb7GJhorR0DvAj8KtaF9iSXnzIQXzDEP1buincpIiLSA0RzzHgSsNFau8la6wPmAtNbLmCtXWCtrWt6+wFQENsye5bRAzMZ0jeVVz4ujXcpIiLSA0QzTD0Q2N7ifSkw+SjLfwNo9WbAxpgbgRsB8vLyKCkpia7KKNTU1MR0e8drfB8fL35ay7OvzWdAWs85T667tWNPpXaMDbVjdDIzM6murm5zfjAYPOp8ic6xtGNDQ8MxfXZjegKXMeZrwETg7NbmW2tnA7MBJk6caKdOnRqzfZeUlBDL7R2v4omNzPv5fDaE8vjK1NhdprOzdbd27KnUjrGhdozO2rVrj/rTpe7w06ZEcCzt6PV6GT9+fNTbjqbLtgMY1OJ9QdO0QxhjzgN+AFxirW2MuoIElZuWxIVj+vPislJqGgPxLkdERLqxaML4Q2CYMabIGOMBrgTmtVzAGDMeeIxwEOsHtk2uPn0wNY0B3TxCRESOqt0wttYGgJuBN4G1wAvW2tXGmPuNMZc0LfYgkAb81Riz3Bgzr43N9SrjB/Vh9MBM5ry/RTePEBGRNkV1zNha+zrw+mHTftTi9XkxrishGGO45vTB3PniChZtOsAZQ3LjXZKISI8WCARwuRLvelU95zTfHurisQPISnEz5/1eeQ0UEelFLr30UiZMmMCoUaOYPXs2AG+88QannHIKY8eO5dxzzwXCZ8nPmjWL0aNHM2bMGF566SUA0tLSItt68cUXue666wC47rrruOmmm5g8eTJ33XUXS5Ys4fTTT2f8+PGcccYZrF+/Hgif7fy9732P4uJixowZwx/+8Afmz5/PpZdeGtnu22+/zWWXXdYFrXFsEu/rRTfjdTuZeeoJzF74GTsq6hnYJzneJYlIIvvn3bB75SGTkoMBcB7HP/f5o+GLv2h3sccff5zs7Gzq6+s59dRTmT59OjfccAMLFy6kqKiIsrIyAH7605+SmZnJypXhOsvLy9vddmlpKe+//z5Op5OqqireffddXC4X77zzDvfccw8vvfQSs2fPZsuWLSxfvhyXy0VZWRlZWVl861vfYt++ffTt25cnnniCr3/96x1vi06innEX+OrkEwB4drF6xyKSuH7/+98zduxYTjvtNLZv387s2bOZMmUKRUVFAGRnZwPwzjvv8O1vfzuyXlZW+/d/nzFjRuSezJWVlcyYMYPi4mJuu+02Vq9eHdnuN7/5zcgwdnZ2NsYYrr76av7yl79QUVHBokWL+OIXvxjTvzsW1DPuAoOyUzh3RB7PLdnOLZ8fhtfd8Zt8i4gcVSs92Pou+J1xSUkJ77zzDosWLSIlJYWpU6cybtw41q1bF/U2jDGR1w0NDYfMS01Njbz+4Q9/yDnnnMMrr7zCli1b2v0t+qxZs7j44ovxer3MmDGjWx5zVs+4i3zjc0WU1fp48v0t8S5FRCTmKisrycrKIiUlhXXr1vHBBx/Q0NDAwoUL2bx5M0BkmHratGk8/PDDkXWbh6nz8vJYu3YtoVCIV1555aj7GjhwIABPPvlkZPq0adN47LHHCAQCh+xvwIABDBgwgAceeIBZs2bF7o+OIYVxFzntxBzOObkvDy/YSHmtL97liIjE1AUXXEAgEGDEiBHcfffdnHbaafTt25fZs2dz+eWXM3bsWGbOnAnAvffeS3l5OcXFxYwdO5YFCxYA8Itf/IKLLrqIM844g/79+7e5r7vuuov/+I//YPz48ZHgBbj++us54YQTGDNmDGPHjuXZZ5+NzPvqV7/KoEGDGDFiRCe1wPEx8fr968SJE+3SpUtjtr2ecNm8DXuqueC3C7nujCJ+dPHhN77qHnpCO/YEasfYUDtGZ+3atUcNGV0OE26++WbGjx/PN77xjQ5v41jasbX/JsaYZdbaia0tr55xFzopL50rJg7i6Q+2sPVAbbzLERHpFSZMmMCKFSv42te+Fu9S2qQw7mK3TTsJl8PBg2+uj3cpIiK9wrJly1i4cCFJSUnxLqVNCuMulpfh5YazinhtxS6Wb6+IdzkiItINKIzj4Mazh5Cb5uE/X1+ra1aLiIjCOB7Sklx857yTWLK5jL8uLY13OSIiEmcK4zj5yqQTOGNIDj+at4r1u6vjXY6IiMSRwjhOnA7Db68cR1qSm28/+xF1vkD7K4mISEJSGMdRv3Qvv7tyHJ/tq+GHf1sd73JERLpMyzs0HW7Lli0UFxd3YTXxpzCOszOH5nLr54fx0kel/HXp9niXIyIicdD9rpbdC9167jCWbC7jh39fxfD8DEYXZMa7JBHpoX655JesKzv05gzBYDByx6OOGJ49nO9P+v5Rl7n77rsZNGhQ5G5M9913Hy6XiwULFlBeXo7f7+eBBx5g+vTpx7TvhoYG/v3f/52lS5ficrn4zW9+wznnnMPq1auZNWsWPp+PUCjESy+9xIABA7jiiisoLS0lGAzywx/+MHIJzu5OPeNuwOkw/O6qceSkJvG1/1nMqh2V8S5JROSYzJw5kxdeeCHy/oUXXuDaa6/llVde4aOPPmLBggXccccdx/xzzocffhhjDCtXruS5557j2muvpaGhgUcffZTvfOc7LF++nKVLl1JQUMAbb7zBgAED+OSTT1i1ahUXXHBBrP/MTqOecTfRL93L3BtP48rZH/DVPy/mmesnUzxQPWQROTat9WC74trU48ePZ+/evezcuZN9+/aRlZVFfn4+t912GwsXLsThcLBjxw727NlDfn5+1Nt97733uOWWWwAYPnw4gwcPZsOGDZx++un87Gc/o7S0lMsvv5xhw4YxevRo7rjjDr7//e9z0UUXcdZZZ3XWnxtz6hl3I4OyU3juhtNIS3Lxtf9ZzOqd6iGLSM8xY8YMXnzxRZ5//nlmzpzJM888w759+1i2bBnLly8nLy/viPsUd9RXvvIV5s2bR3JyMl/60peYP38+J510Eh999BGjR4/m3nvv5f7774/JvrqCwribOSEnHMgpbidf/fNiVpRWxLskEZGozJw5k7lz5/Liiy8yY8YMKisr6devH263mwULFrB169Zj3uZZZ53FM888A8CGDRvYtm0bJ598Mps2beLEE0/k1ltvZfr06axYsYKdO3eSkpLC1772Ne68804++uijWP+JnUZh3A2dkJPC3BtPJ9XjYuZjH/C/a/fEuyQRkXaNGjWK6upqBg4cSP/+/fnqV7/K0qVLGT16NHPmzGH48OHHvM1vfetbhEIhRo8ezcyZM3nyySdJSkrihRdeoLi4mHHjxrFq1SquueYaVq5cyaRJkxg3bhw/+clPuPfeezvhr+wcOmbcTZ2Qk8Ir3z6D659ayg1zlvKTS0Zx9emF8S5LROSoVq5cGXmdm5vLokWLWl2upqamzW0UFhayatUqALxeL0888cQRy9x9993cfffdh0w7//zzOf/88ztSdtypZ9yNNZ/U9fnh/fjh31fzs3+sIRTSjSVERBKNesbdXIrHxWNXT+T+V1fzp3c389m+Wh66YhyZKe54lyYiclxWrlzJ1Vdffci0pKQkFi9eHKeK4kdh3AM4HYb7LhnFkH5p/PS1NVz8x/d45GunMGqAfvokIj3X6NGjWb58ebzL6BY0TN1DGGO45vRC5t54Or5AiMv/+31dPlNEJEEojHuYCYOzeO3WzzFhcBZ3vriCu178hNpG3fFJRKQnUxj3QLlpScz5+iRuPmcof11WykV/eI9PtlfEuywREekghXEP5XI6+N75J/PcDafR6A/y5Ufe5+EFGwnqbGsRkR5HYdzDnXZiDv/8zhTOL87nwTfXc/kj77N0S1m8yxIROaqj3c+4N1IYJ4DMFDd/vGo8D80cy66Kev7t0UX8+1+WsfVAbbxLExHp1gKB7nHOjX7alCCMMVw2voDzR+Uze+EmHvvXJt5Zu4erJp3ArDOLKMpNjXeJItIFdv/nf9K49tD7GQeCQcqO437GSSOGk3/PPUddJpb3M66pqWH69Omtrjdnzhx+/etfY4xhzJgxPP300+zZs4ebbrqJTZs2AfDII48wYMAALrroosiVvH79619TU1PDfffdx9SpUxk3bhzvvfceV111FSeddBIPPPAAPp+PnJwcnnnmGfLy8qipqeGWW25h6dKlGGO466678Pl8rFixgt/+9rcA/OlPf2LNmjU89NBDHW1eQGGccFI8Lr573kl8ZdIJPPTOBp5bso05i7Yy9eS+XHdGIVOG9cXhMPEuU0QSzMyZM/nud78bCeMXXniBN998k1tvvZWMjAz279/PaaedxiWXXIIxR/83yOv18sorrxyx3po1a3jggQd4//33yc3NpawsfEju1ltv5eyzz+aVV14hGAxSU1NDeXn5Uffh8/lYunQpAOXl5XzwwQcYY/jzn//Mr371K/7rv/6Ln/70p2RmZkYu8blt2zays7P52c9+xoMPPojb7eaJJ57gscceO97mUxgnqn4ZXn5++Rhum3YSzy3ezl8Wb+W6Jz7khOwULh7bn4vGDGB4fnq7/6cQkZ6ltR5sT7ufsbWWe+6554j15s+fz4wZM8jNzQUgOzsbgPnz5zNnzhwAnE4nmZmZ7YbxzJkzI69LS0uZOXMmu3btwufzUVRUBMA777zD3LlzI8tlZWWRlpbG5z//eV577TVGjBiB3+9n9OjRx95gh1EYJ7h+6V6+c94w/n3qEP65ahcvLivl0X9t4uEFnzG0XxpfGt2fc07uy5iCPjjVYxaR49B8P+Pdu3cfcT9jt9tNYWFhVPcz7uh6LblcLkKhUOT94eunph48dHfLLbdw++23c8kll1BSUsJ999131G1ff/31/Od//ifDhw9n1qxZx1RXW3QCVy/hcTmYPm4gT39jMovvOZefXlpMTqqHP8z/lMv++30mPvA2tz73Me/t8FNaXhfvckWkB4rV/YzbWu/zn/88f/3rXzlw4ABAZJj63HPP5ZFHHgEgGAxSWVlJXl4ee/fu5cCBAzQ2NvLaa68ddX8DBw4E4KmnnopMnzZtGg8//HDkfXNve/LkyWzfvp1nn32Wq666KtrmOSqFcS+Um5bE1acN5vlvns5H907j91eN55zh/Xj/s/38eaWPz/1yAWf+Yj63Pb+cZxdvY/XOSvzBUPsbFpFeLVb3M25rvVGjRvGDH/yAs88+m7Fjx3L77bcD8Lvf/Y4FCxYwevRoJkyYwJo1a3C73fzoRz9i0qRJTJs27aj7vu+++5gxYwYTJkyIDIED3HvvvZSXl1NcXMzYsWN59913I/OuuOIKzjzzTLKysjrSVEcw1sbnIhETJ060zQfPY6GkpISpU6fGbHu9UShkeeYfCwjlnMiSzWUs3lzG/ppGINyzHtk/gzEFmQzPz+Dk/DSG5aWT4dXdo1qjz2NsqB2js3btWkaMGNHm/K44ZtwbtGzHiy66iNtuu41zzz231WVb+29ijFlmrZ3Y2vI6ZiwRDodhULqDqWcUcu0ZhVhr2XqgjhU7KlmxvYIVOyp5aVkptb5gZJ3+mV6G9E2jKDc18hiUnUJBVjJed8d/SiEi0h1VVFQwadIkxo4d22YQd4TCWNpkjKEwN5XC3FQuGTsACPeed1TUs2FPNev3VPPpnho27a/lb8t3UN1w6I/n+6YnUZCVzIDMZPpneunfJ/ycl+GlX3oSfdOTFNgivVhPvJ9xnz592LBhQ8y3qzCWY+JwGAZlpzAoO4VzR+RFpltrKav1sXl/LdvL6ygtq6e0vJ7SijrW7qrif9ftocF/5HHnzGQ3fdOTyEn1kJuWRG6ah+zUJLJT3WSleshO9ZCV4qFPips+yR68bod+jiWSIHQ/44MUxhITxhhy0pLISUtiYmH2EfOttVTU+dlZWc/eqkb2Vjc0PTeyv6aRAzU+1u6qYn9NI1UNbV+ezuNykJnsJsPrCj8nu8nwukn3ushIDj+ne92kJ7lI97pIS3KR1vSc4gk/K9AlEVlr9bnuJjpyLpbCWLqEMYasVA9ZqR5GDTj6sr5AiIp6H+W1fspqfZTX+ais91NR56ei3kdlnZ/qhgCV9f5Ib7y6IUB1gx9/sP3/EzgMpHpcpCQ5I88pbhfJHicpHufBZ3fTwxMO8GS3E2/k4Yi8TnI5ItOSXOHnUJxOjJTeyev1cuDAAXJychTIcWat5cCBA3i93mNaT2Es3Y7H5aBfupd+6cf2YbbW0hgIUdXgp6YhQE1jgJqGAFUNAep8AWobA9Q0BqltDFDnCz/XNk2v9wepqPOxsyJInS9Igz9IfdOjo7nqevt1klwOkpoC2+Ny4HGGnyPvXU48zoPv3U6D23lw2ebXbmd43sHXB5d1OUxkmstpWkwPL+NqsYzLaXA7HDidJjLNYdA/4D1cQUEBpaWl7Nu3r9X5DQ0NxxwOcqRo29Hr9VJQUHBM244qjI0xFwC/A5zAn621vzhsfhIwB5gAHABmWmu3HFMlIsfJGBPprfaL0a84mgO+OaCbQ7rBH6TRH6IhEKTBH6LBH8QXCD83BkKs+/QzBgw6gUZ/iMam6b5gCF8g/Ghseq6s9+MPhCLz/C2W8YdC+IO2S+5R7XYanI6WQR0OcFdTaDubgtvpOPje5Wh67zSHTA8/wus7TNN0p8FpDs53OQwOx6HTDpnXNP2zbX52LdmG0zQt7yAyLzLtsG00z3cYDpnvMAaHg8h6DtO8DVqsE17P6TCYlts5bH53+/Lidrsjl3BsTUlJCePHj+/CihJTZ7Zju2FsjHECDwPTgFLgQ2PMPGvtmhaLfQMot9YONcZcCfwSmHnk1kR6lpYBfyxK7HamTo3uAgftCYbswXAOhAO6+X0gaPEHQ00PSyAYwh+y+AMhAk1hHnlueh1oMS0YOrhOIBgiGCK8TNP7QKh5mfB+QtZGpvmDIYIhS2MgSNDStL6NPPyhEKFQuP7wOuHthUKWoLWR6e2OPKxZGZN2jCVjmkK9RZg7jAlPPyy0HU3LmsOWbQ755vVafokwbcx3OMDQ4n3Ts4nsr5V1DOzd28i8vcsPW+fgfgwH99tyPWMMBo7YfvP0g/s5uO7BbR2s9eB+wl+QmrcZ2V7TtmheJlJf03RaqxXg0G00r9Oy7ubpzcvQyt97cN1D13M5DaMGZHbJZyqanvEkYKO1dhOAMWYuMB1oGcbTgfuaXr8I/NEYY2y8rigikkCcDkOyx0kyifkzMNsUzM0B3fLx7nv/x+TTTycYsuFgb1om1GLZUItpgWB4O6EQ4em2KfxDlpDlkGXDr8PTmr8ghGz453vNy1l7cJ+2afmgDb9uub5tWrd527ZpXy23F7JNf6s9WIttsZ9Qi23YpnY5pI6QDX+Batr+ocuEX4en2xbbCG+3ti7I1rrwpSMj22ya37wNS7jW5nUsRP6W5u2GIsvH7ePSpTK8Llbcd36X7CuaMB4IbG/xvhSY3NYy1tqAMaYSyAH2x6JIEUlcxjQNh7cyr4/XQf/M5C6vKdF0xpXM7GFfOiwHg7s5zG3zc+jQac2h3vILQ3Pww5HbCId/8/6avhiEDu4TWnxxaGWdyBcNDn6xaPklI7JM04vmaV1585wuPYHLGHMjcGPT2xpjzPoYbj4XhX8sqB1jQ+0YG2rH2FA7xsbxtuPgtmZEE8Y7gEEt3hc0TWttmVJjjAvIJHwi1yGstbOB2VHs85gZY5a2dc1PiZ7aMTbUjrGhdowNtWNsdGY7RnPXpg+BYcaYImOMB7gSmHfYMvOAa5te/xswX8eLRUREotNuz7jpGPDNwJuEf9r0uLV2tTHmfmCptXYe8D/A08aYjUAZ4cAWERGRKER1zNha+zrw+mHTftTidQMwI7alHbNOGf7uhdSOsaF2jA21Y2yoHWOj09oxbvczFhERkbBojhmLiIhIJ0qIMDbGXGCMWW+M2WiMuTve9fQUxphBxpgFxpg1xpjVxpjvNE3PNsa8bYz5tOk5K9619gTGGKcx5mNjzGtN74uMMYubPpfPN50AKUdhjOljjHnRGLPOGLPWGHO6Po/HzhhzW9P/p1cZY54zxnj1eWyfMeZxY8xeY8yqFtNa/fyZsN83tecKY8wpx7PvHh/GLS7X+UVgJHCVMWZkfKvqMQLAHdbakcBpwLeb2u5u4H+ttcOA/216L+37DrC2xftfAg9Za4cC5YQvGytH9zvgDWvtcGAs4fbU5/EYGGMGArcCE621xYRPvG2+TLE+j0f3JHDBYdPa+vx9ERjW9LgReOR4dtzjw5gWl+u01vqA5st1SjustbustR81va4m/A/fQMLt91TTYk8Bl8alwB7EGFMAXAj8uem9AT5P+PKwoHZslzEmE5hC+NcZWGt91toK9HnsCBeQ3HTdhxRgF/o8tstau5DwL4JaauvzNx2YY8M+APoYY/p3dN+JEMatXa5zYJxq6bGMMYXAeGAxkGet3dU0azeQF6+6epDfAncBoab3OUCFtTbQ9F6fy/YVAfuAJ5qG+/9sjElFn8djYq3dAfwa2EY4hCuBZejz2FFtff5imj2JEMZynIwxacBLwHettVUt5zVdvEWn3B+FMeYiYK+1dlm8a+nhXMApwCPW2vFALYcNSevz2L6mY5rTCX+5GQCkcuTQq3RAZ37+EiGMo7lcp7TBGOMmHMTPWGtfbpq8p3m4pel5b7zq6yHOBC4xxmwhfJjk84SPffZpGiYEfS6jUQqUWmsXN71/kXA46/N4bM4DNltr91lr/cDLhD+j+jx2TFufv5hmTyKEcTSX65RWNB3X/B9grbX2Ny1mtby86bXA37u6tp7EWvsf1toCa20h4c/ffGvtV4EFhC8PC2rHdllrdwPbjTEnN006l/CtWvV5PDbbgNOMMSlN/x9vbkd9Hjumrc/fPOCaprOqTwMqWwxnH7OEuOiHMeZLhI/ZNV+u82fxrahnMMZ8DngXWMnBY533ED5u/AJwArAVuMJae/hJDdIKY8xU4HvW2ouMMScS7ilnAx8DX7PWNsaxvG7PGDOO8ElwHmATMItwp0Gfx2NgjPkJMJPwLyY+Bq4nfDxTn8ejMMY8B0wlfHemPcCPgb/Ryuev6YvOHwkfAqgDZllrl3Z434kQxiIiIj1ZIgxTi4iI9GgKYxERkThTGIuIiMSZwlhERCTOFMYiIiJxpjAWERGJM4WxiIhInCmMRURE4uz/AYMySzYNF+hJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.00%\n",
      "\n",
      "1-way Cross Validation mean 100.00% (+/- 0.00%)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Cross valiation\")\n",
    "do_cross_validation(X_train,y_train,model)  \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4fh2GI8beMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_302.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
