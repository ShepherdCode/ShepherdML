{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 301\n",
    "Slight modification of CNN 101.\n",
    "Use the old code base (not imported).\n",
    "Use one hot encoding, as before.\n",
    "Use first 10 of each sequence class truncated to 1000 bases.\n",
    "Expect overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import time\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "EPOCHS=100\n",
    "SPLITS=1\n",
    "K=1\n",
    "EMBED_DIMEN=16\n",
    "FILENAME='CNN301'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and partition sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume file was preprocessed to contain one line per seq.\n",
    "# Prefer Pandas dataframe but df does not support append.\n",
    "# For conversion to tensor, must avoid python lists.\n",
    "def load_fasta(filename,label):\n",
    "    DEFLINE='>'\n",
    "    labels=[]\n",
    "    seqs=[]\n",
    "    lens=[]\n",
    "    nums=[]\n",
    "    num=0\n",
    "    with open (filename,'r') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]!=DEFLINE:\n",
    "                seq=line.rstrip()\n",
    "                num += 1   # first seqnum is 1\n",
    "                seqlen=len(seq)\n",
    "                nums.append(num)\n",
    "                labels.append(label)\n",
    "                seqs.append(seq)\n",
    "                lens.append(seqlen)\n",
    "    df1=pd.DataFrame(nums,columns=['seqnum'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df\n",
    "\n",
    "# Split into train/test stratified by sequence length.\n",
    "def sizebin(df):\n",
    "    return pd.cut(df[\"seqlen\"],\n",
    "                              bins=[0,1000,2000,4000,8000,16000,np.inf],\n",
    "                              labels=[0,1,2,3,4,5])\n",
    "def make_train_test(data):\n",
    "    bin_labels= sizebin(data)\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37863)\n",
    "    # split(x,y) expects that y is the labels. \n",
    "    # Trick: Instead of y, give it it the bin labels that we generated.\n",
    "    for train_index,test_index in splitter.split(data,bin_labels):\n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "    return (train_set,test_set)\n",
    "\n",
    "def separate_X_and_y(data):\n",
    "    y=   data[['class']].copy()\n",
    "    X=   data.drop(columns=['class','seqnum','seqlen'])\n",
    "    return (X,y)\n",
    "\n",
    "def make_slice(data_set,min_len,max_len):\n",
    "    print(\"original \"+str(data_set.shape))\n",
    "    too_short = data_set[ data_set['seqlen'] < min_len ].index\n",
    "    no_short=data_set.drop(too_short)\n",
    "    print(\"no short \"+str(no_short.shape))\n",
    "    too_long = no_short[ no_short['seqlen'] >= max_len ].index\n",
    "    no_long_no_short=no_short.drop(too_long)\n",
    "    print(\"no long, no short \"+str(no_long_no_short.shape))\n",
    "    return no_long_no_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmer_table(K):\n",
    "    npad='N'*K\n",
    "    shorter_kmers=['']\n",
    "    for i in range(K):\n",
    "        longer_kmers=[]\n",
    "        for mer in shorter_kmers:\n",
    "            longer_kmers.append(mer+'A')\n",
    "            longer_kmers.append(mer+'C')\n",
    "            longer_kmers.append(mer+'G')\n",
    "            longer_kmers.append(mer+'T')\n",
    "        shorter_kmers = longer_kmers\n",
    "    all_kmers = shorter_kmers\n",
    "    kmer_dict = {}\n",
    "    kmer_dict[npad]=0\n",
    "    value=1\n",
    "    for mer in all_kmers:\n",
    "        kmer_dict[mer]=value\n",
    "        value += 1\n",
    "    return kmer_dict\n",
    "\n",
    "KMER_TABLE=make_kmer_table(K)\n",
    "\n",
    "def strings_to_vectors(data,uniform_len):\n",
    "    all_seqs=[]\n",
    "    for seq in data['sequence']:\n",
    "        i=0\n",
    "        seqlen=len(seq)\n",
    "        kmers=[]\n",
    "        while i < seqlen-K+1:\n",
    "            kmer=seq[i:i+K]\n",
    "            i += 1\n",
    "            value=KMER_TABLE[kmer]\n",
    "            kmers.append(value)\n",
    "        pad_val=0\n",
    "        while i < uniform_len:\n",
    "            kmers.append(pad_val)\n",
    "            i += 1\n",
    "        all_seqs.append(kmers)\n",
    "    pd2d=pd.DataFrame(all_seqs)\n",
    "    return pd2d   # return 2D dataframe, uniform dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(maxlen,dimen):\n",
    "    vocabulary_size=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
    "    act=\"relu\"\n",
    "    dt='float32'\n",
    "\n",
    "    neurons=32\n",
    "    rnn = keras.models.Sequential()\n",
    "    conv1_layer = keras.layers.Conv1D(filters=64,kernel_size=3,\n",
    "                activation=\"relu\",padding=\"valid\",input_shape=[maxlen,vocabulary_size])\n",
    "    pool1_layer = keras.layers.MaxPooling1D(2)\n",
    "    conv2_layer = keras.layers.Conv1D(neurons,3,activation=\"relu\",padding=\"same\")\n",
    "    conv3_layer = keras.layers.Conv1D(neurons,3,activation=\"relu\",padding=\"same\")\n",
    "    pool2_layer = keras.layers.MaxPooling1D(2)\n",
    "    conv4_layer = keras.layers.Conv1D(neurons,3,activation=\"relu\",padding=\"same\")\n",
    "    conv5_layer = keras.layers.Conv1D(neurons,3,activation=\"relu\",padding=\"same\")\n",
    "    flat1_layer = keras.layers.Flatten()\n",
    "    \n",
    "    dense1_layer = keras.layers.Dense(neurons,activation=act,dtype=dt,input_shape=[50,1000,5])\n",
    "    dense1_layer = keras.layers.Dense(neurons,activation=act,dtype=dt,input_shape=(1000,5))\n",
    "    drop1_layer = keras.layers.Dropout(0.5)\n",
    "    dense2_layer = keras.layers.Dense(neurons,activation=act,dtype=dt)\n",
    "    drop2_layer = keras.layers.Dropout(0.5)\n",
    "    output_layer = keras.layers.Dense(1,activation=act,dtype=dt)\n",
    "\n",
    "    #rnn.add(conv1_layer)\n",
    "    #rnn.add(pool1_layer)\n",
    "    #rnn.add(conv2_layer)\n",
    "    #rnn.add(conv3_layer)\n",
    "    #rnn.add(pool2_layer)\n",
    "    #rnn.add(conv4_layer)\n",
    "    #rnn.add(conv5_layer)\n",
    "    #rnn.add(flat1_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    #rnn.add(drop1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    #rnn.add(drop2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=opt,metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps,maxlen,dimen):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    rnn2=None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        rnn2=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        start_time=time.time()\n",
    "        history=rnn2.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "        end_time=time.time()\n",
    "        elapsed_time=(end_time-start_time)\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs, %d sec\"%(fold,eps,elapsed_time))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = rnn2.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "    return rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kmers(MINLEN,MAXLEN,train_set):\n",
    "    (X_train_all,y_train_all)=separate_X_and_y(train_set)\n",
    "\n",
    "    # The returned values are Pandas dataframes.\n",
    "    # print(X_train_all.shape,y_train_all.shape)\n",
    "    # (X_train_all,y_train_all)\n",
    "    # y: Pandas dataframe to Python list.\n",
    "    # y_train_all=y_train_all.values.tolist()\n",
    "    # The sequences lengths are bounded but not uniform.\n",
    "    X_train_all\n",
    "    #print(type(X_train_all))\n",
    "    #print(X_train_all.shape)\n",
    "    #print(X_train_all.iloc[0])\n",
    "    #print(len(X_train_all.iloc[0]['sequence']))\n",
    "\n",
    "    # X: List of string to List of uniform-length ordered lists of K-mers.\n",
    "    X_train_kmers=strings_to_vectors(X_train_all,MAXLEN)\n",
    "    # X: true 2D array (no more lists)\n",
    "    X_train_kmers.shape\n",
    "\n",
    "    print(\"transform...\")\n",
    "    # From pandas dataframe to numpy to list to numpy\n",
    "    #print(type(X_train_kmers))\n",
    "    num_seqs=len(X_train_kmers)\n",
    "    tmp_seqs=[]\n",
    "    for i in range(num_seqs):\n",
    "        kmer_sequence=X_train_kmers.iloc[i]\n",
    "        tmp_seqs.append(kmer_sequence)\n",
    "    X_train_kmers=np.array(tmp_seqs)\n",
    "    tmp_seqs=None\n",
    "    #print(type(X_train_kmers))\n",
    "    #print(X_train_kmers)\n",
    "\n",
    "    labels=y_train_all.to_numpy()\n",
    "    return (X_train_kmers,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from files.\n",
      "Put aside the test portion.\n",
      "Ready: train_set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqnum</th>\n",
       "      <th>class</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seqlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>ATAAAGAAGAATGAAATCATGACTGTTCCAGCAACATGGATGGAAC...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>ATGAGGGCCCTGGTGCTTCTGCTGTCCCTGTTCCTGCTGGGTGGCC...</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGGCAACCCGCTGGGGTCGTCTTCCATGCGGTAGAAGCTTTGTTC...</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>CGCGGAGGCCGCGGCTGGGGTTGAGCCGCCGGAGGCCGCGCCCGGC...</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>AGGAAATATTTTGCAAATCAGGAAATGACACCGGGCAAGGCCTCTG...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>GTCGGCGGCCGGAGCCCCCGCGCGGGCCGCCTATCGGGTGGAGATG...</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>AGGCTGGAGCTAGTCAGCAGCTTTTGCGTAAGCACTAGGCAGCACT...</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTCCACGCAGAACACAGCGCAGCGTCCTTTAAAGGAAGGCCAAAA...</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>GGCGGCGGTACGAGGCGCGCGCTCGGGGTCCCGGTCGCGAGGAGGA...</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>TTCGGGCTGCAGTAGCAGCATGGCGTCTTTCGACACCAAGGAGACT...</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqnum  class                                           sequence  seqlen\n",
       "37      38      0  ATAAAGAAGAATGAAATCATGACTGTTCCAGCAACATGGATGGAAC...     382\n",
       "30      31      1  ATGAGGGCCCTGGTGCTTCTGCTGTCCCTGTTCCTGCTGGGTGGCC...     942\n",
       "33      34      0  GGGGCAACCCGCTGGGGTCGTCTTCCATGCGGTAGAAGCTTTGTTC...     663\n",
       "13      14      1  CGCGGAGGCCGCGGCTGGGGTTGAGCCGCCGGAGGCCGCGCCCGGC...     855\n",
       "16      17      0  AGGAAATATTTTGCAAATCAGGAAATGACACCGGGCAAGGCCTCTG...     444\n",
       "..     ...    ...                                                ...     ...\n",
       "10      11      1  GTCGGCGGCCGGAGCCCCCGCGCGGGCCGCCTATCGGGTGGAGATG...     684\n",
       "45      46      0  AGGCTGGAGCTAGTCAGCAGCTTTTGCGTAAGCACTAGGCAGCACT...     363\n",
       "28      29      0  ACTCCACGCAGAACACAGCGCAGCGTCCTTTAAAGGAAGGCCAAAA...     808\n",
       "23      24      1  GGCGGCGGTACGAGGCGCGCGCTCGGGGTCCCGGTCGCGAGGAGGA...     567\n",
       "40      41      0  TTCGGGCTGCAGTAGCAGCATGGCGTCTTTCGACACCAAGGAGACT...     531\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load data from files.\")\n",
    "#nc_seq=load_fasta('data/ncRNA.gc34.processed.fasta',0)\n",
    "#pc_seq=load_fasta('data/pcRNA.gc34.processed.fasta',1)\n",
    "nc_seq=load_fasta('data/ncRNA.tiny50.fasta',0)\n",
    "pc_seq=load_fasta('data/pcRNA.tiny50.fasta',1)\n",
    "all_seq=pd.concat((nc_seq,pc_seq),axis=0)\n",
    "\n",
    "print(\"Put aside the test portion.\")\n",
    "(train_set,test_set)=make_train_test(all_seq)\n",
    "# Do this later when using the test data:\n",
    "# (X_test,y_test)=separate_X_and_y(test_set)\n",
    "\n",
    "nc_seq=None\n",
    "pc_seq=None\n",
    "all_seq=None\n",
    "\n",
    "print(\"Ready: train_set\")\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(seqs):\n",
    "    newX = []\n",
    "    vectors=[]\n",
    "    vectors.append([0,0,0,0,1])\n",
    "    vectors.append([1,0,0,0,0])\n",
    "    vectors.append([0,1,0,0,0])\n",
    "    vectors.append([0,0,1,0,0])\n",
    "    vectors.append([0,0,0,1,0])\n",
    "    for seq in X_train:\n",
    "        letters=[]\n",
    "        for num in seq:\n",
    "            hot = vectors[num]\n",
    "            letters.append(hot)\n",
    "        newX.append(letters)\n",
    "    return np.asarray(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Len 200-1Kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on full training set, slice by sequence length.\n",
      "Slice size range [200 - 1000)\n",
      "original (80, 4)\n",
      "no short (80, 4)\n",
      "no long, no short (80, 4)\n",
      "Sequence to Kmer\n",
      "transform...\n",
      "Length of list:\n",
      "80\n",
      "Length of first element:\n",
      "1000\n",
      "First element:\n",
      "[[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n",
      "Compile the model\n",
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000, 32)          192       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000, 1)           33        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Cross valiation\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.4550 - accuracy: 0.4479 - val_loss: 0.7574 - val_accuracy: 0.5625\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.7763 - accuracy: 0.5000 - val_loss: 0.7456 - val_accuracy: 0.4375\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.7317 - accuracy: 0.5104 - val_loss: 0.9174 - val_accuracy: 0.4375\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.8110 - accuracy: 0.5208 - val_loss: 0.8283 - val_accuracy: 0.4375\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7367 - accuracy: 0.5208 - val_loss: 0.7203 - val_accuracy: 0.4375\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6841 - accuracy: 0.5317 - val_loss: 0.6752 - val_accuracy: 0.5691\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6752 - accuracy: 0.5989 - val_loss: 0.6684 - val_accuracy: 0.5914\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6885 - accuracy: 0.5588 - val_loss: 0.6709 - val_accuracy: 0.5625\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6996 - accuracy: 0.4896 - val_loss: 0.6716 - val_accuracy: 0.5756\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6885 - accuracy: 0.5347 - val_loss: 0.6694 - val_accuracy: 0.5914\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6855 - accuracy: 0.5599 - val_loss: 0.6685 - val_accuracy: 0.5914\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.6775 - accuracy: 0.5778 - val_loss: 0.6763 - val_accuracy: 0.5691\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6674 - accuracy: 0.6066 - val_loss: 0.6914 - val_accuracy: 0.5691\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6704 - accuracy: 0.6128 - val_loss: 0.7054 - val_accuracy: 0.5691\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6725 - accuracy: 0.6155 - val_loss: 0.7093 - val_accuracy: 0.5691\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6729 - accuracy: 0.6118 - val_loss: 0.7000 - val_accuracy: 0.5691\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6919 - accuracy: 0.5890 - val_loss: 0.6834 - val_accuracy: 0.5691\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6765 - accuracy: 0.5940 - val_loss: 0.6770 - val_accuracy: 0.5691\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6741 - accuracy: 0.5954 - val_loss: 0.6736 - val_accuracy: 0.5691\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6743 - accuracy: 0.6173 - val_loss: 0.6738 - val_accuracy: 0.5691\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6727 - accuracy: 0.6108 - val_loss: 0.6745 - val_accuracy: 0.5691\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6728 - accuracy: 0.6093 - val_loss: 0.6763 - val_accuracy: 0.5691\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6688 - accuracy: 0.5955 - val_loss: 0.6766 - val_accuracy: 0.5691\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6707 - accuracy: 0.6109 - val_loss: 0.6808 - val_accuracy: 0.5691\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6679 - accuracy: 0.6070 - val_loss: 0.6832 - val_accuracy: 0.5691\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6722 - accuracy: 0.6003 - val_loss: 0.6850 - val_accuracy: 0.5691\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6687 - accuracy: 0.6094 - val_loss: 0.6856 - val_accuracy: 0.5691\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6637 - accuracy: 0.6206 - val_loss: 0.6849 - val_accuracy: 0.5691\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6698 - accuracy: 0.6062 - val_loss: 0.6812 - val_accuracy: 0.5691\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6676 - accuracy: 0.6142 - val_loss: 0.6796 - val_accuracy: 0.5691\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6749 - accuracy: 0.5933 - val_loss: 0.6761 - val_accuracy: 0.5691\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6652 - accuracy: 0.6088 - val_loss: 0.6739 - val_accuracy: 0.5691\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6674 - accuracy: 0.6076 - val_loss: 0.6745 - val_accuracy: 0.5691\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6717 - accuracy: 0.6099 - val_loss: 0.6777 - val_accuracy: 0.5691\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6675 - accuracy: 0.6088 - val_loss: 0.6802 - val_accuracy: 0.5691\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6607 - accuracy: 0.6259 - val_loss: 0.6831 - val_accuracy: 0.5691\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6590 - accuracy: 0.6324 - val_loss: 0.6856 - val_accuracy: 0.5691\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6725 - accuracy: 0.6012 - val_loss: 0.6830 - val_accuracy: 0.5691\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6657 - accuracy: 0.6145 - val_loss: 0.6807 - val_accuracy: 0.5691\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6690 - accuracy: 0.6052 - val_loss: 0.6765 - val_accuracy: 0.5691\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6689 - accuracy: 0.6167 - val_loss: 0.6776 - val_accuracy: 0.5691\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6713 - accuracy: 0.5989 - val_loss: 0.6767 - val_accuracy: 0.5691\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6647 - accuracy: 0.6157 - val_loss: 0.6777 - val_accuracy: 0.5691\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6673 - accuracy: 0.6124 - val_loss: 0.6797 - val_accuracy: 0.5691\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6687 - accuracy: 0.6081 - val_loss: 0.6811 - val_accuracy: 0.5691\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6686 - accuracy: 0.6053 - val_loss: 0.6802 - val_accuracy: 0.5691\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6689 - accuracy: 0.6081 - val_loss: 0.6811 - val_accuracy: 0.5691\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6646 - accuracy: 0.6248 - val_loss: 0.6835 - val_accuracy: 0.5691\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6754 - accuracy: 0.5937 - val_loss: 0.6799 - val_accuracy: 0.5691\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6710 - accuracy: 0.6020 - val_loss: 0.6778 - val_accuracy: 0.5691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6652 - accuracy: 0.6229 - val_loss: 0.6790 - val_accuracy: 0.5691\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6775 - accuracy: 0.5857 - val_loss: 0.6765 - val_accuracy: 0.5691\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6673 - accuracy: 0.6080 - val_loss: 0.6766 - val_accuracy: 0.5691\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6620 - accuracy: 0.6190 - val_loss: 0.6779 - val_accuracy: 0.5691\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6713 - accuracy: 0.6039 - val_loss: 0.6807 - val_accuracy: 0.5691\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6699 - accuracy: 0.6065 - val_loss: 0.6829 - val_accuracy: 0.5691\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6666 - accuracy: 0.6194 - val_loss: 0.6858 - val_accuracy: 0.5691\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6753 - accuracy: 0.5961 - val_loss: 0.6815 - val_accuracy: 0.5691\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6683 - accuracy: 0.6084 - val_loss: 0.6785 - val_accuracy: 0.5691\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6627 - accuracy: 0.6214 - val_loss: 0.6772 - val_accuracy: 0.5691\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6683 - accuracy: 0.6060 - val_loss: 0.6758 - val_accuracy: 0.5691\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6695 - accuracy: 0.6079 - val_loss: 0.6771 - val_accuracy: 0.5691\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6687 - accuracy: 0.6039 - val_loss: 0.6780 - val_accuracy: 0.5691\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6675 - accuracy: 0.6048 - val_loss: 0.6788 - val_accuracy: 0.5691\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6627 - accuracy: 0.6217 - val_loss: 0.6824 - val_accuracy: 0.5691\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6662 - accuracy: 0.6142 - val_loss: 0.6844 - val_accuracy: 0.5691\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6690 - accuracy: 0.6078 - val_loss: 0.6831 - val_accuracy: 0.5691\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6672 - accuracy: 0.6160 - val_loss: 0.6831 - val_accuracy: 0.5691\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6704 - accuracy: 0.6053 - val_loss: 0.6772 - val_accuracy: 0.5691\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6755 - accuracy: 0.5904 - val_loss: 0.6744 - val_accuracy: 0.5691\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6679 - accuracy: 0.6093 - val_loss: 0.6755 - val_accuracy: 0.5691\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6670 - accuracy: 0.6050 - val_loss: 0.6767 - val_accuracy: 0.5691\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6696 - accuracy: 0.6013 - val_loss: 0.6798 - val_accuracy: 0.5691\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6721 - accuracy: 0.5957 - val_loss: 0.6820 - val_accuracy: 0.5691\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6671 - accuracy: 0.6100 - val_loss: 0.6845 - val_accuracy: 0.5691\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6711 - accuracy: 0.6034 - val_loss: 0.6841 - val_accuracy: 0.5691\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6727 - accuracy: 0.5999 - val_loss: 0.6817 - val_accuracy: 0.5691\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6719 - accuracy: 0.6042 - val_loss: 0.6819 - val_accuracy: 0.5691\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6711 - accuracy: 0.6019 - val_loss: 0.6784 - val_accuracy: 0.5691\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6643 - accuracy: 0.6184 - val_loss: 0.6780 - val_accuracy: 0.5691\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6699 - accuracy: 0.6013 - val_loss: 0.6762 - val_accuracy: 0.5691\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.6736 - accuracy: 0.6123 - val_loss: 0.6804 - val_accuracy: 0.5691\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6696 - accuracy: 0.6027 - val_loss: 0.6785 - val_accuracy: 0.5691\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6711 - accuracy: 0.5994 - val_loss: 0.6784 - val_accuracy: 0.5691\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6794 - accuracy: 0.5826 - val_loss: 0.6790 - val_accuracy: 0.5691\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6635 - accuracy: 0.6193 - val_loss: 0.6817 - val_accuracy: 0.5691\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6658 - accuracy: 0.6207 - val_loss: 0.6853 - val_accuracy: 0.5691\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6678 - accuracy: 0.6137 - val_loss: 0.6848 - val_accuracy: 0.5691\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6750 - accuracy: 0.5952 - val_loss: 0.6791 - val_accuracy: 0.5691\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6653 - accuracy: 0.6144 - val_loss: 0.6758 - val_accuracy: 0.5691\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6760 - accuracy: 0.5901 - val_loss: 0.6741 - val_accuracy: 0.5691\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6664 - accuracy: 0.6118 - val_loss: 0.6754 - val_accuracy: 0.5691\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6662 - accuracy: 0.6193 - val_loss: 0.6800 - val_accuracy: 0.5691\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.6684 - accuracy: 0.6071 - val_loss: 0.6824 - val_accuracy: 0.5691\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6693 - accuracy: 0.6048 - val_loss: 0.6812 - val_accuracy: 0.5691\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6701 - accuracy: 0.6062 - val_loss: 0.6826 - val_accuracy: 0.5691\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6646 - accuracy: 0.6158 - val_loss: 0.6807 - val_accuracy: 0.5691\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6618 - accuracy: 0.6227 - val_loss: 0.6804 - val_accuracy: 0.5691\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6694 - accuracy: 0.6050 - val_loss: 0.6788 - val_accuracy: 0.5691\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6733 - accuracy: 0.6029 - val_loss: 0.6799 - val_accuracy: 0.5691\n",
      "Fold 1, 100 epochs, 15 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 56.91%\n",
      "\n",
      "Validation core mean 56.91% (+/- 0.00%)\n",
      "INFO:tensorflow:Assets written to: CNN301.short.model/assets\n"
     ]
    }
   ],
   "source": [
    "MINLEN=200\n",
    "MAXLEN=1000\n",
    "\n",
    "print(\"Working on full training set, slice by sequence length.\")\n",
    "print(\"Slice size range [%d - %d)\"%(MINLEN,MAXLEN))\n",
    "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "(X_train,y_train)=make_kmers(MINLEN,MAXLEN,subset)\n",
    "X_train=onehot(X_train)\n",
    "print(\"Length of list:\")\n",
    "print(len(X_train))\n",
    "print(\"Length of first element:\")\n",
    "print(len(X_train[0]))\n",
    "print(\"First element:\")\n",
    "print(X_train[0])\n",
    "print (\"Compile the model\")\n",
    "model=build_model(MAXLEN,EMBED_DIMEN)\n",
    "print(model.summary())  # Print this only once\n",
    "print (\"Cross valiation\")\n",
    "model1=do_cross_validation(X_train,y_train,EPOCHS,MAXLEN,EMBED_DIMEN)\n",
    "model1.save(FILENAME+'.short.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
