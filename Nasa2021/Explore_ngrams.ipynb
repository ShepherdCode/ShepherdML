{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams\n",
    "We commonly extract K-mers from RNA sequence. \n",
    "K-mers are called n-grams in TensorFlow.\n",
    "They are substrings of length K or length n.\n",
    "We have home-grown code to extract K-mers in Strings/tools_fasta.py.\n",
    "Here, explore the TensorFlow ngrams class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Avoid the old documentation for \n",
    "(ngrams)[https://www.tensorflow.org/tfx/transform/api_docs/python/tft/ngrams]. \n",
    "The only way to know it is TensorFlow 1 is that it doesn't many any version. \n",
    "\n",
    "Here is the documentation for \n",
    "(ngrams)[https://www.tensorflow.org/api_docs/python/tf/strings/ngrams] \n",
    "in TensorFlow 2.\n",
    "The documentation is very hard to understand. The examples are not helpful.\n",
    "\n",
    "This simple text intro \n",
    "(blog)[https://dzlab.github.io/nlp/2019/12/25/tensorflow-text-intro/] \n",
    "demonstrates how to use TensorFlow ngrams.\n",
    "\n",
    "This \n",
    "(tutorial)[https://blog.codecentric.de/en/2019/07/move-n-gram-extraction-into-your-keras-model/] \n",
    "shows how to implement ngrams as convolutions with numpy \n",
    "or Keras lambda function\n",
    "or Keras 1D convolution.\n",
    "\n",
    "Somebody built a Keras Layer called \n",
    "(NGram)[https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/ngram.py].\n",
    "Not clear why. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=\n",
      " ['ABCDEFG', 'HIJKLMN', 'OPQRSTU', 'VWXYZAB']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.strings import ngrams\n",
    "data=[]\n",
    "data.append('ABCDEFG')\n",
    "data.append('HIJKLMN')\n",
    "data.append('OPQRSTU')\n",
    "data.append('VWXYZAB')\n",
    "print(\"data=\\n\",data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2grams=\n",
      " tf.Tensor([b'ABCDEFG HIJKLMN' b'HIJKLMN OPQRSTU' b'OPQRSTU VWXYZAB'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ng=ngrams(data,2)\n",
    "print(\"2grams=\\n\",ng)\n",
    "# This generates all consecutive pairs of words separated by space (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'B', 'C', 'D', 'E', 'F', 'G'],\n",
       " ['H', 'I', 'J', 'K', 'L', 'M', 'N'],\n",
       " ['O', 'P', 'Q', 'R', 'S', 'T', 'U'],\n",
       " ['V', 'W', 'X', 'Y', 'Z', 'A', 'B']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert strings to character arrays.\n",
    "letters=list(map(list,data))\n",
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2grams=\n",
      " tf.Tensor(\n",
      "[[b'A B C' b'B C D' b'C D E' b'D E F' b'E F G']\n",
      " [b'H I J' b'I J K' b'J K L' b'K L M' b'L M N']\n",
      " [b'O P Q' b'P Q R' b'Q R S' b'R S T' b'S T U']\n",
      " [b'V W X' b'W X Y' b'X Y Z' b'Y Z A' b'Z A B']], shape=(4, 5), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ng=ngrams(letters,3)\n",
    "print(\"2grams=\\n\",ng)\n",
    "# This generates 3-mers with spaces (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2grams=\n",
      " tf.Tensor(\n",
      "[[b'ABC' b'BCD' b'CDE' b'DEF' b'EFG']\n",
      " [b'HIJ' b'IJK' b'JKL' b'KLM' b'LMN']\n",
      " [b'OPQ' b'PQR' b'QRS' b'RST' b'STU']\n",
      " [b'VWX' b'WXY' b'XYZ' b'YZA' b'ZAB']], shape=(4, 5), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ng=ngrams(letters,3,separator='')\n",
    "print(\"2grams=\\n\",ng)\n",
    "# This generates 3-mers the way we like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
