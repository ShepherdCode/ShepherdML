{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_302.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# LSTM 302\n",
        "Start with LSTM 201 and modify it to use our updated code infrastructure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh6XplUvC0j0",
        "outputId": "bd80fd1b-f47e-4ef9-e1de-c5af808c6099"
      },
      "source": [
        "NC_FILENAME='ncRNA.gc34.processed.fasta'\n",
        "PC_FILENAME='pcRNA.gc34.processed.fasta'\n",
        "MODEL_FILE='LSTM302'   \n",
        "DATAPATH=''\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "NC_FILENAME = DATAPATH+NC_FILENAME\n",
        "PC_FILENAME = DATAPATH+PC_FILENAME\n",
        "MODEL_FILE=DATAPATH+MODEL_FILE\n",
        "\n",
        "EPOCHS=200\n",
        "SPLITS=5\n",
        "K=3\n",
        "VOCABULARY_SIZE=4**K+1   # e.g. K=3 => 64 DNA K-mers + 'NNN'\n",
        "EMBED_DIMEN=16\n",
        "NEURONS=16\n",
        "DROP=0.25\n",
        "ACT=\"tanh\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9TY3HK9ZklE",
        "outputId": "07b17cdd-221c-4f5e-8f6a-10fd5af7a691"
      },
      "source": [
        "# Load our own tools\n",
        "GITHUB = True\n",
        "if GITHUB:\n",
        "    #!pip install requests  # Uncomment this if necessary. Seems to be pre-installed.\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/ShepherdML/master/Strings/tools_fasta.py')\n",
        "    with open('tools_fasta.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "    # TO DO: delete the file after import\n",
        "import tools_fasta as tools\n",
        "tools.yahoo()  # If this prints \"Yahoo!\" the the import was successful.\n",
        "\n",
        "TOOLS_CHANGED = False   # set to True to re-run with a new version of tools\n",
        "if TOOLS_CHANGED:\n",
        "  from importlib import reload \n",
        "  tools=reload(tools)\n",
        "  print(dir(tools))   # run this to see EVERYTHING in the tools module"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yahoo!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LayerNormalization\n",
        "import time\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx(dt)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jcg6Wl9Kc2"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFNO1Xa9Kc3"
      },
      "source": [
        "def compile_model(model):\n",
        "    print(\"COMPILE...\")\n",
        "    #adam_default_learn_rate = 0.001\n",
        "    #schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    #    initial_learning_rate = adam_default_learn_rate*10,\n",
        "    #    decay_steps=10000, decay_rate=0.99, staircase=True)\n",
        "    # #NOTE learn rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
        "    #alrd = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "    #model.compile(loss=bc, optimizer=alrd, metrics=[\"accuracy\"])\n",
        "\n",
        "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    model.compile(loss=bc, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    print(\"...COMPILED\")\n",
        "    return model\n",
        "\n",
        "def build_model():\n",
        "    embed_layer  = keras.layers.Embedding(\n",
        "        input_dim=VOCABULARY_SIZE, output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "    rnn1_layer =   keras.layers.LSTM(NEURONS, return_sequences=True, \n",
        "          input_shape=[1000,EMBED_DIMEN], activation=ACT, dropout=DROP) \n",
        "    rnn2_layer =  keras.layers.LSTM(NEURONS, return_sequences=False, \n",
        "        activation=ACT, dropout=DROP) \n",
        "    dense1_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    drop1_layer = keras.layers.Dropout(DROP)\n",
        "    dense2_layer = keras.layers.Dense(NEURONS, activation=ACT,dtype=dt)\n",
        "    drop2_layer = keras.layers.Dropout(DROP)\n",
        "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\", dtype=dt)\n",
        "    mlp = keras.models.Sequential()\n",
        "    mlp.add(embed_layer)\n",
        "    mlp.add(rnn1_layer)\n",
        "    mlp.add(rnn2_layer)\n",
        "    mlp.add(dense1_layer)\n",
        "    mlp.add(drop1_layer)\n",
        "    mlp.add(dense2_layer)\n",
        "    mlp.add(drop2_layer)\n",
        "    mlp.add(output_layer)\n",
        "    mlpc = compile_model(mlp)\n",
        "    return mlpc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6k-xOm9Kcn"
      },
      "source": [
        "Partition sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-O_qzw9Kco"
      },
      "source": [
        "def make_slice(data_set,min_len,max_len):\n",
        "    slice = data_set.query('seqlen <= '+str(max_len)+' & seqlen>= '+str(min_len))\n",
        "    return slice"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdIS2utq9Kc9"
      },
      "source": [
        "Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVo4tbB_9Kc-"
      },
      "source": [
        "def do_cross_validation(X,y,given_model):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=37863)\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        fold += 1\n",
        "        X_train=X[train_index] # use iloc[] for dataframe\n",
        "        y_train=y[train_index]\n",
        "        X_valid=X[valid_index]\n",
        "        y_valid=y[valid_index]        \n",
        "        # Avoid continually improving the same model.\n",
        "        model = compile_model(keras.models.clone_model(given_model))\n",
        "        bestname=MODEL_FILE+\".cv.\"+str(fold)+\".best\"\n",
        "        mycallbacks = [keras.callbacks.ModelCheckpoint(\n",
        "            filepath=bestname, save_best_only=True, \n",
        "            monitor='val_accuracy', mode='max')]   \n",
        "        print(\"FIT\")\n",
        "        start_time=time.time()\n",
        "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                callbacks=mycallbacks,\n",
        "                validation_data=(X_valid,y_valid) )\n",
        "        end_time=time.time()\n",
        "        elapsed_time=(end_time-start_time)                        \n",
        "        print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "        plt.grid(True)\n",
        "        plt.gca().set_ylim(0,1)\n",
        "        plt.show()\n",
        "        best_model=keras.models.load_model(bestname)\n",
        "        scores = best_model.evaluate(X_valid, y_valid, verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n",
        "        cv_scores.append(scores[1] * 100)  \n",
        "    print()\n",
        "    print(\"%d-way Cross Validation mean %.2f%% (+/- %.2f%%)\" % (fold, np.mean(cv_scores), np.std(cv_scores)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3Wj_vI9KdP"
      },
      "source": [
        "## Train on RNA lengths 200-1Kb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8fNo6sn9KdH",
        "outputId": "f08448f2-9ed7-4156-dd18-e283b1495bd9"
      },
      "source": [
        "MINLEN=200\n",
        "MAXLEN=1000\n",
        "print(\"Load data from files.\")\n",
        "nc_seq=tools.load_fasta(NC_FILENAME,0)\n",
        "pc_seq=tools.load_fasta(PC_FILENAME,1)\n",
        "train_set=pd.concat((nc_seq,pc_seq),axis=0)\n",
        "nc_seq=None\n",
        "pc_seq=None\n",
        "print(\"Ready: train_set\")\n",
        "#train_set\n",
        "subset=make_slice(train_set,MINLEN,MAXLEN)# One array to two: X and y\n",
        "print (\"Data reshape\")\n",
        "(X_train,y_train)=tools.make_kmers(K,MAXLEN,subset)\n",
        "#print (\"Data prep\")\n",
        "#X_train=tools.make_frequencies(K,X_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data from files.\n",
            "Ready: train_set\n",
            "Data reshape\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1HuSs8ZbeL4",
        "outputId": "bc1bdfd1-30ba-4eb1-ee9b-2d5b4063346c"
      },
      "source": [
        "print (\"Compile the model\")\n",
        "model=build_model()\n",
        "print (\"Summarize the model\")\n",
        "print(model.summary())  # Print this only once\n",
        "model.save(MODEL_FILE+'.model')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compile the model\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "Summarize the model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          1040      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 16)          2112      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,825\n",
            "Trainable params: 5,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mQ8eW5Rg9KdQ",
        "outputId": "4bc9ba88-ea13-4d72-e1d2-02c1ce473669"
      },
      "source": [
        "print (\"Cross valiation\")\n",
        "do_cross_validation(X_train,y_train,model)  \n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross valiation\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "453/453 [==============================] - 42s 72ms/step - loss: 0.6392 - accuracy: 0.6512 - val_loss: 0.6239 - val_accuracy: 0.6636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6223 - accuracy: 0.6673 - val_loss: 0.6153 - val_accuracy: 0.6698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/200\n",
            "453/453 [==============================] - 30s 67ms/step - loss: 0.6228 - accuracy: 0.6655 - val_loss: 0.5991 - val_accuracy: 0.6840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6061 - accuracy: 0.6805 - val_loss: 0.6706 - val_accuracy: 0.6580\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6395 - accuracy: 0.6485 - val_loss: 0.6025 - val_accuracy: 0.6772\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6122 - accuracy: 0.6717 - val_loss: 0.6003 - val_accuracy: 0.6859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6075 - accuracy: 0.6804 - val_loss: 0.5987 - val_accuracy: 0.6946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6126 - accuracy: 0.6842 - val_loss: 0.5918 - val_accuracy: 0.7089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6024 - accuracy: 0.6954 - val_loss: 0.5918 - val_accuracy: 0.7033\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6078 - accuracy: 0.6895 - val_loss: 0.6338 - val_accuracy: 0.6549\n",
            "Epoch 11/200\n",
            "453/453 [==============================] - 31s 67ms/step - loss: 0.6289 - accuracy: 0.6525 - val_loss: 0.5990 - val_accuracy: 0.6797\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6127 - accuracy: 0.6753 - val_loss: 0.6055 - val_accuracy: 0.6760\n",
            "Epoch 13/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6189 - accuracy: 0.6544 - val_loss: 0.6022 - val_accuracy: 0.6828\n",
            "Epoch 14/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6095 - accuracy: 0.6722 - val_loss: 0.5950 - val_accuracy: 0.6977\n",
            "Epoch 15/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6096 - accuracy: 0.6843 - val_loss: 0.6188 - val_accuracy: 0.6803\n",
            "Epoch 16/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6173 - accuracy: 0.6756 - val_loss: 0.5977 - val_accuracy: 0.7033\n",
            "Epoch 17/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6030 - accuracy: 0.6928 - val_loss: 0.6102 - val_accuracy: 0.6245\n",
            "Epoch 18/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.6136 - accuracy: 0.6838 - val_loss: 0.6462 - val_accuracy: 0.6530\n",
            "Epoch 19/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.6543 - accuracy: 0.6405 - val_loss: 0.6465 - val_accuracy: 0.6530\n",
            "Epoch 20/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.6536 - accuracy: 0.6411 - val_loss: 0.6444 - val_accuracy: 0.6530\n",
            "Epoch 21/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6516 - accuracy: 0.6409 - val_loss: 0.6447 - val_accuracy: 0.6530\n",
            "Epoch 22/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6351 - accuracy: 0.6470 - val_loss: 0.6182 - val_accuracy: 0.6431\n",
            "Epoch 23/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6183 - accuracy: 0.6609 - val_loss: 0.6228 - val_accuracy: 0.6530\n",
            "Epoch 24/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6328 - accuracy: 0.6502 - val_loss: 0.5934 - val_accuracy: 0.7132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6330 - accuracy: 0.6524 - val_loss: 0.6154 - val_accuracy: 0.6760\n",
            "Epoch 26/200\n",
            "453/453 [==============================] - 31s 68ms/step - loss: 0.6236 - accuracy: 0.6594 - val_loss: 0.6429 - val_accuracy: 0.6530\n",
            "Epoch 27/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6336 - accuracy: 0.6510 - val_loss: 0.6111 - val_accuracy: 0.6791\n",
            "Epoch 28/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.6233 - accuracy: 0.6605 - val_loss: 0.5868 - val_accuracy: 0.7101\n",
            "Epoch 29/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.5844 - accuracy: 0.7176 - val_loss: 0.5130 - val_accuracy: 0.7554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/200\n",
            "453/453 [==============================] - 31s 69ms/step - loss: 0.5100 - accuracy: 0.7656 - val_loss: 0.4364 - val_accuracy: 0.7976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4539 - accuracy: 0.7970 - val_loss: 0.4193 - val_accuracy: 0.8156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.4456 - accuracy: 0.7971 - val_loss: 0.4067 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4385 - accuracy: 0.8046 - val_loss: 0.3986 - val_accuracy: 0.8237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.4354 - accuracy: 0.8058 - val_loss: 0.4006 - val_accuracy: 0.8206\n",
            "Epoch 35/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4123 - accuracy: 0.8201 - val_loss: 0.4488 - val_accuracy: 0.7945\n",
            "Epoch 36/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4303 - accuracy: 0.8073 - val_loss: 0.3843 - val_accuracy: 0.8262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4116 - accuracy: 0.8183 - val_loss: 0.3889 - val_accuracy: 0.8256\n",
            "Epoch 38/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4088 - accuracy: 0.8214 - val_loss: 0.3779 - val_accuracy: 0.8318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.4024 - accuracy: 0.8248 - val_loss: 0.3763 - val_accuracy: 0.8312\n",
            "Epoch 40/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4179 - accuracy: 0.8152 - val_loss: 0.3814 - val_accuracy: 0.8343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4053 - accuracy: 0.8250 - val_loss: 0.3753 - val_accuracy: 0.8318\n",
            "Epoch 42/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.4046 - accuracy: 0.8270 - val_loss: 0.3733 - val_accuracy: 0.8256\n",
            "Epoch 43/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4122 - accuracy: 0.8196 - val_loss: 0.3709 - val_accuracy: 0.8343\n",
            "Epoch 44/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.4124 - accuracy: 0.8203 - val_loss: 0.4074 - val_accuracy: 0.8194\n",
            "Epoch 45/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.4091 - accuracy: 0.8205 - val_loss: 0.3739 - val_accuracy: 0.8299\n",
            "Epoch 46/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.4093 - accuracy: 0.8208 - val_loss: 0.3808 - val_accuracy: 0.8318\n",
            "Epoch 47/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3957 - accuracy: 0.8291 - val_loss: 0.3676 - val_accuracy: 0.8355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3997 - accuracy: 0.8300 - val_loss: 0.3924 - val_accuracy: 0.8293\n",
            "Epoch 49/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4023 - accuracy: 0.8215 - val_loss: 0.3659 - val_accuracy: 0.8386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3936 - accuracy: 0.8282 - val_loss: 0.3835 - val_accuracy: 0.8343\n",
            "Epoch 51/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3963 - accuracy: 0.8260 - val_loss: 0.3595 - val_accuracy: 0.8399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 52/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3932 - accuracy: 0.8286 - val_loss: 0.3608 - val_accuracy: 0.8399\n",
            "Epoch 53/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3887 - accuracy: 0.8289 - val_loss: 0.3599 - val_accuracy: 0.8423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 54/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3844 - accuracy: 0.8330 - val_loss: 0.3513 - val_accuracy: 0.8492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 55/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3899 - accuracy: 0.8302 - val_loss: 0.3671 - val_accuracy: 0.8423\n",
            "Epoch 56/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3813 - accuracy: 0.8372 - val_loss: 0.3526 - val_accuracy: 0.8473\n",
            "Epoch 57/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3818 - accuracy: 0.8347 - val_loss: 0.3460 - val_accuracy: 0.8510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 58/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3775 - accuracy: 0.8391 - val_loss: 0.3863 - val_accuracy: 0.8287\n",
            "Epoch 59/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3891 - accuracy: 0.8311 - val_loss: 0.3400 - val_accuracy: 0.8510\n",
            "Epoch 60/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3800 - accuracy: 0.8348 - val_loss: 0.6016 - val_accuracy: 0.6809\n",
            "Epoch 61/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.4720 - accuracy: 0.7786 - val_loss: 0.4616 - val_accuracy: 0.8020\n",
            "Epoch 62/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.4087 - accuracy: 0.8238 - val_loss: 0.3526 - val_accuracy: 0.8485\n",
            "Epoch 63/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3872 - accuracy: 0.8281 - val_loss: 0.3507 - val_accuracy: 0.8479\n",
            "Epoch 64/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3834 - accuracy: 0.8359 - val_loss: 0.3514 - val_accuracy: 0.8461\n",
            "Epoch 65/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3858 - accuracy: 0.8317 - val_loss: 0.3432 - val_accuracy: 0.8479\n",
            "Epoch 66/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3878 - accuracy: 0.8321 - val_loss: 0.3807 - val_accuracy: 0.8367\n",
            "Epoch 67/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3756 - accuracy: 0.8390 - val_loss: 0.3343 - val_accuracy: 0.8541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 68/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3774 - accuracy: 0.8397 - val_loss: 0.3325 - val_accuracy: 0.8541\n",
            "Epoch 69/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3636 - accuracy: 0.8463 - val_loss: 0.3301 - val_accuracy: 0.8603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 70/200\n",
            "453/453 [==============================] - 32s 70ms/step - loss: 0.3709 - accuracy: 0.8397 - val_loss: 0.3776 - val_accuracy: 0.8417\n",
            "Epoch 71/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3730 - accuracy: 0.8395 - val_loss: 0.3285 - val_accuracy: 0.8572\n",
            "Epoch 72/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3646 - accuracy: 0.8414 - val_loss: 0.3277 - val_accuracy: 0.8591\n",
            "Epoch 73/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3632 - accuracy: 0.8487 - val_loss: 0.3374 - val_accuracy: 0.8560\n",
            "Epoch 74/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3680 - accuracy: 0.8448 - val_loss: 0.3324 - val_accuracy: 0.8579\n",
            "Epoch 75/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3609 - accuracy: 0.8462 - val_loss: 0.3251 - val_accuracy: 0.8610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 76/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3607 - accuracy: 0.8465 - val_loss: 0.3298 - val_accuracy: 0.8572\n",
            "Epoch 77/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3560 - accuracy: 0.8473 - val_loss: 0.3232 - val_accuracy: 0.8634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 78/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3571 - accuracy: 0.8490 - val_loss: 0.3188 - val_accuracy: 0.8653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 79/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3745 - accuracy: 0.8391 - val_loss: 0.3328 - val_accuracy: 0.8560\n",
            "Epoch 80/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3604 - accuracy: 0.8465 - val_loss: 0.3633 - val_accuracy: 0.8442\n",
            "Epoch 81/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3563 - accuracy: 0.8513 - val_loss: 0.3490 - val_accuracy: 0.8492\n",
            "Epoch 82/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3539 - accuracy: 0.8525 - val_loss: 0.3229 - val_accuracy: 0.8622\n",
            "Epoch 83/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3466 - accuracy: 0.8552 - val_loss: 0.3161 - val_accuracy: 0.8665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 84/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3538 - accuracy: 0.8490 - val_loss: 0.3194 - val_accuracy: 0.8597\n",
            "Epoch 85/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3443 - accuracy: 0.8543 - val_loss: 0.3162 - val_accuracy: 0.8647\n",
            "Epoch 86/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.3552 - accuracy: 0.8499 - val_loss: 0.3105 - val_accuracy: 0.8696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 87/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3395 - accuracy: 0.8584 - val_loss: 0.3162 - val_accuracy: 0.8641\n",
            "Epoch 88/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3426 - accuracy: 0.8569 - val_loss: 0.3091 - val_accuracy: 0.8672\n",
            "Epoch 89/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3451 - accuracy: 0.8556 - val_loss: 0.3306 - val_accuracy: 0.8560\n",
            "Epoch 90/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3413 - accuracy: 0.8526 - val_loss: 0.3484 - val_accuracy: 0.8492\n",
            "Epoch 91/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.3327 - accuracy: 0.8644 - val_loss: 0.3409 - val_accuracy: 0.8523\n",
            "Epoch 92/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3449 - accuracy: 0.8542 - val_loss: 0.3191 - val_accuracy: 0.8616\n",
            "Epoch 93/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3316 - accuracy: 0.8641 - val_loss: 0.3229 - val_accuracy: 0.8634\n",
            "Epoch 94/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3273 - accuracy: 0.8660 - val_loss: 0.3061 - val_accuracy: 0.8678\n",
            "Epoch 95/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3278 - accuracy: 0.8647 - val_loss: 0.3175 - val_accuracy: 0.8622\n",
            "Epoch 96/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3287 - accuracy: 0.8614 - val_loss: 0.3138 - val_accuracy: 0.8634\n",
            "Epoch 97/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3281 - accuracy: 0.8649 - val_loss: 0.3131 - val_accuracy: 0.8641\n",
            "Epoch 98/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3268 - accuracy: 0.8616 - val_loss: 0.3210 - val_accuracy: 0.8616\n",
            "Epoch 99/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3220 - accuracy: 0.8694 - val_loss: 0.3330 - val_accuracy: 0.8547\n",
            "Epoch 100/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3260 - accuracy: 0.8676 - val_loss: 0.3226 - val_accuracy: 0.8659\n",
            "Epoch 101/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3183 - accuracy: 0.8674 - val_loss: 0.3204 - val_accuracy: 0.8628\n",
            "Epoch 102/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3230 - accuracy: 0.8682 - val_loss: 0.3126 - val_accuracy: 0.8665\n",
            "Epoch 103/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3219 - accuracy: 0.8716 - val_loss: 0.3139 - val_accuracy: 0.8603\n",
            "Epoch 104/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3315 - accuracy: 0.8596 - val_loss: 0.3118 - val_accuracy: 0.8684\n",
            "Epoch 105/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3180 - accuracy: 0.8682 - val_loss: 0.3125 - val_accuracy: 0.8665\n",
            "Epoch 106/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3168 - accuracy: 0.8652 - val_loss: 0.3253 - val_accuracy: 0.8641\n",
            "Epoch 107/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3281 - accuracy: 0.8633 - val_loss: 0.3047 - val_accuracy: 0.8684\n",
            "Epoch 108/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3249 - accuracy: 0.8654 - val_loss: 0.3023 - val_accuracy: 0.8734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 109/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3163 - accuracy: 0.8714 - val_loss: 0.3323 - val_accuracy: 0.8616\n",
            "Epoch 110/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3190 - accuracy: 0.8678 - val_loss: 0.3152 - val_accuracy: 0.8709\n",
            "Epoch 111/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3001 - accuracy: 0.8796 - val_loss: 0.3056 - val_accuracy: 0.8678\n",
            "Epoch 112/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3204 - accuracy: 0.8670 - val_loss: 0.3209 - val_accuracy: 0.8690\n",
            "Epoch 113/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3066 - accuracy: 0.8778 - val_loss: 0.3122 - val_accuracy: 0.8647\n",
            "Epoch 114/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3118 - accuracy: 0.8745 - val_loss: 0.3152 - val_accuracy: 0.8628\n",
            "Epoch 115/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3169 - accuracy: 0.8715 - val_loss: 0.3152 - val_accuracy: 0.8641\n",
            "Epoch 116/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.3161 - accuracy: 0.8714 - val_loss: 0.3076 - val_accuracy: 0.8740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 117/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3026 - accuracy: 0.8737 - val_loss: 0.3155 - val_accuracy: 0.8665\n",
            "Epoch 118/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3077 - accuracy: 0.8725 - val_loss: 0.3125 - val_accuracy: 0.8665\n",
            "Epoch 119/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3129 - accuracy: 0.8738 - val_loss: 0.3033 - val_accuracy: 0.8709\n",
            "Epoch 120/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3038 - accuracy: 0.8794 - val_loss: 0.3507 - val_accuracy: 0.8634\n",
            "Epoch 121/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3078 - accuracy: 0.8738 - val_loss: 0.3083 - val_accuracy: 0.8740\n",
            "Epoch 122/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3077 - accuracy: 0.8749 - val_loss: 0.3105 - val_accuracy: 0.8665\n",
            "Epoch 123/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3051 - accuracy: 0.8769 - val_loss: 0.3108 - val_accuracy: 0.8727\n",
            "Epoch 124/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2897 - accuracy: 0.8856 - val_loss: 0.3294 - val_accuracy: 0.8659\n",
            "Epoch 125/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2994 - accuracy: 0.8758 - val_loss: 0.2964 - val_accuracy: 0.8746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 126/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3102 - accuracy: 0.8748 - val_loss: 0.3288 - val_accuracy: 0.8653\n",
            "Epoch 127/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2959 - accuracy: 0.8800 - val_loss: 0.3024 - val_accuracy: 0.8703\n",
            "Epoch 128/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3002 - accuracy: 0.8784 - val_loss: 0.3432 - val_accuracy: 0.8622\n",
            "Epoch 129/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3128 - accuracy: 0.8684 - val_loss: 0.3066 - val_accuracy: 0.8746\n",
            "Epoch 130/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2999 - accuracy: 0.8771 - val_loss: 0.3073 - val_accuracy: 0.8752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 131/200\n",
            "453/453 [==============================] - 34s 75ms/step - loss: 0.2942 - accuracy: 0.8771 - val_loss: 0.3150 - val_accuracy: 0.8690\n",
            "Epoch 132/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2908 - accuracy: 0.8833 - val_loss: 0.3493 - val_accuracy: 0.8579\n",
            "Epoch 133/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2987 - accuracy: 0.8803 - val_loss: 0.3257 - val_accuracy: 0.8715\n",
            "Epoch 134/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2938 - accuracy: 0.8780 - val_loss: 0.3052 - val_accuracy: 0.8808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.1.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 135/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.3032 - accuracy: 0.8742 - val_loss: 0.3136 - val_accuracy: 0.8665\n",
            "Epoch 136/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.3037 - accuracy: 0.8704 - val_loss: 0.3567 - val_accuracy: 0.8634\n",
            "Epoch 137/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.3007 - accuracy: 0.8784 - val_loss: 0.3106 - val_accuracy: 0.8690\n",
            "Epoch 138/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2928 - accuracy: 0.8803 - val_loss: 0.3127 - val_accuracy: 0.8752\n",
            "Epoch 139/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2936 - accuracy: 0.8821 - val_loss: 0.3212 - val_accuracy: 0.8721\n",
            "Epoch 140/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2914 - accuracy: 0.8816 - val_loss: 0.3588 - val_accuracy: 0.8579\n",
            "Epoch 141/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2791 - accuracy: 0.8889 - val_loss: 0.3157 - val_accuracy: 0.8727\n",
            "Epoch 142/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2901 - accuracy: 0.8832 - val_loss: 0.3065 - val_accuracy: 0.8752\n",
            "Epoch 143/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2822 - accuracy: 0.8848 - val_loss: 0.3139 - val_accuracy: 0.8696\n",
            "Epoch 144/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2821 - accuracy: 0.8875 - val_loss: 0.2971 - val_accuracy: 0.8790\n",
            "Epoch 145/200\n",
            "453/453 [==============================] - 34s 75ms/step - loss: 0.2900 - accuracy: 0.8869 - val_loss: 0.3510 - val_accuracy: 0.8684\n",
            "Epoch 146/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2962 - accuracy: 0.8795 - val_loss: 0.3122 - val_accuracy: 0.8703\n",
            "Epoch 147/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.2983 - accuracy: 0.8787 - val_loss: 0.3251 - val_accuracy: 0.8746\n",
            "Epoch 148/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.2845 - accuracy: 0.8814 - val_loss: 0.3170 - val_accuracy: 0.8759\n",
            "Epoch 149/200\n",
            "453/453 [==============================] - 34s 75ms/step - loss: 0.2966 - accuracy: 0.8794 - val_loss: 0.3083 - val_accuracy: 0.8790\n",
            "Epoch 150/200\n",
            "453/453 [==============================] - 34s 75ms/step - loss: 0.2820 - accuracy: 0.8877 - val_loss: 0.3373 - val_accuracy: 0.8585\n",
            "Epoch 151/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.2852 - accuracy: 0.8830 - val_loss: 0.3082 - val_accuracy: 0.8759\n",
            "Epoch 152/200\n",
            "453/453 [==============================] - 33s 74ms/step - loss: 0.2899 - accuracy: 0.8832 - val_loss: 0.3296 - val_accuracy: 0.8703\n",
            "Epoch 153/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2823 - accuracy: 0.8828 - val_loss: 0.3313 - val_accuracy: 0.8659\n",
            "Epoch 154/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2748 - accuracy: 0.8896 - val_loss: 0.3088 - val_accuracy: 0.8690\n",
            "Epoch 155/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2825 - accuracy: 0.8898 - val_loss: 0.3236 - val_accuracy: 0.8715\n",
            "Epoch 156/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2901 - accuracy: 0.8829 - val_loss: 0.3099 - val_accuracy: 0.8734\n",
            "Epoch 157/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2716 - accuracy: 0.8947 - val_loss: 0.3196 - val_accuracy: 0.8734\n",
            "Epoch 158/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2864 - accuracy: 0.8817 - val_loss: 0.3074 - val_accuracy: 0.8727\n",
            "Epoch 159/200\n",
            "453/453 [==============================] - 34s 74ms/step - loss: 0.2829 - accuracy: 0.8829 - val_loss: 0.3336 - val_accuracy: 0.8759\n",
            "Epoch 160/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2721 - accuracy: 0.8893 - val_loss: 0.3408 - val_accuracy: 0.8734\n",
            "Epoch 161/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2836 - accuracy: 0.8874 - val_loss: 0.3145 - val_accuracy: 0.8790\n",
            "Epoch 162/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2858 - accuracy: 0.8818 - val_loss: 0.3594 - val_accuracy: 0.8665\n",
            "Epoch 163/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2805 - accuracy: 0.8862 - val_loss: 0.3112 - val_accuracy: 0.8783\n",
            "Epoch 164/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2755 - accuracy: 0.8858 - val_loss: 0.3210 - val_accuracy: 0.8771\n",
            "Epoch 165/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2866 - accuracy: 0.8827 - val_loss: 0.3091 - val_accuracy: 0.8777\n",
            "Epoch 166/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2841 - accuracy: 0.8861 - val_loss: 0.3081 - val_accuracy: 0.8808\n",
            "Epoch 167/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2739 - accuracy: 0.8883 - val_loss: 0.3079 - val_accuracy: 0.8647\n",
            "Epoch 168/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2747 - accuracy: 0.8898 - val_loss: 0.3022 - val_accuracy: 0.8777\n",
            "Epoch 169/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2753 - accuracy: 0.8864 - val_loss: 0.3241 - val_accuracy: 0.8721\n",
            "Epoch 170/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2785 - accuracy: 0.8855 - val_loss: 0.3839 - val_accuracy: 0.8547\n",
            "Epoch 171/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2826 - accuracy: 0.8864 - val_loss: 0.3000 - val_accuracy: 0.8783\n",
            "Epoch 172/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2753 - accuracy: 0.8919 - val_loss: 0.3189 - val_accuracy: 0.8721\n",
            "Epoch 173/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2783 - accuracy: 0.8852 - val_loss: 0.3080 - val_accuracy: 0.8709\n",
            "Epoch 174/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2694 - accuracy: 0.8966 - val_loss: 0.3185 - val_accuracy: 0.8727\n",
            "Epoch 175/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2635 - accuracy: 0.8948 - val_loss: 0.3115 - val_accuracy: 0.8721\n",
            "Epoch 176/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2767 - accuracy: 0.8883 - val_loss: 0.3069 - val_accuracy: 0.8740\n",
            "Epoch 177/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2762 - accuracy: 0.8880 - val_loss: 0.3103 - val_accuracy: 0.8740\n",
            "Epoch 178/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2719 - accuracy: 0.8889 - val_loss: 0.3308 - val_accuracy: 0.8696\n",
            "Epoch 179/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2682 - accuracy: 0.8972 - val_loss: 0.3345 - val_accuracy: 0.8678\n",
            "Epoch 180/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2882 - accuracy: 0.8829 - val_loss: 0.3184 - val_accuracy: 0.8759\n",
            "Epoch 181/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2714 - accuracy: 0.8922 - val_loss: 0.3207 - val_accuracy: 0.8715\n",
            "Epoch 182/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2700 - accuracy: 0.8890 - val_loss: 0.3163 - val_accuracy: 0.8703\n",
            "Epoch 183/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2658 - accuracy: 0.8973 - val_loss: 0.3415 - val_accuracy: 0.8672\n",
            "Epoch 184/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2670 - accuracy: 0.8936 - val_loss: 0.3387 - val_accuracy: 0.8709\n",
            "Epoch 185/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2773 - accuracy: 0.8887 - val_loss: 0.3453 - val_accuracy: 0.8678\n",
            "Epoch 186/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2713 - accuracy: 0.8930 - val_loss: 0.3094 - val_accuracy: 0.8796\n",
            "Epoch 187/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2654 - accuracy: 0.8902 - val_loss: 0.3149 - val_accuracy: 0.8771\n",
            "Epoch 188/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2718 - accuracy: 0.8912 - val_loss: 0.3162 - val_accuracy: 0.8771\n",
            "Epoch 189/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2755 - accuracy: 0.8901 - val_loss: 0.3551 - val_accuracy: 0.8622\n",
            "Epoch 190/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2712 - accuracy: 0.8945 - val_loss: 0.3534 - val_accuracy: 0.8721\n",
            "Epoch 191/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2679 - accuracy: 0.8928 - val_loss: 0.3233 - val_accuracy: 0.8752\n",
            "Epoch 192/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2747 - accuracy: 0.8901 - val_loss: 0.3169 - val_accuracy: 0.8771\n",
            "Epoch 193/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2615 - accuracy: 0.8967 - val_loss: 0.3094 - val_accuracy: 0.8765\n",
            "Epoch 194/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.2638 - accuracy: 0.8942 - val_loss: 0.3417 - val_accuracy: 0.8684\n",
            "Epoch 195/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2675 - accuracy: 0.8927 - val_loss: 0.3359 - val_accuracy: 0.8696\n",
            "Epoch 196/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2785 - accuracy: 0.8896 - val_loss: 0.3114 - val_accuracy: 0.8746\n",
            "Epoch 197/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2664 - accuracy: 0.8915 - val_loss: 0.3248 - val_accuracy: 0.8715\n",
            "Epoch 198/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.2622 - accuracy: 0.8964 - val_loss: 0.3350 - val_accuracy: 0.8721\n",
            "Epoch 199/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.2700 - accuracy: 0.8905 - val_loss: 0.3293 - val_accuracy: 0.8759\n",
            "Epoch 200/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.2618 - accuracy: 0.8923 - val_loss: 0.3172 - val_accuracy: 0.8759\n",
            "Fold 1, 200 epochs, 7029 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 88.08%\n",
            "COMPILE...\n",
            "...COMPILED\n",
            "FIT\n",
            "Epoch 1/200\n",
            "453/453 [==============================] - 41s 76ms/step - loss: 0.6416 - accuracy: 0.6490 - val_loss: 0.6435 - val_accuracy: 0.6449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.6279 - accuracy: 0.6518 - val_loss: 0.6095 - val_accuracy: 0.6735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/200\n",
            "453/453 [==============================] - 32s 71ms/step - loss: 0.6035 - accuracy: 0.6801 - val_loss: 0.6081 - val_accuracy: 0.6741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.6020 - accuracy: 0.6875 - val_loss: 0.7401 - val_accuracy: 0.5326\n",
            "Epoch 5/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.6192 - accuracy: 0.6676 - val_loss: 0.6466 - val_accuracy: 0.6449\n",
            "Epoch 6/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.6222 - accuracy: 0.6506 - val_loss: 0.6022 - val_accuracy: 0.6791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.6002 - accuracy: 0.6810 - val_loss: 0.6028 - val_accuracy: 0.6927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.5939 - accuracy: 0.7018 - val_loss: 0.6152 - val_accuracy: 0.6691\n",
            "Epoch 9/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.6176 - accuracy: 0.6733 - val_loss: 0.6091 - val_accuracy: 0.6716\n",
            "Epoch 10/200\n",
            "453/453 [==============================] - 33s 73ms/step - loss: 0.6085 - accuracy: 0.6829 - val_loss: 0.5953 - val_accuracy: 0.6946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/LSTM302.cv.2.best/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/200\n",
            "453/453 [==============================] - 32s 72ms/step - loss: 0.6257 - accuracy: 0.6641 - val_loss: 0.6050 - val_accuracy: 0.6654\n",
            "Epoch 12/200\n",
            "453/453 [==============================] - 33s 72ms/step - loss: 0.6123 - accuracy: 0.6819 - val_loss: 0.6477 - val_accuracy: 0.6449\n",
            "Epoch 13/200\n",
            "452/453 [============================>.] - ETA: 0s - loss: 0.6460 - accuracy: 0.6385"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4fh2GI8beMQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}