{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Random Forest\n",
        "Compare RF to Yuri by FDR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "92df883b-7eb8-4069-d10e-31c9d1e4d713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-07 18:12:30.746216\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "a18f0016-639b-4174-d8ac-a58986b7f3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/IRP2/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/IRP2/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print('Running on Mac')\n",
        "    DATA_DIR=\"/Users/jasonmiller/WVU/BAM_ML/\"\n",
        "    MODEL_DIR=\"/Users/jasonmiller/WVU/BAM_ML/Models/\"\n",
        "SAVE_MODEL_FILENAME = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "c788dbc9-7a46-4468-c2ce-40511af74816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import pandas as pd  # for plotting\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "import gzip\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "EPOCHS=150 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkpVKdMFLA-",
        "outputId": "3334b557-2122-426c-ca95-a5e83e062ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data directory: /content/drive/My Drive/data/IRP2/\n",
            "Data file 0 MxM_BR4/ml_stats.csv.gz\n",
            "Data file 1 SxS_BR4/ml_stats.csv.gz\n",
            "Input lines for training: 1000000\n"
          ]
        }
      ],
      "source": [
        "MAX_LINES_TO_LOAD =    10000 # use this for debugging\n",
        "MAX_LINES_TO_LOAD =    1000000 # training - 1M lines requires 2GB RAM\n",
        "\n",
        "VALID_PORTION = 0.20\n",
        "\n",
        "DATA_FILE_0 = 'MxM_BR4/ml_stats.csv.gz'\n",
        "DATA_FILE_1 = 'SxS_BR4/ml_stats.csv.gz'\n",
        "\n",
        "print('Data directory: %s'%DATA_DIR)\n",
        "print('Data file 0 %s'%DATA_FILE_0)\n",
        "print('Data file 1 %s'%DATA_FILE_1)\n",
        "print('Input lines for training: %d'%MAX_LINES_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uUBLdpVEVQ3I"
      },
      "outputs": [],
      "source": [
        "# P1 parent 1\n",
        "# R1 read 1\n",
        "# PS primary or secondary\n",
        "# AS bowtie alignment score (0 is best)\n",
        "# ED edit distance\n",
        "# MM mismatch count\n",
        "# GO gap open count\n",
        "# GE gap extend count\n",
        "feature_names = [\n",
        "    'P1 R1 AS',\n",
        "    'P1 R1 ED',\n",
        "    'P1 R1 MM',\n",
        "    'P1 R1 GO',\n",
        "    'P1 R1 GE',\n",
        "    'P1 R2 AS',\n",
        "    'P1 R2 ED',\n",
        "    'P1 R2 MM',\n",
        "    'P1 R2 GO',\n",
        "    'P1 R2 GE',\n",
        "    'P2 R1 AS',\n",
        "    'P2 R1 ED',\n",
        "    'P2 R1 MM',\n",
        "    'P2 R1 GO',\n",
        "    'P2 R1 GE',\n",
        "    'P2 R2 AS',\n",
        "    'P2 R2 ED',\n",
        "    'P2 R2 MM',\n",
        "    'P2 R2 GO',\n",
        "    'P2 R2 GE',\n",
        "    'AS diff',\n",
        "    'ED diff',\n",
        "    'MM diff',\n",
        "    'GO diff',\n",
        "    'GE diff',\n",
        "    'P2 Primary',\n",
        "    'P1 Span',\n",
        "    'P2 Span',\n",
        "    'Span diff']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,filepath1,filepath2,verbose=True):\n",
        "        self.files = [filepath1,filepath2]\n",
        "        self.alignments=[]\n",
        "        self.labels=[]\n",
        "        self.is_primary={'P':1, 'S':0}\n",
        "        self.verbose = verbose\n",
        "        self.max_lines = None\n",
        "        \n",
        "    def set_max_lines(self,lines):\n",
        "        '''Limit the dataset size to fit in RAM.'''\n",
        "        self.max_lines = lines\n",
        "        if self.verbose:\n",
        "            print('Maximum lines to load per file: %d'%lines)\n",
        "        \n",
        "    def _count_lines_(self):\n",
        "        '''Show number of lines per input file.'''\n",
        "        count0 = 0\n",
        "        with gzip.open (self.files[0],'rt') as handle0:\n",
        "            for row in handle0:\n",
        "                count0 += 1\n",
        "        count1 = 0\n",
        "        with gzip.open(self.files[1],'rt') as handle1:\n",
        "            for row in handle1:\n",
        "                count1 += 1\n",
        "        minimum = min(count0,count1)\n",
        "        if self.verbose:\n",
        "            print('File0 size: %d %s'%(count0,self.files[0]))\n",
        "            print('File1 size: %d %s'%(count1,self.files[1]))\n",
        "        return minimum\n",
        "        \n",
        "    def _load_line_(self,row):\n",
        "        '''Load data structure from one line of CSV file.'''\n",
        "        line = row.strip()\n",
        "        fields = line.split(',')\n",
        "        ints = [0] * 29\n",
        "        # These fields come straight from the input file.\n",
        "        # These fields are grouped by which read they describe.\n",
        "        # P1 R1 AS = Parent 1, Read 1, Alignment Score\n",
        "        ints[0] = int(fields[1]) # P1 R1 AS\n",
        "        ints[1] = int(fields[2]) # P1 R1 ED\n",
        "        ints[2] = int(fields[3]) # P1 R1 MM\n",
        "        ints[3] = int(fields[4]) # P1 R1 GO\n",
        "        ints[4] = int(fields[5]) # P1 R1 GE\n",
        "        ints[5] = int(fields[7]) # P1 R2 AS\n",
        "        ints[6] = int(fields[8]) # P1 R2 ED\n",
        "        ints[7] = int(fields[9]) # P1 R2 MM\n",
        "        ints[8] = int(fields[10]) # P1 R2 GO\n",
        "        ints[9] = int(fields[11]) # P1 R2 GE\n",
        "        ints[10] = int(fields[13]) # P2 R1 AS\n",
        "        ints[11] = int(fields[14]) # P2 R1 ED\n",
        "        ints[12] = int(fields[15]) # P2 R1 MM\n",
        "        ints[13] = int(fields[16]) # P2 R1 GO\n",
        "        ints[14] = int(fields[17]) # P2 R1 GE\n",
        "        ints[15] = int(fields[19]) # P2 R2 AS\n",
        "        ints[16] = int(fields[20]) # P2 R2 ED\n",
        "        ints[17] = int(fields[21]) # P2 R2 MM\n",
        "        ints[18] = int(fields[22]) # P2 R2 GO\n",
        "        ints[19] = int(fields[23]) # P2 R2 GE    \n",
        "        # We compute these 'diff' fields from the input data.\n",
        "        ints[20] = int(((ints[10]+ints[15])-(ints[0]+ints[5]))/2) # AS diff\n",
        "        ints[21] = int(((ints[11]+ints[16])-(ints[1]+ints[6]))/2) # ED diff\n",
        "        ints[22] = int(((ints[12]+ints[17])-(ints[2]+ints[7]))/2) # MM diff\n",
        "        ints[23] = int(((ints[13]+ints[18])-(ints[3]+ints[8]))/2) # GO diff\n",
        "        ints[24] = int(((ints[14]+ints[19])-(ints[4]+ints[9]))/2) # GE diff\n",
        "        # The data file contains one letter describing parent 2 (e.g. SxS).\n",
        "        # The letter is P for primary or S for secondary (derived from a BAM flag).\n",
        "        # We convert so is_primary==1 means parent 2 is the primary parent.\n",
        "        primary_letter = fields[12]  # parent 2 is P=primary or S=Secondary\n",
        "        primary_digit = self.is_primary[primary_letter] # convert P to 1, S to 0\n",
        "        ints[25] = primary_digit  # value 1 means Parent 2 is primary\n",
        "        # The span of this read pair along either parent.\n",
        "        ints[26] = int(fields[24]) # span on P1\n",
        "        ints[27] = int(fields[25]) # span on P2\n",
        "        ints[28] = ints[25]-ints[24] # Span diff\n",
        "        # The transcript (in both parents) that this read pair aligned to.\n",
        "        # An upstream filter removes cases of different transcript per parent.\n",
        "        transcript_id = fields[26] # TO DO: where to put this?\n",
        "        self.alignments.append(ints)\n",
        "    \n",
        "    def load_full_train_set(self):\n",
        "        '''Load full train set (to be used for train and valiation).\n",
        "           Use set_max_lines() to leave some data for the test set.'''\n",
        "        minimum = 0\n",
        "        train_size = self.max_lines\n",
        "        if self.verbose:\n",
        "            print('Trying to load %d lines per file...'%train_size)\n",
        "        try:\n",
        "            handle0 = gzip.open(self.files[0],'rt')\n",
        "            handle1 = gzip.open(self.files[1],'rt')\n",
        "            # Associate label 0 with data from file 0. Same for 1.\n",
        "            for i in range(train_size):\n",
        "                row = next(handle0)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(0) \n",
        "                row = next(handle1)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(1)\n",
        "            handle0.close()\n",
        "            handle1.close()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise Exception('CANNOT LOAD DATA FROM FILE!')\n",
        "\n",
        "    def show_examples(self,head=6):\n",
        "        head = min(head,len(self.alignments))\n",
        "        for i in range(head):\n",
        "            print('From '+self.files[self.labels[i]])\n",
        "            print('Score,Edit,Mismatch,GapOpen,GapExtend')\n",
        "            print(self.alignments[i][0:5])\n",
        "            print(self.alignments[i][5:10])\n",
        "            print(self.alignments[i][10:15])\n",
        "            print(self.alignments[i][15:20])\n",
        "            print(self.alignments[i][20:26])\n",
        "            \n",
        "    def get_X_y(self):\n",
        "        loaded = len(self.alignments)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        X_train = np.array(self.alignments[:divider])\n",
        "        y_train = np.array(self.labels[:divider])\n",
        "        X_valid = np.array(self.alignments[divider:])\n",
        "        y_valid = np.array(self.labels[divider:])\n",
        "        if self.verbose:\n",
        "            print('Full train set size = '+str(len(self.alignments)))\n",
        "            print('Training/Validation partition: %d/%d'%(len(y_train),len(y_valid)))\n",
        "        return X_train,y_train, X_valid,y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcZVyvS_126",
        "outputId": "abda98bf-5e56-4086-8099-88c03de4c5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-07 18:12:57.285977\n",
            "Maximum lines to load per file: 1000000\n",
            "LOADING\n",
            "Trying to load 1000000 lines per file...\n",
            "2023-06-07 18:13:19.605384\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-25, 5, 5, 0, 0]\n",
            "[-10, 2, 2, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[17, -3, -3, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-6, 2, 2, 0, 0]\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-6, 2, 2, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-19, 4, 4, 0, 0]\n",
            "[-24, 6, 6, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[-4, 2, 2, 0, 0]\n",
            "[19, -4, -4, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, 0, 0, 0, 0]\n",
            "[-1, 1, 1, 0, 0]\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-4, 2, 2, 0, 0]\n",
            "[-4, 1, 1, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/ml_stats.csv.gz\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-3, 1, 1, 0, 0]\n",
            "[-11, 6, 6, 0, 0]\n",
            "[-3, 1, 1, 0, 0]\n",
            "[-11, 6, 6, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "filepath0 = DATA_DIR+DATA_FILE_0\n",
        "filepath1 = DATA_DIR+DATA_FILE_1\n",
        "loader=DataLoader(filepath0,filepath1)\n",
        "loader.set_max_lines(MAX_LINES_TO_LOAD)\n",
        "print('LOADING')\n",
        "loader.load_full_train_set()\n",
        "print(datetime.now())\n",
        "loader.show_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uHn9Ib_129",
        "outputId": "e864b929-b055-4aec-b005-31aae9b6e5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train set size = 2000000\n",
            "Training/Validation partition: 1600000/400000\n",
            "X train shape: \n",
            "(1600000, 29)\n",
            "y train shape: \n",
            "(1600000,)\n",
            "X valid shape: \n",
            "(400000, 29)\n",
            "y valid shape: \n",
            "(400000,)\n",
            "X[5]=\n",
            "[ -3   1   1   0   0 -11   6   6   0   0  -3   1   1   0   0 -11   6   6\n",
            "   0   0   0   0   0   0   0   1 260 260   1]\n",
            "y[5]=\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train, X_valid,y_valid = loader.get_X_y()\n",
        "print('X train shape: ')\n",
        "print(np.shape(X_train))\n",
        "print('y train shape: ')\n",
        "print(np.shape(y_train))\n",
        "print('X valid shape: ')\n",
        "print(np.shape(X_valid))\n",
        "print('y valid shape: ')\n",
        "print(np.shape(y_valid))\n",
        "print('X[5]=')\n",
        "print(X_train[5])\n",
        "print('y[5]=')\n",
        "print(y_train[5])\n",
        "#loader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SToJAYLADyA4"
      },
      "source": [
        "## Yuri Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cm5G-u9DyA6",
        "outputId": "44577c3c-cb9e-4183-c850-ae07221de59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs examined: 400000\n",
            "Predicted M 124607 times, 103862 correctly, FDR=16.65%\n",
            "Predicted S 130222 times, 116573 correctly, FDR=10.48%\n"
          ]
        }
      ],
      "source": [
        "M_pred = 0\n",
        "M_true = 0\n",
        "S_pred = 0\n",
        "S_true = 0\n",
        "length = len(X_valid)\n",
        "for i in range(length):\n",
        "    pair = X_valid[i]  # list of features\n",
        "    truth = y_valid[i]  # 0 for M, 1 for S\n",
        "    M_MM = pair[2]+pair[7]\n",
        "    M_GO = pair[3]+pair[8]\n",
        "    S_MM = pair[12]+pair[17]\n",
        "    S_GO = pair[13]+pair[18]\n",
        "    say_M = False\n",
        "    say_S = False\n",
        "    if M_MM+M_GO==0 and S_MM+S_GO>0:\n",
        "        say_M = True\n",
        "    elif M_MM+M_GO>0 and S_MM+S_GO==0:\n",
        "        say_S = True\n",
        "    elif M_GO==0 and S_GO>0:\n",
        "        say_M = True\n",
        "    elif M_GO>0 and S_GO==0:\n",
        "        say_S = True\n",
        "    elif M_GO==0 and S_GO==0:\n",
        "        if S_MM >= M_MM*2:\n",
        "            say_M = True\n",
        "        elif M_MM >= S_MM*2:\n",
        "            say_S = True\n",
        "    if say_M:\n",
        "        M_pred += 1\n",
        "        if truth==0:\n",
        "            M_true += 1\n",
        "    elif say_S:\n",
        "        S_pred += 1\n",
        "        if truth==1:\n",
        "            S_true += 1\n",
        "print('Total pairs examined: %d'%length)\n",
        "print('Predicted M %d times, %d correctly, FDR=%5.2f%%'%(M_pred,M_true,100-100.0*M_true/M_pred))\n",
        "print('Predicted S %d times, %d correctly, FDR=%5.2f%%'%(S_pred,S_true,100-100.0*S_true/S_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}