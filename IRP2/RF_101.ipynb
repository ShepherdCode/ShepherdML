{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Random Forest\n",
        "Same as 102 but ran on CoLab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "b48e0cd4-0ddf-4353-96a6-14254e686a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-03 16:38:19.523096\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "6cb907f2-9cdd-4076-c13d-717630f3494c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data/IRP2/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/IRP2/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/IRP2/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR=\"/Users/jasonmiller/WVU/BAM_ML/\"\n",
        "    MODEL_DIR=\"/Users/jasonmiller/WVU/BAM_ML/Models/\"\n",
        "print(DATA_DIR)\n",
        "SAVE_MODEL_FILENAME = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "a7bb6c97-6b7b-4dde-b414-b5df7564e4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "EPOCHS=150 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkpVKdMFLA-",
        "outputId": "1435cf2e-5a9d-461d-bfab-e8d22126a73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data file 0 MxM_BR4/first_million_stats.csv\n",
            "Data file 1 SxS_BR4/first_million_stats.csv\n",
            "Maximum lines to load per file for training: 1000000\n"
          ]
        }
      ],
      "source": [
        "# Full dataset (may exceed RAM)\n",
        "DATA_FILE_0 = 'MxM_BR4/ml_stats.csv'\n",
        "DATA_FILE_1 = 'SxS_BR4/ml_stats.csv'\n",
        "# Tiny dataset for debugging\n",
        "DATA_FILE_0 = 'tiny_MxM/ml_stats.csv'\n",
        "DATA_FILE_1 = 'tiny_SxS/ml_stats.csv'\n",
        "# First million for testing\n",
        "DATA_FILE_0 = 'MxM_BR4/first_million_stats.csv'\n",
        "DATA_FILE_1 = 'SxS_BR4/first_million_stats.csv'\n",
        "\n",
        "print('Data file 0 %s'%DATA_FILE_0)\n",
        "print('Data file 1 %s'%DATA_FILE_1)\n",
        "TEST_PORTION=0.00   # set to 20% when using complete files (ml_stats)\n",
        "VALID_PORTION=0.20\n",
        "MAX_LINES_TO_LOAD=1000000  # million\n",
        "print('Maximum lines to load per file for training: %d'%MAX_LINES_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,filepath1,filepath2,verbose=True):\n",
        "        self.files = [filepath1,filepath2]\n",
        "        self.alignments=[]\n",
        "        self.labels=[]\n",
        "        self.is_primary={'P':1, 'S':0}\n",
        "        self.verbose = verbose\n",
        "        self.max_lines = None\n",
        "        \n",
        "    def set_max_lines(self,lines):\n",
        "        self.max_lines = lines\n",
        "        if self.verbose:\n",
        "            print('Maximum lines to load per file: %d'%lines)\n",
        "        \n",
        "    def _count_lines_(self):\n",
        "        count0 = 0\n",
        "        with open (self.files[0],'r') as handle0:\n",
        "            for row in handle0:\n",
        "                count0 += 1\n",
        "        count1 = 0\n",
        "        with open(self.files[1],'r') as handle1:\n",
        "            for row in handle1:\n",
        "                count1 += 1\n",
        "        minimum = min(count0,count1)\n",
        "        if self.verbose:\n",
        "            print('File0 size: %d %s'%(count0,self.files[0]))\n",
        "            print('File1 size: %d %s'%(count1,self.files[1]))\n",
        "        return minimum\n",
        "        \n",
        "    def _load_line_(self,row):\n",
        "        line = row.strip()\n",
        "        fields = line.split(',')\n",
        "        fields[0] =  self.is_primary[fields[0]]\n",
        "        fields[6] =  self.is_primary[fields[6]]\n",
        "        fields[12] = self.is_primary[fields[12]]\n",
        "        fields[18] = self.is_primary[fields[18]]\n",
        "        integers = [int(x) for x in fields]\n",
        "        self.alignments.append(integers)\n",
        "    \n",
        "    def load_full_train_set(self):\n",
        "        '''Load first 80% of the data (assumed to be in random order)'''\n",
        "        minimum = 0\n",
        "        try:\n",
        "            minimum = self._count_lines_()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise Exception('CANNOT COUNT LINES IN FILE!')\n",
        "        train_size = int(minimum - minimum * TEST_PORTION)\n",
        "        if self.max_lines is not None:\n",
        "            train_size = min(train_size,self.max_lines)\n",
        "        if self.verbose:\n",
        "            print('Trying to load %d lines per file...'%train_size)\n",
        "        try:\n",
        "            handle0 = open(self.files[0],'r')\n",
        "            handle1 = open(self.files[1],'r')\n",
        "            # Associate label 0 with data from file 0. Same for 1.\n",
        "            for i in range(train_size):\n",
        "                row = next(handle0)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(0) \n",
        "                row = next(handle1)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(1)\n",
        "            handle0.close()\n",
        "            handle1.close()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise Exception('CANNOT LOAD DATA FROM FILE!')\n",
        "\n",
        "    def show_examples(self,head=6):\n",
        "        head = min(head,len(self.alignments))\n",
        "        for i in range(head):\n",
        "            print('From '+self.files[self.labels[i]])\n",
        "            print('Primary,Score,Edit,Mismatch,GapOpen,GapExtend')\n",
        "            print(self.alignments[i][0:6])\n",
        "            print(self.alignments[i][6:12])\n",
        "            print(self.alignments[i][12:18])\n",
        "            print(self.alignments[i][18:24])\n",
        "            \n",
        "    def get_X_y(self):\n",
        "        loaded = len(self.alignments)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        X_train = np.array(self.alignments[:divider])\n",
        "        y_train = np.array(self.labels[:divider])\n",
        "        X_valid = np.array(self.alignments[divider:])\n",
        "        y_valid = np.array(self.labels[divider:])\n",
        "        if self.verbose:\n",
        "            print('Full train set size = '+str(len(self.alignments)))\n",
        "            print('Training/Validation partition: %d/%d'%(len(y_train),len(y_valid)))\n",
        "        return X_train,y_train, X_valid,y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcZVyvS_126",
        "outputId": "15cdc877-ee85-43b8-d78c-1616cff53e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-03 16:38:48.855022\n",
            "Maximum lines to load per file: 1000000\n",
            "LOADING\n",
            "File0 size: 1000000 /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "File1 size: 1000000 /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Trying to load 1000000 lines per file...\n",
            "2023-06-03 16:39:07.890497\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, -25, 5, 5, 0, 0]\n",
            "[0, -10, 2, 2, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, -5, 1, 1, 0, 0]\n",
            "[0, -6, 2, 2, 0, 0]\n",
            "[1, -5, 1, 1, 0, 0]\n",
            "[1, -6, 2, 2, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, -19, 4, 4, 0, 0]\n",
            "[0, -24, 6, 6, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[1, -4, 2, 2, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[1, -1, 1, 1, 0, 0]\n",
            "[0, -5, 1, 1, 0, 0]\n",
            "[0, -4, 2, 2, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Primary,Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, -3, 1, 1, 0, 0]\n",
            "[0, -11, 6, 6, 0, 0]\n",
            "[1, -3, 1, 1, 0, 0]\n",
            "[1, -11, 6, 6, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "filepath0 = DATA_DIR+DATA_FILE_0\n",
        "filepath1 = DATA_DIR+DATA_FILE_1\n",
        "loader=DataLoader(filepath0,filepath1)\n",
        "loader.set_max_lines(MAX_LINES_TO_LOAD)\n",
        "print('LOADING')\n",
        "loader.load_full_train_set()\n",
        "print(datetime.now())\n",
        "loader.show_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uHn9Ib_129",
        "outputId": "1983b278-025f-455a-a437-f7d91adbc3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train set size = 2000000\n",
            "Training/Validation partition: 1600000/400000\n",
            "X train shape: \n",
            "(1600000, 24)\n",
            "y train shape: \n",
            "(1600000,)\n",
            "X valid shape: \n",
            "(400000, 24)\n",
            "y valid shape: \n",
            "(400000,)\n",
            "X[5]=\n",
            "[  0  -3   1   1   0   0   0 -11   6   6   0   0   1  -3   1   1   0   0\n",
            "   1 -11   6   6   0   0]\n",
            "y[5]=\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train, X_valid,y_valid = loader.get_X_y()\n",
        "print('X train shape: ')\n",
        "print(np.shape(X_train))\n",
        "print('y train shape: ')\n",
        "print(np.shape(y_train))\n",
        "print('X valid shape: ')\n",
        "print(np.shape(X_valid))\n",
        "print('y valid shape: ')\n",
        "print(np.shape(y_valid))\n",
        "print('X[5]=')\n",
        "print(X_train[5])\n",
        "print('y[5]=')\n",
        "print(y_train[5])\n",
        "#loader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    rfc = RFC()\n",
        "    return rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "f25c926e-c18e-4ec6-8efa-7c2c9f133adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-03 16:39:12.428396\n",
            "RandomForestClassifier()\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "rfc_model=build_model()\n",
        "print(rfc_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPC9vPhB_13E",
        "outputId": "256e8444-0cf6-41a1-9620-1ab1eb2967cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-03 16:39:12.445018\n",
            "FIT\n",
            "2023-06-03 16:42:43.869013\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "print(\"FIT\")\n",
        "rfc_model.fit(X_train, y_train) # sample weight\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4HCWG_w9_13F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82264d2-f73e-4af3-d7ed-d4ea65d421f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-03 16:42:43.881110\n",
            "PREDICT\n",
            "debug pred [0.0, 0.2702261904761905, 0.5483498278046592]\n",
            "debug class [0 0 1]\n",
            "2023-06-03 16:43:10.596661\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())        \n",
        "print(\"PREDICT\")\n",
        "yhat_pairs=rfc_model.predict_proba(X_valid)  # [ prob of 0, prob of 1 ]\n",
        "yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "yhat_classes=rfc_model.predict(X_valid)  # 0 or 1\n",
        "\n",
        "print('debug pred',yhat_pred[:3])\n",
        "print('debug class',yhat_classes[:3])\n",
        "print(datetime.now())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Si8QbOpY_13G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69fb363-b8e8-40ef-c948-fb782f642136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distrib of scores: 0.502600326716645 mean 0.3912884539604919 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[159918  40082]\n",
            " [ 23223 176777]]\n",
            "Normalized matrix\n",
            " [[0.399795  0.100205 ]\n",
            " [0.0580575 0.4419425]]\n",
            "Accuracy: 84.17% Precision: 81.52% Recall: 88.39%\n",
            "F1: 84.81% MCC: 0.6859\n",
            "AUPRC: 92.36% AUROC: 92.80%\n"
          ]
        }
      ],
      "source": [
        "print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "cm1 = confusion_matrix(y_valid,yhat_classes)\n",
        "print('Confusion matrix\\n',cm1)\n",
        "cm2 = confusion_matrix(y_valid,yhat_classes,normalize='all')\n",
        "print('Normalized matrix\\n',cm2)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
        "precision = precision_score(y_valid, yhat_classes)*100.\n",
        "recall = recall_score(y_valid, yhat_classes)*100.\n",
        "f1 = f1_score(y_valid, yhat_classes)*100.\n",
        "prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
        "auprc = auc(prc_X,prc_Y)*100.\n",
        "auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
        "mcc = matthews_corrcoef(y_valid, yhat_classes)\n",
        "\n",
        "print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjSVa72v4IsA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}