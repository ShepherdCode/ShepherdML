{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Support Vector Machine\n",
        "Arabidopsis, bowtie, transcripts.\n",
        "\n",
        "Compare to notebook RF_141\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "6a7edbd4-2688-4bb1-859b-dced56d5493b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 10:26:04.598483\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "36831c18-14b7-48d3-e1aa-2e9777ec8b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/IRP2/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/IRP2/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print('Running on Mac')\n",
        "    DATA_DIR=\"/Users/jasonmiller/WVU/BAM_ML/\"\n",
        "    MODEL_DIR=\"/Users/jasonmiller/WVU/BAM_ML/Models/\"\n",
        "SAVE_MODEL_FILENAME = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIAT2G5DYwvS",
        "outputId": "72d4a759-37db-4aa6-b312-b61b6a03441e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.6\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import random\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import pandas as pd  # for plotting\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "import gzip\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "# consider sklearn.metrics.classification_report\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "#from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "EPOCHS=150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkpVKdMFLA-",
        "outputId": "55e1af7b-9aef-44a5-a808-a6901f810f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data directory: /content/drive/My Drive/data/IRP2/\n",
            "Data file 0 Arabidopsis/Bowtie/lyrata/read_stats.csv.gz\n",
            "Data file 1 Arabidopsis/Bowtie/halleri/read_stats.csv.gz\n",
            "Input lines for training: 100000\n"
          ]
        }
      ],
      "source": [
        "#MAX_LINES_TO_LOAD =    1000000 # SVM ran for a day\n",
        "MAX_LINES_TO_LOAD =      100000 # try this\n",
        "#MAX_LINES_TO_LOAD =      10000 # use this for debugging\n",
        "\n",
        "VALID_PORTION = 0.20\n",
        "\n",
        "DATA_FILE_0 = 'Arabidopsis/Bowtie/lyrata/read_stats.csv.gz'\n",
        "DATA_FILE_1 = 'Arabidopsis/Bowtie/halleri/read_stats.csv.gz'\n",
        "\n",
        "print('Data directory: %s'%DATA_DIR)\n",
        "print('Data file 0 %s'%DATA_FILE_0)\n",
        "print('Data file 1 %s'%DATA_FILE_1)\n",
        "print('Input lines for training: %d'%MAX_LINES_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUBLdpVEVQ3I",
        "outputId": "a3b15d7c-8f67-4ac4-bbfa-5355e553d452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total feature names:  53\n",
            "0 P1 R1 AS\n",
            "1 P1 R1 ED\n",
            "2 P1 R1 MM\n",
            "3 P1 R1 HQMM\n",
            "4 P1 R1 GO\n",
            "5 P1 R1 GE\n",
            "6 P1 R1 INS\n",
            "7 P1 R1 DELS\n",
            "8 P1 R1 HQINS\n",
            "9 P1 R1 HQDEL\n",
            "10 P1 R2 AS\n",
            "11 P1 R2 ED\n",
            "12 P1 R2 MM\n",
            "13 P1 R2 HQMM\n",
            "14 P1 R2 GO\n",
            "15 P1 R2 GE\n",
            "16 P1 R2 INS\n",
            "17 P1 R2 DELS\n",
            "18 P1 R2 HQINS\n",
            "19 P1 R2 HQDEL\n",
            "20 P2 R1 AS\n",
            "21 P2 R1 ED\n",
            "22 P2 R1 MM\n",
            "23 P2 R1 HQMM\n",
            "24 P2 R1 GO\n",
            "25 P2 R1 GE\n",
            "26 P2 R1 INS\n",
            "27 P2 R1 DELS\n",
            "28 P2 R1 HQINS\n",
            "29 P2 R1 HQDEL\n",
            "30 P2 R2 AS\n",
            "31 P2 R2 ED\n",
            "32 P2 R2 MM\n",
            "33 P2 R2 HQMM\n",
            "34 P2 R2 GO\n",
            "35 P2 R2 GE\n",
            "36 P2 R2 INS\n",
            "37 P2 R2 DELS\n",
            "38 P2 R2 HQINS\n",
            "39 P2 R2 HQDEL\n",
            "40 Span diff\n",
            "41 AS diff\n",
            "42 ED diff\n",
            "43 MAT diff\n",
            "44 MM diff\n",
            "45 HQMM diff\n",
            "46 GO diff\n",
            "47 GE diff\n",
            "48 INS diff\n",
            "49 DELS diff\n",
            "50 HQINS diff\n",
            "51 HQDEL diff\n",
            "52 PARENT\n"
          ]
        }
      ],
      "source": [
        "# P1 parent 1\n",
        "# R1 read 1\n",
        "# PS primary or secondary\n",
        "# AS bowtie alignment score (0 is best)\n",
        "# ED edit distance\n",
        "# MM mismatch count\n",
        "# GO gap open count\n",
        "# GE gap extend count\n",
        "feature_names = [\n",
        "    'P1 R1 AS',\n",
        "    'P1 R1 ED',\n",
        "    ##'P1 R1 MAT',\n",
        "    'P1 R1 MM',\n",
        "    'P1 R1 HQMM',\n",
        "    'P1 R1 GO',\n",
        "    'P1 R1 GE',\n",
        "    'P1 R1 INS',\n",
        "    'P1 R1 DELS',\n",
        "    'P1 R1 HQINS',\n",
        "    'P1 R1 HQDEL',\n",
        "    'P1 R2 AS',\n",
        "    'P1 R2 ED',\n",
        "    ##'P1 R2 MAT',\n",
        "    'P1 R2 MM',\n",
        "    'P1 R2 HQMM',\n",
        "    'P1 R2 GO',\n",
        "    'P1 R2 GE',\n",
        "    'P1 R2 INS',\n",
        "    'P1 R2 DELS',\n",
        "    'P1 R2 HQINS',\n",
        "    'P1 R2 HQDEL',\n",
        "    'P2 R1 AS',\n",
        "    'P2 R1 ED',\n",
        "    ##'P2 R1 MAT',\n",
        "    'P2 R1 MM',\n",
        "    'P2 R1 HQMM',\n",
        "    'P2 R1 GO',\n",
        "    'P2 R1 GE',\n",
        "    'P2 R1 INS',\n",
        "    'P2 R1 DELS',\n",
        "    'P2 R1 HQINS',\n",
        "    'P2 R1 HQDEL',\n",
        "    'P2 R2 AS',\n",
        "    'P2 R2 ED',\n",
        "    ##'P2 R2 MAT',\n",
        "    'P2 R2 MM',\n",
        "    'P2 R2 HQMM',\n",
        "    'P2 R2 GO',\n",
        "    'P2 R2 GE',\n",
        "    'P2 R2 INS',\n",
        "    'P2 R2 DELS',\n",
        "    'P2 R2 HQINS',\n",
        "    'P2 R2 HQDEL',\n",
        "    ##'R1 length',\n",
        "    ##'R2 length',\n",
        "    ##'P1 span',\n",
        "    ##'P2 span',\n",
        "    'Span diff',\n",
        "    'AS diff',\n",
        "    'ED diff',\n",
        "    'MAT diff',\n",
        "    'MM diff',\n",
        "    'HQMM diff',\n",
        "    'GO diff',\n",
        "    'GE diff',\n",
        "    'INS diff',\n",
        "    'DELS diff',\n",
        "    'HQINS diff',\n",
        "    'HQDEL diff',\n",
        "    'PARENT']\n",
        "print('Total feature names: ',len(feature_names))\n",
        "for i in range(len(feature_names)):\n",
        "    print(i,feature_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,filepath1,filepath2,verbose=True):\n",
        "        self.files = [filepath1,filepath2]\n",
        "        self.alignments=[]\n",
        "        self.labels=[]\n",
        "        self.verbose = verbose\n",
        "        self.max_lines = None\n",
        "        self.ties = 0\n",
        "        self.predictions = []\n",
        "        self.num_features = 1\n",
        "\n",
        "    def set_num_features(self,count):\n",
        "        self.num_features = count\n",
        "\n",
        "    def set_max_lines(self,lines):\n",
        "        '''Limit the dataset size to fit in RAM.'''\n",
        "        self.max_lines = lines\n",
        "        if self.verbose:\n",
        "            print('Maximum lines to load per file: %d'%lines)\n",
        "\n",
        "    def _count_lines_(self):\n",
        "        '''Show number of lines per input file.'''\n",
        "        count0 = 0\n",
        "        with gzip.open (self.files[0],'rt') as handle0:\n",
        "            for row in handle0:\n",
        "                count0 += 1\n",
        "        count1 = 0\n",
        "        with gzip.open(self.files[1],'rt') as handle1:\n",
        "            for row in handle1:\n",
        "                count1 += 1\n",
        "        minimum = min(count0,count1)\n",
        "        if self.verbose:\n",
        "            print('File0 size: %d %s'%(count0,self.files[0]))\n",
        "            print('File1 size: %d %s'%(count1,self.files[1]))\n",
        "        return minimum\n",
        "\n",
        "    def _load_line_(self,row):\n",
        "        '''Load data structure from one line of CSV file.'''\n",
        "        line = row.strip()\n",
        "        fields = line.split(',')\n",
        "        ints = [0] * self.num_features\n",
        "        # These fields come straight from the input file.\n",
        "        # These fields are grouped by which read they describe.\n",
        "        # P1 R1 = Parent 1, Read 1\n",
        "        ints[0] = int(fields[0]) # P1 R1 AS\n",
        "        ints[1] = int(fields[1]) # P1 R1 ED\n",
        "        P1R1_MAT = int(fields[2]) # P1 R1 MAT\n",
        "        ints[2] = int(fields[3]) # P1 R1 MM\n",
        "        ints[3] = int(fields[4]) # P1 R1 HQMM\n",
        "        ints[4] = int(fields[5]) # P1 R1 GO\n",
        "        ints[5] = int(fields[6]) # P1 R1 GE\n",
        "        ints[6] = int(fields[7]) # P1 R1 INS\n",
        "        ints[7] = int(fields[8]) # P1 R1 DELS\n",
        "        ints[8] = int(fields[9]) # P1 R1 HQINS\n",
        "        ints[9] = int(fields[10]) # P1 R1 HQDEL\n",
        "        #  = Parent 1, Read 2\n",
        "        ints[10] = int(fields[11]) # P1 R2 AS\n",
        "        ints[11] = int(fields[12]) # P1 R2 ED\n",
        "        P1R2_MAT = int(fields[13]) # P1 R2 MAT\n",
        "        ints[12] = int(fields[14]) # P1 R2 MM\n",
        "        ints[13] = int(fields[15]) # P1 R2 HQMM\n",
        "        ints[14] = int(fields[16]) # P1 R2 GO\n",
        "        ints[15] = int(fields[17]) # P1 R2 GE\n",
        "        ints[16] = int(fields[18]) # P1 R2 INS\n",
        "        ints[17] = int(fields[19]) # P1 R2 DELS\n",
        "        ints[18] = int(fields[20]) # P1 R2 HQINS\n",
        "        ints[19] = int(fields[21]) # P1 R2 HQDEL\n",
        "        # P2 R1 = Parent 2, Read 1\n",
        "        ints[20] = int(fields[22]) # P2 R1 AS\n",
        "        ints[21] = int(fields[23]) # P2 R1 ED\n",
        "        P2R1_MAT = int(fields[24]) # P2 R1 MAT\n",
        "        ints[22] = int(fields[25]) # P2 R1 MM\n",
        "        ints[23] = int(fields[26]) # P2 R1 HQMM\n",
        "        ints[24] = int(fields[27]) # P2 R1 GO\n",
        "        ints[25] = int(fields[28]) # P2 R1 GE\n",
        "        ints[26] = int(fields[29]) # P2 R1 INS\n",
        "        ints[27] = int(fields[30]) # P2 R1 DELS\n",
        "        ints[28] = int(fields[31]) # P2 R1 HQINS\n",
        "        ints[29] = int(fields[32]) # P2 R1 HQDEL\n",
        "        # P2 R2 = Parent 2, Read 2\n",
        "        ints[30] = int(fields[33]) # P2 R2 AS\n",
        "        ints[31] = int(fields[34]) # P2 R2 ED\n",
        "        P2R2_MAT = int(fields[35]) # P2 R2 MAT\n",
        "        ints[32] = int(fields[36]) # P2 R2 MM\n",
        "        ints[33] = int(fields[37]) # P2 R2 HQMM\n",
        "        ints[34] = int(fields[38]) # P2 R2 GO\n",
        "        ints[35] = int(fields[39]) # P2 R2 GE\n",
        "        ints[36] = int(fields[40]) # P2 R2 INS\n",
        "        ints[37] = int(fields[41]) # P2 R2 DELS\n",
        "        ints[38] = int(fields[42]) # P2 R2 HQINS\n",
        "        ints[39] = int(fields[43]) # P2 R2 HQDEL\n",
        "        # Fields that come in twos\n",
        "        R1_LEN = int(fields[44]) # R1 length (of read)\n",
        "        R2_LEN = int(fields[45]) # R2 length (of read)\n",
        "        P1_SPAN = int(fields[46]) # P1 span (of mapped read pair)\n",
        "        P2_SPAN = int(fields[47]) # P2 span (of mapped read pair)\n",
        "        # Read-wise differences\n",
        "        ints[40] = P2_SPAN-P1_SPAN # P2-P1 span diff\n",
        "        ints[41] = (ints[33]+ints[22])-(ints[11]+ints[0]) # AS diff\n",
        "        ints[42] = (ints[34]+ints[23])-(ints[12]+ints[1]) # ED diff\n",
        "        ints[43] = (P2R1_MAT+P2R2_MAT)-(P1R1_MAT+P1R2_MAT) # MAT diff\n",
        "        ints[44] = (ints[36]+ints[25])-(ints[14]+ints[3]) # MM diff\n",
        "        ints[45] = (ints[37]+ints[26])-(ints[15]+ints[4]) # HQMM diff\n",
        "        ints[46] = (ints[38]+ints[27])-(ints[16]+ints[5]) # GO diff\n",
        "        ints[47] = (ints[39]+ints[28])-(ints[17]+ints[6]) # GE diff\n",
        "        ints[48] = (ints[40]+ints[29])-(ints[18]+ints[7]) # INS diff\n",
        "        ints[49] = (ints[41]+ints[30])-(ints[19]+ints[8]) # DELS diff\n",
        "        ints[50] = (ints[42]+ints[31])-(ints[20]+ints[9]) # HQINS diff\n",
        "        ints[51] = (ints[43]+ints[32])-(ints[21]+ints[10]) # HQDEL diff\n",
        "        # The feature-extraction program populated a field\n",
        "        # to indicate which parent had higher alignment score.\n",
        "        # Values were 0=same, 1=parent1, 2=parent2.\n",
        "        # We change the values to -1=parent1, 0=unknown, +1=parent2\n",
        "        parent_choice = int(fields[48])\n",
        "        if parent_choice == 1:\n",
        "            ints[52] = -1  # not parent 2\n",
        "        elif parent_choice == 2:\n",
        "            ints[52] = 1  # is parent 2\n",
        "        elif parent_choice == 0:\n",
        "            ints[52] = 0\n",
        "        else:\n",
        "            raise Exception('Unrecognized parent choice:'+str(parent_choice))\n",
        "        # For fair comparison, force aligner to choose.\n",
        "        # We change 1 to 0, 2 to 1, and 0 to 1 or 2 randomly.\n",
        "        # TO DO: faster alternative to list.append() ???\n",
        "        parent_choice = int(fields[48])\n",
        "        if parent_choice == 1:\n",
        "            self.predictions.append(0)  # not parent 2\n",
        "        elif parent_choice == 2:\n",
        "            self.predictions.append(1)  # is parent 2\n",
        "        else: # parent_choice == 0:\n",
        "            self.ties += 1\n",
        "            guess = random.randint(0,1)\n",
        "            self.predictions.append(guess)\n",
        "        # The transcript that this read pair aligned to.\n",
        "        # This is for pipelines that only process reads that map\n",
        "        # to same transcript in both parents and (filter the others).\n",
        "        # Pipelines that assign reads to parent, regardless of which gene,\n",
        "        # should ignore this value. (It only reflects first parent map anyway.)\n",
        "        transcript_id = fields[49] # TO DO: where to put this?\n",
        "        self.alignments.append(ints)\n",
        "\n",
        "    def count_ties(self):\n",
        "        return self.ties\n",
        "\n",
        "    def load_full_train_set(self):\n",
        "        '''Load full train set (to be used for train and valiation).\n",
        "           Use set_max_lines() to leave some data for the test set.'''\n",
        "        minimum = 0\n",
        "        train_size = self.max_lines\n",
        "        if self.verbose:\n",
        "            print('Trying to load %d lines per file...'%train_size)\n",
        "        try:\n",
        "            handle0 = gzip.open(self.files[0],'rt')\n",
        "            handle1 = gzip.open(self.files[1],'rt')\n",
        "            # Associate label 0 with data from file 0. Same for 1.\n",
        "            for i in range(train_size):\n",
        "                row = next(handle0)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(0)\n",
        "                row = next(handle1)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(1)\n",
        "            handle0.close()\n",
        "            handle1.close()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print('Most likely, one file has too few reads.')\n",
        "            raise Exception('CANNOT LOAD DATA FROM FILE!')\n",
        "\n",
        "    def show_examples(self,head=6):\n",
        "        head = min(head,len(self.alignments))\n",
        "        for i in range(head):\n",
        "            print('From '+self.files[self.labels[i]])\n",
        "            print('Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL')\n",
        "            print(self.alignments[i][0:9])\n",
        "            print(self.alignments[i][10:19])\n",
        "            print(self.alignments[i][20:29])\n",
        "            print(self.alignments[i][30:39])\n",
        "            print('Parent choice:',self.alignments[i][52])\n",
        "\n",
        "    def get_X_y(self):\n",
        "        loaded = len(self.alignments)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        X_train = np.array(self.alignments[:divider])\n",
        "        y_train = np.array(self.labels[:divider])\n",
        "        X_valid = np.array(self.alignments[divider:])\n",
        "        y_valid = np.array(self.labels[divider:])\n",
        "        if self.verbose:\n",
        "            print('Full train set size = '+str(len(self.alignments)))\n",
        "            print('Training/Validation partition: %d/%d'%(len(y_train),len(y_valid)))\n",
        "        return X_train,y_train, X_valid,y_valid\n",
        "\n",
        "    def get_predictions(self):\n",
        "        loaded = len(self.predictions)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        y_train = self.predictions[:divider]\n",
        "        y_valid = self.predictions[divider:]\n",
        "        return y_train, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcZVyvS_126",
        "outputId": "1b22caa9-6155-411b-effe-68c0c1d3af08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 10:26:34.352196\n",
            "Maximum lines to load per file: 100000\n",
            "LOADING\n",
            "Trying to load 100000 lines per file...\n",
            "Number of ties: 27393\n",
            "2023-07-25 10:26:41.761644\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/lyrata/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[-6, 2, 2, 0, 0, 0, 0, 0, 0]\n",
            "[-3, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[-12, 3, 3, 1, 0, 0, 0, 0, 0]\n",
            "[-9, 2, 2, 1, 0, 0, 0, 0, 0]\n",
            "Parent choice: -1\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/halleri/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[-36, 6, 6, 0, 0, 0, 0, 0, 0]\n",
            "[-25, 5, 5, 0, 0, 0, 0, 0, 0]\n",
            "[-30, 5, 5, 0, 0, 0, 0, 0, 0]\n",
            "[-31, 6, 6, 0, 0, 0, 0, 0, 0]\n",
            "Parent choice: 0\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/lyrata/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[-17, 3, 3, 2, 0, 0, 0, 0, 0]\n",
            "[-12, 3, 3, 1, 0, 0, 0, 0, 0]\n",
            "Parent choice: -1\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/halleri/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-6, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[-6, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "Parent choice: -1\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/lyrata/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-37, 10, 3, 0, 1, 7, 7, 0, 6]\n",
            "[-18, 3, 3, 3, 0, 0, 0, 0, 0]\n",
            "[-17, 4, 4, 1, 0, 0, 0, 0, 0]\n",
            "Parent choice: 1\n",
            "From /content/drive/My Drive/data/IRP2/Arabidopsis/Bowtie/halleri/read_stats.csv.gz\n",
            "Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL\n",
            "[-30, 5, 5, 0, 0, 0, 0, 0, 0]\n",
            "[-47, 8, 6, 0, 1, 2, 2, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-23, 4, 2, 0, 1, 2, 2, 0, 0]\n",
            "Parent choice: 1\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "filepath0 = DATA_DIR+DATA_FILE_0\n",
        "filepath1 = DATA_DIR+DATA_FILE_1\n",
        "loader=DataLoader(filepath0,filepath1)\n",
        "loader.set_max_lines(MAX_LINES_TO_LOAD)\n",
        "loader.set_num_features(len(feature_names))\n",
        "print('LOADING')\n",
        "loader.load_full_train_set()\n",
        "print('Number of ties: %d' % loader.count_ties())\n",
        "aligner_predictions_train, aligner_predictions_valid = loader.get_predictions()\n",
        "print(datetime.now())\n",
        "loader.show_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uHn9Ib_129",
        "outputId": "6429f513-3b06-497e-a6de-27e6cf29dd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train set size = 200000\n",
            "Training/Validation partition: 160000/40000\n",
            "X train shape: \n",
            "(160000, 53)\n",
            "y train shape: \n",
            "(160000,)\n",
            "X valid shape: \n",
            "(40000, 53)\n",
            "y valid shape: \n",
            "(40000,)\n",
            "X[5]=\n",
            "[-30   5   5   0   0   0   0   0   0   0 -47   8   6   0   1   2   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0 -23   4   2   0   1   2\n",
            "   2   0   0   0   0  22 -10   9   1  -2  -2   0   0  -1  -6  58   1]\n",
            "y[5]=\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train, X_valid,y_valid = loader.get_X_y()\n",
        "print('X train shape: ')\n",
        "print(np.shape(X_train))\n",
        "print('y train shape: ')\n",
        "print(np.shape(y_train))\n",
        "print('X valid shape: ')\n",
        "print(np.shape(X_valid))\n",
        "print('y valid shape: ')\n",
        "print(np.shape(y_valid))\n",
        "print('X[5]=')\n",
        "print(X_train[5])\n",
        "print('y[5]=')\n",
        "print(y_train[5])\n",
        "#loader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    svm = SVC(probability=True)\n",
        "    return svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "82e1bd22-9a4f-437b-84f3-888f231e0572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 10:26:43.808404\n",
            "SVC(probability=True)\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "rfc_model=build_model()\n",
        "print(rfc_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPC9vPhB_13E",
        "outputId": "db761c0b-5306-4b00-f8a1-d06a18d95db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 10:26:43.823676\n",
            "FIT\n",
            "Elapsed seconds: 7416.181834936142\n",
            "2023-07-25 12:30:20.010442\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "print(\"FIT\")\n",
        "start_time = time.time()\n",
        "rfc_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "print('Elapsed seconds:', (end_time-start_time))\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfgplJ3Ep8Vr"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCWG_w9_13F",
        "outputId": "425e72fd-3425-42f3-a172-3b5b2196e2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 12:30:20.038901\n",
            "PREDICT\n",
            "debug pred [4.955902991656021e-06, 0.9849020729638469, 7.351707638385572e-07]\n",
            "debug class [0 1 0]\n",
            "2023-07-25 12:34:47.637553\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "print(\"PREDICT\")\n",
        "yhat_pairs=rfc_model.predict_proba(X_valid)  # [ prob of 0, prob of 1 ]\n",
        "yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "yhat_classes=rfc_model.predict(X_valid)  # 0 or 1\n",
        "\n",
        "print('debug pred',yhat_pred[:3])\n",
        "print('debug class',yhat_classes[:3])\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VCzbj21FMpfU"
      },
      "outputs": [],
      "source": [
        "# docs: Note that in binary classification, recall of the positive class is also known as “sensitivity”; recall of the negative class is “specificity”.\n",
        "def show_performance(y_valid, yhat_classes, yhat_pred):\n",
        "    accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
        "    precision = precision_score(y_valid, yhat_classes)*100.\n",
        "    recall = recall_score(y_valid, yhat_classes)*100.\n",
        "    sensitivity = recall_score(y_valid, yhat_classes, pos_label=1)*100.\n",
        "    specificity = recall_score(y_valid, yhat_classes, pos_label=0)*100.\n",
        "    f1 = f1_score(y_valid, yhat_classes)*100.\n",
        "    mcc = matthews_corrcoef(y_valid, yhat_classes)\n",
        "    if yhat_pred is None:\n",
        "        # these stats are possible for probabilistic models only\n",
        "        auprc = 0.\n",
        "        auroc = 0.\n",
        "    else:\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
        "    values,counts=np.unique(yhat_classes, return_counts=True)\n",
        "    print('Predictions: ', dict(zip(values, counts)))\n",
        "    print('Accuracy: %.2f%% F1: %.2f%% MCC: %.4f' % (accuracy,f1,mcc))\n",
        "    print('Precision: %.2f%% Recall: %.2f%% AUPRC: %.2f%%' % (precision,recall,auprc))\n",
        "    print('Sensitivity: %.2f%% Specificity: %.2f%% AUROC: %.2f%%' % (sensitivity,specificity,auroc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8QbOpY_13G",
        "outputId": "5dd67686-1a0b-41fb-eacf-4a0519ded2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distrib of scores: 0.4953389725789836 mean 0.46069285072291644 std\n",
            "Range of scores: 1.0000000994736041e-07 to 0.9999999817771809\n",
            "Confusion matrix\n",
            " [[19502   498]\n",
            " [ 1853 18147]]\n",
            "Normalized matrix\n",
            " [[0.48755  0.01245 ]\n",
            " [0.046325 0.453675]]\n",
            "Predictions:  {0: 21355, 1: 18645}\n",
            "Accuracy: 94.12% F1: 93.92% MCC: 0.8845\n",
            "Precision: 97.33% Recall: 90.73% AUPRC: 99.02%\n",
            "Sensitivity: 90.73% Specificity: 97.51% AUROC: 98.90%\n"
          ]
        }
      ],
      "source": [
        "print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "cm1 = confusion_matrix(y_valid,yhat_classes)\n",
        "print('Confusion matrix\\n',cm1)\n",
        "cm2 = confusion_matrix(y_valid,yhat_classes,normalize='all')\n",
        "print('Normalized matrix\\n',cm2)\n",
        "\n",
        "show_performance(y_valid, yhat_classes, yhat_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkR5p_t4b4Ex"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S2yWyqUcHt9",
        "outputId": "b9c0059f-8231-4fe6-8b2f-dbbc2b0886f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  {0: 23846, 1: 16154}\n",
            "Accuracy: 81.56% F1: 79.60% MCC: 0.6433\n",
            "Precision: 89.08% Recall: 71.95% AUPRC: 0.00%\n",
            "Sensitivity: 71.95% Specificity: 91.18% AUROC: 0.00%\n"
          ]
        }
      ],
      "source": [
        "show_performance(y_valid, aligner_predictions_valid, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a86dksKXYwvy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}