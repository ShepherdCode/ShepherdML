{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Random Forest\n",
        "Like RF_106 but save the RF probability distribution.\n",
        "No more need for the feature ranking or Bowtie comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "f111ed8f-4535-4ba7-f373-5d1f2763a7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 18:04:00.160227\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "54a4fadb-2a80-4e5a-917e-7b7b7196049e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data/IRP2/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/IRP2/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/IRP2/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print('Running on Mac')\n",
        "    DATA_DIR=\"/Users/jasonmiller/WVU/BAM_ML/\"\n",
        "    MODEL_DIR=\"/Users/jasonmiller/WVU/BAM_ML/Models/\"\n",
        "print(DATA_DIR)\n",
        "SAVE_MODEL_FILENAME = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "627dd8e8-1de9-4ac2-d21e-b822cef810d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import pandas as pd  # for plotting\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "EPOCHS=150 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkpVKdMFLA-",
        "outputId": "8af3f31a-3fc8-4659-ba5c-2b01d4396a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data file 0 MxM_BR4/first_million_stats.csv\n",
            "Data file 1 SxS_BR4/first_million_stats.csv\n",
            "Maximum lines to load per file for training: 1000000\n"
          ]
        }
      ],
      "source": [
        "DATASET = 2   # 1=full, 2=million, 3=tiny\n",
        "\n",
        "# Full dataset (may exceed RAM)\n",
        "DATA_FILE_0 = 'MxM_BR4/ml_stats.csv'\n",
        "DATA_FILE_1 = 'SxS_BR4/ml_stats.csv'\n",
        "if DATASET==2:\n",
        "    # First million for testing\n",
        "    DATA_FILE_0 = 'MxM_BR4/first_million_stats.csv'\n",
        "    DATA_FILE_1 = 'SxS_BR4/first_million_stats.csv'\n",
        "if DATASET==3:\n",
        "    # Tiny dataset for debugging\n",
        "    DATA_FILE_0 = 'tiny_MxM/ml_stats.csv'\n",
        "    DATA_FILE_1 = 'tiny_SxS/ml_stats.csv'\n",
        "\n",
        "print('Data file 0 %s'%DATA_FILE_0)\n",
        "print('Data file 1 %s'%DATA_FILE_1)\n",
        "TEST_PORTION=0.00   # set to 20% when using complete files (ml_stats)\n",
        "VALID_PORTION=0.20\n",
        "MAX_LINES_TO_LOAD=1000000  # million\n",
        "print('Maximum lines to load per file for training: %d'%MAX_LINES_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,filepath1,filepath2,verbose=True):\n",
        "        self.files = [filepath1,filepath2]\n",
        "        self.alignments=[]\n",
        "        self.labels=[]\n",
        "        self.is_primary={'P':1, 'S':0}\n",
        "        self.verbose = verbose\n",
        "        self.max_lines = None\n",
        "        \n",
        "    def set_max_lines(self,lines):\n",
        "        self.max_lines = lines\n",
        "        if self.verbose:\n",
        "            print('Maximum lines to load per file: %d'%lines)\n",
        "        \n",
        "    def _count_lines_(self):\n",
        "        count0 = 0\n",
        "        with open (self.files[0],'r') as handle0:\n",
        "            for row in handle0:\n",
        "                count0 += 1\n",
        "        count1 = 0\n",
        "        with open(self.files[1],'r') as handle1:\n",
        "            for row in handle1:\n",
        "                count1 += 1\n",
        "        minimum = min(count0,count1)\n",
        "        if self.verbose:\n",
        "            print('File0 size: %d %s'%(count0,self.files[0]))\n",
        "            print('File1 size: %d %s'%(count1,self.files[1]))\n",
        "        return minimum\n",
        "        \n",
        "    def _load_line_(self,row):\n",
        "        line = row.strip()\n",
        "        fields = line.split(',')\n",
        "        ints = [0] * 26\n",
        "        ints[0] = int(fields[1]) # P1 R1 AS\n",
        "        ints[1] = int(fields[2]) # P1 R1 ED\n",
        "        ints[2] = int(fields[3]) # P1 R1 MM\n",
        "        ints[3] = int(fields[4]) # P1 R1 GO\n",
        "        ints[4] = int(fields[5]) # P1 R1 GE\n",
        "        ints[5] = int(fields[7]) # P1 R2 AS\n",
        "        ints[6] = int(fields[8]) # P1 R2 ED\n",
        "        ints[7] = int(fields[9]) # P1 R2 MM\n",
        "        ints[8] = int(fields[10]) # P1 R2 GO\n",
        "        ints[9] = int(fields[11]) # P1 R2 GE\n",
        "        ints[10] = int(fields[13]) # P2 R1 AS\n",
        "        ints[11] = int(fields[14]) # P2 R1 ED\n",
        "        ints[12] = int(fields[15]) # P2 R1 MM\n",
        "        ints[13] = int(fields[16]) # P2 R1 GO\n",
        "        ints[14] = int(fields[17]) # P2 R1 GE\n",
        "        ints[15] = int(fields[19]) # P2 R2 AS\n",
        "        ints[16] = int(fields[20]) # P2 R2 ED\n",
        "        ints[17] = int(fields[21]) # P2 R2 MM\n",
        "        ints[18] = int(fields[22]) # P2 R2 GO\n",
        "        ints[19] = int(fields[23]) # P2 R2 GE        \n",
        "        ints[20] = int(((ints[10]+ints[15])-(ints[0]+ints[5]))/2) # AS diff\n",
        "        ints[21] = int(((ints[11]+ints[16])-(ints[1]+ints[6]))/2) # ED diff\n",
        "        ints[22] = int(((ints[12]+ints[17])-(ints[2]+ints[7]))/2) # MM diff\n",
        "        ints[23] = int(((ints[13]+ints[18])-(ints[3]+ints[8]))/2) # GO diff\n",
        "        ints[24] = int(((ints[14]+ints[19])-(ints[4]+ints[9]))/2) # GE diff\n",
        "        primary_letter = fields[12]  # parent 2 is P=primary or S=Secondary\n",
        "        primary_digit = self.is_primary[primary_letter] # convert to 1 or 0\n",
        "        ints[25] = primary_digit  # 1 for P2 is primary\n",
        "        self.alignments.append(ints)\n",
        "    \n",
        "    def load_full_train_set(self):\n",
        "        '''Load first 80% of the data (assumed to be in random order)'''\n",
        "        minimum = 0\n",
        "        try:\n",
        "            minimum = self._count_lines_()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise Exception('CANNOT COUNT LINES IN FILE!')\n",
        "        train_size = int(minimum - minimum * TEST_PORTION)\n",
        "        if self.max_lines is not None:\n",
        "            train_size = min(train_size,self.max_lines)\n",
        "        if self.verbose:\n",
        "            print('Trying to load %d lines per file...'%train_size)\n",
        "        try:\n",
        "            handle0 = open(self.files[0],'r')\n",
        "            handle1 = open(self.files[1],'r')\n",
        "            # Associate label 0 with data from file 0. Same for 1.\n",
        "            for i in range(train_size):\n",
        "                row = next(handle0)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(0) \n",
        "                row = next(handle1)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(1)\n",
        "            handle0.close()\n",
        "            handle1.close()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise Exception('CANNOT LOAD DATA FROM FILE!')\n",
        "\n",
        "    def show_examples(self,head=6):\n",
        "        head = min(head,len(self.alignments))\n",
        "        for i in range(head):\n",
        "            print('From '+self.files[self.labels[i]])\n",
        "            print('Score,Edit,Mismatch,GapOpen,GapExtend')\n",
        "            print(self.alignments[i][0:5])\n",
        "            print(self.alignments[i][5:10])\n",
        "            print(self.alignments[i][10:15])\n",
        "            print(self.alignments[i][15:20])\n",
        "            print(self.alignments[i][20:26])\n",
        "            \n",
        "    def get_X_y(self):\n",
        "        loaded = len(self.alignments)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        X_train = np.array(self.alignments[:divider])\n",
        "        y_train = np.array(self.labels[:divider])\n",
        "        X_valid = np.array(self.alignments[divider:])\n",
        "        y_valid = np.array(self.labels[divider:])\n",
        "        if self.verbose:\n",
        "            print('Full train set size = '+str(len(self.alignments)))\n",
        "            print('Training/Validation partition: %d/%d'%(len(y_train),len(y_valid)))\n",
        "        return X_train,y_train, X_valid,y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcZVyvS_126",
        "outputId": "664f2168-adb1-4b65-9786-7f06f69d68b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 18:04:27.740918\n",
            "Maximum lines to load per file: 1000000\n",
            "LOADING\n",
            "File0 size: 1000000 /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "File1 size: 1000000 /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Trying to load 1000000 lines per file...\n",
            "2023-06-05 18:04:47.170466\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-25, 5, 5, 0, 0]\n",
            "[-10, 2, 2, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[17, -3, -3, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-6, 2, 2, 0, 0]\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-6, 2, 2, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-19, 4, 4, 0, 0]\n",
            "[-24, 6, 6, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[-4, 2, 2, 0, 0]\n",
            "[19, -4, -4, 0, 0, 1]\n",
            "From /content/drive/My Drive/data/IRP2/MxM_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[0, 0, 0, 0, 0]\n",
            "[-1, 1, 1, 0, 0]\n",
            "[-5, 1, 1, 0, 0]\n",
            "[-4, 2, 2, 0, 0]\n",
            "[-4, 1, 1, 0, 0, 0]\n",
            "From /content/drive/My Drive/data/IRP2/SxS_BR4/first_million_stats.csv\n",
            "Score,Edit,Mismatch,GapOpen,GapExtend\n",
            "[-3, 1, 1, 0, 0]\n",
            "[-11, 6, 6, 0, 0]\n",
            "[-3, 1, 1, 0, 0]\n",
            "[-11, 6, 6, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "filepath0 = DATA_DIR+DATA_FILE_0\n",
        "filepath1 = DATA_DIR+DATA_FILE_1\n",
        "loader=DataLoader(filepath0,filepath1)\n",
        "loader.set_max_lines(MAX_LINES_TO_LOAD)\n",
        "print('LOADING')\n",
        "loader.load_full_train_set()\n",
        "print(datetime.now())\n",
        "loader.show_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uHn9Ib_129",
        "outputId": "9b29ce0c-5467-450c-9436-d63a56a1b561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train set size = 2000000\n",
            "Training/Validation partition: 1600000/400000\n",
            "X train shape: \n",
            "(1600000, 26)\n",
            "y train shape: \n",
            "(1600000,)\n",
            "X valid shape: \n",
            "(400000, 26)\n",
            "y valid shape: \n",
            "(400000,)\n",
            "X[5]=\n",
            "[ -3   1   1   0   0 -11   6   6   0   0  -3   1   1   0   0 -11   6   6\n",
            "   0   0   0   0   0   0   0   1]\n",
            "y[5]=\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train, X_valid,y_valid = loader.get_X_y()\n",
        "print('X train shape: ')\n",
        "print(np.shape(X_train))\n",
        "print('y train shape: ')\n",
        "print(np.shape(y_train))\n",
        "print('X valid shape: ')\n",
        "print(np.shape(X_valid))\n",
        "print('y valid shape: ')\n",
        "print(np.shape(y_valid))\n",
        "print('X[5]=')\n",
        "print(X_train[5])\n",
        "print('y[5]=')\n",
        "print(y_train[5])\n",
        "#loader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    rfc = RFC()\n",
        "    return rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "4374a6a9-c34b-4c1d-8123-26f6eb651e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 18:04:53.140824\n",
            "RandomForestClassifier()\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "rfc_model=build_model()\n",
        "print(rfc_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPC9vPhB_13E",
        "outputId": "9740a853-24d0-47c6-befd-3d674a8da7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 18:04:53.161081\n",
            "FIT\n",
            "2023-06-05 18:10:19.003978\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "print(\"FIT\")\n",
        "rfc_model.fit(X_train, y_train) # sample weight\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfgplJ3Ep8Vr"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCWG_w9_13F",
        "outputId": "5d57989e-a4a4-4700-ef8b-0fb64f0b8305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 18:10:19.019598\n",
            "PREDICT\n",
            "debug pred [0.0, 0.20030952380952377, 0.5483498278046592]\n",
            "debug class [0 0 1]\n",
            "2023-06-05 18:10:51.500537\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())        \n",
        "print(\"PREDICT\")\n",
        "yhat_pairs=rfc_model.predict_proba(X_valid)  # [ prob of 0, prob of 1 ]\n",
        "yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "yhat_classes=rfc_model.predict(X_valid)  # 0 or 1\n",
        "\n",
        "print('debug pred',yhat_pred[:3])\n",
        "print('debug class',yhat_classes[:3])\n",
        "print(datetime.now())        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8QbOpY_13G",
        "outputId": "f0405839-7fe8-42f5-fdbb-bd7f462d60d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distrib of scores: 0.5023859974779071 mean 0.3915598328136507 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[160110  39890]\n",
            " [ 22992 177008]]\n",
            "Normalized matrix\n",
            " [[0.400275 0.099725]\n",
            " [0.05748  0.44252 ]]\n",
            "Accuracy: 84.28% Precision: 81.61% Recall: 88.50%\n",
            "F1: 84.92% MCC: 0.6881\n",
            "AUPRC: 92.41% AUROC: 92.86%\n"
          ]
        }
      ],
      "source": [
        "print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "cm1 = confusion_matrix(y_valid,yhat_classes)\n",
        "print('Confusion matrix\\n',cm1)\n",
        "cm2 = confusion_matrix(y_valid,yhat_classes,normalize='all')\n",
        "print('Normalized matrix\\n',cm2)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
        "precision = precision_score(y_valid, yhat_classes)*100.\n",
        "recall = recall_score(y_valid, yhat_classes)*100.\n",
        "f1 = f1_score(y_valid, yhat_classes)*100.\n",
        "prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
        "auprc = auc(prc_X,prc_Y)*100.\n",
        "auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
        "mcc = matthews_corrcoef(y_valid, yhat_classes)\n",
        "\n",
        "print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOp3DVaYp8V5"
      },
      "source": [
        "# Save the score distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1l2Tmp_urzL",
        "outputId": "082bde71-5463-423a-b1f1-55a676da9231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/data/IRP2/RF_107.csv\n",
            "2023-06-05 18:10:53.197578\n"
          ]
        }
      ],
      "source": [
        "length = len(y_valid)\n",
        "filename=DATA_DIR+'RF_107.csv'\n",
        "with open (filename, 'w') as fout:\n",
        "    for i in range(length):\n",
        "        line = '%d,%d,%f' % (y_valid[i],yhat_classes[i],yhat_pred[i])\n",
        "        print(line, file=fout)\n",
        "print(filename)\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pSp5YCu1urzM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}