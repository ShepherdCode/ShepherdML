{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBC Filter then Random Forest\n",
    "Same as notebook 01 but don't try to save mem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 8\n",
    "N_ESTIMATORS = 1000\n",
    "CHOOSE_EVERY = 1   # ultimately controlled by the save_mem parameter\n",
    "SAVE_MEM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-01 19:55:00.093353\n",
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "# The model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch data.\n",
    "# This is the patch-level csv file: one row per patch, with nucleus totals from CellProfiler.\n",
    "FILENAME='Process100_Image.csv'\n",
    "# This directory contains one Image.csv file per patient.\n",
    "# These csv files were slimmed to remove give-away columns.\n",
    "# These csv files do contain high-RBC patches; consider filtering them.\n",
    "BASE_PATH='/home/jrm/Adjeroh/Glioma/August_Run/CellProfilerPerPatient/'  # alien\n",
    "\n",
    "# Patient data.\n",
    "# Each patch filename indicates patient/case [0:19] and WSI [0:23].\n",
    "# For example: TCGA-06-0129-01Z-00-DX1_5400_5100.png\n",
    "LEN_PATIENT_ID = 19\n",
    "FOLDS_META_FILE = '/home/jrm/Adjeroh/Glioma/August_Run/TrainValidSplits/aug_train_valid_splits.csv'\n",
    "NUM_FOLDS = 5\n",
    "RBC_CUTOFF = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Case</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0004-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0010-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-14-0789-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0025-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0033-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-S9-A7J2-01Z-00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-02-0430-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-28-1746-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-HT-7676-01Z-00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-CS-5397-01Z-00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Split                 Case  Class\n",
       "0       0  Train  TCGA-02-0004-01Z-00      0\n",
       "1       0  Train  TCGA-02-0010-01Z-00      0\n",
       "2       0  Train  TCGA-14-0789-01Z-00      0\n",
       "3       0  Train  TCGA-02-0025-01Z-00      0\n",
       "4       0  Train  TCGA-02-0033-01Z-00      0\n",
       "..    ...    ...                  ...    ...\n",
       "630     4  Valid  TCGA-S9-A7J2-01Z-00      5\n",
       "631     4  Valid  TCGA-02-0430-01Z-00      0\n",
       "632     4  Valid  TCGA-28-1746-01Z-00      0\n",
       "633     4  Valid  TCGA-HT-7676-01Z-00      1\n",
       "634     4  Valid  TCGA-CS-5397-01Z-00      3\n",
       "\n",
       "[635 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA = pd.read_csv(FOLDS_META_FILE)\n",
    "METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_one_fold(fold,is_train):\n",
    "    df = METADATA.loc[METADATA['Fold']==fold]\n",
    "    if is_train:\n",
    "        df = df.loc[df['Split']=='Train']\n",
    "    else:\n",
    "        df = df.loc[df['Split']=='Valid']\n",
    "    patients = df['Case'].tolist()\n",
    "    labels = df['Class'].tolist()\n",
    "    return patients,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a patient name, load the Image.csv file.\n",
    "# Expect a string that matches a directory name, like 'TCGA-S9-A6UB-01Z-00'\n",
    "# Returns a numpy array.\n",
    "def load_one_patient_data(filepath):\n",
    "    # Reading csv file, skip row 1 = column headers\n",
    "    ary = np.loadtxt(filepath,skiprows=1,delimiter=',')\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_patients_data(patients,labels,save_mem=False):\n",
    "    X = None  # dataframe with 5000 feature columns, one row per patch\n",
    "    y = None  # list of labels = cancer class for each row\n",
    "    z = None  # list of patient name for each row\n",
    "    count=0\n",
    "    for patient in patients:\n",
    "        label = labels[count]\n",
    "        count += 1\n",
    "        directory = patient+'/'\n",
    "        filepath=BASE_PATH+directory+FILENAME\n",
    "        Xall = load_one_patient_data(filepath)\n",
    "        if (save_mem):\n",
    "            Xi = Xall[0::CHOOSE_EVERY].copy()  # e.g. choose every tenth patch\n",
    "        else:\n",
    "            Xi = Xall\n",
    "        yi = np.full(shape=len(Xi), fill_value=label, dtype=np.int8)\n",
    "        zi = [patient]*len(Xi)  # same ID for all patches from one patient\n",
    "        if X is None:\n",
    "            X = Xi\n",
    "            y = yi\n",
    "            z = zi\n",
    "        else:\n",
    "            X = np.concatenate( (X, Xi) )\n",
    "            y = np.concatenate( (y, yi) )\n",
    "            z = np.concatenate( (z, zi) )\n",
    "    # X combines all patches of all WSI for all patients requested.\n",
    "    # For debugging, we'll add column headers to the dataframe.\n",
    "    X = pd.DataFrame(X)\n",
    "    directory = patients[0] + '/'   # first patient is as good as any\n",
    "    filepath=BASE_PATH+directory+FILENAME\n",
    "    with open(filepath) as infile:\n",
    "        rows = csv.reader(infile)\n",
    "        for row in rows:\n",
    "            header = row    # first row has column headers\n",
    "            break\n",
    "    X.columns = header\n",
    "    if 'ImageNumber' in X.columns:\n",
    "        X = X.drop(columns=['ImageNumber'])\n",
    "    return X,y,z   # patch data, patch labels, patch patient names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow, probably due to concatenating dataframes.\n",
    "# Consider a rewrite that concatenates csv before constructing a dataframe.\n",
    "def load_train_valid_set(fold):\n",
    "    patients,labels = get_metadata_one_fold(fold,True) # True=train\n",
    "    X_train,y_train,z_train = load_all_patients_data(patients,labels,SAVE_MEM) \n",
    "    patients,labels = get_metadata_one_fold(fold,False) # False=valid\n",
    "    X_valid,y_valid,z_valid = load_all_patients_data(patients,labels,False) # should always be False\n",
    "    return X_train,y_train,z_train,X_valid,y_valid,z_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each patch votes on the class for its WSI.\n",
    "# Later, weight each patch label by the confidence i.e. score\n",
    "def aggregate_accuracy(y_pred,y_valid,z_valid):\n",
    "    L = len(y_pred)\n",
    "    if L != len(y_valid) or L != len(z_valid):\n",
    "        raise Exception('Lengths do not match')\n",
    "    correct = {}\n",
    "    incorrect = {}\n",
    "    patients = np.unique(z_valid)\n",
    "    for patient in patients:\n",
    "        correct[patient]=0  # accumulate correct votes on patches\n",
    "        incorrect[patient]=0  # accumulate incorrect votes\n",
    "    for i in range(L):\n",
    "        patient = z_valid[i]\n",
    "        label =   y_valid[i]\n",
    "        pred =    y_pred[i]\n",
    "        if pred == label:\n",
    "            correct[patient] += 1\n",
    "        else:\n",
    "            incorrect[patient] += 1\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for patient in patients:\n",
    "        denominator += 1\n",
    "        if correct[patient]>incorrect[patient]:\n",
    "            numerator += 1\n",
    "    accuracy = float(0)\n",
    "    if denominator>0:\n",
    "        accuracy = 100.0*numerator/denominator \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop: Load, Classify, Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(model):\n",
    "        # Prereqs: fit().\n",
    "        names = model.feature_names_in_\n",
    "        importances = model.feature_importances_\n",
    "        pairs = np.column_stack( (names,importances) )\n",
    "        top_array = sorted(pairs, key = lambda e:e[1], reverse=True)\n",
    "        # There must be a way to do this witout a loop!\n",
    "        top_list = []\n",
    "        for i in top_array:\n",
    "             top_list.append((i[1],i[0]))  # 0=feature_name, 1=importance\n",
    "        top_df = pd.DataFrame(top_list)\n",
    "        return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbc_filter(X,y,z):\n",
    "    if RBC_CUTOFF is not None:\n",
    "        bad_rows = X[X.AreaOccupied_AreaOccupied_MergeRBC>=RBC_CUTOFF].index    \n",
    "        X = X.drop(bad_rows)  # pandas dataframe\n",
    "        y = np.delete(y,bad_rows)  # numpy array\n",
    "        z = np.delete(z,bad_rows)\n",
    "    return X,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-01 19:55:00.741649 Fold 0 Loading...\n",
      "Train shapes X,y,z: (75448, 5301) 75448 75448\n",
      "Valid shapes X,y,z: (15500, 5301) 15500 15500\n",
      "2022-08-01 19:57:03.787674 Fold 0 RBC Filter...\n",
      "Train shapes X,y,z: (68528, 5301) 68528 68528\n",
      "Valid shapes X,y,z: (14084, 5301) 14084 14084\n",
      "2022-08-01 19:57:05.830757 Fold 0 Train...\n",
      "2022-08-01 20:25:26.831370 Fold 0 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.012491             Median_Nucleus_AreaShape_MaximumRadius\n",
      "1   0.011509                Median_Nucleus_AreaShape_MeanRadius\n",
      "2   0.009531               Mean_Nucleus_AreaShape_MaximumRadius\n",
      "3   0.008944  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "4   0.008572             Mean_Nucleus_AreaShape_MinorAxisLength\n",
      "5   0.008275                Mean_Nucleus_AreaShape_MedianRadius\n",
      "6   0.007826                  Mean_Nucleus_AreaShape_MeanRadius\n",
      "7   0.007722  Median_Nucleus_AreaShape_InertiaTensorEigenval...\n",
      "8   0.007660  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_4...\n",
      "9   0.007450          Median_Nucleus_AreaShape_MinFeretDiameter\n",
      "10  0.007178  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_4...\n",
      "2022-08-01 20:25:26.940156 Fold 0 Evaluate...\n",
      "Fold 0 Patch-level Training Accuracy: 75.72816950735466\n",
      "2022-08-01 20:25:36.390503 Fold 0 Validate...\n",
      "Fold 0 Patch-level Validation Accuracy: 55.090883271797786\n",
      "Fold 0 Patient-level Validation Accuracy: 42.30769230769231\n",
      "\n",
      "2022-08-01 20:25:38.294897 Fold 1 Loading...\n",
      "Train shapes X,y,z: (64485, 5301) 64485 64485\n",
      "Valid shapes X,y,z: (26463, 5301) 26463 26463\n",
      "2022-08-01 20:27:32.366655 Fold 1 RBC Filter...\n",
      "Train shapes X,y,z: (57991, 5301) 57991 57991\n",
      "Valid shapes X,y,z: (24621, 5301) 24621 24621\n",
      "2022-08-01 20:27:34.465613 Fold 1 Train...\n",
      "2022-08-01 20:51:28.759365 Fold 1 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.009934             Median_Nucleus_AreaShape_MaximumRadius\n",
      "1   0.009737              Median_Nucleus_AreaShape_MedianRadius\n",
      "2   0.009108  Mean_Nucleus_Texture_InfoMeas1_Hematoxylin_4_0...\n",
      "3   0.008981                Mean_Nucleus_AreaShape_MedianRadius\n",
      "4   0.008962               Mean_Nucleus_AreaShape_MaximumRadius\n",
      "5   0.008724                  Mean_Nucleus_AreaShape_MeanRadius\n",
      "6   0.008396                Median_Nucleus_AreaShape_MeanRadius\n",
      "7   0.008220  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_5...\n",
      "8   0.007833  Median_Nucleus_AreaShape_InertiaTensorEigenval...\n",
      "9   0.007697  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_5...\n",
      "10  0.007606  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "2022-08-01 20:51:28.860676 Fold 1 Evaluate...\n",
      "Fold 1 Patch-level Training Accuracy: 77.23957165767102\n",
      "2022-08-01 20:51:36.715273 Fold 1 Validate...\n",
      "Fold 1 Patch-level Validation Accuracy: 58.22671703017749\n",
      "Fold 1 Patient-level Validation Accuracy: 30.76923076923077\n",
      "\n",
      "2022-08-01 20:51:40.096582 Fold 2 Loading...\n",
      "Train shapes X,y,z: (71643, 5301) 71643 71643\n",
      "Valid shapes X,y,z: (19305, 5301) 19305 19305\n",
      "2022-08-01 20:53:40.993022 Fold 2 RBC Filter...\n",
      "Train shapes X,y,z: (66079, 5301) 66079 66079\n",
      "Valid shapes X,y,z: (16533, 5301) 16533 16533\n",
      "2022-08-01 20:53:43.101213 Fold 2 Train...\n",
      "2022-08-01 21:20:58.331056 Fold 2 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.011959             Median_Nucleus_AreaShape_MaximumRadius\n",
      "1   0.010481                  Mean_Nucleus_AreaShape_MeanRadius\n",
      "2   0.010160               Mean_Nucleus_AreaShape_MaximumRadius\n",
      "3   0.009098                Median_Nucleus_AreaShape_MeanRadius\n",
      "4   0.008827           Median_Nucleus_AreaShape_MinorAxisLength\n",
      "5   0.008298              Median_Nucleus_AreaShape_MedianRadius\n",
      "6   0.007997                Mean_Nucleus_AreaShape_MedianRadius\n",
      "7   0.007851  Mean_Nucleus_Texture_InfoMeas1_Hematoxylin_7_0...\n",
      "8   0.007600  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "9   0.007343          Median_Nucleus_AreaShape_MinFeretDiameter\n",
      "10  0.006773  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_5...\n",
      "2022-08-01 21:20:58.487678 Fold 2 Evaluate...\n",
      "Fold 2 Patch-level Training Accuracy: 76.69456256904614\n",
      "2022-08-01 21:21:07.486583 Fold 2 Validate...\n",
      "Fold 2 Patch-level Validation Accuracy: 56.51121998427388\n",
      "Fold 2 Patient-level Validation Accuracy: 36.0\n",
      "\n",
      "2022-08-01 21:21:09.762367 Fold 3 Loading...\n",
      "Train shapes X,y,z: (74477, 5301) 74477 74477\n",
      "Valid shapes X,y,z: (16471, 5301) 16471 16471\n",
      "2022-08-01 21:23:13.161288 Fold 3 RBC Filter...\n",
      "Train shapes X,y,z: (67665, 5301) 67665 67665\n",
      "Valid shapes X,y,z: (14947, 5301) 14947 14947\n",
      "2022-08-01 21:23:15.682127 Fold 3 Train...\n",
      "2022-08-01 21:51:22.716789 Fold 3 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.012995                  Mean_Nucleus_AreaShape_MeanRadius\n",
      "1   0.011623                Mean_Nucleus_AreaShape_MedianRadius\n",
      "2   0.011617              Median_Nucleus_AreaShape_MedianRadius\n",
      "3   0.011595                Median_Nucleus_AreaShape_MeanRadius\n",
      "4   0.010037  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "5   0.009728               Mean_Nucleus_AreaShape_MaximumRadius\n",
      "6   0.009207           Median_Nucleus_AreaShape_MinorAxisLength\n",
      "7   0.009023  Median_Nucleus_AreaShape_InertiaTensorEigenval...\n",
      "8   0.008334             Median_Nucleus_AreaShape_MaximumRadius\n",
      "9   0.007474  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "10  0.007071             Mean_Nucleus_AreaShape_MinorAxisLength\n",
      "2022-08-01 21:51:22.831344 Fold 3 Evaluate...\n",
      "Fold 3 Patch-level Training Accuracy: 75.35653587526787\n",
      "2022-08-01 21:51:31.993174 Fold 3 Validate...\n",
      "Fold 3 Patch-level Validation Accuracy: 57.40282330902522\n",
      "Fold 3 Patient-level Validation Accuracy: 44.0\n",
      "\n",
      "2022-08-01 21:51:34.069837 Fold 4 Loading...\n",
      "Train shapes X,y,z: (77739, 5301) 77739 77739\n",
      "Valid shapes X,y,z: (13209, 5301) 13209 13209\n",
      "2022-08-01 21:53:39.385006 Fold 4 RBC Filter...\n",
      "Train shapes X,y,z: (70185, 5301) 70185 70185\n",
      "Valid shapes X,y,z: (12427, 5301) 12427 12427\n",
      "2022-08-01 21:53:41.670140 Fold 4 Train...\n",
      "2022-08-01 22:23:00.388678 Fold 4 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.012376              Median_Nucleus_AreaShape_MedianRadius\n",
      "1   0.011504                  Mean_Nucleus_AreaShape_MeanRadius\n",
      "2   0.009875           Median_Nucleus_AreaShape_MinorAxisLength\n",
      "3   0.009539                Mean_Nucleus_AreaShape_MedianRadius\n",
      "4   0.009213  Median_Nucleus_AreaShape_InertiaTensorEigenval...\n",
      "5   0.008802                Median_Nucleus_AreaShape_MeanRadius\n",
      "6   0.008728  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_7...\n",
      "7   0.008723  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_5...\n",
      "8   0.008659             Median_Nucleus_AreaShape_MaximumRadius\n",
      "9   0.008502               Mean_Nucleus_AreaShape_MaximumRadius\n",
      "10  0.007893  Median_Nucleus_Texture_InfoMeas1_Hematoxylin_5...\n",
      "2022-08-01 22:23:00.488099 Fold 4 Evaluate...\n",
      "Fold 4 Patch-level Training Accuracy: 76.97228752582461\n",
      "2022-08-01 22:23:09.928669 Fold 4 Validate...\n",
      "Fold 4 Patch-level Validation Accuracy: 44.53206727287358\n",
      "Fold 4 Patient-level Validation Accuracy: 36.0\n"
     ]
    }
   ],
   "source": [
    "patch_accuracies = []   # summary statistics\n",
    "patient_accuracies = [] # summary statistics\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    print()\n",
    "    print(datetime.now(),'Fold',fold,'Loading...')\n",
    "    X_train,y_train,z_train,X_valid,y_valid,z_valid = load_train_valid_set(fold)\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'RBC Filter...')\n",
    "    X_train,y_train,z_train = rbc_filter(X_train,y_train,z_train)\n",
    "    X_valid,y_valid,z_valid = rbc_filter(X_valid,y_valid,z_valid)\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "\n",
    "    # The shuffle is not strictly necessary with RF.\n",
    "    # CNN models are sensitive to train set order but RF models are not. \n",
    "    # print(datetime.datetime.now(),'Shuffle...')\n",
    "    # X_train,y_train = sklearn.shuffle(X_train,y_train)\n",
    "\n",
    "    print(datetime.now(),'Fold',fold,'Train...')\n",
    "    # min_samples_leaf=1 (default) led to overfitting\n",
    "    rfc = RandomForestClassifier(max_depth=MAX_DEPTH,n_estimators=N_ESTIMATORS)\n",
    "    rfc.fit(X_train,y_train)  # slow\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Ranked feature imporances...')\n",
    "    top = important_features(rfc)\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    print(top.loc[:10])\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Evaluate...')\n",
    "    y_pred = rfc.predict(X_train)\n",
    "    matches = np.count_nonzero(y_train==y_pred)\n",
    "    accuracy_t = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Training Accuracy:',accuracy_t)\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Validate...')\n",
    "    y_pred = rfc.predict(X_valid)\n",
    "    matches = np.count_nonzero(y_valid==y_pred)\n",
    "    accuracy_v = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Validation Accuracy:',accuracy_v)\n",
    "    patch_accuracies.append(accuracy_v)\n",
    "    \n",
    "    accuracy_p = aggregate_accuracy(y_pred,y_valid,z_valid)\n",
    "    patient_accuracies.append(accuracy_p)\n",
    "    print('Fold',fold,'Patient-level Validation Accuracy:',accuracy_p)\n",
    "    \n",
    "    # This shouldn't be necessary but it seems to reduce memory footprint.\n",
    "    X_train=None\n",
    "    X_valid=None\n",
    "    y_train=None\n",
    "    y_valid=None\n",
    "    z_train=None\n",
    "    z_valid=None\n",
    "    rfc = None\n",
    "    y_pred = None\n",
    "    matches = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-01 22:23:11.764992\n",
      "Cross validation patch-level accuracy: [55.090883271797786, 58.22671703017749, 56.51121998427388, 57.40282330902522, 44.53206727287358]\n",
      "mean: 54.352742173629586 std: 5.01916746817337\n",
      "Cross validation patient-level accuracy: [42.30769230769231, 30.76923076923077, 36.0, 44.0, 36.0]\n",
      "mean: 37.815384615384616 std: 4.7889418974384546\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Cross validation patch-level accuracy:',patch_accuracies)\n",
    "print('mean:',np.mean(patch_accuracies),'std:',np.std(patch_accuracies))\n",
    "print('Cross validation patient-level accuracy:',patient_accuracies)\n",
    "print('mean:',np.mean(patient_accuracies),'std:',np.std(patient_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
