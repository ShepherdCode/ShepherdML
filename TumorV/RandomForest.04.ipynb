{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Opposite of notebook 03. That used only columns with Nucleus in the name. This used only columns without Nucleus in the name. The goal is to find the most important non-nucleus features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 8\n",
    "N_ESTIMATORS = 500\n",
    "CHOOSE_EVERY = 10\n",
    "SAVE_MEM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-02 13:12:17.891767\n",
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "# The model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch data.\n",
    "# This is the patch-level csv file: one row per patch, with nucleus totals from CellProfiler.\n",
    "FILENAME='Process100_Image.csv'\n",
    "# This directory contains one Image.csv file per patient.\n",
    "# These csv files were slimmed to remove give-away columns.\n",
    "# These csv files do contain high-RBC patches; consider filtering them.\n",
    "BASE_PATH='/home/jrm/Adjeroh/Glioma/August_Run/CellProfilerPerPatient/'  # alien\n",
    "\n",
    "# Patient data.\n",
    "# Each patch filename indicates patient/case [0:19] and WSI [0:23].\n",
    "# For example: TCGA-06-0129-01Z-00-DX1_5400_5100.png\n",
    "LEN_PATIENT_ID = 19\n",
    "FOLDS_META_FILE = '/home/jrm/Adjeroh/Glioma/August_Run/TrainValidSplits/aug_train_valid_splits.csv'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Case</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0004-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0010-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-14-0789-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0025-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0033-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-S9-A7J2-01Z-00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-02-0430-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-28-1746-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-HT-7676-01Z-00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-CS-5397-01Z-00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Split                 Case  Class\n",
       "0       0  Train  TCGA-02-0004-01Z-00      0\n",
       "1       0  Train  TCGA-02-0010-01Z-00      0\n",
       "2       0  Train  TCGA-14-0789-01Z-00      0\n",
       "3       0  Train  TCGA-02-0025-01Z-00      0\n",
       "4       0  Train  TCGA-02-0033-01Z-00      0\n",
       "..    ...    ...                  ...    ...\n",
       "630     4  Valid  TCGA-S9-A7J2-01Z-00      5\n",
       "631     4  Valid  TCGA-02-0430-01Z-00      0\n",
       "632     4  Valid  TCGA-28-1746-01Z-00      0\n",
       "633     4  Valid  TCGA-HT-7676-01Z-00      1\n",
       "634     4  Valid  TCGA-CS-5397-01Z-00      3\n",
       "\n",
       "[635 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA = pd.read_csv(FOLDS_META_FILE)\n",
    "METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_one_fold(fold,is_train):\n",
    "    df = METADATA.loc[METADATA['Fold']==fold]\n",
    "    if is_train:\n",
    "        df = df.loc[df['Split']=='Train']\n",
    "    else:\n",
    "        df = df.loc[df['Split']=='Valid']\n",
    "    patients = df['Case'].tolist()\n",
    "    labels = df['Class'].tolist()\n",
    "    return patients,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a patient name, load the Image.csv file.\n",
    "# Expect a string that matches a directory name, like 'TCGA-S9-A6UB-01Z-00'\n",
    "# Returns a numpy array.\n",
    "def load_one_patient_data(filepath):\n",
    "    # Reading csv file, skip row 1 = column headers\n",
    "    ary = np.loadtxt(filepath,skiprows=1,delimiter=',')\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_patients_data(patients,labels,save_mem=False):\n",
    "    X = None  # dataframe with 5000 feature columns, one row per patch\n",
    "    y = None  # list of labels = cancer class for each row\n",
    "    z = None  # list of patient name for each row\n",
    "    count=0\n",
    "    for patient in patients:\n",
    "        label = labels[count]\n",
    "        count += 1\n",
    "        directory = patient+'/'\n",
    "        filepath=BASE_PATH+directory+FILENAME\n",
    "        Xall = load_one_patient_data(filepath)\n",
    "        if (save_mem):\n",
    "            Xi = Xall[0::CHOOSE_EVERY].copy()  # e.g. choose every tenth patch\n",
    "        else:\n",
    "            Xi = Xall\n",
    "        yi = np.full(shape=len(Xi), fill_value=label, dtype=np.int8)\n",
    "        zi = [patient]*len(Xi)  # same ID for all patches from one patient\n",
    "        if X is None:\n",
    "            X = Xi\n",
    "            y = yi\n",
    "            z = zi\n",
    "        else:\n",
    "            X = np.concatenate( (X, Xi) )\n",
    "            y = np.concatenate( (y, yi) )\n",
    "            z = np.concatenate( (z, zi) )\n",
    "    # X combines all patches of all WSI for all patients requested.\n",
    "    # For debugging, we'll add column headers to the dataframe.\n",
    "    X = pd.DataFrame(X)\n",
    "    directory = patients[0] + '/'   # first patient is as good as any\n",
    "    filepath=BASE_PATH+directory+FILENAME\n",
    "    with open(filepath) as infile:\n",
    "        rows = csv.reader(infile)\n",
    "        for row in rows:\n",
    "            header = row    # first row has column headers\n",
    "            break\n",
    "    X.columns = header\n",
    "    if 'ImageNumber' in X.columns:\n",
    "        X = X.drop(columns=['ImageNumber'])\n",
    "    return X,y,z   # patch data, patch labels, patch patient names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow, probably due to concatenating dataframes.\n",
    "# Consider a rewrite that concatenates csv before constructing a dataframe.\n",
    "def load_train_valid_set(fold):\n",
    "    patients,labels = get_metadata_one_fold(fold,True) # True=train\n",
    "    X_train,y_train,z_train = load_all_patients_data(patients,labels,SAVE_MEM) \n",
    "    patients,labels = get_metadata_one_fold(fold,False) # False=valid\n",
    "    X_valid,y_valid,z_valid = load_all_patients_data(patients,labels,False) # should always be False\n",
    "    return X_train,y_train,z_train,X_valid,y_valid,z_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each patch votes on the class for its WSI.\n",
    "# Later, weight each patch label by the confidence i.e. score\n",
    "def aggregate_accuracy(y_pred,y_valid,z_valid):\n",
    "    L = len(y_pred)\n",
    "    if L != len(y_valid) or L != len(z_valid):\n",
    "        raise Exception('Lengths do not match')\n",
    "    correct = {}\n",
    "    incorrect = {}\n",
    "    patients = np.unique(z_valid)\n",
    "    for patient in patients:\n",
    "        correct[patient]=0  # accumulate correct votes on patches\n",
    "        incorrect[patient]=0  # accumulate incorrect votes\n",
    "    for i in range(L):\n",
    "        patient = z_valid[i]\n",
    "        label =   y_valid[i]\n",
    "        pred =    y_pred[i]\n",
    "        if pred == label:\n",
    "            correct[patient] += 1\n",
    "        else:\n",
    "            incorrect[patient] += 1\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for patient in patients:\n",
    "        denominator += 1\n",
    "        if correct[patient]>incorrect[patient]:\n",
    "            numerator += 1\n",
    "    accuracy = float(0)\n",
    "    if denominator>0:\n",
    "        accuracy = 100.0*numerator/denominator \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop: Load, Classify, Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(model):\n",
    "    # Prereqs: fit().\n",
    "    names = model.feature_names_in_\n",
    "    importances = model.feature_importances_\n",
    "    pairs = np.column_stack( (names,importances) )\n",
    "    top_array = sorted(pairs, key = lambda e:e[1], reverse=True)\n",
    "    # There must be a way to do this witout a loop!\n",
    "    top_list = []\n",
    "    for i in top_array:\n",
    "         top_list.append((i[1],i[0]))  # 0=feature_name, 1=importance\n",
    "    top_df = pd.DataFrame(top_list)\n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-02 13:12:18.571209 Fold 0 Loading...\n",
      "Train lengths X,y,z: (7592, 5301) 7592 7592\n",
      "Valid lengths X,y,z: (15500, 5301) 15500 15500\n",
      "2022-08-02 13:13:26.170262 Fold 0 Reduce columns...\n",
      "Train lengths X,y,z: (7592, 3350) 7592 7592\n",
      "Valid lengths X,y,z: (15500, 3350) 15500 15500\n",
      "2022-08-02 13:13:26.331938 Fold 0 Train...\n",
      "2022-08-02 13:14:27.046974 Fold 0 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.021925                          Granularity_2_Hematoxylin\n",
      "1   0.014394  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.012488  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.011467  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "4   0.011074  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.005962           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.005921           Texture_Correlation_Hematoxylin_7_01_256\n",
      "7   0.005746  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.005033  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "9   0.004541  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "10  0.004466  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2022-08-02 13:14:27.082615 Fold 0 Evaluate...\n",
      "Fold 0 Patch-level Training Accuracy: 78.6222339304531\n",
      "2022-08-02 13:14:27.671850 Validate...\n",
      "Fold 0 Patch-level Validation Accuracy: 53.561290322580646\n",
      "Fold 0 Patient-level Validation Accuracy: 38.46153846153846\n",
      "\n",
      "2022-08-02 13:14:28.781474 Fold 1 Loading...\n",
      "Train lengths X,y,z: (6490, 5301) 6490 6490\n",
      "Valid lengths X,y,z: (26463, 5301) 26463 26463\n",
      "2022-08-02 13:15:38.600548 Fold 1 Reduce columns...\n",
      "Train lengths X,y,z: (6490, 3350) 6490 6490\n",
      "Valid lengths X,y,z: (26463, 3350) 26463 26463\n",
      "2022-08-02 13:15:38.843243 Fold 1 Train...\n",
      "2022-08-02 13:16:32.725629 Fold 1 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.019741                          Granularity_2_Hematoxylin\n",
      "1   0.012984  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2   0.012450  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.010916  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.010692  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.008682           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.006244  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "7   0.005992                          Granularity_1_Hematoxylin\n",
      "8   0.005877           Texture_Correlation_Hematoxylin_7_01_256\n",
      "9   0.005653  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "10  0.005179  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2022-08-02 13:16:32.757045 Fold 1 Evaluate...\n",
      "Fold 1 Patch-level Training Accuracy: 81.66409861325116\n",
      "2022-08-02 13:16:33.380899 Validate...\n",
      "Fold 1 Patch-level Validation Accuracy: 58.069757775006615\n",
      "Fold 1 Patient-level Validation Accuracy: 34.61538461538461\n",
      "\n",
      "2022-08-02 13:16:35.809620 Fold 2 Loading...\n",
      "Train lengths X,y,z: (7212, 5301) 7212 7212\n",
      "Valid lengths X,y,z: (19305, 5301) 19305 19305\n",
      "2022-08-02 13:17:46.018426 Fold 2 Reduce columns...\n",
      "Train lengths X,y,z: (7212, 3350) 7212 7212\n",
      "Valid lengths X,y,z: (19305, 3350) 19305 19305\n",
      "2022-08-02 13:17:46.223115 Fold 2 Train...\n",
      "2022-08-02 13:18:45.274328 Fold 2 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.022508                          Granularity_2_Hematoxylin\n",
      "1   0.016157  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2   0.015459  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.013360  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.012990  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.007925           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.007351  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "7   0.007248  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.006731  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "9   0.006207  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "10  0.005150           Texture_Correlation_Hematoxylin_7_01_256\n",
      "2022-08-02 13:18:45.302784 Fold 2 Evaluate...\n",
      "Fold 2 Patch-level Training Accuracy: 80.37992235163617\n",
      "2022-08-02 13:18:45.846083 Validate...\n",
      "Fold 2 Patch-level Validation Accuracy: 52.4009324009324\n",
      "Fold 2 Patient-level Validation Accuracy: 32.0\n",
      "\n",
      "2022-08-02 13:18:47.333821 Fold 3 Loading...\n",
      "Train lengths X,y,z: (7493, 5301) 7493 7493\n",
      "Valid lengths X,y,z: (16471, 5301) 16471 16471\n",
      "2022-08-02 13:19:59.297064 Fold 3 Reduce columns...\n",
      "Train lengths X,y,z: (7493, 3350) 7493 7493\n",
      "Valid lengths X,y,z: (16471, 3350) 16471 16471\n",
      "2022-08-02 13:19:59.497064 Fold 3 Train...\n",
      "2022-08-02 13:21:01.763048 Fold 3 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.026427                          Granularity_2_Hematoxylin\n",
      "1   0.015848  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.013602  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "3   0.011766  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.011456  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.007911           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.007371  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "7   0.004925  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.004840  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "9   0.004634  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "10  0.004515           Texture_Correlation_Hematoxylin_7_01_256\n",
      "2022-08-02 13:21:01.808671 Fold 3 Evaluate...\n",
      "Fold 3 Patch-level Training Accuracy: 80.02135326304551\n",
      "2022-08-02 13:21:02.422973 Validate...\n",
      "Fold 3 Patch-level Validation Accuracy: 52.65618359541011\n",
      "Fold 3 Patient-level Validation Accuracy: 40.0\n",
      "\n",
      "2022-08-02 13:21:03.702219 Fold 4 Loading...\n",
      "Train lengths X,y,z: (7817, 5301) 7817 7817\n",
      "Valid lengths X,y,z: (13209, 5301) 13209 13209\n",
      "2022-08-02 13:22:17.805618 Fold 4 Reduce columns...\n",
      "Train lengths X,y,z: (7817, 3350) 7817 7817\n",
      "Valid lengths X,y,z: (13209, 3350) 13209 13209\n",
      "2022-08-02 13:22:18.268058 Fold 4 Train...\n",
      "2022-08-02 13:23:29.910644 Fold 4 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.022146                          Granularity_2_Hematoxylin\n",
      "1   0.013787  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.012649  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "3   0.011460  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.011338  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.008114           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.005433  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "7   0.005199  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "8   0.005082  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "9   0.005020  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "10  0.004782                          Granularity_1_Hematoxylin\n",
      "2022-08-02 13:23:29.982810 Fold 4 Evaluate...\n",
      "Fold 4 Patch-level Training Accuracy: 80.1202507355763\n",
      "2022-08-02 13:23:30.899238 Validate...\n",
      "Fold 4 Patch-level Validation Accuracy: 41.08562343856462\n",
      "Fold 4 Patient-level Validation Accuracy: 32.0\n"
     ]
    }
   ],
   "source": [
    "patch_accuracies = []   # summary statistics\n",
    "patient_accuracies = [] # summary statistics\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    print()\n",
    "    print(datetime.now(),'Fold',fold,'Loading...')\n",
    "    X_train,y_train,z_train,X_valid,y_valid,z_valid = load_train_valid_set(fold)    \n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Reduce columns...')\n",
    "    good_cols = [c for c in X_train.columns if 'Nucleus' not in c]\n",
    "    X_train = X_train[good_cols]\n",
    "    X_valid = X_valid[good_cols]\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "\n",
    "    # The shuffle is not strictly necessary with RF.\n",
    "    # CNN models are sensitive to train set order but RF models are not. \n",
    "    # print(datetime.now(),'Shuffle...')\n",
    "    # X_train,y_train = sklearn.shuffle(X_train,y_train)\n",
    "\n",
    "    print(datetime.now(),'Fold',fold,'Train...')\n",
    "    # min_samples_leaf=1 (default) led to overfitting\n",
    "    rfc = RandomForestClassifier(max_depth=MAX_DEPTH,n_estimators=N_ESTIMATORS)\n",
    "    rfc.fit(X_train,y_train)  # slow\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Ranked feature imporances...')\n",
    "    top = important_features(rfc)\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    print(top.loc[:10])\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Evaluate...')\n",
    "    y_pred = rfc.predict(X_train)\n",
    "    matches = np.count_nonzero(y_train==y_pred)\n",
    "    accuracy_t = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Training Accuracy:',accuracy_t)\n",
    "    \n",
    "    print(datetime.now(),'Validate...')\n",
    "    y_pred = rfc.predict(X_valid)\n",
    "    matches = np.count_nonzero(y_valid==y_pred)\n",
    "    accuracy_v = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Validation Accuracy:',accuracy_v)\n",
    "    patch_accuracies.append(accuracy_v)\n",
    "    \n",
    "    accuracy_p = aggregate_accuracy(y_pred,y_valid,z_valid)\n",
    "    patient_accuracies.append(accuracy_p)\n",
    "    print('Fold',fold,'Patient-level Validation Accuracy:',accuracy_p)\n",
    "    \n",
    "    # This shouldn't be necessary but it seems to reduce memory footprint.\n",
    "    X_train=None\n",
    "    X_valid=None\n",
    "    y_train=None\n",
    "    y_valid=None\n",
    "    z_train=None\n",
    "    z_valid=None\n",
    "    y_pred = None\n",
    "    matches = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-02 13:23:32.590357\n",
      "Cross validation patch-level accuracy: [53.561290322580646, 58.069757775006615, 52.4009324009324, 52.65618359541011, 41.08562343856462]\n",
      "mean: 51.55475750649888 std: 5.621446823627429\n",
      "Cross validation patient-level accuracy: [38.46153846153846, 34.61538461538461, 32.0, 40.0, 32.0]\n",
      "mean: 35.41538461538461 std: 3.294463708141335\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Cross validation patch-level accuracy:',patch_accuracies)\n",
    "print('mean:',np.mean(patch_accuracies),'std:',np.std(patch_accuracies))\n",
    "print('Cross validation patient-level accuracy:',patient_accuracies)\n",
    "print('mean:',np.mean(patient_accuracies),'std:',np.std(patient_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
