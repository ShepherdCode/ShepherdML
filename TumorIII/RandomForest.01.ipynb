{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Start with notebook for lung cancer images, modify for glioma images.\n",
    "\n",
    "Train a default random forest on 6-way cancer classification using just Image.csv data.\n",
    "\n",
    "Do 4-fold cross-validation, and aggregate patch-level predictions up to the WSI level.\n",
    "\n",
    "For now, aggregate by majority voting, with each patch casting an equal vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-19 09:41:52.845781\n",
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle X,y in tandem -- can cause shape problems\n",
    "from sklearn.utils import shuffle\n",
    "# The model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input is the output from the Data notebooks.\n",
    "# These csv files were filtered to remove give-away columns and bad rows.\n",
    "BASE_PATH='/home/jrm/Adjeroh/Naved/July_Run/CellProfilerFiltered/'\n",
    "# This is the patch-level csv file: one row per patch, with nucleus totals.\n",
    "# Later, incorporate the nucleus-specific csv files.\n",
    "FILENAME='Process100_Image.csv'\n",
    "# This directory contains lists of patch filenames,\n",
    "# divided into 5 folds of train/valid splits.\n",
    "# Notice patch filename [0:19] is case ID, [0:23] is WSI ID,\n",
    "# and last column is the 6-way cancer class (zero to five) of the case.\n",
    "# For example, fold0_train.txt starts:\n",
    "# TCGA-06-0129-01Z-00-DX1_5400_5100.png, 0\n",
    "# TCGA-06-0129-01Z-00-DX1_5700_6000.png, 0\n",
    "LEN_PATIENT_ID = 19\n",
    "SPLITS_BASE='/home/jrm/Adjeroh/Naved/July_Run/TrainTestSplit/'\n",
    "SPLITS_FILES = [\n",
    "    ('fold0_train.txt','fold0_test.txt'),\n",
    "    ('fold1_train.txt','fold1_test.txt'),\n",
    "    ('fold2_train.txt','fold2_test.txt'),\n",
    "    ('fold3_train.txt','fold3_test.txt'),\n",
    "    ('fold4_train.txt','fold4_test.txt'),\n",
    "]\n",
    "NUM_FOLDS = 5\n",
    "PATIENT_TO_CANCER = {}  # hash case ID to class number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn can do this but we were stumbling on shape & type problems\n",
    "def list_shuffle(X):   \n",
    "    L = len(X)\n",
    "    for i in range(L):\n",
    "        r = random.randrange(0,L)\n",
    "        if i!=r:\n",
    "            temp = X[i]\n",
    "            X[i] = X[r]\n",
    "            X[r] = temp\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a case ID = patient name = directory, load the csv file.\n",
    "# Expect a value like p='TCGA-S9-A6UB-01Z-00'\n",
    "def load_patient_data(p):\n",
    "    filepath=BASE_PATH+p+'/'+FILENAME\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given fold, load the case/patient IDs separated into training and validation.\n",
    "# Fold should be an in between 0 and 4 for 5-fold cross validation.\n",
    "# The returned list has unique strings like  TCGA-06-0129-01Z-00\n",
    "def _load_patient_names(filename):\n",
    "    patients = []\n",
    "    with open(filename) as infile:\n",
    "        rows = csv.reader(infile)\n",
    "        for row in rows:\n",
    "            patient = row[0][:LEN_PATIENT_ID]\n",
    "            patients.append(patient)\n",
    "            cancer_class = row[1]\n",
    "            if patient in PATIENT_TO_CANCER:\n",
    "                if PATIENT_TO_CANCER[patient] != cancer_class:\n",
    "                    raise Exception('One patient in two classes:',patient)\n",
    "            else:\n",
    "                PATIENT_TO_CANCER[patient] = cancer_class\n",
    "    return patients\n",
    "def load_patient_names(fold):\n",
    "    filenames = SPLITS_FILES[fold]  # tuple of train,valid\n",
    "    train_patients = _load_patient_names(SPLITS_BASE+filenames[0])\n",
    "    valid_patients = _load_patient_names(SPLITS_BASE+filenames[1])\n",
    "    return train_patients,valid_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv rows for one set of train+valid patient names.\n",
    "def _load_train_valid_set(patients):\n",
    "    X = None  # instances = features\n",
    "    y = None  # labels = cancer class\n",
    "    z = []  # patient_id for aggregation\n",
    "    for patient in patients:\n",
    "        df = load_patient_data(patient)\n",
    "        # apply the same cancer label to all patches from one patient\n",
    "        label = PATIENT_TO_CANCER[patient]\n",
    "        if X is None:\n",
    "            X = df \n",
    "            y = np.full(shape=len(df), fill_value=label, dtype=np.int8)\n",
    "        else:\n",
    "            X = pd.concat( (X, df) )\n",
    "            more = np.full(shape=len(df), fill_value=label, dtype=np.int8)\n",
    "            y = np.concatenate( (y, more) )\n",
    "        z = z + [patient]*len(df)  # same ID for all patches from one patient\n",
    "    return X,y,z\n",
    "def load_train_valid_set(train_patient_names,valid_patient_names):\n",
    "    X_train,y_train,z_train = _load_train_valid_set(train_patient_names)\n",
    "    X_valid,y_valid,z_valid = _load_train_valid_set(valid_patient_names)\n",
    "    return X_train,y_train,z_train,X_valid,y_valid,z_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, weight each patch label by the confidence i.e. score\n",
    "def aggregate_accuracy(y_pred,z_valid):\n",
    "    L = len(y_pred)\n",
    "    if L != len(z_valid):\n",
    "        raise Exception('Lengths of y and z do not match')\n",
    "    correct = {}\n",
    "    incorrect = {}\n",
    "    patients = np.unique(z_valid)\n",
    "    for patient in patients:\n",
    "        correct[patient]=0\n",
    "        incorrect[patient]=0\n",
    "    for i in range(L):\n",
    "        patient = z_valid[i]\n",
    "        label = PATIENT_TO_CANCER[patient]\n",
    "        pred = y_pred[i]\n",
    "        if pred == label:\n",
    "            correct[patient] += 1\n",
    "        else:\n",
    "            incorrect[patient] += 1\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for patient in patients:\n",
    "        denominator += 1\n",
    "        if correct[patient]>incorrect[patient]:\n",
    "            numerator += 1\n",
    "    accuracy = float(0)\n",
    "    if denominator>0:\n",
    "        accuracy = float(numerator/denominator) \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop: Load, Classify, Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-07-19 09:41:53.285324\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jrm/Adjeroh/Naved/July_Run/CellProfilerFilteredTCGA-06-0129-01Z-00/Process100_Image.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-acc547724c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_patients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_patients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_patient_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_valid\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mload_train_valid_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_patients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_patients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'patients train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_patients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'patients valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_patients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7ff2f4bd9ff>\u001b[0m in \u001b[0;36mload_train_valid_set\u001b[0;34m(train_patient_names, valid_patient_names)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_train_valid_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_patient_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_patient_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_train_valid_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_patient_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_train_valid_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_patient_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7ff2f4bd9ff>\u001b[0m in \u001b[0;36m_load_train_valid_set\u001b[0;34m(patients)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# patient_id for aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpatient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_patient_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# apply the same cancer label to all patches from one patient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATIENT_TO_CANCER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-562581e0afcc>\u001b[0m in \u001b[0;36mload_patient_data\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_patient_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jrm/Adjeroh/Naved/July_Run/CellProfilerFilteredTCGA-06-0129-01Z-00/Process100_Image.csv'"
     ]
    }
   ],
   "source": [
    "patch_accuracies = []\n",
    "patient_accuracies = []\n",
    "for fold in range(NUM_FOLDS):\n",
    "    print()\n",
    "    print(datetime.datetime.now())\n",
    "    train_patients,valid_patients = load_patient_names(fold)  \n",
    "    X_train,y_train,z_train,X_valid,y_valid,z_valid = \\\n",
    "        load_train_valid_set(train_patients,valid_patients)\n",
    "    \n",
    "    print('Fold',fold,'patients train',train_patients,'patients valid',valid_patients)\n",
    "    print('Fold:',fold,'patches train',X_train.shape,'patches valid',X_valid.shape)\n",
    "    # CNN models are sensitive to train set order but RF models are not. \n",
    "    X_train,y_train = shuffle(X_train,y_train)\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train,y_train)  # slow\n",
    "    \n",
    "    y_pred = rfc.predict(X_valid)\n",
    "    matches = np.count_nonzero(y_valid==y_pred)\n",
    "    accuracy = 100.0 * matches / len(y_pred)\n",
    "    patch_accuracies.append(accuracy)\n",
    "    print('Fold',fold,'Patch-level Validation Accuracy:',accuracy)\n",
    "    \n",
    "    accuracy = aggregate_accuracy(y_pred,z_valid)\n",
    "    patient_accuracies.append(accuracy)\n",
    "    print('Fold',fold,'Patient-level Validation Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\n",
    "print('Cross validation patch-level accuracy:',patch_accuracies)\n",
    "print('mean:',np.mean(patch_accuracies),'std:',np.std(patch_accuracies))\n",
    "print('Cross validation patient-level accuracy:',patient_accuracies)\n",
    "print('mean:',np.mean(patient_accuracies),'std:',np.std(patient_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
