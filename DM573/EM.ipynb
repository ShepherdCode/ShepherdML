{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM and EM\n",
    "Gaussian Mixture Models and Expectation Maximization  \n",
    "\n",
    "Here we show canned and homgrown implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a library call\n",
    "Follow tutorial in [mastery](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n",
    "\n",
    "Use [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) class GaussianMixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Construct a bimodal from two Gaussian processes.\n",
    "from numpy import hstack\n",
    "from numpy.random import normal\n",
    "from matplotlib import pyplot\n",
    "# normal ( mean, standard deviation, count )\n",
    "def plot(X1,X2):\n",
    "    X = hstack( (X1, X2) )  # horizontal stack i.e. concat\n",
    "    pyplot.hist(X, bins=50, density=True)\n",
    "    pyplot.show()\n",
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "plot(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gmm(model):\n",
    "    print(model)\n",
    "    for i in range(model.n_components):\n",
    "        print('Gaussian',i,'mean=',model.means_[i],\n",
    "            'wgt=',model.weights_[i], \n",
    "            'Cov=',model.covariances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "Initialization converged: True\n",
      "GaussianMixture(covariance_type='spherical', n_components=2, verbose=1)\n",
      "Gaussian 0 mean= [20.17692285] wgt= 0.3419892768307201 Cov= 17.83515328324393\n",
      "Gaussian 1 mean= [40.09866455] wgt= 0.6580107231692798 Cov= 35.070832462359135\n"
     ]
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Use EM to reverse engineer the model i.e. fit a GMM to the data.\n",
    "from sklearn.mixture import GaussianMixture\n",
    "X = hstack( (X1, X2) ) \n",
    "X = X.reshape((len(X), 1))\n",
    "# By default, covariance=‘full’: each component has its own general covariance matrix.\n",
    "# Use 'spherical' (one variance per mean) since our data has only one feature.\n",
    "# By default, init_params='kmeans'. Works much better than 'random'!\n",
    "model = GaussianMixture(n_components=2, verbose=1, covariance_type='spherical')\n",
    "model.fit(X)\n",
    "show_gmm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class of a point on the left: 0\n",
      "Predicted class of a point on the right: 1\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X)\n",
    "print('Predicted class of a point on the left:',yhat[100])\n",
    "print('Predicted class of a point on the right:',yhat[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean0=model.means_[0]\n",
    "mean1=model.means_[1]\n",
    "G0 = normal(loc=mean0, scale=4, size=3000) \n",
    "G1 = normal(loc=mean1, scale=6, size=6000)\n",
    "if mean0>mean1:\n",
    "    G0 = normal(loc=mean0, scale=4, size=6000) \n",
    "    G1 = normal(loc=mean1, scale=6, size=3000)\n",
    "plot(G0,G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homegrown version\n",
    "Assumption: the observed data was generated by n Gaussian processes.\n",
    "\n",
    "The maximum likelihood estimate can be appoximated by exepctation maximization with one caveat: there are singularities in the search space\n",
    "where mean = some data point, variance is zero, and likelihood is infinite.\n",
    "\n",
    "See Bishop, Pattern Recognition, section 9.2, starting on page 430.\n",
    "See [YouTube](https://youtu.be/iQoXFmbXRJA) video by Victor Lavrenko."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model includes a vector of Gaussians.\n",
    "Each Gaussian is characterized by a mean and standard deviation\n",
    "(or mean and covariance matrix for higher dimensional points).\n",
    "The model also includes a mixing parameter $\\pi$.\n",
    "This ia a vector holding the probability of drawing from each Gaussian.\n",
    "The mixture model says point x has probability equal to weigthed sum of Gaussians:    \n",
    "$p(x) = \\sum_i \\pi_i \\mathcal{N}(x|\\mu_i,\\sigma_i)$\n",
    "We wish to compute $\\pi, \\mu, \\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bishop introduces a latent, unknown variable \n",
    "z = a 1-of-K bit vector indicting which Gaussian was responsible for x.\n",
    "This doesn't change anything but it allows him to deal with\n",
    "conditional probabilities p(z|x) rather than marginal probabilities p(x).\n",
    "Then he derives likelihood formulas for mean and stdev. \n",
    "These formulae involve the conditionals as weights on the deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code tackles an easy case.\n",
    "Easy case: one-dimensional data (avoids matricies & covariance).\n",
    "Easy case: n=2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "def responsibility(mean,stdev,data):\n",
    "    # Probability of each datapoint under the given Gaussian parameters.\n",
    "    L=np.asarray([ss.norm.pdf(x,loc=mean,scale=stdev) for x in data])\n",
    "    return L\n",
    "def conditional_probabilities(like1,like2): \n",
    "    # get conditional probability of each model given these likelihoods\n",
    "    length = len(like1)\n",
    "    cond1=np.zeros(length)\n",
    "    cond2=np.zeros(length)\n",
    "    # TO DO: use vectors instead of for loop \n",
    "    for i in range(length):      \n",
    "        # This formula is same as Bayes rule \n",
    "        # if we multiply both likelihoods by prior=50%\n",
    "        prob_of_data = like1[i]+like2[i]\n",
    "        cond1[i] = like1[i] / prob_of_data  \n",
    "        cond2[i] = like2[i] / prob_of_data  \n",
    "    return cond1,cond2\n",
    "def mle_mean(weights,data):\n",
    "    length = len(data)\n",
    "    weighted = data*weights  # Hadamard vector multiply\n",
    "    mean=sum(weighted)/sum(weights)\n",
    "    return mean\n",
    "def mle_stdev(mean,weights,data):\n",
    "    # sum of the squares of the weighted deviations from the mean\n",
    "    dev = data-mean\n",
    "    wdev = dev*weights\n",
    "    sse = sum(wdev**2)\n",
    "    stdev=float(np.sqrt(sse/sum(weights)))\n",
    "    return stdev\n",
    "def show(stage,mean1,stdev1,mean2,stdev2,mix,lnp):\n",
    "    mixing = \"{}/{}\".format(int(100*mix),int(100*(1-mix)))\n",
    "    print('%s: %f +/- %d, %f +/- %d, Mix=%s LL=%d'%\n",
    "          (stage,mean1,stdev1,mean2,stdev2,mixing,lnp))\n",
    "def log_likelihood(data,mean1,mean2,stdev1,stdev2,mix1):\n",
    "    mix2 = 1-mix1\n",
    "    #lsum1 = np.log2 (mix1 * np.sum(responsibility(mean1,stdev1,data)))\n",
    "    #lsum2 = np.log2 (mix2 * np.sum(responsibility(mean2,stdev2,data)))\n",
    "    sum_of_logs = 0\n",
    "    for x in data:\n",
    "        sum  = mix1 * ss.norm.pdf(x,loc=mean1,scale=stdev1)\n",
    "        sum += mix2 * ss.norm.pdf(x,loc=mean2,scale=stdev2)\n",
    "        sum_of_logs += np.log2(sum)\n",
    "    return sum_of_logs\n",
    "def expectation_maximization(data,num_iter):\n",
    "    # 1. Initial step.\n",
    "    # These initial guesses are arbitrary but ok being based on the overall data.\n",
    "    mean=np.mean(data)\n",
    "    stdev=np.std(data)\n",
    "    mean1 = mean-0.5\n",
    "    mean2 = mean+0.5\n",
    "    stdev1 = stdev\n",
    "    stdev2 = stdev\n",
    "    mix = .5\n",
    "    lnp=0\n",
    "    show('Initial',mean1,stdev1,mean2,stdev2,mix,lnp)\n",
    "    for i in range(num_iter):\n",
    "        # 2. E-step. Evaluate responsibilities.\n",
    "        # Get conditional prob of each point assuming either Gaussian model.\n",
    "        resp1 = responsibility(mean1,stdev1,data)\n",
    "        resp2 = responsibility(mean2,stdev2,data)\n",
    "        cond1,cond2 = conditional_probabilities(resp1,resp2)\n",
    "        # 3. M-step. Re-estimate model parameters by weighted MLE.\n",
    "        mean1 = mle_mean(cond1,data)\n",
    "        mean2 = mle_mean(cond2,data)\n",
    "        stdev1 = mle_stdev(mean1,cond1,data)\n",
    "        stdev2 = mle_stdev(mean2,cond2,data)\n",
    "        # re-compute the mixing parameter\n",
    "        mix = np.sum(cond1)/np.sum(cond1+cond2)\n",
    "        # 4. Terminate if log likelihood is no longer changing.\n",
    "        # As shortcut, we just fix the number of iterations.\n",
    "        lnp = log_likelihood(data,mean1,mean2,stdev1,stdev2,mix)\n",
    "        show('Intermediate',mean1,stdev1,mean2,stdev2,mix,lnp)\n",
    "    print()\n",
    "    show('Final',mean1,stdev1,mean2,stdev2,mix,lnp)\n",
    "    return mean1,mean2,stdev1,stdev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 32.870677 +/- 10, 33.870677 +/- 10, Mix=50/50 LL=0\n",
      "Intermediate: 32.871339 +/- 7, 33.870007 +/- 7, Mix=49/50 LL=-51417\n",
      "Intermediate: 32.332359 +/- 8, 34.431170 +/- 7, Mix=50/49 LL=-51336\n",
      "Intermediate: 31.203924 +/- 8, 35.727749 +/- 6, Mix=52/47 LL=-50937\n",
      "Intermediate: 29.384025 +/- 9, 38.222052 +/- 4, Mix=54/45 LL=-49874\n",
      "Intermediate: 27.770841 +/- 8, 40.363064 +/- 3, Mix=55/44 LL=-49300\n",
      "Intermediate: 26.827593 +/- 8, 41.358072 +/- 3, Mix=54/45 LL=-49233\n",
      "Intermediate: 26.011321 +/- 7, 41.992183 +/- 3, Mix=53/46 LL=-48983\n",
      "Intermediate: 24.937790 +/- 6, 42.341204 +/- 4, Mix=51/48 LL=-48613\n",
      "Intermediate: 23.931757 +/- 5, 42.124266 +/- 4, Mix=48/51 LL=-48355\n",
      "Intermediate: 23.116127 +/- 5, 41.773953 +/- 4, Mix=45/54 LL=-48144\n",
      "Intermediate: 22.408774 +/- 5, 41.468598 +/- 4, Mix=42/57 LL=-47947\n",
      "Intermediate: 21.818065 +/- 4, 41.204207 +/- 4, Mix=40/59 LL=-47780\n",
      "Intermediate: 21.355901 +/- 4, 40.984637 +/- 5, Mix=38/61 LL=-47655\n",
      "Intermediate: 21.020926 +/- 4, 40.813166 +/- 5, Mix=37/62 LL=-47572\n",
      "Intermediate: 20.793439 +/- 4, 40.687562 +/- 5, Mix=36/63 LL=-47523\n",
      "Intermediate: 20.645612 +/- 3, 40.600483 +/- 5, Mix=36/63 LL=-47495\n",
      "Intermediate: 20.552118 +/- 3, 40.542635 +/- 5, Mix=35/64 LL=-47479\n",
      "Intermediate: 20.493940 +/- 3, 40.505377 +/- 5, Mix=35/64 LL=-47470\n",
      "Intermediate: 20.458081 +/- 3, 40.481883 +/- 5, Mix=35/64 LL=-47465\n",
      "Intermediate: 20.436102 +/- 3, 40.467271 +/- 5, Mix=35/64 LL=-47462\n",
      "\n",
      "Final: 20.436102 +/- 3, 40.467271 +/- 5, Mix=35/64 LL=-47462\n"
     ]
    }
   ],
   "source": [
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "X = hstack( (X1, X2) ) \n",
    "X = np.asarray(X)\n",
    "mean1,mean2,stdev1,stdev2=expectation_maximization(X,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "Assume every point was generated by process 0 or process 1.\n",
    "Z is a vector naming the generating process for each point. \n",
    "Z is an unknown, a latent variable, that we'll predict.\n",
    "\n",
    "Assume processes 0 and 1 are Gaussian. \n",
    "Each has a mean and stdev.\n",
    "These are the parameters of the generating model.\n",
    "These are unknowns that we'll estimate.\n",
    "\n",
    "Start by guessing the number of processes, and the mean and stdev of each.\n",
    "\n",
    "EM loops over two steps.  \n",
    "* E-Step: The word expectation is not helpul. For every point, assign responsibility to each process. For K-means, assign 0 for one and 1 for the other i.e. all-or-nothing. For GMM, assign probabilities that sum to one across all processes.  \n",
    "* M-Step: Re-estimate the mean and stdev of each process. Use maximum likelihood to choose parameters that maximize the likelihood of this data. When computing the new mean and stdev, weight the sums by the assigned responsibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
