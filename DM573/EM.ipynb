{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM and EM\n",
    "Gaussian Mixture Models and Expectation Maximization  \n",
    "\n",
    "Here we show canned and homgrown implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a library call\n",
    "Follow tutorial in [mastery](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n",
    "\n",
    "Use [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) class GaussianMixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Construct a bimodal from two Gaussian processes.\n",
    "from numpy import hstack\n",
    "from numpy.random import normal\n",
    "from matplotlib import pyplot\n",
    "# normal ( mean, standard deviation, count )\n",
    "def plot(X1,X2):\n",
    "    X = hstack( (X1, X2) )  # horizontal stack i.e. concat\n",
    "    pyplot.hist(X, bins=50, density=True)\n",
    "    pyplot.show()\n",
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "plot(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gmm(model):\n",
    "    print(model)\n",
    "    for i in range(model.n_components):\n",
    "        print('Gaussian',i,'mean=',model.means_[i],\n",
    "            'wgt=',model.weights_[i], \n",
    "            'Cov=',model.covariances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "Initialization converged: True\n",
      "GaussianMixture(covariance_type='spherical', n_components=2, verbose=1)\n",
      "Gaussian 0 mean= [20.05309374] wgt= 0.34004644852388455 Cov= 16.718874625114612\n",
      "Gaussian 1 mean= [40.22980955] wgt= 0.6599535514761126 Cov= 33.756151766542985\n"
     ]
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Use EM to reverse engineer the model i.e. fit a GMM to the data.\n",
    "from sklearn.mixture import GaussianMixture\n",
    "X = hstack( (X1, X2) ) \n",
    "X = X.reshape((len(X), 1))\n",
    "# By default, covariance=‘full’: each component has its own general covariance matrix.\n",
    "# Use 'spherical' (one variance per mean) since our data has only one feature.\n",
    "# By default, init_params='kmeans'. Works much better than 'random'!\n",
    "model = GaussianMixture(n_components=2, verbose=1, covariance_type='spherical')\n",
    "model.fit(X)\n",
    "show_gmm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class of a point on the left: 0\n",
      "Predicted class of a point on the right: 1\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X)\n",
    "print('Predicted class of a point on the left:',yhat[100])\n",
    "print('Predicted class of a point on the right:',yhat[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean0=model.means_[0]\n",
    "mean1=model.means_[1]\n",
    "G0 = normal(loc=mean0, scale=4, size=3000) \n",
    "G1 = normal(loc=mean1, scale=6, size=6000)\n",
    "if mean0>mean1:\n",
    "    G0 = normal(loc=mean0, scale=4, size=6000) \n",
    "    G1 = normal(loc=mean1, scale=6, size=3000)\n",
    "plot(G0,G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homegrown version\n",
    "Assumption: the observed data was generated by n Gaussian processes.\n",
    "Easy case: one-dimensional data (avoids matricies & covariance).\n",
    "Easy case: n=2.\n",
    "\n",
    "See [YouTube](https://youtu.be/iQoXFmbXRJA) video by Victor Lavrenko.\n",
    "\n",
    "At each iteration, we have two models to explain the data.\n",
    "Each model \"votes\" for each data point by assigning its Gaussian probability.\n",
    "\n",
    "The weight for the ith data point w[i]   \n",
    "equals   \n",
    "prob_of_i_under_model_1 / prob_of_i_under_all_models  \n",
    "equals  \n",
    "prob_of_i_under_model_1 / prob_of_i_under_model_1+prob_of_i_under_model_2\n",
    "\n",
    "Alternately, we can use Bayes rule to calculate posterior probabilities if priors are known.\n",
    "This code sets both priors to 50% so it doesn't really use Bayes. \n",
    "Optionally, this code can update the prior by counting cluster size at each step.\n",
    "It is not clear that these updates are justified,\n",
    "and in practice is makes the results much worse. \n",
    "We've seen it go on a downhill spiral where stdev and thus prior approach 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "def likelihood_of_data(mean,stdev,data):\n",
    "    # Likelihood of each datapoint under the given Gaussian parameters.\n",
    "    L=np.asarray([ss.norm.pdf(x,loc=mean,scale=stdev) for x in data])\n",
    "    return L\n",
    "def conditional_probabilities(like1,like2): \n",
    "    # get conditional probability of each model given these likelihoods\n",
    "    length = len(like1)\n",
    "    cond1=np.zeros(length)\n",
    "    cond2=np.zeros(length)\n",
    "    # TO DO: use vectors instead of for loop \n",
    "    for i in range(length):      \n",
    "        # This formula is same as Bayes rule \n",
    "        # if we multiply both likelihoods by prior=50%\n",
    "        prob_of_data = like1[i]+like2[i]\n",
    "        cond1[i] = like1[i] / prob_of_data  \n",
    "        cond2[i] = like2[i] / prob_of_data  \n",
    "    return cond1,cond2\n",
    "def mle_mean(weights,data):\n",
    "    length = len(data)\n",
    "    weighted = data*weights  # Hadamard vector multiply\n",
    "    mean=sum(weighted)/sum(weights)\n",
    "    return mean\n",
    "def mle_stdev(mean,weights,data):\n",
    "    # sum of the squares of the weighted deviations from the mean\n",
    "    dev = data-mean\n",
    "    wdev = dev*weights\n",
    "    sse = sum(wdev**2)\n",
    "    stdev=float(np.sqrt(sse/sum(weights)))\n",
    "    return stdev\n",
    "def expectation_maximization(data,num_iter):\n",
    "    # These initial guesses are arbitrary but based on the overall data.\n",
    "    mean=np.mean(data)\n",
    "    stdev=np.std(data)\n",
    "    mean1 = mean-0.5\n",
    "    mean2 = mean+0.5\n",
    "    stdev1 = stdev\n",
    "    stdev2 = stdev\n",
    "    print('Initial means: %f +/- %d, %f +/- %d'%(mean1,stdev1,mean2,stdev2))\n",
    "    for i in range(num_iter):\n",
    "        # likelihood of each data point under each Gaussian model\n",
    "        like1 = likelihood_of_data(mean1,stdev1,data)\n",
    "        like2 = likelihood_of_data(mean2,stdev2,data)\n",
    "        # conditional prob of each point assuming either Gaussian model\n",
    "        cond1,cond2 = conditional_probabilities(like1,like2)\n",
    "        # re-compute MLE given the conditionals\n",
    "        mean1 = mle_mean(cond1,data)\n",
    "        mean2 = mle_mean(cond2,data)\n",
    "        stdev1 = mle_stdev(mean1,cond1,data)\n",
    "        stdev2 = mle_stdev(mean2,cond2,data)\n",
    "        print('Intermediate means: %f +/- %d, %f +/- %d'%(mean1,stdev1,mean2,stdev2))\n",
    "    print()\n",
    "    print('Final means: %f +/- %d, %f +/- %d'%(mean1,stdev1,mean2,stdev2))\n",
    "    return mean1,mean2,stdev1,stdev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial means: 32.853365 +/- 10, 33.853365 +/- 10\n",
      "Intermediate means: 32.854026 +/- 7, 33.852696 +/- 7\n",
      "Intermediate means: 32.303825 +/- 8, 34.427703 +/- 7\n",
      "Intermediate means: 31.135043 +/- 8, 35.787601 +/- 6\n",
      "Intermediate means: 29.308834 +/- 9, 38.341446 +/- 4\n",
      "Intermediate means: 27.819773 +/- 9, 40.347093 +/- 3\n",
      "Intermediate means: 27.084902 +/- 8, 41.274618 +/- 3\n",
      "Intermediate means: 26.602027 +/- 8, 41.840215 +/- 3\n",
      "Intermediate means: 25.927297 +/- 7, 42.240890 +/- 3\n",
      "Intermediate means: 24.927243 +/- 6, 42.445485 +/- 4\n",
      "Intermediate means: 23.974419 +/- 6, 42.202100 +/- 4\n",
      "Intermediate means: 23.206768 +/- 5, 41.872863 +/- 4\n",
      "Intermediate means: 22.559093 +/- 5, 41.593148 +/- 4\n",
      "Intermediate means: 22.021608 +/- 5, 41.352999 +/- 4\n",
      "Intermediate means: 21.586262 +/- 4, 41.149522 +/- 4\n",
      "Intermediate means: 21.244946 +/- 4, 40.981724 +/- 5\n",
      "Intermediate means: 20.986302 +/- 4, 40.847931 +/- 5\n",
      "Intermediate means: 20.796235 +/- 4, 40.744899 +/- 5\n",
      "Intermediate means: 20.660133 +/- 4, 40.668104 +/- 5\n",
      "Intermediate means: 20.564669 +/- 4, 40.612471 +/- 5\n",
      "Intermediate means: 20.498749 +/- 4, 40.573092 +/- 5\n",
      "\n",
      "Final means: 20.498749 +/- 4, 40.573092 +/- 5\n"
     ]
    }
   ],
   "source": [
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "X = hstack( (X1, X2) ) \n",
    "X = np.asarray(X)\n",
    "mean1,mean2,stdev1,stdev2=expectation_maximization(X,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "Assume every point was generated by process 0 or process 1.\n",
    "Z is a vector naming the generating process for each point. \n",
    "Z is an unknown, a latent variable, that we'll predict.\n",
    "\n",
    "Assume processes 0 and 1 are Gaussian. \n",
    "Each has a mean and stdev.\n",
    "These are the parameters of the generating model.\n",
    "These are unknowns that we'll estimate.\n",
    "\n",
    "Start by guessing the number of processes, and the mean and stdev of each.\n",
    "\n",
    "EM loops over two steps.  \n",
    "* E-Step: The word expectation is not helpul. For every point, assign responsibility to each process. For K-means, assign 0 for one and 1 for the other i.e. all-or-nothing. For GMM, assign probabilities that sum to one across all processes.  \n",
    "* M-Step: Re-estimate the mean and stdev of each process. Use maximum likelihood to choose parameters that maximize the likelihood of this data. When computing the new mean and stdev, weight the sums by the assigned responsibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
