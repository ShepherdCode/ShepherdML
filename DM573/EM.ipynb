{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM and EM\n",
    "Gaussian Mixture Models and Expectation Maximization  \n",
    "\n",
    "Here we show canned and homgrown implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a library call\n",
    "Follow tutorial in [mastery](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n",
    "\n",
    "Use [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) class GaussianMixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPNElEQVR4nO3df6zd9V3H8edrrWVzU3DlZkHKdmtaXTp1bKndFtFMCLNk085YXKdGYkjQOJKZuGgxERmZyfCP4RKICRkoadRCqtPrVsU59oea2fWyH4GCjXesC0U3Lj+GYQaw4+0f50s8Od5yv5d7bu85nz4fSdPv9/P9HO77k568zofP93w/N1WFJKldr1jvAiRJa8ugl6TGGfSS1DiDXpIaZ9BLUuM2rncBo84///yanZ1d7zIkaarcd999j1fVzFLXJi7oZ2dnmZ+fX+8yJGmqJPn66a65dCNJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY2buCdjJfU3u//TS7af+Oi7z3AlmmTO6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXE+GSs1yCdmNcwZvSQ1zqCXpMa5dCOtg9MtrZyOSy5aDWf0ktQ4g16SGmfQS1LjDHpJapxBL0mN81s30hRY6bd0pGHO6CWpcb2CPsnuJMeTLCTZv8T1c5Lc1V0/kmR25PrrkzyT5ENjqluS1NOyQZ9kA3ArcAWwA3h/kh0j3a4GnqqqbcDNwE0j1z8G/N3qy5UkrVSfGf0uYKGqHq6q54GDwJ6RPnuAO7vjQ8BlSQKQ5L3A14BjY6lYkrQifYL+QuCRofOTXduSfarqFPA0sDnJa4DfAT78Uj8gyTVJ5pPMLy4u9q1dktTDWt+MvQG4uaqeealOVXVbVe2sqp0zMzNrXJIknV36fL3yUeCiofMtXdtSfU4m2QicCzwBvA3Ym+QPgfOAF5I8W1W3rLZwSVI/fYL+KLA9yVYGgb4P+MWRPnPAVcDngb3AvVVVwE+82CHJDcAzhrwknVnLBn1VnUpyLXAPsAG4o6qOJbkRmK+qOeB24ECSBeBJBh8G0lnPB500CXo9GVtVh4HDI23XDx0/C1y5zH/jhpdRnyRplXwyVpIaZ9BLUuMMeklqnEEvSY0z6CWpce5HL42BX6PUJHNGL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcD0xJZ5GXerDrxEfffQYr0ZnkjF6SGmfQS1LjDHpJapxBL0mN82Zsw1a6o6I346Q2OaOXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnLtXSgJOv9upu5pOP2f0ktQ4g16SGtcr6JPsTnI8yUKS/UtcPyfJXd31I0lmu/ZdSb7c/flKkp8bc/2SpGUsu0afZANwK3A5cBI4mmSuqh4c6nY18FRVbUuyD7gJeB/wALCzqk4luQD4SpK/rapTYx+JVs01WqlNfWb0u4CFqnq4qp4HDgJ7RvrsAe7sjg8BlyVJVf33UKi/EqhxFC1J6q9P0F8IPDJ0frJrW7JPF+xPA5sBkrwtyTHgfuDXnc1L0pm15jdjq+pIVb0J+DHguiSvHO2T5Jok80nmFxcX17okSTqr9An6R4GLhs63dG1L9kmyETgXeGK4Q1U9BDwD/PDoD6iq26pqZ1XtnJmZ6V+9JGlZfYL+KLA9ydYkm4B9wNxInzngqu54L3BvVVX3mo0ASd4AvBE4MZbKJUm9LPutm+4bM9cC9wAbgDuq6liSG4H5qpoDbgcOJFkAnmTwYQBwCbA/yf8ALwC/UVWPr8VAzlan+6aMJL2o1xYIVXUYODzSdv3Q8bPAlUu87gBwYJU1SpJWwSdjJalxbmqmZfkglTTdnNFLUuMMeklqnEEvSY0z6CWpcQa9JDXOb91IS/CbRmqJQS+tgE8iaxq5dCNJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOvW4kvSQ3eJt+Bv2UcDMtSS+XSzeS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGucWCHrZ3ANFmg4Gvc5q7iGks4FLN5LUOINekhpn0EtS43oFfZLdSY4nWUiyf4nr5yS5q7t+JMls1355kvuS3N/9femY65ckLWPZoE+yAbgVuALYAbw/yY6RblcDT1XVNuBm4Kau/XHgZ6rqR4CrgAPjKlyS1E+fGf0uYKGqHq6q54GDwJ6RPnuAO7vjQ8BlSVJVX6qq/+jajwGvSnLOOAqXJPXTJ+gvBB4ZOj/ZtS3Zp6pOAU8Dm0f6/Dzwxap6bvQHJLkmyXyS+cXFxb61S5J6OCM3Y5O8icFyzq8tdb2qbquqnVW1c2Zm5kyUJElnjT5B/yhw0dD5lq5tyT5JNgLnAk9051uATwK/UlVfXW3BkqSV6RP0R4HtSbYm2QTsA+ZG+swxuNkKsBe4t6oqyXnAp4H9VfUvY6pZkrQCy26BUFWnklwL3ANsAO6oqmNJbgTmq2oOuB04kGQBeJLBhwHAtcA24Pok13dt76qqx8Y9EE0O98A5O/jvPD167XVTVYeBwyNt1w8dPwtcucTrPgJ8ZJU1SpJWwSdjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuP8VYJqnr8uUGc7Z/SS1DiDXpIa59LNhHGZQdK4OaOXpMYZ9JLUOINekhrnGr2ksXL74snjjF6SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhrnk7Fqhjt/Sksz6NeJoSTpTHHpRpIa54xeZ4ybXUnrwxm9JDXOoJekxhn0ktQ41+i17ly7Pzv477x+nNFLUuMMeklqnEEvSY1zjV5Tx6eKpZUx6DWxDHRpPFy6kaTG9Qr6JLuTHE+ykGT/EtfPSXJXd/1IktmufXOSzyV5JsktY65dktTDskGfZANwK3AFsAN4f5IdI92uBp6qqm3AzcBNXfuzwO8BHxpbxZKkFekzo98FLFTVw1X1PHAQ2DPSZw9wZ3d8CLgsSarq21X1zwwCX5K0DvoE/YXAI0PnJ7u2JftU1SngaWBz3yKSXJNkPsn84uJi35dJknqYiJuxVXVbVe2sqp0zMzPrXY4kNaVP0D8KXDR0vqVrW7JPko3AucAT4yhQkrQ6fYL+KLA9ydYkm4B9wNxInzngqu54L3BvVdX4ypQkvVzLPjBVVaeSXAvcA2wA7qiqY0luBOarag64HTiQZAF4ksGHAQBJTgDfC2xK8l7gXVX14NhHIklaUq8nY6vqMHB4pO36oeNngStP89rZVdQnqXFuX7z2JuJmrCRp7Rj0ktQ4NzVbY27MJWm9OaOXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY1zm+IxcTtiSZPKGb0kNc4ZvaSJ5O+SHR9n9JLUOINekhpn0EtS4wx6SWqcQS9JjfNbN5Kmit/GWTln9JLUOINekhpn0EtS41yjXyH3tJE0bQx6SU3wJu3puXQjSY0z6CWpcS7dSGqaSzoG/Wl501VSK1y6kaTGnfUzemfukoa9VCZM63JPrxl9kt1JjidZSLJ/ievnJLmru34kyezQteu69uNJfnqMtUuSelh2Rp9kA3ArcDlwEjiaZK6qHhzqdjXwVFVtS7IPuAl4X5IdwD7gTcD3A/+Y5Aer6jvjHsiLvPEiqY+X83/z05ovfZZudgELVfUwQJKDwB5gOOj3ADd0x4eAW5Kkaz9YVc8BX0uy0P33Pj+e8vtziUbSWlnpB8CZ/sDoE/QXAo8MnZ8E3na6PlV1KsnTwOau/V9HXnvh6A9Icg1wTXf6TJLjvao/c84HHl/vItZAi+NqcUzQ5rhaHBMMjSs3reyFK+0/4g2nuzARN2Or6jbgtvWu43SSzFfVzvWuY9xaHFeLY4I2x9XimGAyx9XnZuyjwEVD51u6tiX7JNkInAs80fO1kqQ11CfojwLbk2xNsonBzdW5kT5zwFXd8V7g3qqqrn1f962crcB24AvjKV2S1MeySzfdmvu1wD3ABuCOqjqW5EZgvqrmgNuBA93N1icZfBjQ9bubwY3bU8AH1vIbN2toYpeVVqnFcbU4JmhzXC2OCSZwXBlMvCVJrXILBElqnEEvSY0z6EckuSPJY0keGGp7bZLPJPn37u/vW88aVyrJRUk+l+TBJMeSfLBrn/ZxvTLJF5J8pRvXh7v2rd1WHAvd1hyb1rvWlUqyIcmXknyqO29hTCeS3J/ky0nmu7Zpfw+el+RQkn9L8lCSd0zimAz6/+9Pgd0jbfuBz1bVduCz3fk0OQX8VlXtAN4OfKDbnmLax/UccGlVvRm4GNid5O0MtuC4uaq2AU8x2KJj2nwQeGjovIUxAfxUVV089D3zaX8Pfhz4+6p6I/BmBv9mkzemqvLPyB9gFnhg6Pw4cEF3fAFwfL1rXOX4/obB3kXNjAv4buCLDJ7afhzY2LW/A7hnvetb4Vi2MAiIS4FPAZn2MXV1nwDOH2mb2vcgg+eFvkb3pZZJHpMz+n5eV1X/2R1/A3jdehazGt3Oom8BjtDAuLolji8DjwGfAb4KfKuqTnVdltx2Y8L9EfDbwAvd+Wamf0wABfxDkvu6bU9gut+DW4FF4E+6ZbZPJHk1Ezgmg36FavAxPZXfSU3yGuAvgd+sqv8avjat46qq71TVxQxmwbuAN65vRauT5D3AY1V133rXsgYuqaq3AlcwWD78yeGLU/ge3Ai8FfjjqnoL8G1GlmkmZUwGfT/fTHIBQPf3Y+tcz4ol+S4GIf9nVfVXXfPUj+tFVfUt4HMMljXO67bigOnbduPHgZ9NcgI4yGD55uNM95gAqKpHu78fAz7J4IN5mt+DJ4GTVXWkOz/EIPgnbkwGfT/DWzxcxWCNe2p0W0bfDjxUVR8bujTt45pJcl53/CoG9x0eYhD4e7tuUzWuqrquqrZU1SyDJ8zvrapfYorHBJDk1Um+58Vj4F3AA0zxe7CqvgE8kuSHuqbLGOwCMHFj8snYEUn+Angng61Gvwn8PvDXwN3A64GvA79QVU+uU4krluQS4J+A+/m/dd/fZbBOP83j+lHgTgZbc7wCuLuqbkzyAwxmw68FvgT8cg1+J8JUSfJO4ENV9Z5pH1NX/ye7043An1fVHyTZzHS/By8GPgFsAh4GfpXuvcgEjcmgl6TGuXQjSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj/hekX05kvyRi3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Construct a bimodal from two Gaussian processes.\n",
    "from numpy import hstack\n",
    "from numpy.random import normal\n",
    "from matplotlib import pyplot\n",
    "# normal ( mean, standard deviation, count )\n",
    "def plot(X1,X2):\n",
    "    X = hstack( (X1, X2) )  # horizontal stack i.e. concat\n",
    "    pyplot.hist(X, bins=50, density=True)\n",
    "    pyplot.show()\n",
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "plot(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gmm(model):\n",
    "    print(model)\n",
    "    for i in range(model.n_components):\n",
    "        print('Gaussian',i,'mean=',model.means_[i],\n",
    "            'wgt=',model.weights_[i], \n",
    "            'Cov=',model.covariances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "Initialization converged: True\n",
      "GaussianMixture(covariance_type='spherical', n_components=2, verbose=1)\n",
      "Gaussian 0 mean= [40.12945753] wgt= 0.6563470239494186 Cov= 33.647695302458146\n",
      "Gaussian 1 mean= [20.20550312] wgt= 0.3436529760505827 Cov= 17.082524852264957\n"
     ]
    }
   ],
   "source": [
    "# Straight from the Mastery site.\n",
    "# Use EM to reverse engineer the model i.e. fit a GMM to the data.\n",
    "from sklearn.mixture import GaussianMixture\n",
    "X = hstack( (X1, X2) ) \n",
    "X = X.reshape((len(X), 1))\n",
    "# By default, covariance=‘full’: each component has its own general covariance matrix.\n",
    "# Use 'spherical' (one variance per mean) since our data has only one feature.\n",
    "# By default, init_params='kmeans'. Works much better than 'random'!\n",
    "model = GaussianMixture(n_components=2, verbose=1, covariance_type='spherical')\n",
    "model.fit(X)\n",
    "show_gmm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class of a point on the left: 1\n",
      "Predicted class of a point on the right: 0\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X)\n",
    "print('Predicted class of a point on the left:',yhat[100])\n",
    "print('Predicted class of a point on the right:',yhat[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean0=model.means_[0]\n",
    "mean1=model.means_[1]\n",
    "G0 = normal(loc=mean0, scale=4, size=3000) \n",
    "G1 = normal(loc=mean1, scale=6, size=6000)\n",
    "if mean0>mean1:\n",
    "    G0 = normal(loc=mean0, scale=4, size=6000) \n",
    "    G1 = normal(loc=mean1, scale=6, size=3000)\n",
    "plot(G0,G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homegrown version\n",
    "See [YouTube](https://youtu.be/iQoXFmbXRJA) video by Victor Lavrenko,\n",
    "especially minute 3:46.\n",
    "\n",
    "At each iteration, we have two models to explain the data.\n",
    "Each model \"votes\" for each data point by assigning its Gaussian probability.\n",
    "\n",
    "The weight for the ith data point w[i]   \n",
    "equals   \n",
    "prob_of_i_under_model_1 / prob_of_i_under_all_models  \n",
    "equals  \n",
    "prob_of_i_under_model_1 / prob_of_i_under_model_1+prob_of_i_under_model_2\n",
    "\n",
    "Alternately, we can use Bayes rule to calculate posterior probabilities if priors are known.\n",
    "This code sets both priors to 50% so it doesn't really use Bayes. \n",
    "Optionally, this code can update the prior by counting cluster size at each step.\n",
    "It is not clear that these updates are justified,\n",
    "and in practice is makes the results much worse. \n",
    "We've seen it go on a downhill spiral where stdev and thus prior approach 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "def assign_probs(mean,stdev,data):\n",
    "    probs=np.asarray([ss.norm.pdf(x,loc=mean,scale=stdev) for x in data])\n",
    "    return probs\n",
    "def bayes(prob_under_this,prior_for_this,prob_under_other):\n",
    "    prior_for_other = 1-prior_for_this\n",
    "    numerator = prob_under_this * prior_for_this\n",
    "    denominator = numerator + prob_under_other * prior_for_other\n",
    "    posterior = numerator / denominator\n",
    "    return posterior\n",
    "def assign_weights(probs1,probs2,prior1):\n",
    "    prior2 = 1-prior1\n",
    "    length = len(probs1)\n",
    "    weights1=np.zeros(length)\n",
    "    weights2=np.zeros(length)\n",
    "    for i in range(length):    # do without for loop ?                 \n",
    "        weights1[i]=bayes(probs1[i],prior1,probs2[i])  \n",
    "        weights2[i]=bayes(probs2[i],prior2,probs1[i])  \n",
    "    return weights1,weights2\n",
    "def update_mean(weights,data):\n",
    "    length = len(data)\n",
    "    weighted = data*weights  # Hadamard vector multiply\n",
    "    mean=sum(weighted)/sum(weights)\n",
    "    return mean\n",
    "def update_stdev(mean,weights,data):\n",
    "    # sum of the squares of the weighted deviations from the mean\n",
    "    dev = data-mean\n",
    "    wdev = dev*weights\n",
    "    sse = sum(wdev**2)\n",
    "    stdev=float(np.sqrt(sse/sum(weights)))\n",
    "    return stdev\n",
    "def update_prior(probs1,probs2):\n",
    "    # Not clear there is any prior information to build on.\n",
    "    # prior = sum(probs)/len(probs)  # doesn't work!\n",
    "    length = len(probs1)\n",
    "    mine = 0\n",
    "    for i in range(length):\n",
    "        if probs1[i]>probs2[i]:\n",
    "            mine += 1\n",
    "    return mine / length\n",
    "def iterative_2_means(mean1,mean2,data,num_iter,update_priors):\n",
    "    # initial guess is both equal to overall\n",
    "    stdev1=np.std(data)\n",
    "    stdev2=update_stdev(np.mean(data),np.ones(len(data)),data)  # should be same\n",
    "    print('Initial means: %f +/- %d, %f +/- %d'%(mean1,stdev1,mean2,stdev2))\n",
    "    prior1 = 0.5\n",
    "    for i in range(num_iter):\n",
    "        probs1=assign_probs(mean1,stdev1,data)\n",
    "        probs2=assign_probs(mean2,stdev2,data)\n",
    "        weights1,weights2 = assign_weights(probs1,probs2,prior1)\n",
    "        mean1 = update_mean(weights1,data)\n",
    "        mean2 = update_mean(weights2,data)\n",
    "        stdev1 = update_stdev(mean1,weights1,data)\n",
    "        stdev2 = update_stdev(mean2,weights2,data)\n",
    "        print('Intermediate means: %f +/- %d, %f +/- %d (%f)'%(mean1,stdev1,mean2,stdev2,prior1))\n",
    "        if update_priors:\n",
    "            prior1=update_prior(probs1,probs2)\n",
    "    print()\n",
    "    print('Final means: %f +/- %d, %f +/- %d'%(mean1,stdev1,mean2,stdev2))\n",
    "    return mean1,mean2,stdev1,stdev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial means: 10.000000 +/- 10, 20.000000 +/- 10\n",
      "Intermediate means: 26.008602 +/- 4, 35.375446 +/- 8 (0.500000)\n",
      "Intermediate means: 23.493979 +/- 4, 38.553664 +/- 6 (0.500000)\n",
      "Intermediate means: 21.159856 +/- 4, 40.536749 +/- 5 (0.500000)\n",
      "Intermediate means: 20.847897 +/- 4, 40.703031 +/- 5 (0.500000)\n",
      "Intermediate means: 20.762206 +/- 4, 40.653841 +/- 5 (0.500000)\n",
      "Intermediate means: 20.705592 +/- 4, 40.619504 +/- 5 (0.500000)\n",
      "Intermediate means: 20.668055 +/- 4, 40.596387 +/- 5 (0.500000)\n",
      "Intermediate means: 20.643392 +/- 4, 40.581015 +/- 5 (0.500000)\n",
      "Intermediate means: 20.627270 +/- 4, 40.570887 +/- 5 (0.500000)\n",
      "Intermediate means: 20.616768 +/- 4, 40.564253 +/- 5 (0.500000)\n",
      "Intermediate means: 20.609941 +/- 4, 40.559927 +/- 5 (0.500000)\n",
      "Intermediate means: 20.605510 +/- 4, 40.557111 +/- 5 (0.500000)\n",
      "Intermediate means: 20.602637 +/- 4, 40.555283 +/- 5 (0.500000)\n",
      "Intermediate means: 20.600774 +/- 4, 40.554097 +/- 5 (0.500000)\n",
      "Intermediate means: 20.599568 +/- 4, 40.553328 +/- 5 (0.500000)\n",
      "Intermediate means: 20.598786 +/- 4, 40.552830 +/- 5 (0.500000)\n",
      "Intermediate means: 20.598280 +/- 4, 40.552507 +/- 5 (0.500000)\n",
      "Intermediate means: 20.597953 +/- 4, 40.552298 +/- 5 (0.500000)\n",
      "Intermediate means: 20.597740 +/- 4, 40.552163 +/- 5 (0.500000)\n",
      "Intermediate means: 20.597603 +/- 4, 40.552075 +/- 5 (0.500000)\n",
      "\n",
      "Final means: 20.597603 +/- 4, 40.552075 +/- 5\n"
     ]
    }
   ],
   "source": [
    "X1 = normal(loc=20, scale=4, size=3000) \n",
    "X2 = normal(loc=40, scale=6, size=6000)\n",
    "guess1 = 10\n",
    "guess2 = 20\n",
    "X = hstack( (X1, X2) ) \n",
    "X = np.asarray(X)\n",
    "mean1,mean2,stdev1,stdev2=iterative_2_means(guess1,guess2,X,20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "Assume every point was generated by process 0 or process 1.\n",
    "Z is a vector naming the generating process for each point. \n",
    "Z is an unknown, a latent variable, that we'll predict.\n",
    "\n",
    "Assume processes 0 and 1 are Gaussian. \n",
    "Each has a mean and stdev.\n",
    "These are the parameters of the generating model.\n",
    "These are unknowns that we'll estimate.\n",
    "\n",
    "Start by guessing the number of processes, and the mean and stdev of each.\n",
    "\n",
    "EM loops over two steps.  \n",
    "* E-Step: The word expectation is not helpul. For every point, assign responsibility to each process. For K-means, assign 0 for one and 1 for the other i.e. all-or-nothing. For GMM, assign probabilities that sum to one across all processes.  \n",
    "* M-Step: Re-estimate the mean and stdev of each process. Use maximum likelihood to choose parameters that maximize the likelihood of this data. When computing the new mean and stdev, weight the sums by the assigned responsibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
