{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7cfa16",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "Based on Charu Aggarwal, Data Mining, chapter 14, Time Series.\n",
    "\n",
    "Time series data have two components:\n",
    "1. behavioral e.g. the temperature values\n",
    "1. contextual e.g. the measurement times\n",
    "\n",
    "SIMILARITY:   \n",
    "To compare two time series, use:\n",
    "1. Euclidean distance (requires same number of time points)\n",
    "1. Edit distance\n",
    "1. Longest Common Substring (found by dynamic programming)\n",
    "1. Difference between their coefficients in an FFT representation\n",
    "1. DTW = Dynamic Time Warp: measure differences after aligning periods with similar meaning (such as valve-open and valve-closed) if not similar duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4a7c8",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "Ideally, work with consecutive time points and no missing values.\n",
    "\n",
    "### Missing values\n",
    "INTERPOLATION:   \n",
    "Interpolate missing values if required. \n",
    "Linear interpolation is usually fine, but polynomial and spline can be used.\n",
    "\n",
    "### Noise reduction\n",
    "PAA = BINNING:   \n",
    "Binning does smoothing and data reduction.\n",
    "Replace original values with means of non-overlapping windows.\n",
    "Use median instead of mean for less sensitivity to outliers.\n",
    "Larger bin sizes provide more smoothing.\n",
    "PAA = piecewise aggregate approximation.\n",
    "\n",
    "MOVING AVERAGE:   \n",
    "Moving average smoothing does data smoothing but not data reduction.\n",
    "Replace original values with means of overlapping windows e.g. stride=1.\n",
    "Use median instead of mean for less sensitivity to outliers.\n",
    "Larger window sizes provide more smoothing.\n",
    "\n",
    "Downsides: \n",
    "1. lose first window of data\n",
    "1. lag for predictions to catch up to recent big changes\n",
    "1. can actually invert big, fast oscillation\n",
    "\n",
    "EXPONENTIAL SMOOTHING:   \n",
    "Exponential smoothing uses weighted average,\n",
    "so the most recent value counts more or less than the trend.\n",
    "Requires the smoothing parameter a. \n",
    "Larger values of a emphasize the most recent value more.\n",
    "\n",
    "If a=1/4:   \n",
    "$\\hat{y}_{i} = (\\frac{1}{4})(y_{i})-(\\frac{3}{4})(\\hat{y}_{i-1})$   \n",
    "The recursion leads to exponential decay of older values.\n",
    "\n",
    "### Normalization\n",
    "Normalize multivariate behavioral data on different scales.\n",
    "1. Range-based: (yi-min)/(max-min)\n",
    "1. Z-score: (yi-mean)/(stdev)\n",
    "\n",
    "Z-score standardization is preferable mathematically but \n",
    "range-based is computationally convenient since \n",
    "no value ever exceeds the minimum or maximum.\n",
    "\n",
    "### Log transform\n",
    "A log transform can make data stationary.\n",
    "For example: it can remove the compounding effects of inflation on prices.\n",
    "After the log transform plus differencing, the series is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950b0f0",
   "metadata": {},
   "source": [
    "## Data Reduction\n",
    "### DTW = Discrete Wavelet Transform\n",
    "Generates ranked series of coefficients; \n",
    "using the first few provides lossy compression.\n",
    "Each wavelet captures difference between consecutive periods.\n",
    "Wavelets capture local changes.\n",
    "Best for one-time events.\n",
    "### Fourier Transform\n",
    "DFT = Discrete Fourier Transform,\n",
    "usually calculated by FFT = Fast Fourier Transform\n",
    "or replaced with DCT = Discrete Cosine Transform.\n",
    "DFT describes the global data by combinations of sinusoidal waves.\n",
    "Best for periodic time series.\n",
    "The coefficients are complex numbers but \n",
    "the complex terms cancel out to give real-valued predictions.\n",
    "Distance between FFTs = difference in coefficients = distance between time series.\n",
    "### SAX = Symbolic Aggregate Approximation \n",
    "Choose certain values that are sybolic or representative.\n",
    "Ideally, those values should be equally represented and equally likely.\n",
    "Example: replace a sine wave with a square wave with 3 values: +1, -1, 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196feeb",
   "metadata": {},
   "source": [
    "## ARIMA(p,d,q)\n",
    "For a single-valued time series.\n",
    "\n",
    "Stationary time series have time-independent mean and variance. Most time series are non-stationary but can be made so. For example, prices might be steady after adjusting for inflation.\n",
    "\n",
    "### I(d): differencing   \n",
    "With I(d), we predict not the actual values but the d-order differences. At d=1, we predict first-order differences, which should account for a mean that increases with time:   \n",
    "$\\hat{y}_{i} = y_{i}-y_{i-1}$   \n",
    "At d=2, we predict second-order differences, i.e. differences of differences, which I suppose captures a bit of non-linearity:   \n",
    "$\\hat{y}_{i} = \\hat{y}_{i}-\\hat{y}_{i-1}$   \n",
    "\n",
    "Since AR(p) and MA(q) assume stationary data, apply I(d) first.\n",
    "The For stationary data, use I(d=0) or use ARMA without the I.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea58ebf",
   "metadata": {},
   "source": [
    "### AR(p): autoregression\n",
    "With AR(p), we predict the current time value by a linear combination of p previous values. \n",
    "AR assumes stationarity.\n",
    "\n",
    "For p=2, the model uses a combination of 2 previous values plus a term for white noise:    \n",
    "$\\hat{y}_{i} = (a_{1})(y_{i-1}) + (a_{2})(y_{i-2}) + \\epsilon_i$   \n",
    "Note that $a_1 = a_2 = \\frac{1}{2}$ means use the average of the previous two points.\n",
    "Other values mean take a weighted average of the previous times.\n",
    "\n",
    "To fit this model to the data and learn the $a_i$ parameters, \n",
    "use linear regression and least squares.\n",
    "Each previous time window provides one linear equation.\n",
    "Since there are more equations than unknowns,\n",
    "the system is overspecified (with contradiction), \n",
    "and there are no solutions, only estimates.\n",
    "\n",
    "The autoregression plot helps choose p.\n",
    "The X-axis is the \"lag\"; values 1,2,3 represent the previous 1,2,3 time points. \n",
    "The Y-axis is the correlation between -1 and 1.\n",
    "Usually the plot starts near one and drops close to zero for no more correlation.\n",
    "Choose p where the correlation is still high.\n",
    "Keep p small to avoid overfitting.\n",
    "\n",
    "In seasonal data, the autoregression plot looks like a sine wave.\n",
    "In temperature data, correlation is near +1 at 12-month lag,\n",
    "and near -1 at 6-month lag.\n",
    "AR(12) could pick up, \"After an especially cold winter comes a rather cool summer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7b248",
   "metadata": {},
   "source": [
    "### MA(q): moving average\n",
    "With MA(q), we predict the shocks i.e. deviations from the mean.\n",
    "MA assumes stationarity.\n",
    "Obviously, it assumes previous shocks are predictive of future shocks.\n",
    "I think it also assumes that shocks come in regular periods.\n",
    "\n",
    "The prediction does not depend on the previous value, only its deviation.\n",
    "I guess this would work on mean-centered data\n",
    "and you could re-insert the mean later.\n",
    "For q=2, the model uses the previous two deviations from the predition:       \n",
    "$\\hat{y}_{i} = (b_{1})(\\epsilon_{i-1}) + (b_{2})(\\epsilon_{i-2}) + \\epsilon_i$   \n",
    "\n",
    "To fit this model to the data and learn the $b_i$ parameters, \n",
    "but the system is recursive and non-linear so regression is inappropriate.\n",
    "Use an iterative method like gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045c8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
