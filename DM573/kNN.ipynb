{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    "Classification. Lazy (no training). Supervised. Non-parametric. Requires scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic idea: incorporate neighbor data to be robust to noise. \n",
    "At prediction time, given an instance, find K nearest neighbors, \n",
    "predict major class among those.\n",
    "\n",
    "Naive O(N): compute instance-vs-all.    \n",
    "Pre-processing O(lg(N)): sort or compute pair-wise distances, organize as a tree.    \n",
    "\n",
    "Problems:  \n",
    "The decision boundaries are extremely non-linear at any K.\n",
    "Thus the results are sensitive to noise and unequal scaling.\n",
    "\n",
    "There are accuracy guarrantees for various special cases\n",
    "(K=1; binary classification on infinite data; etc.).\n",
    "\n",
    "In condensed nearest neighbors, \n",
    "use a reduced set of prototypes instead of all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision rule\n",
    "Possible return values:  \n",
    "The winner-take-all class of the majority of neighbors.  \n",
    "The centroid: a representative value, point in space, mean. \n",
    "For continuous data and regression.   \n",
    "Mediod: a representative instance, actually exists, median. \n",
    "For discrete data and classifcation.  \n",
    "A weighted mean: weight each neighbor by 1/distance.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of K\n",
    "Done by heuristics. \n",
    "Or by bootstrap (testing various K on random subsets).\n",
    "Choose odd K for binary classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of distance metric\n",
    "Conceive of points or vectors in N-dimentional space.  \n",
    "Usually use Euclidean distances on real data,\n",
    "Hamming distance on discrete data e.g. word frequencies of documents. \n",
    "The best distance metric can be learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations to other algorithms\n",
    "Self organizing maps (SOM): same idea on a modified search space. \n",
    "\n",
    "KNN is often the classifier used after feature extraction\n",
    "by Haar face detection, or mean-shift, or PCA, etc.  \n",
    "KNN by itself performs poorly on high-dimensional data due to \n",
    "curse of dimensionality.\n",
    "For real-time forecasting on high-dimensional big data,\n",
    "KNN is applied to sketeches or locality sensitive hashing.\n",
    "\n",
    "KNN can be used for outlier detection.\n",
    "Choose a K, find instances that are misclassified.\n",
    "Remove outliers with more than R neighbors of another class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data: Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo run\n",
    "See model parameters at \n",
    "[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbors, 0.95 % accuracy\n",
      "2 neighbors, 0.95 % accuracy\n",
      "3 neighbors, 0.95 % accuracy\n",
      "4 neighbors, 0.97 % accuracy\n",
      "5 neighbors, 0.95 % accuracy\n",
      "6 neighbors, 0.92 % accuracy\n",
      "7 neighbors, 0.95 % accuracy\n",
      "8 neighbors, 0.92 % accuracy\n",
      "9 neighbors, 0.95 % accuracy\n"
     ]
    }
   ],
   "source": [
    "for neighbors in range(1,10):\n",
    "    knn = KNN(neighbors)\n",
    "    knn.fit(X_train,y_train)   # does nothing but store the points and labels!\n",
    "    y_pred = knn.predict(X_test)    # aligns test points to training points!\n",
    "    scores = metrics.accuracy_score(y_test,y_pred)\n",
    "    print('%d neighbors, %4.2f %% accuracy' % (neighbors,scores) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is highly variable. Run it again, get different results. \n",
    "\n",
    "But this is merely due to the random train/test split. For a given train/test split, the results are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
