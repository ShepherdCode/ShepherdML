{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Network\n",
    "A dense NN is also called a Fully Connected (FC) or Multi-Layer Perceptron (MLP).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "The network consists of layers. \n",
    "The network architecture is: Input Layer | Internal Layer(s) | Output Layer.\n",
    "A deep NN has many internal layers.\n",
    "\n",
    "Each layer consists of Neurons.\n",
    "The input layer should have one neuron per feature of the input vector.\n",
    "The output layer should have one neuron per label that needs to be predicted.\n",
    "\n",
    "In the MLP architecture, \n",
    "neurons have no connections to other neurons in the same layer,\n",
    "but they are connected to every neuron in the layers immediately before and after.\n",
    "\n",
    "Neurons consist of Weighted Inputs | Summation | Activation Function | Output.\n",
    "With non-linear activations, the network can model any non-linear function.\n",
    "Each neuron also has one weighted input called the bias.\n",
    "The bias is merely for scaling the output, \n",
    "equivalent to the y-intercept b in the linear equation y=mx+b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Trainable parameters:  \n",
    "The model as trainable weights on every edge.\n",
    "The weights are initialized randomly (e.g. by the glorot_uniform algorithm).\n",
    "\n",
    "One forward calculation:  \n",
    "The model is shown one data instance from the labeled training set.\n",
    "Using the weights and activations, the output scores are computed.\n",
    "\n",
    "One back propagation:   \n",
    "For each labeled training instance, the actual scores are known.\n",
    "A loss function is applied to the calculated as actual minus difference.\n",
    "The partial derivative of the loss, with respect to each input, provides a gradient.\n",
    "The gradient tells the amount and direction that each input contributed to the loss.\n",
    "Using partial derivatives of the activations,\n",
    "the total loss is distributed, such that every neuron accepts some portion of the loss. \n",
    "Finally, the weight of each neuron's output is updated\n",
    "in the opposite direction of the gradient, so as to reduce the loss.\n",
    "The size of the update can be controlled by a learn rate parameter.\n",
    "\n",
    "Gradient descent:   \n",
    "The back propagation can apply to the loss over any number of instances, called a batch.\n",
    "If the batch size is 1, and each next training instance is chosen randomly,\n",
    "that is called \"stochastic gradient descent.\"\n",
    "If the batch size equals the whole training set,\n",
    "that is called \"batch gradient descent\" but it is computationally prohibitive.\n",
    "In keras, the default batch size is 32, \n",
    "and instances within each batch are used in random order.\n",
    "\n",
    "Epoch:   \n",
    "When all the training samples have been used once, the model has been trained for one epoch.\n",
    "It is usually necessary to train a model for many epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Validiation cycles:   \n",
    "We train a model on a training set.\n",
    "We evaluate the model on a separate validation set.\n",
    "In cycles, we adjust the model architecture and hyperparameters\n",
    "until the validation accuracy looks good.\n",
    "Finally, we measure the true accuracy on the previously-unused test data.\n",
    "\n",
    "Test set:   \n",
    "Some portion of the data, maybe 20%, is set aside for post-training evaluation.\n",
    "It is very important to avoid looking within the test set.\n",
    "Otherwise, the model accuracy could be artificially and inadvertently inflated.\n",
    "\n",
    "Validation set:   \n",
    "Some portion of the remaining data, maybe 20%, is set aside for hyperparameter tuning.\n",
    "For instance, should the deep neural network have 10 layers or 20?\n",
    "The model gets trained and evaluated and then tuned in cycles.\n",
    "It is important to avoid using any validation data for training, and vice-versa.\n",
    "Otherwise, the validation accuracy could be inflated.\n",
    "\n",
    "Training set:   \n",
    "After removing the test and validation data, the training set is what remains.\n",
    "\n",
    "Cross validation:   \n",
    "This is used to alleviate a data shortage,\n",
    "when we would rather not have to set aside a validation set.\n",
    "In 5-fold cross-validation, we make 5 mutually exclusive partions,\n",
    "of 80% train and 20% valid. \n",
    "Each data instaince will be used 4 times for training and 1 time for validation.\n",
    "The total validation accuracy is the mean of 5 rounds of training & validation.\n",
    "After model tuning is complete, the full dataset is used to retrain the model.\n",
    "The model thus trained is then evaluated on the previously-unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-03 18:40:18.480499\n",
      "Python 3.10.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "Iris:   \n",
    "We'll use the Iris dataset,\n",
    "famous because it was used in a paper by R.A. Fisher.\n",
    "There are 150 data instances, each a flower with 4 numeric features.\n",
    "Each instance is one of 3 species, labled 0, 1, 2.\n",
    "\n",
    "Shuffle:  \n",
    "The data are provided in order (0s first, 2s last).\n",
    "We must avoid training on 0s and testing on 2s, so we shuffle the rows.\n",
    "In our experiments, this was critical.\n",
    "\n",
    "Normalize:   \n",
    "Some features have larger values and larger variances than others.\n",
    "We must not let the model infer feature importance from those attributes.\n",
    "We use a library function that applies mean-center and unit-variance.\n",
    "This made no difference in our experiments on this data, but it could have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (150, 4)\n",
      "features ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "labels ['setosa' 'versicolor' 'virginica']\n",
      "X shape (150, 4)\n",
      "y shape (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "iris = datasets.load_iris()\n",
    "print('shape',iris.data.shape)\n",
    "print('features',iris.feature_names)\n",
    "print('labels',iris.target_names)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# At start, all species=0 come first and all species=2 come last.\n",
    "# Important to shuffle rows before doing train/test split and train/valid split.\n",
    "# Another way is using the sklearn train_test_split class.\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "print('X shape',X.shape)\n",
    "print('y shape',y.shape)\n",
    "num_instances = X.shape[0]\n",
    "num_features =  X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8, 2.8, 5.1, 2.4],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [4.6, 3.2, 1.4, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "       1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without normalization, the feature with biggest variance dominates.  \n",
    "Unfortunately, on these data, normalization reduces the attainable accuracy.   \n",
    "We use the Keras Normalization class:\n",
    "1. Constructor takes axis, mean, var. By default, axis = -1 (the last axis), mean=0, var=1.\n",
    "1. The adapt() method tunes the scaling parameters to the given data.\n",
    "1. From then on, the object scales any given data.\n",
    "1. Importantly, we adapt() to the training data and apply to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 18:40:54.475680: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150, 4), dtype=float32, numpy=\n",
       "array([[-0.04237568, -0.4948195 ,  0.7840797 ,  1.7010827 ],\n",
       "       [ 0.23398574, -1.8361979 ,  0.09298381, -0.33556128],\n",
       "       [-0.45691848,  2.6350634 , -1.5405157 , -1.4993577 ],\n",
       "       [ 2.0303369 , -0.2712561 ,  1.5380026 ,  0.82823515],\n",
       "       [-1.1478227 ,  0.84655935, -1.4776887 , -1.4993577 ],\n",
       "       [ 0.6485285 ,  0.622996  ,  1.3495218 ,  1.8465571 ],\n",
       "       [-1.1478227 ,  1.0701222 , -1.6033425 , -1.3538831 ],\n",
       "       [ 1.2012514 ,  0.17586967,  0.532772  ,  0.39181152],\n",
       "       [ 1.3394327 , -0.4948195 ,  0.5955991 ,  0.24633694],\n",
       "       [ 0.37216645, -0.4948195 ,  0.09298381,  0.10086234],\n",
       "       [ 0.37216645, -0.9419458 ,  1.0982141 ,  0.24633694],\n",
       "       [ 0.78670925,  0.39943308,  0.40711832,  0.39181152],\n",
       "       [ 0.37216645, -0.4948195 ,  0.532772  , -0.04461209],\n",
       "       [ 0.92489   , -0.4948195 ,  0.46994513,  0.39181152],\n",
       "       [ 0.37216645, -0.2712561 ,  0.532772  ,  0.24633694],\n",
       "       [-1.2860034 ,  1.2936851 , -1.5405157 , -1.6448323 ],\n",
       "       [ 0.23398574, -0.2712561 ,  0.40711832,  0.39181152],\n",
       "       [-0.45691848, -0.9419458 ,  0.34429148, -0.04461209],\n",
       "       [-1.4241841 , -0.0476932 , -1.5405157 , -1.3538831 ],\n",
       "       [-0.5950992 ,  1.9643748 , -1.6033425 , -1.2084087 ],\n",
       "       [-0.31873778, -0.4948195 ,  0.658426  ,  1.1191844 ],\n",
       "       [-0.31873778, -0.0476932 ,  0.40711832,  0.39181152],\n",
       "       [-1.4241841 ,  0.84655935, -1.2263811 , -1.4993577 ],\n",
       "       [-1.9769076 , -0.2712561 , -1.5405157 , -1.4993577 ],\n",
       "       [ 0.5103472 , -0.4948195 ,  0.5955991 ,  0.82823515],\n",
       "       [-1.7005461 ,  1.2936851 , -1.7918231 , -1.4993577 ],\n",
       "       [-1.009642  ,  1.7408113 , -1.2263811 , -1.2084087 ],\n",
       "       [ 0.5103472 , -0.2712561 ,  0.28146464,  0.10086234],\n",
       "       [-1.1478227 , -1.6126349 , -0.3468045 , -0.33556128],\n",
       "       [-1.1478227 ,  0.84655935, -1.4148617 , -1.2084087 ],\n",
       "       [ 0.78670925,  0.17586967,  1.0353873 ,  0.82823515],\n",
       "       [-0.5950992 , -0.0476932 ,  0.40711832,  0.39181152],\n",
       "       [-0.8714613 ,  1.0701222 , -1.4776887 , -1.4993577 ],\n",
       "       [ 0.37216645, -0.0476932 ,  0.658426  ,  0.82823515],\n",
       "       [ 0.78670925, -0.4948195 ,  1.0982141 ,  1.4101335 ],\n",
       "       [-0.8714613 , -0.71838236,  0.03015697,  0.24633694],\n",
       "       [-0.18055706,  1.7408113 , -1.3520348 , -1.3538831 ],\n",
       "       [ 0.23398574, -0.71838236,  0.7840797 ,  0.5372861 ],\n",
       "       [ 0.09580503, -0.0476932 ,  0.2186375 ,  0.39181152],\n",
       "       [-0.04237568, -0.9419458 ,  0.09298381, -0.04461209],\n",
       "       [ 1.3394327 , -0.0476932 ,  1.0353873 ,  1.2646588 ],\n",
       "       [-1.5623655 ,  0.39943308, -1.6033425 , -1.4993577 ],\n",
       "       [ 1.4776134 ,  0.17586967,  0.7840797 ,  1.5556079 ],\n",
       "       [-1.1478227 ,  1.0701222 , -1.4148617 , -0.9174595 ],\n",
       "       [-0.5950992 ,  1.5172485 , -1.4776887 , -1.4993577 ],\n",
       "       [-1.1478227 , -2.283324  , -0.22115068, -0.33556128],\n",
       "       [ 0.92489   , -0.0476932 ,  1.0353873 ,  0.82823515],\n",
       "       [ 1.2012514 ,  0.622996  ,  1.161041  ,  1.8465571 ],\n",
       "       [ 0.23398574, -1.8361979 ,  0.7212528 ,  0.39181152],\n",
       "       [ 1.2012514 , -1.1655086 ,  1.2238681 ,  0.82823515],\n",
       "       [-0.31873778, -1.1655086 ,  0.03015697, -0.19008668],\n",
       "       [ 2.5830598 , -0.0476932 ,  1.4123486 ,  1.5556079 ],\n",
       "       [ 0.6485285 ,  0.622996  ,  0.532772  ,  0.5372861 ],\n",
       "       [-0.45691848, -1.3890715 , -0.03267002, -0.19008668],\n",
       "       [ 0.6485285 , -0.71838236,  0.658426  ,  0.82823515],\n",
       "       [ 0.6485285 , -0.4948195 ,  0.7840797 ,  0.39181152],\n",
       "       [-1.2860034 , -1.1655086 ,  0.40711832,  0.6827607 ],\n",
       "       [ 0.6485285 , -1.1655086 ,  0.7212528 ,  0.97370976],\n",
       "       [ 1.6157942 ,  0.39943308,  0.532772  ,  0.24633694],\n",
       "       [ 0.92489   , -0.0476932 ,  0.8469065 ,  1.1191844 ],\n",
       "       [ 0.23398574,  0.84655935,  0.40711832,  0.5372861 ],\n",
       "       [-1.4241841 ,  0.17586967, -1.4148617 , -1.4993577 ],\n",
       "       [-0.04237568, -0.71838236,  0.7840797 ,  0.97370976],\n",
       "       [-0.31873778, -0.71838236,  0.2186375 ,  0.10086234],\n",
       "       [-0.31873778, -0.2712561 , -0.15832384,  0.10086234],\n",
       "       [-0.45691848, -1.1655086 ,  0.09298381,  0.10086234],\n",
       "       [ 0.37216645, -0.0476932 ,  0.46994513,  0.24633694],\n",
       "       [ 1.8921556 ,  0.39943308,  1.3495218 ,  0.82823515],\n",
       "       [-0.7332799 ,  1.5172485 , -1.4776887 , -1.4993577 ],\n",
       "       [-2.1150882 , -0.0476932 , -1.7289962 , -1.6448323 ],\n",
       "       [ 0.78670925, -0.71838236,  0.9097336 ,  0.97370976],\n",
       "       [-0.18055706, -0.0476932 ,  0.2186375 , -0.04461209],\n",
       "       [-0.5950992 ,  0.84655935, -1.3520348 , -1.4993577 ],\n",
       "       [-0.18055706,  3.0821903 , -1.4776887 , -1.2084087 ],\n",
       "       [ 1.4776134 ,  0.17586967,  0.658426  ,  0.39181152],\n",
       "       [-1.7005461 ,  0.17586967, -1.4776887 , -1.4993577 ],\n",
       "       [ 0.09580503, -0.0476932 ,  0.7840797 ,  0.82823515],\n",
       "       [-1.009642  , -1.1655086 , -0.5352852 , -0.19008668],\n",
       "       [-1.7005461 ,  0.84655935, -1.5405157 , -1.3538831 ],\n",
       "       [ 0.5103472 , -1.8361979 ,  0.40711832,  0.39181152],\n",
       "       [ 1.8921556 ,  1.2936851 ,  1.4123486 ,  1.8465571 ],\n",
       "       [-0.18055706, -0.2712561 ,  0.2186375 ,  0.10086234],\n",
       "       [-1.4241841 , -0.0476932 , -1.5405157 , -1.6448323 ],\n",
       "       [ 1.7539749 , -0.0476932 ,  1.286695  ,  1.2646588 ],\n",
       "       [ 1.4776134 ,  0.39943308,  1.161041  ,  1.5556079 ],\n",
       "       [ 0.92489   , -0.0476932 ,  1.2238681 ,  1.4101335 ],\n",
       "       [ 0.78670925, -0.4948195 ,  1.0982141 ,  1.2646588 ],\n",
       "       [-1.009642  ,  1.7408113 , -1.4148617 , -1.4993577 ],\n",
       "       [-1.4241841 ,  0.84655935, -1.4148617 , -1.4993577 ],\n",
       "       [ 0.92489   ,  0.39943308,  0.7840797 ,  1.1191844 ],\n",
       "       [ 1.2012514 ,  0.622996  ,  1.161041  ,  1.2646588 ],\n",
       "       [-1.8387269 , -1.6126349 , -1.6033425 , -1.3538831 ],\n",
       "       [ 0.5103472 ,  0.84655935,  0.97256047,  1.5556079 ],\n",
       "       [-1.2860034 , -0.0476932 , -1.5405157 , -1.4993577 ],\n",
       "       [-0.18055706, -1.1655086 ,  0.7212528 ,  1.1191844 ],\n",
       "       [ 1.4776134 ,  0.17586967,  0.97256047,  1.2646588 ],\n",
       "       [-1.9769076 ,  0.39943308, -1.6033425 , -1.4993577 ],\n",
       "       [-1.1478227 ,  1.2936851 , -1.5405157 , -1.4993577 ],\n",
       "       [ 1.8921556 , -0.0476932 ,  1.2238681 ,  0.5372861 ],\n",
       "       [-1.009642  ,  1.0701222 , -1.5405157 , -1.3538831 ],\n",
       "       [-1.9769076 , -0.0476932 , -1.6033425 , -1.4993577 ],\n",
       "       [-0.5950992 ,  1.9643748 , -1.3520348 , -1.2084087 ],\n",
       "       [-0.45691848, -1.6126349 ,  0.09298381,  0.10086234],\n",
       "       [ 1.3394327 ,  0.39943308,  1.286695  ,  1.5556079 ],\n",
       "       [ 2.444879  , -0.0476932 ,  1.7264831 ,  1.2646588 ],\n",
       "       [-1.009642  ,  1.0701222 , -1.5405157 , -1.4993577 ],\n",
       "       [-1.2860034 ,  0.17586967, -1.4776887 , -1.4993577 ],\n",
       "       [-0.8714613 ,  0.84655935, -1.5405157 , -1.4993577 ],\n",
       "       [-0.18055706, -0.4948195 ,  0.40711832,  0.10086234],\n",
       "       [ 1.0630707 , -0.0476932 ,  0.34429148,  0.24633694],\n",
       "       [-1.1478227 ,  0.39943308, -1.6661693 , -1.4993577 ],\n",
       "       [-1.009642  ,  0.622996  , -1.3520348 , -1.062934  ],\n",
       "       [ 0.78670925, -0.2712561 ,  0.28146464,  0.10086234],\n",
       "       [-0.5950992 ,  0.84655935, -1.4776887 , -1.2084087 ],\n",
       "       [ 2.5830598 , -0.9419458 ,  1.914964  ,  1.5556079 ],\n",
       "       [-1.2860034 , -1.3890715 , -0.3468045 , -0.33556128],\n",
       "       [ 2.859422  ,  1.7408113 ,  1.6008295 ,  1.1191844 ],\n",
       "       [ 1.2012514 ,  0.17586967,  0.34429148,  0.24633694],\n",
       "       [-0.8714613 ,  2.4115005 , -1.4776887 , -1.6448323 ],\n",
       "       [ 0.23398574, -0.0476932 ,  0.5955991 ,  0.82823515],\n",
       "       [-0.04237568,  2.1879377 , -1.6661693 , -1.4993577 ],\n",
       "       [ 2.5830598 , -0.4948195 ,  1.78931   ,  1.1191844 ],\n",
       "       [-1.009642  ,  1.7408113 , -1.4776887 , -1.3538831 ],\n",
       "       [-1.5623655 ,  0.39943308, -1.4148617 , -1.4993577 ],\n",
       "       [ 2.1685176 , -0.4948195 ,  1.4123486 ,  0.97370976],\n",
       "       [-1.1478227 ,  0.622996  , -1.5405157 , -1.4993577 ],\n",
       "       [ 0.6485285 ,  0.84655935,  1.0982141 ,  1.7010827 ],\n",
       "       [-0.18055706, -0.4948195 ,  0.15581065,  0.10086234],\n",
       "       [-0.04237568, -0.71838236,  0.03015697, -0.04461209],\n",
       "       [-0.18055706, -0.9419458 , -0.22115068, -0.33556128],\n",
       "       [ 0.78670925,  0.39943308,  0.9097336 ,  1.5556079 ],\n",
       "       [ 1.2012514 , -0.0476932 ,  0.8469065 ,  1.5556079 ],\n",
       "       [ 0.6485285 , -1.1655086 ,  0.658426  ,  0.39181152],\n",
       "       [ 1.2012514 , -0.0476932 ,  0.7212528 ,  0.6827607 ],\n",
       "       [-1.1478227 , -0.0476932 , -1.4148617 , -1.4993577 ],\n",
       "       [-0.45691848, -1.3890715 , -0.09549686, -0.33556128],\n",
       "       [ 1.2012514 ,  0.17586967,  1.0982141 ,  1.7010827 ],\n",
       "       [-0.04237568, -0.71838236,  0.7840797 ,  0.97370976],\n",
       "       [-1.009642  ,  0.84655935, -1.4776887 , -1.4993577 ],\n",
       "       [ 1.0630707 , -0.2712561 ,  0.46994513,  0.10086234],\n",
       "       [-0.31873778, -0.0476932 ,  0.15581065,  0.10086234],\n",
       "       [ 0.09580503,  0.39943308,  0.5955991 ,  0.82823515],\n",
       "       [ 0.6485285 , -1.6126349 ,  0.34429148,  0.10086234],\n",
       "       [-0.45691848,  1.0701222 , -1.6033425 , -1.4993577 ],\n",
       "       [-1.009642  ,  1.5172485 , -1.4776887 , -1.2084087 ],\n",
       "       [-1.2860034 ,  0.17586967, -1.4776887 , -1.6448323 ],\n",
       "       [ 0.6485285 , -0.2712561 ,  1.0982141 ,  0.82823515],\n",
       "       [-0.04237568, -0.71838236,  0.15581065, -0.33556128],\n",
       "       [ 2.5830598 ,  1.7408113 ,  1.78931   ,  1.4101335 ],\n",
       "       [-1.7005461 ,  0.39943308, -1.5405157 , -1.4993577 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize on half the data. This isn't exactly fair, as some test data is included.\n",
    "X_train = X[:75] \n",
    "normalizer = layers.Normalization() \n",
    "normalizer.adapt(X_train)\n",
    "X = normalizer(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters\n",
    "Here we decide number of layers, number of neurons per layer, and activation functions.\n",
    "Deciding this is an artform. \n",
    "In fact, we played with several settings before settling on the ones shown here. \n",
    "\n",
    "Keras offers 2 means of building a model.  \n",
    "1. The [Sequential class](https://keras.io/api/models/sequential/#sequential-class) is simple. It has an add(layer) method. It maintains layers in the order they were added. It allows linear models only. Every layer has one input and one output.\n",
    "1. The [Functional API](https://keras.io/guides/functional_api/) is complex. It allows DAG models. Layers can be skipped, reused, and multiply connected. We use the Functional API even though our model is linear in this example.\n",
    "\n",
    "The Keras Dense layer class has these constructor options.\n",
    "1. num units\n",
    "1. activation. Default=linear. Choices are relu, elu, softplus (smooth relu), softmax, sigmoid, tanh, exponential. There is an API so you can build your own.\n",
    "1. use_bias. Default=True\n",
    "1. kernel_initializer. Default=\"glorot_uniform\"\n",
    "1. regularizers for the bias, kernel, and activity. Default=None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(num_features,))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'dense_2')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras output layer raises exception unless #neurons == #labels in Y.\n",
    "dense1 =  layers.Dense(8, activation=\"relu\")   (inputs)\n",
    "dense2 =  layers.Dense(8, activation=\"relu\")   (dense1)\n",
    "outputs = layers.Dense(3)                      (dense2)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable Parameters\n",
    "Here we explain the number of trainable parameters that are shown below.\n",
    "1. Dense_0: (4 input + 1 bias) * 8 out = 40 \n",
    "1. Dense_0: (8 input + 1 bias) * 8 out = 72 \n",
    "1. Dense_2: (8 input + 1 bias) * 3 out = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"MLP_1\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "We evaluate the model by 5-fold cross validation.\n",
    "We use \"stratified\" KFold so that each validation set\n",
    "has approximately the same number of each label (flower species).\n",
    "\n",
    "Within each loop, the cricial steps are:\n",
    "1. Re-compile the model. Otherwise we would continously improve the same model.\n",
    "2. Fit the model to the training data by adjusting parameters. In Keras, model.fit() is made to be customized, but we use it as is. By default, [model.fit()](https://keras.io/api/models/model_training_apis/#fit-method)\n",
    "has shuffle=True within each batch.  \n",
    "3. Evaluate the model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNSEEN_PORTION = 0.10\n",
    "split_point = int ( X.shape[0] * (1-UNSEEN_PORTION) )\n",
    "X_unseen = np.array(X)[split_point:]\n",
    "y_unseen = np.array(y)[split_point:]\n",
    "X_seen   = np.array(X)[:split_point]\n",
    "y_seen   = np.array(y)[:split_point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 1.0914 - accuracy: 0.3611\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0500 - accuracy: 0.3889\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0232 - accuracy: 0.4259\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9982 - accuracy: 0.4630\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9762 - accuracy: 0.5185\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9545 - accuracy: 0.5463\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9369 - accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9194 - accuracy: 0.6111\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9032 - accuracy: 0.6296\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8889 - accuracy: 0.6204\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8765 - accuracy: 0.6481\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8622 - accuracy: 0.6481\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8501 - accuracy: 0.6481\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8397 - accuracy: 0.6574\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8293 - accuracy: 0.6759\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8205 - accuracy: 0.6944\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8113 - accuracy: 0.6944\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8028 - accuracy: 0.7130\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7946 - accuracy: 0.7130\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7874 - accuracy: 0.7222\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7805 - accuracy: 0.7315\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7730 - accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7670 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7600 - accuracy: 0.7593\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7534 - accuracy: 0.7593\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7468 - accuracy: 0.7593\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.7593\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7287 - accuracy: 0.7685\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7235 - accuracy: 0.7685\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7124 - accuracy: 0.7870\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7074 - accuracy: 0.7870\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7036 - accuracy: 0.7870\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.7963\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.8056\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.8056\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6769 - accuracy: 0.8056\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.8056\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.8148\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.8148\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.8241\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6498 - accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.8426\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.8426\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.8426\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.8426\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.8426\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6246 - accuracy: 0.8426\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.8426\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.8426\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.8426\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.8519\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.8426\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.8426\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.8519\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.8426\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.8611\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.8611\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.8611\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8704\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.8611\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.8611\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.8611\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.8704\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.8704\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.8796\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.8796\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.8704\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.8704\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.8704\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.8704\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.8704\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8704\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.8704\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.8704\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.8704\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.8704\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8704\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8796\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8796\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8796\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.9074\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8981\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9074\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.9074\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.9074\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.9167\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.9074\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.9074\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4700 - accuracy: 0.8148\n",
      "Fold 1 Valid accuracy: 0.8148148059844971 Valid loss: 0.46995216608047485\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.9167\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.9352\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.9259\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.9352\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.9444\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.9444\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.9537\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.9630\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.9630\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.9722\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.9722\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.9722\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9630\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.9537\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.9722\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.9815\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.9815\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.9815\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.9722\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.9815\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.9815\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.9815\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.9815\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.9815\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9815\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9815\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9815\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9815\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9815\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9815\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2205 - accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2097 - accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9815\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1457 - accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1248 - accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9815\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9815\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2637 - accuracy: 0.8519\n",
      "Fold 2 Valid accuracy: 0.8518518805503845 Valid loss: 0.2636967897415161\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9537\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9630\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9630\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9630\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9537\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9630\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9537\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9630\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9537\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9630\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9630\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9630\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9630\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9630\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9630\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9630\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9630\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9630\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9630\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9815\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9815\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9907\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9630\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9815\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9815\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9815\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9815\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9815\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9907\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9815\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9722\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9907\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Fold 3 Valid accuracy: 1.0 Valid loss: 0.015086145140230656\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9815\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9815\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9815\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9907\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9815\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9815\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9815\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9815\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9815\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9815\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9815\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9815\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9815\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9815\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9815\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9815\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9815\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9815\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9815\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9815\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9815\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9815\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9815\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9815\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9815\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9815\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9815\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9815\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9815\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9907\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9815\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9815\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9907\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9907\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9907\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9815\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Fold 4 Valid accuracy: 1.0 Valid loss: 0.011959697119891644\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0396 - accuracy: 0.9907\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9907\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9907\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9907\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9907\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9907\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9907\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9907\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9907\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9907\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9907\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9907\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9907\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9907\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9907\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9907\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9907\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9907\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9907\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9907\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9907\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9907\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9907\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9907\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9907\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9907\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9907\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9907\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9907\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9907\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9907\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9907\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9907\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9907\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9907\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9907\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9907\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9907\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9907\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9907\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9907\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9907\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9907\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9907\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9907\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9907\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9907\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9907\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9907\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9907\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9907\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9907\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9907\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9907\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9907\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9907\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9907\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9907\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9907\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9907\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9907\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9907\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9907\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9907\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9907\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9907\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9907\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9907\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9907\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9907\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x12aac9a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0475 - accuracy: 0.9630\n",
      "Fold 5 Valid accuracy: 0.9629629850387573 Valid loss: 0.04753085598349571\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "fold=1\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "history_vector=[]\n",
    "valid_vector=[]\n",
    "for train, valid in skf.split(X_seen,y_seen):\n",
    "    print(type(X))\n",
    "    print(type(train))\n",
    "    X_train = np.array(X_seen)[train]\n",
    "    y_train = np.array(y_seen)[train]\n",
    "    X_valid = np.array(X_seen)[valid]\n",
    "    y_valid = np.array(y_seen)[valid]\n",
    "    model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),metrics=[\"accuracy\"])\n",
    "    history = model.fit(X_train, y_train, batch_size=25, epochs=EPOCHS)\n",
    "    valid_scores = model.evaluate(X_valid, y_valid)\n",
    "    print(\"Fold\", fold,\"Valid accuracy:\",valid_scores[1],\"Valid loss:\", valid_scores[0])\n",
    "    fold += 1\n",
    "    history_vector.append(history)\n",
    "    valid_vector.append(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc = 0.8148148059844971 Validation loss = 0.46995216608047485\n",
      "Validation acc = 0.8518518805503845 Validation loss = 0.2636967897415161\n",
      "Validation acc = 1.0 Validation loss = 0.015086145140230656\n",
      "Validation acc = 1.0 Validation loss = 0.011959697119891644\n",
      "Validation acc = 0.9629629850387573 Validation loss = 0.04753085598349571\n"
     ]
    }
   ],
   "source": [
    "for pair in valid_vector:\n",
    "    print('Validation acc =',pair[1],'Validation loss =',pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: TEST ACC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
