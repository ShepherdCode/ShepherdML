{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN on the color-based training set.\n",
    "Assume training patches are in files on disk. See DF_Filter.011  \n",
    "Here, work out loading them as needed for training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure is\n",
    "* cache  \n",
    "    * train  \n",
    "        * 0  (green)\n",
    "        * 1   (blue)\n",
    "    * valid  \n",
    "        * 0  (green)\n",
    "        * 1   (blue)\n",
    "\n",
    "Filename like F15.209.tif is original_image.filenum_this_category.tif  \n",
    "Each file holds a 224x224 patch of a color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "DIR_IMAGES_OUT = \"/home/jrm/Martinez/images/cache/\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: normalize color channel ints to floats (0,1)\n",
    "# See https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "normalization_layer = kl.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_valid=[]\n",
    "Y_valid=[]\n",
    "# Required for tensorflow+\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "X_valid = np.asarray(X_valid)\n",
    "Y_valid = np.asarray(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(len(X_train))\n",
    "print(X_train[0].shape)\n",
    "print(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION=\"tanh\"\n",
    "NUM_CLASSES = 2\n",
    "INPUT_SHAPE=[PATCH_SIZE,PATCH_SIZE,3]\n",
    "cnn = keras.models.Sequential([\n",
    "    kl.Conv2D(filters=64,kernel_size=7,activation=ACTIVATION,padding=\"SAME\",\n",
    "    input_shape=INPUT_SHAPE),\n",
    "    kl.MaxPooling2D(2),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2),   \n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2), \n",
    "    kl.Flatten(),\n",
    "    kl.Dense(128,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),\n",
    "    kl.Dense(64,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),    \n",
    "    kl.Dense(2,activation=\"softmax\")\n",
    "])\n",
    "# 10 nodes in the output layer\n",
    "# corresponds to 10 classes of MNIST clothes.\n",
    "# cnn.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "EPOCHS=10\n",
    "start = time.time()\n",
    "hist = cnn.fit(X_train,Y_train,epochs=EPOCHS,\n",
    "                 validation_data=(X_valid,Y_valid))\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.0,1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-02-08 13:39:32.313479: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    "2022-02-08 13:39:32.313577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Alien): /proc/driver/nvidia/version does not exist\n",
    "2022-02-08 13:39:32.314790: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2022-02-08 13:39:32.783647: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 411041792 exceeds 10% of free system memory.\n",
    "2022-02-08 13:39:32.972057: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 205520896 exceeds 10% of free system memory.\n",
    "2022-02-08 13:39:33.075415: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 205520896 exceeds 10% of free system memory.\n",
    "2022-02-08 13:39:34.623417: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 205520896 exceeds 10% of free system memory.\n",
    "2022-02-08 13:39:34.779412: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 205520896 exceeds 10% of free system memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
