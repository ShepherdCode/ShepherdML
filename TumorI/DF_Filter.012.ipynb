{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN on the color-based training set.\n",
    "Assume training patches are in files on disk. See DF_Filter.011  \n",
    "Here, work out loading them as needed for training.  \n",
    "One issue is cuda.  \n",
    "Another issue is the TensorFlow Data API.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure is\n",
    "* cache  \n",
    "    * train  \n",
    "        * 0  (green) 2680 files\n",
    "        * 1   (blue) 3099 files\n",
    "    * valid  \n",
    "        * 0  (green) 266 files\n",
    "        * 1   (blue) 311 files\n",
    "\n",
    "Filename like F5..208 or F15.209.tif i.e. original_image.patch num.tif  \n",
    "All prefixes are 3 characters with either one or two dots.  \n",
    "Patch nums are per category.  \n",
    "Each file holds a 224x224 patch of a color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR_IMAGES_IN = \"/home/jrm/Martinez/images/cache/\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "BLUE=1\n",
    "GREEN=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: normalize color channel ints to floats (0,1)\n",
    "# See https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "normalization_layer = kl.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: load patches in random order\n",
    "# TO DO: or, give patch files randome names\n",
    "class patch_loader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def load_pixel_array(self,filename):\n",
    "        im = Image.open(filename)\n",
    "        ima = np.array(im)   # convert to numpy\n",
    "        return ima\n",
    "    def load_dataset(self,path,tv,label,max_files=None):\n",
    "        file_count=0\n",
    "        images=[]\n",
    "        labels=[]\n",
    "        pstr = path+tv+'/'+str(label)+'/*.tif'\n",
    "        fullpaths = glob.glob(pstr)\n",
    "        # names = [os.path.basename(x) for x in fullpaths]\n",
    "        for name in fullpaths:\n",
    "            file_count += 1\n",
    "            if file_count <= max_files:\n",
    "                ima = self.load_pixel_array(name)\n",
    "                images.append(ima)\n",
    "                labels.append(label)\n",
    "        return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_valid=[]\n",
    "Y_valid=[]\n",
    "pl = patch_loader()\n",
    "greenX,greenY = pl.load_dataset(DIR_IMAGES_IN,'train',GREEN,max_files=10)\n",
    "blueX, blueY =  pl.load_dataset(DIR_IMAGES_IN,'train',BLUE,max_files=10)\n",
    "X_train = greenX + blueX\n",
    "Y_train = greenY + blueY\n",
    "# Required for tensorflow+\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "X_valid = np.asarray(X_valid)\n",
    "Y_valid = np.asarray(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "20\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n",
    "print(type(X_train))\n",
    "print(len(X_train))\n",
    "print(X_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION=\"tanh\"\n",
    "NUM_CLASSES = 2\n",
    "INPUT_SHAPE=[PATCH_SIZE,PATCH_SIZE,3]\n",
    "cnn = keras.models.Sequential([\n",
    "    kl.Conv2D(filters=64,kernel_size=7,activation=ACTIVATION,padding=\"SAME\",\n",
    "    input_shape=INPUT_SHAPE),\n",
    "    kl.MaxPooling2D(2),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2),   \n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2), \n",
    "    kl.Flatten(),\n",
    "    kl.Dense(128,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),\n",
    "    kl.Dense(64,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),    \n",
    "    kl.Dense(2,activation=\"softmax\")\n",
    "])\n",
    "# 10 nodes in the output layer\n",
    "# corresponds to 10 classes of MNIST clothes.\n",
    "# cnn.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7697 - accuracy: 0.6500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.7745 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.7300 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.0830 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.1711 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.4955 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.5279 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0135 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.8729 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7324 - accuracy: 0.5000\n",
      "Elapsed time: 26.14322590827942\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "EPOCHS=10\n",
    "start = time.time()\n",
    "hist = cnn.fit(X_train,Y_train,epochs=EPOCHS,\n",
    "                 validation_data=(X_valid,Y_valid))\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.0,1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "022-02-15 09:21:18.088128: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    "2022-02-15 09:21:18.088162: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Alien): /proc/driver/nvidia/version does not exist\n",
    "2022-02-15 09:21:18.088620: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "[I 09:22:14.940 NotebookApp] Saving file at /TumorI/DF_Filter.012.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
