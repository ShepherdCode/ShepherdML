{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcess csv files from CellProfiler\n",
    "\n",
    "We built a pipeline to segment red blood cells (RBC), nuclei (based on hematoxylin), and nucleated cells (based on eosin).  \n",
    "* CP_20220429f = Ypos  \n",
    "* CP_20220429g = Yneg  \n",
    "\n",
    "We used MeasureShape and MeasureNeighbor. Thus, we get about 68 measures per object (spreadsheet columns), for 4 object classes (csv files), for as many objects as were detected in each path (spreadsheet rows).  \n",
    "\n",
    "    39616 Cells.csv 68 columns\n",
    "    39616 Nuclei.csv 68 columns\n",
    "    60887 RBC.csv 60 columns\n",
    "    12980 Image.csv 62 columns\n",
    "    153099 total\n",
    "\n",
    "Here, each image is actually a patch. The image data includes redundant fields: #RBC, #nuclei, #cells. But the rest of the image data seems non-redundant, including thresholds used and total areas covered. CellProfiler assigned image numbers in order starting at 1 for the first patch. It would take some work to reconstruct the mapping of these numbers to tumor names (e.g. patches 1-200 came from tumor B3); check whether CellProfiler has an option to add filenames to the csv files.\n",
    "\n",
    "We ran CellProfiler on the full training set (excludes a 20% test set) of center patches. Here, transform per-object metrics into per-patch metrics. Also, exclude patches with no nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(filename):\n",
    "    df = pd.read_csv(filename,dtype=np.float32)  # remove dtype?\n",
    "    count1 = df.isnull().sum().sum()\n",
    "    print('Zero out this many NaN:', count1)\n",
    "    df = df.fillna(0)\n",
    "    count2 = df.isnull().sum().sum()\n",
    "    print('Now how many NaN?:', count2)\n",
    "    print('Largest value:', df.max().max())\n",
    "    print('Smallest:', df.min().min())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero out this many NaN: 35\n",
      "Now how many NaN?: 0\n",
      "Largest value: 19328.0\n",
      "Smallest: -89.999825\n"
     ]
    }
   ],
   "source": [
    "FILENAME_YPOS = '/home/jrm/Martinez/CellProfilerRuns/CP_20220417_Ypos/Nuclei.CP_20220417_Ypos.csv'\n",
    "feature_vec_Ypos = make_dataframe(FILENAME_YPOS)\n",
    "#feature_vec_Ypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero out this many NaN: 20\n",
      "Now how many NaN?: 0\n",
      "Largest value: 25110.0\n",
      "Smallest: -89.99928\n"
     ]
    }
   ],
   "source": [
    "FILENAME_YNEG = '/home/jrm/Martinez/CellProfilerRuns/CP_20220417_Yneg/Nuclei.CP_20220417_Yneg.csv'\n",
    "feature_vec_Yneg = make_dataframe(FILENAME_YNEG)\n",
    "#feature_vec_Yneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframes are compatible.\n"
     ]
    }
   ],
   "source": [
    "Ypos_rows,Ypos_cols = feature_vec_Ypos.shape\n",
    "Yneg_rows,Yneg_cols = feature_vec_Yneg.shape\n",
    "if Ypos_cols == Yneg_cols:\n",
    "    print('The dataframes are compatible.')\n",
    "else:\n",
    "    print('ERROR! Column counts do not match.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec_all = pd.concat ( [feature_vec_Ypos, feature_vec_Yneg], ignore_index=True )\n",
    "label_vec_Ypos = np.ones(Ypos_rows,dtype=int)\n",
    "label_vec_Yneg = np.zeros(Yneg_rows,dtype=int)\n",
    "label_vec_all = np.concatenate ( [label_vec_Ypos, label_vec_Yneg] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (28364, 68) ytrain (28364,) ones: 13621\n",
      "Xtest (9455, 68) ytest (9455,) ones: 4517\n"
     ]
    }
   ],
   "source": [
    "# Default test size is 25%\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(feature_vec_all, label_vec_all.ravel(), random_state=42)\n",
    "print('Xtrain',Xtrain.shape,'ytrain',ytrain.shape,'ones:',np.count_nonzero(ytrain))\n",
    "print('Xtest',Xtest.shape,'ytest',ytest.shape,'ones:',np.count_nonzero(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
