{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo Big Run: apply small color 3-class CNN to mixed patches\n",
    "\n",
    "This file is similar to DF_Filter.020\n",
    "Use the CNN was trained on the obviously blue, green, black from DF_Filter.021      \n",
    "Predict the 'mixed' patches i.e. not obviously blue, green, black from DF_Filter.021  \n",
    "Generate csv file.\n",
    "\n",
    "DF_Filter.021: \n",
    "* Read from 'raw' images. Make patches. \n",
    "* Write to 'cache/train' and 'cache/valid'.\n",
    "* Write mixed uncertain images to 'patches'.\n",
    "DF_Filter.022: \n",
    "* Train the CNN on {black,green,blue}={3930,2946,3410}\n",
    "* use train/valid split 80:20.  \n",
    "DF_Filter.023: \n",
    "* Run the CNN on 36739 files in 'patches'. \n",
    "* Write labels to 'predictions.csv' file.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#  os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"   # turns off GPU?\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use model from /home/jrm/Martinez/models/CNN_SMALL_REDO\n"
     ]
    }
   ],
   "source": [
    "DIR_IMAGES_IN = \"/home/jrm/Martinez/images/patches/\"\n",
    "#DIR_IMAGES_IN = \"/home/jrm/Martinez/images/tinytest/\"   # just for testing\n",
    "PATTERN_PATCHES = \"*.jpg\"\n",
    "OUTPUT_CSV = \"predictions.csv\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "IMAGE_SIZE=(PATCH_SIZE,PATCH_SIZE)\n",
    "DIR_MODELS = \"/home/jrm/Martinez/models/\"\n",
    "FILE_MODEL = \"CNN_SMALL_REDO\"\n",
    "filepath=DIR_MODELS+FILE_MODEL\n",
    "print(\"Will use model from \"+filepath)\n",
    "cnn = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(path,pattern):\n",
    "    paths = glob.glob(path+pattern)\n",
    "    names = [os.path.basename(x) for x in paths]\n",
    "    return names\n",
    "FILENAMES_PATCHES = get_image_names(DIR_IMAGES_IN,PATTERN_PATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = kl.Rescaling(1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches to process:  36739\n",
      "At 1000 {'black': 376, 'blue': 247, 'green': 130, 'mixed': 247}\n",
      "At 2000 {'black': 748, 'blue': 461, 'green': 262, 'mixed': 529}\n",
      "At 3000 {'black': 1125, 'blue': 658, 'green': 415, 'mixed': 802}\n",
      "At 4000 {'black': 1527, 'blue': 862, 'green': 566, 'mixed': 1045}\n",
      "At 5000 {'black': 1909, 'blue': 1096, 'green': 685, 'mixed': 1310}\n",
      "At 6000 {'black': 2295, 'blue': 1308, 'green': 811, 'mixed': 1586}\n",
      "At 7000 {'black': 2712, 'blue': 1512, 'green': 937, 'mixed': 1839}\n",
      "At 8000 {'black': 3106, 'blue': 1730, 'green': 1069, 'mixed': 2095}\n",
      "At 9000 {'black': 3475, 'blue': 1959, 'green': 1191, 'mixed': 2375}\n",
      "At 10000 {'black': 3854, 'blue': 2189, 'green': 1319, 'mixed': 2638}\n",
      "At 11000 {'black': 4246, 'blue': 2425, 'green': 1463, 'mixed': 2866}\n",
      "At 12000 {'black': 4680, 'blue': 2634, 'green': 1581, 'mixed': 3105}\n",
      "At 13000 {'black': 5065, 'blue': 2859, 'green': 1706, 'mixed': 3370}\n",
      "At 14000 {'black': 5425, 'blue': 3068, 'green': 1861, 'mixed': 3646}\n",
      "At 15000 {'black': 5792, 'blue': 3294, 'green': 1978, 'mixed': 3936}\n",
      "At 16000 {'black': 6159, 'blue': 3524, 'green': 2110, 'mixed': 4207}\n",
      "At 17000 {'black': 6548, 'blue': 3754, 'green': 2255, 'mixed': 4443}\n",
      "At 18000 {'black': 6925, 'blue': 3959, 'green': 2405, 'mixed': 4711}\n",
      "At 19000 {'black': 7282, 'blue': 4180, 'green': 2541, 'mixed': 4997}\n",
      "At 20000 {'black': 7640, 'blue': 4415, 'green': 2679, 'mixed': 5266}\n",
      "At 21000 {'black': 7999, 'blue': 4657, 'green': 2834, 'mixed': 5510}\n",
      "At 22000 {'black': 8395, 'blue': 4876, 'green': 2965, 'mixed': 5764}\n",
      "At 23000 {'black': 8765, 'blue': 5101, 'green': 3101, 'mixed': 6033}\n",
      "At 24000 {'black': 9136, 'blue': 5327, 'green': 3227, 'mixed': 6310}\n",
      "At 25000 {'black': 9498, 'blue': 5560, 'green': 3367, 'mixed': 6575}\n",
      "At 26000 {'black': 9916, 'blue': 5778, 'green': 3473, 'mixed': 6833}\n",
      "At 27000 {'black': 10284, 'blue': 5999, 'green': 3605, 'mixed': 7112}\n",
      "At 28000 {'black': 10688, 'blue': 6190, 'green': 3730, 'mixed': 7392}\n",
      "At 29000 {'black': 11052, 'blue': 6440, 'green': 3869, 'mixed': 7639}\n",
      "At 30000 {'black': 11430, 'blue': 6644, 'green': 4004, 'mixed': 7922}\n",
      "At 31000 {'black': 11828, 'blue': 6849, 'green': 4153, 'mixed': 8170}\n",
      "At 32000 {'black': 12241, 'blue': 7047, 'green': 4284, 'mixed': 8428}\n",
      "At 33000 {'black': 12649, 'blue': 7268, 'green': 4400, 'mixed': 8683}\n",
      "At 34000 {'black': 13017, 'blue': 7500, 'green': 4541, 'mixed': 8942}\n",
      "At 35000 {'black': 13413, 'blue': 7705, 'green': 4687, 'mixed': 9195}\n",
      "At 36000 {'black': 13791, 'blue': 7928, 'green': 4836, 'mixed': 9445}\n",
      "Elapsed time: 870.4476716518402\n",
      "Total: 36739\n",
      "{'black': 14065, 'blue': 8096, 'green': 4930, 'mixed': 9648}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# With keras models, augmentation and dropout are inactive during prediction.\n",
    "import csv\n",
    "csvpath = DIR_IMAGES_IN+OUTPUT_CSV\n",
    "print(\"Patches to process: \",len(FILENAMES_PATCHES))\n",
    "color_counts={'black':0,'blue':0,'green':0,'mixed':0}\n",
    "pcount = mcount = 0\n",
    "with open(csvpath, 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',')\n",
    "    start = time.time()\n",
    "    for filename in FILENAMES_PATCHES:\n",
    "        path = DIR_IMAGES_IN+filename\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            path, target_size=IMAGE_SIZE\n",
    "        )\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = normalization_layer(img_array)\n",
    "        img_array = tf.expand_dims(img_array, 0)  # create tensor\n",
    "        # TODO: consider using predict_classes() instead\n",
    "        predictions = cnn.predict(img_array)\n",
    "        score = predictions[0]  # TODO: explore other array slices\n",
    "        blackscore,bluescore,greenscore = score\n",
    "        if blackscore >= 0.90:\n",
    "            word = \"black\"\n",
    "            color_counts['black'] += 1\n",
    "        elif bluescore >= 0.90:\n",
    "            word = \"blue\"\n",
    "            color_counts['blue'] += 1\n",
    "        elif greenscore >= 0.99:\n",
    "            word = \"green\"\n",
    "            color_counts['green'] += 1\n",
    "        else:\n",
    "            word = \"mixed\"\n",
    "            color_counts['mixed'] += 1\n",
    "        datawriter.writerow( (filename, score[0], score[1], word) )\n",
    "        pcount += 1\n",
    "        mcount += 1\n",
    "        if (mcount == 1000):\n",
    "            print(\"At\",pcount,color_counts)\n",
    "            mcount = 0\n",
    "    end = time.time()\n",
    "print(\"Elapsed time:\",end-start)\n",
    "print(\"Total:\",pcount)\n",
    "print (color_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data subset was used to set thresholds\n",
    "\n",
    "At .99 threshold: 78 black, 69 blue, 688 green, 650 uncertain  \n",
    "At .95 threshold: 101 black, 90 blue, 864 green, 430 uncertain  \n",
    "At .90 threshold: 108 black, 101 blue, 932 green, 344 uncertain  \n",
    "\n",
    "At .9/.9/.995: 108 black, 101 blue, 585 green, 691 uncertain  \n",
    "At .9/.9/.997: 108 black, 101 blue, 452 green, 824 uncertain  \n",
    "At .9/.9/.998: 108 black, 101 blue, 283 green, 993 uncertain  \n",
    "At .9/.9/.999: 108 black, 101 blue, 0 green, 1276 uncertain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
