{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo Big Run: apply small color 3-class CNN to mixed patches\n",
    "\n",
    "This file is similar to DF_Filter.020\n",
    "Use the CNN was trained on the obviously blue, green, black from DF_Filter.021      \n",
    "Predict the 'mixed' patches i.e. not obviously blue, green, black from DF_Filter.021  \n",
    "Generate csv file.\n",
    "\n",
    "DF_Filter.021: \n",
    "* Read from 'raw' images. Make patches. \n",
    "* Write to 'cache/train' and 'cache/valid'.\n",
    "* Write mixed uncertain images to 'patches'.\n",
    "DF_Filter.022: \n",
    "* Train the CNN on {black,green,blue}={3930,2946,3410}\n",
    "* use train/valid split 80:20.  \n",
    "DF_Filter.023: \n",
    "* Run the CNN on 36739 files in 'patches'. \n",
    "* Write labels to 'predictions.csv' file.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#  os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"   # turns off GPU?\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use model from /home/jrm/Martinez/models/CNN_SMALL_REDO\n"
     ]
    }
   ],
   "source": [
    "DIR_IMAGES_IN = \"/home/jrm/Martinez/images/patches/\"\n",
    "#DIR_IMAGES_IN = \"/home/jrm/Martinez/images/tinytest/\"   # just for testing\n",
    "PATTERN_PATCHES = \"*.jpg\"\n",
    "OUTPUT_CSV = \"predictions.csv\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "IMAGE_SIZE=(PATCH_SIZE,PATCH_SIZE)\n",
    "DIR_MODELS = \"/home/jrm/Martinez/models/\"\n",
    "FILE_MODEL = \"CNN_SMALL_REDO\"\n",
    "filepath=DIR_MODELS+FILE_MODEL\n",
    "print(\"Will use model from \"+filepath)\n",
    "cnn = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(path,pattern):\n",
    "    paths = glob.glob(path+pattern)\n",
    "    names = [os.path.basename(x) for x in paths]\n",
    "    return names\n",
    "FILENAMES_PATCHES = get_image_names(DIR_IMAGES_IN,PATTERN_PATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = kl.Rescaling(1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches to process:  30232\n",
      "At 1000 {'black': 318, 'blue': 361, 'green': 108, 'mixed': 213}\n",
      "At 2000 {'black': 661, 'blue': 703, 'green': 228, 'mixed': 408}\n",
      "At 3000 {'black': 1002, 'blue': 1054, 'green': 343, 'mixed': 601}\n",
      "At 4000 {'black': 1371, 'blue': 1392, 'green': 434, 'mixed': 803}\n",
      "At 5000 {'black': 1714, 'blue': 1734, 'green': 548, 'mixed': 1004}\n",
      "At 6000 {'black': 2042, 'blue': 2122, 'green': 638, 'mixed': 1198}\n",
      "At 7000 {'black': 2376, 'blue': 2473, 'green': 744, 'mixed': 1407}\n",
      "At 8000 {'black': 2711, 'blue': 2851, 'green': 848, 'mixed': 1590}\n",
      "At 9000 {'black': 3043, 'blue': 3225, 'green': 938, 'mixed': 1794}\n",
      "At 10000 {'black': 3417, 'blue': 3565, 'green': 1032, 'mixed': 1986}\n",
      "At 11000 {'black': 3752, 'blue': 3930, 'green': 1138, 'mixed': 2180}\n",
      "At 12000 {'black': 4091, 'blue': 4301, 'green': 1258, 'mixed': 2350}\n",
      "At 13000 {'black': 4447, 'blue': 4675, 'green': 1351, 'mixed': 2527}\n",
      "At 14000 {'black': 4765, 'blue': 5055, 'green': 1457, 'mixed': 2723}\n",
      "At 15000 {'black': 5101, 'blue': 5415, 'green': 1567, 'mixed': 2917}\n",
      "At 16000 {'black': 5449, 'blue': 5780, 'green': 1660, 'mixed': 3111}\n",
      "At 17000 {'black': 5769, 'blue': 6144, 'green': 1790, 'mixed': 3297}\n",
      "At 18000 {'black': 6099, 'blue': 6508, 'green': 1897, 'mixed': 3496}\n",
      "At 19000 {'black': 6453, 'blue': 6849, 'green': 2000, 'mixed': 3698}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# With keras models, augmentation and dropout are inactive during prediction.\n",
    "import csv\n",
    "csvpath = DIR_IMAGES_IN+OUTPUT_CSV\n",
    "print(\"Patches to process: \",len(FILENAMES_PATCHES))\n",
    "color_counts={'black':0,'blue':0,'green':0,'mixed':0}\n",
    "pcount = mcount = 0\n",
    "with open(csvpath, 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',')\n",
    "    start = time.time()\n",
    "    for filename in FILENAMES_PATCHES:\n",
    "        path = DIR_IMAGES_IN+filename\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            path, target_size=IMAGE_SIZE\n",
    "        )\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = normalization_layer(img_array)\n",
    "        img_array = tf.expand_dims(img_array, 0)  # create tensor\n",
    "        # TODO: consider using predict_classes() instead\n",
    "        predictions = cnn.predict(img_array)\n",
    "        score = predictions[0]  # TODO: explore other array slices\n",
    "        blackscore,bluescore,greenscore = score\n",
    "        if blackscore >= 0.90:\n",
    "            word = \"black\"\n",
    "            color_counts['black'] += 1\n",
    "        elif bluescore >= 0.90:\n",
    "            word = \"blue\"\n",
    "            color_counts['blue'] += 1\n",
    "        elif greenscore >= 0.99:\n",
    "            word = \"green\"\n",
    "            color_counts['green'] += 1\n",
    "        else:\n",
    "            word = \"mixed\"\n",
    "            color_counts['mixed'] += 1\n",
    "        os.rename(path,DIR_IMAGES_IN+word+\"/\"+filename)\n",
    "        datawriter.writerow( (filename, score[0], score[1], word) )\n",
    "        pcount += 1\n",
    "        mcount += 1\n",
    "        if (mcount == 1000):\n",
    "            print(\"At\",pcount,color_counts)\n",
    "            mcount = 0\n",
    "    end = time.time()\n",
    "print(\"Elapsed time:\",end-start)\n",
    "print(\"Total:\",pcount)\n",
    "print (color_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data subset was used to set thresholds\n",
    "\n",
    "At .99 threshold: 78 black, 69 blue, 688 green, 650 uncertain  \n",
    "At .95 threshold: 101 black, 90 blue, 864 green, 430 uncertain  \n",
    "At .90 threshold: 108 black, 101 blue, 932 green, 344 uncertain  \n",
    "\n",
    "At .9/.9/.995: 108 black, 101 blue, 585 green, 691 uncertain  \n",
    "At .9/.9/.997: 108 black, 101 blue, 452 green, 824 uncertain  \n",
    "At .9/.9/.998: 108 black, 101 blue, 283 green, 993 uncertain  \n",
    "At .9/.9/.999: 108 black, 101 blue, 0 green, 1276 uncertain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
