{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN on the color-based training set.\n",
    "TensorFlow CNN uses GPU but fewer than 100 patch images fit in GPU RAM.  \n",
    "Since we can't load all the images, learn to use TensorFlow Data API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure is\n",
    "* cache  \n",
    "    * train  \n",
    "        * 0  (green) 2680 files\n",
    "        * 1   (blue) 3099 files\n",
    "    * valid  \n",
    "        * 0  (green) 266 files\n",
    "        * 1   (blue) 311 files\n",
    "\n",
    "Filename like F5..208 or F15.209.tif i.e. original_image.patch num.tif  \n",
    "All prefixes are 3 characters with either one or two dots.  \n",
    "Patch nums are per category.  \n",
    "Each file holds a 224x224 patch of a color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#  os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"   # turns off GPU?\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMAGES_IN = \"/home/jrm/Martinez/images/cache/\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "BLUE=1\n",
    "GREEN=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5779 files belonging to 2 classes.\n",
      "Found 577 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(DIR_IMAGES_IN, 'train')\n",
    "valid_dir = os.path.join(DIR_IMAGES_IN, 'valid')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (244,244)\n",
    "\n",
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "valid_dataset = keras.utils.image_dataset_from_directory(\n",
    "    valid_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 244, 244, 3)\n",
      "tf.Tensor([1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "iterator = valid_dataset.take(1)\n",
    "for x in iterator:\n",
    "    print(x[0].shape)\n",
    "    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: normalize color channel ints to floats (0,1)\n",
    "# See https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "normalization_layer = kl.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0d81233b25c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mINPUT_SHAPE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m cnn = keras.models.Sequential([\n\u001b[0m\u001b[1;32m      5\u001b[0m     kl.Conv2D(filters=64,kernel_size=7,activation=ACTIVATION,padding=\"SAME\",\n\u001b[1;32m      6\u001b[0m     input_shape=INPUT_SHAPE),\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1829\u001b[0m       return self._generator.uniform(\n\u001b[1;32m   1830\u001b[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001b[0;32m-> 1831\u001b[0;31m     return tf.random.uniform(\n\u001b[0m\u001b[1;32m   1832\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "ACTIVATION=\"tanh\"\n",
    "NUM_CLASSES = 2\n",
    "INPUT_SHAPE=[PATCH_SIZE,PATCH_SIZE,3]\n",
    "cnn = keras.models.Sequential([\n",
    "    kl.Conv2D(filters=64,kernel_size=7,activation=ACTIVATION,padding=\"SAME\",\n",
    "    input_shape=INPUT_SHAPE),\n",
    "    kl.MaxPooling2D(2),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2),   \n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(256,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2), \n",
    "    kl.Flatten(),\n",
    "    kl.Dense(128,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),\n",
    "    kl.Dense(64,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),    \n",
    "    kl.Dense(2,activation=\"softmax\")\n",
    "])\n",
    "# 10 nodes in the output layer\n",
    "# corresponds to 10 classes of MNIST clothes.\n",
    "# cnn.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "EPOCHS=15\n",
    "start = time.time()\n",
    "hist = cnn.fit(train_dataset,validation_data=valid_dataset,\n",
    "               shuffle=True,epochs=EPOCHS,\n",
    "                 validation_data=(X_valid,Y_valid))\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.0,1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This worked after a complete reinstall.\n",
    "\n",
    "After installing nvtop, all of nvidia software stopped working.  \n",
    "Purge and reinstall was required.\n",
    "\n",
    "We cannot run this notebook repeatedly.  \n",
    "Firefox or Python or TensorFlow doesn't release the GPU memory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
