{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN on the color-based training set.\n",
    "Classify patches from all Y-neg tumors.  \n",
    "Regain those that are certainly blue or certainly green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "DIR_IMAGES_RAW = \"/home/jrm/Martinez/images/raw/\"\n",
    "DIR_IMAGES_OUT = \"/home/jrm/Martinez/images/temp/\"\n",
    "PATTERN_IMAGES_RAW = \"*.DF1.*.tif\"\n",
    "PATCH_SIZE=224  # matches VGG\n",
    "IMAGE_FILENAME='B13.DF1.115.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Ypos = ['B7.','B15','D1.','D5.','E7.','E9.','F9.','G3.','H13','I1.','I5.','I13']\n",
    "DF_Yneg = ['A3.','A5.','B13','C1.','C11','D3.','E5.','F3.','F7','F11','F13','F15','G15','H1.','H3.','H7.','H15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(path,pattern):\n",
    "    #RAW_IMAGE_NAMES = os.listdir(DIR_IMAGES_RAW)\n",
    "    paths = glob.glob(path+pattern)\n",
    "    names = [os.path.basename(x) for x in paths]\n",
    "    return names\n",
    "FILENAMES_IMAGES_RAW = get_image_names(DIR_IMAGES_RAW,PATTERN_IMAGES_RAW)\n",
    "#FILENAMES_IMAGES_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class patch_maker:\n",
    "    def __init__(self):\n",
    "        self.path=\"\"\n",
    "        self.w=0\n",
    "        self.h=0\n",
    "        self.im_width = 0\n",
    "        self.im_height = 0\n",
    "        self.patch_size = 10 # scalar, assumed square for now\n",
    "        self.pixel_array = None\n",
    "    def set_input_path(self,path):\n",
    "        self.path=path\n",
    "    def set_patch_size(self,scalar):\n",
    "        self.patch_size = scalar\n",
    "    def load_pixel_array(self,filename,verbose=False):\n",
    "        self.w=0\n",
    "        self.h=0\n",
    "        im = Image.open(self.path+filename)\n",
    "        ima = np.array(im)   # convert to numpy\n",
    "        self.im_width = ima.shape[0]\n",
    "        self.im_height = ima.shape[1]    \n",
    "        if verbose:\n",
    "            print(filename, ima.size, ima.shape)\n",
    "        self.pixel_array = ima\n",
    "        return ima\n",
    "    def get_next_patch(self): \n",
    "        IM_WIDTH = self.im_width\n",
    "        IM_HEIGHT = self.im_height\n",
    "        PIXEL_ARRAY = self.pixel_array\n",
    "        patch = None\n",
    "        if self.w+self.patch_size > IM_WIDTH:\n",
    "            self.h += self.patch_size\n",
    "            self.w = 0\n",
    "        if self.w+self.patch_size <= IM_WIDTH and self.h+self.patch_size <= IM_HEIGHT:\n",
    "            patch = PIXEL_ARRAY[self.w:self.w+self.patch_size, self.h:self.h+self.patch_size]\n",
    "            self.w += self.patch_size\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_heatmap(green,blue):   # TO DO: this is slow, need a hash function\n",
    "    bins=[10,20,30,40,50,60,70,80,90,256]\n",
    "    gbin=None\n",
    "    bbin=None\n",
    "    for bin in range(0,10):\n",
    "        if gbin is None and green<=bins[bin]:\n",
    "            gbin=bin\n",
    "        if bbin is None and blue<=bins[bin]:\n",
    "            bbin=bin\n",
    "        if gbin is not None and bbin is not None:\n",
    "            return gbin,bbin\n",
    "    return gbin,bbin\n",
    "def accumulate_pixels(imary,verbose=False):  # TO DO: nested for loop is very slow\n",
    "    heatmap=np.zeros( (10,10), dtype=np.int32)\n",
    "    if verbose:\n",
    "        print(\"accumulate\",imary.shape)\n",
    "    nrows,ncols,nchannel=imary.shape\n",
    "    for row in range(0,nrows):\n",
    "        for col in range(0,ncols):\n",
    "            pixel = imary[row,col]\n",
    "            #red = pixel[0]\n",
    "            green = pixel[1]\n",
    "            blue = pixel[2]\n",
    "            gbin,bbin = pixel_to_heatmap(green,blue)\n",
    "            heatmap[gbin,bbin] += 1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patch (patch,name):\n",
    "    pic = Image.fromarray(patch)\n",
    "    pic.save(DIR_IMAGES_OUT+name)  \n",
    "def show_heatmap (patch,name):\n",
    "    hm = accumulate_pixels(patch)\n",
    "    print(hm,name)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image patch counts: green, blue, total\n",
    "Analyzing F15.DF1.135.tif 34 262 3135   \n",
    "Analyzing H3.DF1.27.tif 110 30 3135  \n",
    "Analyzing C11.DF1.96.tif 292 16 3135  \n",
    "Analyzing C1.DF1.01.tif 69 293 3135  \n",
    "Analyzing F11.DF1.94.tif 54 375 3135  \n",
    "Analyzing H7.DF1.62.tif 178 228 3135  \n",
    "Analyzing A3.DF1.26.tif 1 1482 3135  \n",
    "Analyzing A5.DF1.45.tif 454 6 3135  \n",
    "Analyzing H15.DF1.132.tif 66 0 3135  \n",
    "Analyzing G15.DF1.133.tif 239 0 3135  \n",
    "Analyzing F3.DF1.22.tif 430 41 3135  \n",
    "Analyzing B13.DF1.115.tif 70 407 3135  \n",
    "Analyzing D3.DF1.20.tif 325 4 3135  \n",
    "Analyzing E5.DF1.42.tif 31 266 3135  \n",
    "Analyzing H1.DF1.07.tif 593 0 3135  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F15.DF1.135.tif, \n"
     ]
    }
   ],
   "source": [
    "NO_GREEN_INTENSITY=np.array( [0,35,0] )\n",
    "NO_BLUE_INTENSITY=np.array( [0,0,30] )\n",
    "pm = patch_maker()\n",
    "pm.set_input_path(DIR_IMAGES_RAW)\n",
    "pm.set_patch_size(PATCH_SIZE)\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_valid=[]\n",
    "Y_valid=[]\n",
    "VMOD=10\n",
    "pcount=0\n",
    "BLUE=1\n",
    "GREEN=0\n",
    "def add_patch (patch, color):  # TO DO: make this a class, dispense with globals\n",
    "    global pcount\n",
    "    global VMOD\n",
    "    if pcount >= VMOD:\n",
    "        X_valid.append(patch)\n",
    "        Y_valid.append(color)\n",
    "        pcount = 0\n",
    "    else:\n",
    "        X_train.append(patch)\n",
    "        Y_train.append(color)\n",
    "        pcount += 1\n",
    "for filename in FILENAMES_IMAGES_RAW:\n",
    "    prefix = filename[0:3]\n",
    "    if prefix in DF_Yneg:\n",
    "        print(filename,end=\", \")\n",
    "        pixels = pm.load_pixel_array(filename)\n",
    "        patch = pm.get_next_patch()\n",
    "        while patch is not None:\n",
    "            num_green_pixels = np.sum(np.all(patch >= NO_GREEN_INTENSITY,axis=2))\n",
    "            num_blue_pixels = np.sum(np.all(patch >= NO_BLUE_INTENSITY,axis=2))\n",
    "            if num_blue_pixels>=10000 and num_blue_pixels>num_green_pixels*20:\n",
    "                add_patch(patch,BLUE)\n",
    "            elif num_green_pixels>=15000 and num_green_pixels>num_blue_pixels*2:\n",
    "                add_patch(patch,GREEN)\n",
    "            patch = pm.get_next_patch()\n",
    "    break  # FOR STARTERS, JUST PROCESS ONE FILE!\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "270\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(len(X_train))\n",
    "print(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as kl\n",
    "cnn = keras.models.Sequential([\n",
    "    kl.Conv2D(filters=64,kernel_size=7,activation=\"relu\",padding=\"SAME\",\n",
    "    input_shape=[28,28,1]),\n",
    "    kl.MaxPooling2D(2),\n",
    "    kl.Conv2D(128,3,activation=\"relu\",padding=\"same\"),\n",
    "    kl.Conv2D(128,3,activation=\"relu\",padding=\"same\"),\n",
    "    kl.MaxPooling2D(2),   \n",
    "    kl.Conv2D(256,3,activation=\"relu\",padding=\"same\"),\n",
    "    kl.Conv2D(256,3,activation=\"relu\",padding=\"same\"),\n",
    "    kl.MaxPooling2D(2), \n",
    "    kl.Flatten(),\n",
    "    kl.Dense(128,activation=\"relu\"),\n",
    "    kl.Dropout(0.5),\n",
    "    kl.Dense(64,activation=\"relu\"),\n",
    "    kl.Dropout(0.5),    \n",
    "    kl.Dense(2,activation=\"softmax\")\n",
    "])\n",
    "# 10 nodes in the output layer\n",
    "# corresponds to 10 classes of MNIST clothes.\n",
    "# cnn.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f8c196422aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            metrics=[\"accuracy\"])\n\u001b[0;32m----> 4\u001b[0;31m hist = cnn.fit(X_train,Y_train,epochs=10,\n\u001b[0m\u001b[1;32m      5\u001b[0m                  validation_data=(X_valid,Y_valid))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "hist = cnn.fit(X_train,Y_train,epochs=10,\n",
    "                 validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplt as plt\n",
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,0.12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
