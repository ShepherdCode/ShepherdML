{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toward patch-free:\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#  os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"   # turns off GPU?\n",
    "import glob\n",
    "#import cv2 # OpenCV-Python\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "import keras.layers as kl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will overwrite model at /home/jrm/Martinez/models/PatchFree_002\n"
     ]
    }
   ],
   "source": [
    "DIR_IMAGES_IN = \"/home/jrm/Martinez/images/BigPatch/\"  \n",
    "PATCH_SIZE=224  # 224 matches VGG\n",
    "PATCH_SIZE=256\n",
    "# PATCH_SIZE=512    # dies\n",
    "# PATCH_SIZE=1024   # dies\n",
    "# PATCH_SIZE=2048   # kernel death at start of training\n",
    "DIR_MODELS = \"/home/jrm/Martinez/models/\"\n",
    "FILE_MODEL = \"PatchFree_002\" \n",
    "filepath=DIR_MODELS+FILE_MODEL\n",
    "print(\"Will overwrite model at \"+filepath)\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (PATCH_SIZE,PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12903 files belonging to 2 classes.\n",
      "Found 3225 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(DIR_IMAGES_IN, 'train')\n",
    "valid_dir = os.path.join(DIR_IMAGES_IN, 'valid')\n",
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
    "valid_dataset = keras.utils.image_dataset_from_directory(\n",
    "    valid_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize color channel ints to floats (0,1)\n",
    "# See https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "normalization_layer = kl.Rescaling(1.0/255.0)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterator = valid_dataset.take(5)\n",
    "#for x in iterator:\n",
    "#    print(x[0].shape)\n",
    "#    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION=\"tanh\"\n",
    "NUM_CLASSES = 2\n",
    "CHANNELS=3\n",
    "INPUT_SHAPE=[PATCH_SIZE,PATCH_SIZE,CHANNELS]\n",
    "cnn = keras.models.Sequential([\n",
    "    #kl.RandomFlip(),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\",input_shape=INPUT_SHAPE),\n",
    "    kl.MaxPooling2D(2),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(128,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2),   \n",
    "    kl.Conv2D(64,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.Conv2D(64,3,activation=ACTIVATION,padding=\"same\"),\n",
    "    kl.MaxPooling2D(2), \n",
    "    kl.Flatten(),\n",
    "    kl.Dense(32,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),\n",
    "    kl.Dense(16,activation=ACTIVATION),\n",
    "    kl.Dropout(0.5),    \n",
    "    kl.Dense(NUM_CLASSES,activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "404/404 [==============================] - 59s 140ms/step - loss: 0.5505 - accuracy: 0.7820 - val_loss: 0.5208 - val_accuracy: 0.7857\n",
      "Epoch 2/5\n",
      "404/404 [==============================] - 56s 138ms/step - loss: 0.5293 - accuracy: 0.7856 - val_loss: 0.5227 - val_accuracy: 0.7857\n",
      "Epoch 3/5\n",
      "404/404 [==============================] - 56s 138ms/step - loss: 0.5275 - accuracy: 0.7857 - val_loss: 0.5195 - val_accuracy: 0.7857\n",
      "Epoch 4/5\n",
      "404/404 [==============================] - 55s 137ms/step - loss: 0.5220 - accuracy: 0.7855 - val_loss: 0.5194 - val_accuracy: 0.7857\n",
      "Epoch 5/5\n",
      "404/404 [==============================] - 55s 137ms/step - loss: 0.5212 - accuracy: 0.7857 - val_loss: 0.5198 - val_accuracy: 0.7857\n",
      "Elapsed time: 282.4208490848541\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "           optimizer=\"sgd\",\n",
    "           metrics=[\"accuracy\"])\n",
    "EPOCHS=5\n",
    "start = time.time()\n",
    "hist = cnn.fit(train_dataset,validation_data=valid_dataset,epochs=EPOCHS)\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.0,1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dies before epoch 1 with with patch size 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dies during epoch 1 with patch size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-10-1dbbef6fc570>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-1dbbef6fc570>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2022-04-05 14:24:44.298579: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 1. 9.00GiB allocated for chunks. 384.00MiB in use in bin. 384.00MiB client-requested in use in bin.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "2022-04-05 14:24:44.298579: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 1. 9.00GiB allocated for chunks. 384.00MiB in use in bin. 384.00MiB client-requested in use in bin.\n",
    "2022-04-05 14:24:44.298896: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 16.00GiB was 256.00MiB, Chunk State: \n",
    "2022-04-05 14:24:44.299127: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 256.00MiB | Requested Size: 128.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 576.0KiB | Requested Size: 576.0KiB | in_use: 1 | bin_num: -1, next:   Size: 128.00MiB | Requested Size: 128.00MiB | in_use: 1 | bin_num: -1\n",
    "2022-04-05 14:24:44.299134: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 384.00MiB | Requested Size: 384.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 128.00MiB | Requested Size: 128.00MiB | in_use: 1 | bin_num: -1, next:   Size: 384.00MiB | Requested Size: 384.00MiB | in_use: 1 | bin_num: -1\n",
    "2022-04-05 14:24:44.299138: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 8.00GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 384.00MiB | Requested Size: 384.00MiB | in_use: 1 | bin_num: -1\n",
    "2022-04-05 14:24:44.299140: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 9799794688\n",
    "2022-04-05 14:24:44.299948: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f3dce000000 of size 1280 next 1\n",
    "...\n",
    "2022-04-05 14:24:44.300123: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f3de624b500 of size 402653184 next 61\n",
    "2022-04-05 14:24:44.300125: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f3dfe24b500 of size 402653184 next 65\n",
    "2022-04-05 14:24:44.300128: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f3e1624b500 of size 8589429504 next 18446744073709551615\n",
    "2022-04-05 14:24:44.300131: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
    "2022-04-05 14:24:44.300136: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 48 Chunks of size 256 totalling 12.0KiB\n",
    "2022-04-05 14:24:44.300139: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 512 totalling 1.5KiB\n",
    "2022-04-05 14:24:44.300142: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
    "2022-04-05 14:24:44.300145: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2048 totalling 2.0KiB\n",
    "2022-04-05 14:24:44.300148: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 13824 totalling 13.5KiB\n",
    "2022-04-05 14:24:44.300152: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 147456 totalling 144.0KiB\n",
    "2022-04-05 14:24:44.300155: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 294912 totalling 288.0KiB\n",
    "2022-04-05 14:24:44.300158: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 589824 totalling 1.12MiB\n",
    "2022-04-05 14:24:44.300161: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 134217728 totalling 128.00MiB\n",
    "2022-04-05 14:24:44.300164: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 402653184 totalling 384.00MiB\n",
    "2022-04-05 14:24:44.300167: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 513.58MiB\n",
    "2022-04-05 14:24:44.300170: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 9799794688 memory_limit_: 9799794688 available bytes: 0 curr_region_allocation_bytes_: 19599589376\n",
    "2022-04-05 14:24:44.300871: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
    "Limit:                      9799794688\n",
    "InUse:                       538523904\n",
    "MaxInUse:                    941177856\n",
    "NumAllocs:                          97\n",
    "MaxAllocSize:                402653184\n",
    "Reserved:                            0\n",
    "PeakReserved:                        0\n",
    "LargestFreeBlock:                    0\n",
    "\n",
    "2022-04-05 14:24:44.301069: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *_***___*****_______________________________________________________________________________________\n",
    "2022-04-05 14:24:44.308969: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:684 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,128,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "[I 14:24:47.950 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports\n",
    "WARNING:root:kernel 6323ff09-60fd-4cea-b718-ccb4eb748d5f restarted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/5\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ResourceExhaustedError                    Traceback (most recent call last)\n",
    "<ipython-input-7-6cc733c7d1e1> in <module>\n",
    "      4 EPOCHS=5\n",
    "      5 start = time.time()\n",
    "----> 6 hist = cnn.fit(train_dataset,validation_data=valid_dataset,epochs=EPOCHS)\n",
    "      7 end = time.time()\n",
    "      8 print(\"Elapsed time:\",end-start)\n",
    "\n",
    "~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\n",
    "     65     except Exception as e:  # pylint: disable=broad-except\n",
    "     66       filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "---> 67       raise e.with_traceback(filtered_tb) from None\n",
    "     68     finally:\n",
    "     69       del filtered_tb\n",
    "\n",
    "~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n",
    "     56   try:\n",
    "     57     ctx.ensure_initialized()\n",
    "---> 58     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
    "     59                                         inputs, attrs, num_outputs)\n",
    "     60   except core._NotOkStatusException as e:\n",
    "\n",
    "ResourceExhaustedError:  OOM when allocating tensor with shape[32,128,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "\t [[node sequential/conv2d/Conv2D\n",
    " (defined at /home/jrm/.local/lib/python3.8/site-packages/keras/layers/convolutional.py:231)\n",
    "]]\n",
    "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
    " [Op:__inference_train_function_1010]\n",
    "\n",
    "Errors may have originated from an input operation.\n",
    "Input Source operations connected to node sequential/conv2d/Conv2D:\n",
    "In[0] IteratorGetNext (defined at /home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py:866)\t\n",
    "In[1] sequential/conv2d/Conv2D/ReadVariableOp:\n",
    "\n",
    "Operation defined at: (most recent call last)\n",
    ">>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
    ">>>     return _run_code(code, main_globals, None,\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
    ">>>     exec(code, run_globals)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
    ">>>     app.launch_new_instance()\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
    ">>>     app.start()\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 583, in start\n",
    ">>>     self.io_loop.start()\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
    ">>>     self.asyncio_loop.run_forever()\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
    ">>>     self._run_once()\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
    ">>>     handle._run()\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
    ">>>     self._context.run(self._callback, *self._args)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
    ">>>     lambda f: self._run_callback(functools.partial(callback, future))\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
    ">>>     ret = callback()\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
    ">>>     self.ctx_run(self.run)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
    ">>>     yielded = self.gen.send(value)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
    ">>>     yield self.process_one()\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 250, in wrapper\n",
    ">>>     runner = Runner(ctx_run, result, future, yielded)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 741, in __init__\n",
    ">>>     self.ctx_run(self.run)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
    ">>>     yielded = self.gen.send(value)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
    ">>>     yield gen.maybe_future(dispatch(*args))\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
    ">>>     yielded = ctx_run(next, result)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
    ">>>     yield gen.maybe_future(handler(stream, idents, msg))\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
    ">>>     yielded = ctx_run(next, result)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
    ">>>     self.do_execute(\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
    ">>>     yielded = ctx_run(next, result)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
    ">>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
    ">>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2857, in run_cell\n",
    ">>>     result = self._run_cell(\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
    ">>>     return runner(coro)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
    ">>>     coro.send(None)\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3062, in run_cell_async\n",
    ">>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
    ">>>     if (await self.run_code(code, result,  async_=asy)):\n",
    ">>> \n",
    ">>>   File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
    ">>>     exec(code_obj, self.user_global_ns, self.user_ns)\n",
    ">>> \n",
    ">>>   File \"<ipython-input-7-6cc733c7d1e1>\", line 6, in <module>\n",
    ">>>     hist = cnn.fit(train_dataset,validation_data=valid_dataset,epochs=EPOCHS)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
    ">>>     return fn(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n",
    ">>>     tmp_logs = self.train_function(iterator)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n",
    ">>>     return step_function(self, iterator)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n",
    ">>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n",
    ">>>     outputs = model.train_step(data)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n",
    ">>>     y_pred = self(x, training=True)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
    ">>>     return fn(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n",
    ">>>     outputs = call_fn(inputs, *args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
    ">>>     return fn(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n",
    ">>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n",
    ">>>     return self._run_internal_graph(\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
    ">>>     outputs = node.layer(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
    ">>>     return fn(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n",
    ">>>     outputs = call_fn(inputs, *args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
    ">>>     return fn(*args, **kwargs)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 246, in call\n",
    ">>>     outputs = self.convolution_op(inputs, self.kernel)\n",
    ">>> \n",
    ">>>   File \"/home/jrm/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 231, in convolution_op\n",
    ">>>     return tf.nn.convolution(\n",
    ">>> \n",
    "\n",
    "pd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dies at PATCH SIZE 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works great at PATCH SIZE 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ smi\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0  On |                  N/A |\n",
    "| 18%   41C    P5    17W / 250W |  10512MiB / 11264MiB |      5%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      1018      G   /usr/lib/xorg/Xorg                 35MiB |\n",
    "|    0   N/A  N/A      1584      G   /usr/lib/xorg/Xorg                 72MiB |\n",
    "|    0   N/A  N/A      1709      G   /usr/bin/gnome-shell               25MiB |\n",
    "|    0   N/A  N/A      2209      G   /usr/lib/firefox/firefox          147MiB |\n",
    "|    0   N/A  N/A      2668      G   /usr/lib/firefox/firefox            2MiB |\n",
    "|    0   N/A  N/A      6570      G   /usr/lib/firefox/firefox            2MiB |\n",
    "|    0   N/A  N/A      6971      C   /usr/bin/python3                10209MiB |\n",
    "+-----------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works great at PATCH SIZE 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ smi\n",
    "Tue Apr  5 14:55:21 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0  On |                  N/A |\n",
    "| 50%   78C    P2   228W / 250W |  10513MiB / 11264MiB |     89%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      1018      G   /usr/lib/xorg/Xorg                 35MiB |\n",
    "|    0   N/A  N/A      1584      G   /usr/lib/xorg/Xorg                 72MiB |\n",
    "|    0   N/A  N/A      1709      G   /usr/bin/gnome-shell               25MiB |\n",
    "|    0   N/A  N/A      2209      G   /usr/lib/firefox/firefox          145MiB |\n",
    "|    0   N/A  N/A      2668      G   /usr/lib/firefox/firefox            2MiB |\n",
    "|    0   N/A  N/A      7785      C   /usr/bin/python3                10215MiB |\n",
    "+-----------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
