{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBC Filter then Random Forest\n",
    "Opposite of notebook 03 which only used columns whose name includes Nucleus. This only uses columns whose names do not include Nucleus. The goal is to discover other important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 8\n",
    "N_ESTIMATORS = 1000\n",
    "CHOOSE_EVERY = 10   # ultimately controlled by the save_mem parameter\n",
    "SAVE_MEM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-02 13:21:23.604834\n",
      "Python 3.8.10\n",
      "sklearn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "# The model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch data.\n",
    "# This is the patch-level csv file: one row per patch, with nucleus totals from CellProfiler.\n",
    "FILENAME='Process100_Image.csv'\n",
    "# This directory contains one Image.csv file per patient.\n",
    "# These csv files were slimmed to remove give-away columns.\n",
    "# These csv files do contain high-RBC patches; consider filtering them.\n",
    "BASE_PATH='/home/jrm/Adjeroh/Glioma/August_Run/CellProfilerPerPatient/'  # alien\n",
    "\n",
    "# Patient data.\n",
    "# Each patch filename indicates patient/case [0:19] and WSI [0:23].\n",
    "# For example: TCGA-06-0129-01Z-00-DX1_5400_5100.png\n",
    "LEN_PATIENT_ID = 19\n",
    "FOLDS_META_FILE = '/home/jrm/Adjeroh/Glioma/August_Run/TrainValidSplits/aug_train_valid_splits.csv'\n",
    "NUM_FOLDS = 5\n",
    "RBC_CUTOFF = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Case</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0004-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0010-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-14-0789-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0025-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>TCGA-02-0033-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-S9-A7J2-01Z-00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-02-0430-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-28-1746-01Z-00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-HT-7676-01Z-00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>4</td>\n",
       "      <td>Valid</td>\n",
       "      <td>TCGA-CS-5397-01Z-00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Split                 Case  Class\n",
       "0       0  Train  TCGA-02-0004-01Z-00      0\n",
       "1       0  Train  TCGA-02-0010-01Z-00      0\n",
       "2       0  Train  TCGA-14-0789-01Z-00      0\n",
       "3       0  Train  TCGA-02-0025-01Z-00      0\n",
       "4       0  Train  TCGA-02-0033-01Z-00      0\n",
       "..    ...    ...                  ...    ...\n",
       "630     4  Valid  TCGA-S9-A7J2-01Z-00      5\n",
       "631     4  Valid  TCGA-02-0430-01Z-00      0\n",
       "632     4  Valid  TCGA-28-1746-01Z-00      0\n",
       "633     4  Valid  TCGA-HT-7676-01Z-00      1\n",
       "634     4  Valid  TCGA-CS-5397-01Z-00      3\n",
       "\n",
       "[635 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA = pd.read_csv(FOLDS_META_FILE)\n",
    "METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_one_fold(fold,is_train):\n",
    "    df = METADATA.loc[METADATA['Fold']==fold]\n",
    "    if is_train:\n",
    "        df = df.loc[df['Split']=='Train']\n",
    "    else:\n",
    "        df = df.loc[df['Split']=='Valid']\n",
    "    patients = df['Case'].tolist()\n",
    "    labels = df['Class'].tolist()\n",
    "    return patients,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a patient name, load the Image.csv file.\n",
    "# Expect a string that matches a directory name, like 'TCGA-S9-A6UB-01Z-00'\n",
    "# Returns a numpy array.\n",
    "def load_one_patient_data(filepath):\n",
    "    # Reading csv file, skip row 1 = column headers\n",
    "    ary = np.loadtxt(filepath,skiprows=1,delimiter=',')\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_patients_data(patients,labels,save_mem=False):\n",
    "    X = None  # dataframe with 5000 feature columns, one row per patch\n",
    "    y = None  # list of labels = cancer class for each row\n",
    "    z = None  # list of patient name for each row\n",
    "    count=0\n",
    "    for patient in patients:\n",
    "        label = labels[count]\n",
    "        count += 1\n",
    "        directory = patient+'/'\n",
    "        filepath=BASE_PATH+directory+FILENAME\n",
    "        Xall = load_one_patient_data(filepath)\n",
    "        if (save_mem):\n",
    "            Xi = Xall[0::CHOOSE_EVERY].copy()  # e.g. choose every tenth patch\n",
    "        else:\n",
    "            Xi = Xall\n",
    "        yi = np.full(shape=len(Xi), fill_value=label, dtype=np.int8)\n",
    "        zi = [patient]*len(Xi)  # same ID for all patches from one patient\n",
    "        if X is None:\n",
    "            X = Xi\n",
    "            y = yi\n",
    "            z = zi\n",
    "        else:\n",
    "            X = np.concatenate( (X, Xi) )\n",
    "            y = np.concatenate( (y, yi) )\n",
    "            z = np.concatenate( (z, zi) )\n",
    "    # X combines all patches of all WSI for all patients requested.\n",
    "    # For debugging, we'll add column headers to the dataframe.\n",
    "    X = pd.DataFrame(X)\n",
    "    directory = patients[0] + '/'   # first patient is as good as any\n",
    "    filepath=BASE_PATH+directory+FILENAME\n",
    "    with open(filepath) as infile:\n",
    "        rows = csv.reader(infile)\n",
    "        for row in rows:\n",
    "            header = row    # first row has column headers\n",
    "            break\n",
    "    X.columns = header\n",
    "    if 'ImageNumber' in X.columns:\n",
    "        X = X.drop(columns=['ImageNumber'])\n",
    "    return X,y,z   # patch data, patch labels, patch patient names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow, probably due to concatenating dataframes.\n",
    "# Consider a rewrite that concatenates csv before constructing a dataframe.\n",
    "def load_train_valid_set(fold):\n",
    "    patients,labels = get_metadata_one_fold(fold,True) # True=train\n",
    "    X_train,y_train,z_train = load_all_patients_data(patients,labels,SAVE_MEM) \n",
    "    patients,labels = get_metadata_one_fold(fold,False) # False=valid\n",
    "    X_valid,y_valid,z_valid = load_all_patients_data(patients,labels,False) # should always be False\n",
    "    return X_train,y_train,z_train,X_valid,y_valid,z_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each patch votes on the class for its WSI.\n",
    "# Later, weight each patch label by the confidence i.e. score\n",
    "def aggregate_accuracy(y_pred,y_valid,z_valid):\n",
    "    L = len(y_pred)\n",
    "    if L != len(y_valid) or L != len(z_valid):\n",
    "        raise Exception('Lengths do not match')\n",
    "    correct = {}\n",
    "    incorrect = {}\n",
    "    patients = np.unique(z_valid)\n",
    "    for patient in patients:\n",
    "        correct[patient]=0  # accumulate correct votes on patches\n",
    "        incorrect[patient]=0  # accumulate incorrect votes\n",
    "    for i in range(L):\n",
    "        patient = z_valid[i]\n",
    "        label =   y_valid[i]\n",
    "        pred =    y_pred[i]\n",
    "        if pred == label:\n",
    "            correct[patient] += 1\n",
    "        else:\n",
    "            incorrect[patient] += 1\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for patient in patients:\n",
    "        denominator += 1\n",
    "        if correct[patient]>incorrect[patient]:\n",
    "            numerator += 1\n",
    "    accuracy = float(0)\n",
    "    if denominator>0:\n",
    "        accuracy = 100.0*numerator/denominator \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop: Load, Classify, Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(model):\n",
    "        # Prereqs: fit().\n",
    "        names = model.feature_names_in_\n",
    "        importances = model.feature_importances_\n",
    "        pairs = np.column_stack( (names,importances) )\n",
    "        top_array = sorted(pairs, key = lambda e:e[1], reverse=True)\n",
    "        # There must be a way to do this witout a loop!\n",
    "        top_list = []\n",
    "        for i in top_array:\n",
    "             top_list.append((i[1],i[0]))  # 0=feature_name, 1=importance\n",
    "        top_df = pd.DataFrame(top_list)\n",
    "        return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbc_filter(X,y,z):\n",
    "    if RBC_CUTOFF is not None:\n",
    "        bad_rows = X[X.AreaOccupied_AreaOccupied_MergeRBC>=RBC_CUTOFF].index    \n",
    "        X = X.drop(bad_rows)  # pandas dataframe\n",
    "        y = np.delete(y,bad_rows)  # numpy array\n",
    "        z = np.delete(z,bad_rows)\n",
    "    return X,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-02 13:21:24.499416 Fold 0 Loading...\n",
      "Train shapes X,y,z: (7592, 5301) 7592 7592\n",
      "Valid shapes X,y,z: (15500, 5301) 15500 15500\n",
      "2022-08-02 13:22:41.707001 Fold 0 RBC Filter...\n",
      "Train shapes X,y,z: (6893, 5301) 6893 6893\n",
      "Valid shapes X,y,z: (14084, 5301) 14084 14084\n",
      "2022-08-02 13:22:42.052061 Fold 0 Reduce columns...\n",
      "Train shapes X,y,z: (6893, 3350) 6893 6893\n",
      "Valid shapes X,y,z: (14084, 3350) 14084 14084\n",
      "2022-08-02 13:22:42.218327 Fold 0 Train...\n",
      "2022-08-02 13:24:39.469088 Fold 0 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.025485                          Granularity_2_Hematoxylin\n",
      "1   0.013244  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.012485  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "3   0.012142  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.011515  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.007446           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.006150           Texture_Correlation_Hematoxylin_7_01_256\n",
      "7   0.005014  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.004804  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "9   0.004616  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "10  0.004379  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2022-08-02 13:24:39.564334 Fold 0 Evaluate...\n",
      "Fold 0 Patch-level Training Accuracy: 79.58798781372407\n",
      "2022-08-02 13:24:40.586768 Fold 0 Validate...\n",
      "Fold 0 Patch-level Validation Accuracy: 54.032945186026694\n",
      "Fold 0 Patient-level Validation Accuracy: 38.46153846153846\n",
      "\n",
      "2022-08-02 13:24:42.693906 Fold 1 Loading...\n",
      "Train shapes X,y,z: (6490, 5301) 6490 6490\n",
      "Valid shapes X,y,z: (26463, 5301) 26463 26463\n",
      "2022-08-02 13:25:55.642690 Fold 1 RBC Filter...\n",
      "Train shapes X,y,z: (5846, 5301) 5846 5846\n",
      "Valid shapes X,y,z: (24621, 5301) 24621 24621\n",
      "2022-08-02 13:25:56.108461 Fold 1 Reduce columns...\n",
      "Train shapes X,y,z: (5846, 3350) 5846 5846\n",
      "Valid shapes X,y,z: (24621, 3350) 24621 24621\n",
      "2022-08-02 13:25:56.340585 Fold 1 Train...\n",
      "2022-08-02 13:27:31.309379 Fold 1 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.026459                          Granularity_2_Hematoxylin\n",
      "1   0.012375  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2   0.012170  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.011107  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.010624  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.006658           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.006247           Texture_Correlation_Hematoxylin_7_01_256\n",
      "7   0.006040    Median_ExpandCells_Intensity_MaxIntensity_Eosin\n",
      "8   0.005613  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "9   0.005587                          Granularity_1_Hematoxylin\n",
      "10  0.005443      Mean_ExpandCells_Intensity_MaxIntensity_Eosin\n",
      "2022-08-02 13:27:31.393384 Fold 1 Evaluate...\n",
      "Fold 1 Patch-level Training Accuracy: 83.04823811152924\n",
      "2022-08-02 13:27:32.249536 Fold 1 Validate...\n",
      "Fold 1 Patch-level Validation Accuracy: 58.685674830429306\n",
      "Fold 1 Patient-level Validation Accuracy: 34.61538461538461\n",
      "\n",
      "2022-08-02 13:27:35.957501 Fold 2 Loading...\n",
      "Train shapes X,y,z: (7212, 5301) 7212 7212\n",
      "Valid shapes X,y,z: (19305, 5301) 19305 19305\n",
      "2022-08-02 13:28:47.522516 Fold 2 RBC Filter...\n",
      "Train shapes X,y,z: (6646, 5301) 6646 6646\n",
      "Valid shapes X,y,z: (16533, 5301) 16533 16533\n",
      "2022-08-02 13:28:47.914426 Fold 2 Reduce columns...\n",
      "Train shapes X,y,z: (6646, 3350) 6646 6646\n",
      "Valid shapes X,y,z: (16533, 3350) 16533 16533\n",
      "2022-08-02 13:28:48.101432 Fold 2 Train...\n",
      "2022-08-02 13:30:35.630527 Fold 2 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.024004                          Granularity_2_Hematoxylin\n",
      "1   0.016921  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2   0.015703  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.015065  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.011944  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.008229           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.006918  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "7   0.006891           Texture_Correlation_Hematoxylin_7_01_256\n",
      "8   0.006100  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "9   0.005566  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "10  0.005478  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2022-08-02 13:30:35.690852 Fold 2 Evaluate...\n",
      "Fold 2 Patch-level Training Accuracy: 81.40234727655732\n",
      "2022-08-02 13:30:36.593365 Fold 2 Validate...\n",
      "Fold 2 Patch-level Validation Accuracy: 52.579689106635215\n",
      "Fold 2 Patient-level Validation Accuracy: 32.0\n",
      "\n",
      "2022-08-02 13:30:39.020311 Fold 3 Loading...\n",
      "Train shapes X,y,z: (7493, 5301) 7493 7493\n",
      "Valid shapes X,y,z: (16471, 5301) 16471 16471\n",
      "2022-08-02 13:31:46.834533 Fold 3 RBC Filter...\n",
      "Train shapes X,y,z: (6801, 5301) 6801 6801\n",
      "Valid shapes X,y,z: (14947, 5301) 14947 14947\n",
      "2022-08-02 13:31:47.115499 Fold 3 Reduce columns...\n",
      "Train shapes X,y,z: (6801, 3350) 6801 6801\n",
      "Valid shapes X,y,z: (14947, 3350) 14947 14947\n",
      "2022-08-02 13:31:47.263952 Fold 3 Train...\n",
      "2022-08-02 13:33:33.973640 Fold 3 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.025634                          Granularity_2_Hematoxylin\n",
      "1   0.014928  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.013846  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "3   0.013513  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "4   0.009972  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.009196           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.005979           Texture_Correlation_Hematoxylin_7_01_256\n",
      "7   0.005556  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.005278  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "9   0.004552  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "10  0.004544  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "2022-08-02 13:33:34.036988 Fold 3 Evaluate...\n",
      "Fold 3 Patch-level Training Accuracy: 81.23805322746655\n",
      "2022-08-02 13:33:34.970920 Fold 3 Validate...\n",
      "Fold 3 Patch-level Validation Accuracy: 52.80658326085502\n",
      "Fold 3 Patient-level Validation Accuracy: 40.0\n",
      "\n",
      "2022-08-02 13:33:37.074570 Fold 4 Loading...\n",
      "Train shapes X,y,z: (7817, 5301) 7817 7817\n",
      "Valid shapes X,y,z: (13209, 5301) 13209 13209\n",
      "2022-08-02 13:34:44.374162 Fold 4 RBC Filter...\n",
      "Train shapes X,y,z: (7042, 5301) 7042 7042\n",
      "Valid shapes X,y,z: (12427, 5301) 12427 12427\n",
      "2022-08-02 13:34:44.600243 Fold 4 Reduce columns...\n",
      "Train shapes X,y,z: (7042, 3350) 7042 7042\n",
      "Valid shapes X,y,z: (12427, 3350) 12427 12427\n",
      "2022-08-02 13:34:44.737352 Fold 4 Train...\n",
      "2022-08-02 13:36:35.959996 Fold 4 Ranked feature imporances...\n",
      "           0                                                  1\n",
      "0   0.025350                          Granularity_2_Hematoxylin\n",
      "1   0.013998  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "2   0.013229  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "3   0.012686  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "4   0.010823  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "5   0.007708           Texture_Correlation_Hematoxylin_7_03_256\n",
      "6   0.006007           Texture_Correlation_Hematoxylin_7_01_256\n",
      "7   0.005588  Mean_ExpandCells_Texture_Correlation_Hematoxyl...\n",
      "8   0.005099  Median_ExpandCells_Texture_Correlation_Hematox...\n",
      "9   0.004525  StDev_ExpandCells_Intensity_MaxIntensityEdge_E...\n",
      "10  0.004443  StDev_ExpandCells_Texture_SumVariance_Hematoxy...\n",
      "2022-08-02 13:36:36.019126 Fold 4 Evaluate...\n",
      "Fold 4 Patch-level Training Accuracy: 81.08491905708605\n",
      "2022-08-02 13:36:36.977467 Fold 4 Validate...\n",
      "Fold 4 Patch-level Validation Accuracy: 41.28108151605375\n",
      "Fold 4 Patient-level Validation Accuracy: 32.0\n"
     ]
    }
   ],
   "source": [
    "patch_accuracies = []   # summary statistics\n",
    "patient_accuracies = [] # summary statistics\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    print()\n",
    "    print(datetime.now(),'Fold',fold,'Loading...')\n",
    "    X_train,y_train,z_train,X_valid,y_valid,z_valid = load_train_valid_set(fold)\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'RBC Filter...')\n",
    "    X_train,y_train,z_train = rbc_filter(X_train,y_train,z_train)\n",
    "    X_valid,y_valid,z_valid = rbc_filter(X_valid,y_valid,z_valid)\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Reduce columns...')\n",
    "    good_cols = [c for c in X_train.columns if 'Nucleus' not in c]\n",
    "    X_train = X_train[good_cols]\n",
    "    X_valid = X_valid[good_cols]\n",
    "    print('Train shapes X,y,z:',X_train.shape,len(y_train),len(z_train))\n",
    "    print('Valid shapes X,y,z:',X_valid.shape,len(y_valid),len(z_valid))\n",
    "\n",
    "    # The shuffle is not strictly necessary with RF.\n",
    "    # CNN models are sensitive to train set order but RF models are not. \n",
    "    # print(datetime.datetime.now(),'Shuffle...')\n",
    "    # X_train,y_train = sklearn.shuffle(X_train,y_train)\n",
    "\n",
    "    print(datetime.now(),'Fold',fold,'Train...')\n",
    "    # min_samples_leaf=1 (default) led to overfitting\n",
    "    rfc = RandomForestClassifier(max_depth=MAX_DEPTH,n_estimators=N_ESTIMATORS)\n",
    "    rfc.fit(X_train,y_train)  # slow\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Ranked feature imporances...')\n",
    "    top = important_features(rfc)\n",
    "    #pd.set_option('display.max_rows', None)\n",
    "    print(top.loc[:10])\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Evaluate...')\n",
    "    y_pred = rfc.predict(X_train)\n",
    "    matches = np.count_nonzero(y_train==y_pred)\n",
    "    accuracy_t = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Training Accuracy:',accuracy_t)\n",
    "    \n",
    "    print(datetime.now(),'Fold',fold,'Validate...')\n",
    "    y_pred = rfc.predict(X_valid)\n",
    "    matches = np.count_nonzero(y_valid==y_pred)\n",
    "    accuracy_v = 100.0 * matches / len(y_pred)\n",
    "    print('Fold',fold,'Patch-level Validation Accuracy:',accuracy_v)\n",
    "    patch_accuracies.append(accuracy_v)\n",
    "    \n",
    "    accuracy_p = aggregate_accuracy(y_pred,y_valid,z_valid)\n",
    "    patient_accuracies.append(accuracy_p)\n",
    "    print('Fold',fold,'Patient-level Validation Accuracy:',accuracy_p)\n",
    "    \n",
    "    # This shouldn't be necessary but it seems to reduce memory footprint.\n",
    "    X_train=None\n",
    "    X_valid=None\n",
    "    y_train=None\n",
    "    y_valid=None\n",
    "    z_train=None\n",
    "    z_valid=None\n",
    "    rfc = None\n",
    "    y_pred = None\n",
    "    matches = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-02 13:36:38.732056\n",
      "Cross validation patch-level accuracy: [54.032945186026694, 58.685674830429306, 52.579689106635215, 52.80658326085502, 41.28108151605375]\n",
      "mean: 51.87719477999999 std: 5.738249522979222\n",
      "Cross validation patient-level accuracy: [38.46153846153846, 34.61538461538461, 32.0, 40.0, 32.0]\n",
      "mean: 35.41538461538461 std: 3.294463708141335\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Cross validation patch-level accuracy:',patch_accuracies)\n",
    "print('mean:',np.mean(patch_accuracies),'std:',np.std(patch_accuracies))\n",
    "print('Cross validation patient-level accuracy:',patient_accuracies)\n",
    "print('mean:',np.mean(patient_accuracies),'std:',np.std(patient_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
