{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# CNN + MaxPool\n",
    "Investigated possible bug. See PROBLEM. \n",
    "Discovered it was a canonical transcript excluded for exceeding MAX_LEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "da2195c4-f39e-438c-94cd-83dfd95d0b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:33:02.719399\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "2caf37c9-a3b0-47ac-af9a-e3f3c5fa9ea1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:33:02.766963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:33:13.326717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "# tf.random.set_seed(42) # supposedly leads to reproducible results\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/'    # Mac\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRX-UEr8FLA8",
    "outputId": "cb891000-ce6c-44ee-da94-faaf6446046d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "K=4\n",
    "CFILTERS=128 \n",
    "FILTERSIZE=8\n",
    "RCELLS=32\n",
    "DCELLS=16\n",
    "EPOCHS=20 \n",
    "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
    "MINLEN=200\n",
    "MAXLEN=5000   \n",
    "PRETTY_PICTURES = True\n",
    "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
    "BREAK = False   # break after first fold\n",
    "EXCLUSIONS = [1]   # exclude cell line 1 = H1.hESC\n",
    "EXCLUSIONS = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]   # exclude all but 0=A549\n",
    "\n",
    "PROBLEM = 'ENSG00000240137'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "RCI_FILE_TRAIN = 'train.lncRNA_RCI.csv'\n",
    "RCI_FILE_VALID = 'train.lncRNA_RCI.csv'\n",
    "RCI_FILE_TEST  = None # else 'test.lncRNA_RCI.csv'\n",
    "\n",
    "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
    "SEQ_FILE_VALID = 'train.canon_lncRNA_transcripts.csv'\n",
    "SEQ_FILE_TEST  = None # else 'test.canon_lncRNA_transcripts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        self.gene2rci = dict()\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,exclusions):\n",
    "        '''\n",
    "        Load all the genes from the given RCI csv file.\n",
    "        The given file usually contains train or test, not both.\n",
    "        Load average RCI for each across cell lines.\n",
    "        Define average as log of mean of antilogs: log2(mean(2^RCI)).\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        self.gene2rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row # skip file's header line\n",
    "                else:\n",
    "                    line = row.strip()\n",
    "                    fields = line.split(',')\n",
    "                    gene_id = fields.pop(0)\n",
    "                    cell_line_index = 0\n",
    "                    rci_values = []\n",
    "                    for rci_str in fields:\n",
    "                        if cell_line_index not in exclusions:\n",
    "                            if rci_str != \"nan\":\n",
    "                                rci_val = float(rci_str)\n",
    "                                rci_values.append(rci_val)\n",
    "                        cell_line_index += 1\n",
    "                    if len(rci_values)>1:\n",
    "                        values = np.array(rci_values)\n",
    "                        antilogs = np.power(values,2)\n",
    "                        big_mean = np.mean(antilogs)\n",
    "                        if np.absolute(big_mean)<0.000001:\n",
    "                            log_mean = 0.0\n",
    "                        else:\n",
    "                            log_mean = np.log2(big_mean) \n",
    "                        self.gene2rci[gene_id] = log_mean\n",
    "                    elif len(rci_values)==1:  # TO DO: is this different from above?\n",
    "                        self.gene2rci[gene_id] = rci_values[0]\n",
    "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
    "        return self.gene2rci\n",
    "\n",
    "    def _seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        '''\n",
    "        Load all the sequences from the given file. \n",
    "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
    "        Each line has IDs plus sequence.\n",
    "        The IDs in the file do not include dot-version numbers.\n",
    "        The file may already be filtered e.g. canonical transcripts.\n",
    "        '''\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        NREPEAT = str('N'*MAXLEN)\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # without version number\n",
    "                    gene_id = fields[1]  # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    if gene_id==PROBLEM:\n",
    "                        print(gene_id,tran_id,seq_len)\n",
    "                    if seq_len>=MINLEN and seq_len<=MAXLEN \\\n",
    "                    and gene_id in self.gene2rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        if seq_len<MAXLEN:\n",
    "                            seq_txt = seq_txt + NREPEAT\n",
    "                            seq_txt = seq_txt[:MAXLEN]\n",
    "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "                        if gene_id==PROBLEM:\n",
    "                            print(gene_id,tran_id,hot_vec)\n",
    "                    else:\n",
    "                        if gene_id==PROBLEM:\n",
    "                            print(gene_id,tran_id,seq_len,'not included')\n",
    "        self.cache=dict() # save RAM\n",
    "        return allids,allseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ALPHABET=4**K+1  # NUMBER OF DISTINCT KMERS POSSIBLE, add one if N gets mask value\n",
    "    ADJUST_LENGTH = MAXLEN-K+1  # fixed length sequences\n",
    "    cnn = Sequential()\n",
    "    embed_layer = Embedding(ALPHABET,EMBED_DIMEN,input_length=ADJUST_LENGTH,mask_zero=True)   \n",
    "    cnn1_layer = Conv1D(CFILTERS, FILTERSIZE)\n",
    "    cnn2_layer = Conv1D(CFILTERS, FILTERSIZE)\n",
    "    pool1_layer = MaxPooling1D(pool_size=FILTERSIZE, strides=FILTERSIZE//2)\n",
    "    cnn3_layer = Conv1D(CFILTERS//2, FILTERSIZE)\n",
    "    cnn4_layer = Conv1D(CFILTERS//2, FILTERSIZE)\n",
    "    pool2_layer = MaxPooling1D(pool_size=FILTERSIZE, strides=FILTERSIZE//2)\n",
    "    flat_layer = Flatten()\n",
    "    #dens_layer = Dense(DCELLS,activation='relu')\n",
    "    #drop_layer = Dropout(0.5)\n",
    "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
    "\n",
    "    cnn.add(embed_layer)\n",
    "    cnn.add(cnn1_layer)\n",
    "    cnn.add(cnn2_layer)\n",
    "    cnn.add(pool1_layer)\n",
    "    cnn.add(cnn3_layer)\n",
    "    cnn.add(cnn4_layer)\n",
    "    cnn.add(pool2_layer)\n",
    "    cnn.add(flat_layer)\n",
    "    #cnn.add(dens_layer)\n",
    "    #cnn.add(drop_layer)\n",
    "    cnn.add(output_layer)\n",
    "\n",
    "    # Logits=False because sigmoid output is a probability in range [0.,1.]; see\n",
    "    # https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    cnn.compile(loss=bc, optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "bf4fce23-c246-4a8e-aea3-9cbb5a314cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:33:18.143573\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4997, 4)           1028      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4990, 128)         4224      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4983, 128)         131200    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1244, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1237, 64)          65600     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1230, 64)          32832     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 306, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 19584)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 19585     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,469\n",
      "Trainable params: 254,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model.summary())  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,quick_test=False,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.quick_test = quick_test\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = None\n",
    "        self.flip = False\n",
    "        self.reset_statistics()\n",
    "        \n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "        self.cv_mcc=[]\n",
    "        \n",
    "    def _get_X_y(self, all_ids, all_seqs, rci_map, exclude_middle=False): \n",
    "        # Prepare X and y for training or testing.\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        for t in range(len(all_ids)):\n",
    "            gene_id,tran_id = all_ids[t]\n",
    "            oneX            = all_seqs[t]\n",
    "            oneY            = rci_map[gene_id]\n",
    "            if exclude_middle and oneY >= -2 and oneY <= 0:\n",
    "                # Exclude middle from train set only, for comparison to Yuan et al\n",
    "                continue\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        # Takes list of float, returns list of labels [0,1].\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:  # 'THE_MEAN' or 'ZERO'\n",
    "            rci_threshold = self.discriminator\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values, create=True):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            if create:  # during training, create a new GMM\n",
    "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
    "                gmm.fit(rci_values)\n",
    "            else:   # during testing, use existing GMM\n",
    "                gmm=self.discriminator\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm   # redundant but consistent\n",
    "        elif self.mechanism == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        elif self.mechanism == 'ZERO':\n",
    "            self.discriminator = -1   # 0 usually, -1 is as in Yuan et al.\n",
    "        else: # not expected\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "    \n",
    "    def _show_sizes(self,label,values):\n",
    "        a = np.count_nonzero(values==1)\n",
    "        b = np.count_nonzero(values==0)\n",
    "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
    "        \n",
    "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
    "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
    "        print(datetime.now())\n",
    "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
    "        self._prepare_threshold(y_rci,True)  \n",
    "        self._explain_threshold()\n",
    "        y_train = self._apply_threshold(y_rci)\n",
    "        cw = class_weight.compute_class_weight(\n",
    "            'balanced', classes=[0,1], y=y_train)\n",
    "        cwd = {0: cw[0], 1: cw[1]}\n",
    "        self._show_sizes('Train',y_train)\n",
    "        print('Computed class weights:',cwd)\n",
    "        if valid_ids is not None:\n",
    "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
    "            y_valid = self._apply_threshold(y_rci)\n",
    "        y_rci = None\n",
    "\n",
    "        self.model=build_model()\n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        history=[]\n",
    "        if False:  # QUICK TEST WITHOUT FIT\n",
    "            if valid_ids is None:\n",
    "                history=self.model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=self.epochs, verbose=0)  # verbose=1 for ascii art, verbose=0 for none \n",
    "                # validation_data=(X_valid,y_valid) ) \n",
    "                # class_weight=cwd) \n",
    "            else:\n",
    "                history=self.model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=self.epochs, verbose=0,  # verbose=1 for ascii art, verbose=0 for none \n",
    "                validation_data=(X_valid,y_valid) ) \n",
    "                # class_weight=cwd) \n",
    "\n",
    "        if PRETTY_PICTURES:\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1)\n",
    "            plt.show()\n",
    "        \n",
    "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
    "        # For final test, do no train.\n",
    "        # Assume set_sequences() set the test set.\n",
    "        print(datetime.now())\n",
    "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
    "        y_test = self._apply_threshold(y_rci)\n",
    "        y_rci = None\n",
    "        \n",
    "        print(\"PREDICT\")\n",
    "        print(datetime.now())        \n",
    "        yhat_pred=self.model.predict(X_test, verbose=0)     \n",
    "        yhat_classes=np.where(yhat_pred > self.score_threshold, 1, 0)\n",
    "\n",
    "        self._show_sizes('Test',y_test)\n",
    "        self._show_sizes('Predict',yhat_classes)\n",
    "        print('Test sizes',X_test.shape,y_test.shape)\n",
    "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "        print('Score threshold',self.score_threshold)\n",
    "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "        print('Confusion matrix\\n',cm1)\n",
    "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "        print('Normalized matrix\\n',cm2)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "        if PRETTY_PICTURES:\n",
    "            self._pretty_pictures(y_test,yhat_pred,prc_X,prc_Y)\n",
    "            print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "            print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
    "            print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "\n",
    "    def _pretty_pictures(self,y_valid,yhat_pred,prc_X,prc_Y):\n",
    "        count_ones= len(y_valid[y_valid==1])\n",
    "        count_zeros= len(y_valid[y_valid==0])\n",
    "        guess = max(count_ones,count_zeros) / len(y_valid)\n",
    "        # PRC\n",
    "        plt.plot(prc_X, prc_Y, marker='.')\n",
    "        plt.plot([0, 1], [guess,guess], linestyle='--')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.show()\n",
    "        # ROC\n",
    "        fpr, tpr, roc_bins = roc_curve(y_valid, yhat_pred)\n",
    "        plt.plot(fpr, tpr, marker='.')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "    def get_statistics(self):\n",
    "        return \\\n",
    "        self.cv_accuracy,\\\n",
    "        self.cv_precision,\\\n",
    "        self.cv_recall,\\\n",
    "        self.cv_f1,\\\n",
    "        self.cv_mcc,\\\n",
    "        self.cv_auprc,\\\n",
    "        self.cv_auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td97uyyj5qDq"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "poe3rwAF4Ir7"
   },
   "outputs": [],
   "source": [
    "class Separator():\n",
    "    def __init__(self):\n",
    "        self.train_ids = []\n",
    "        self.train_seq = []\n",
    "        self.train_rci = dict()\n",
    "        self.val_ids = []\n",
    "        self.val_seq = []\n",
    "        self.val_rci = dict()\n",
    "    def load(self,data_dir,rep,fold):\n",
    "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
    "        filename = data_dir + filename\n",
    "        self.val_genes = set()\n",
    "        with open(filename,'r') as fin:\n",
    "            for line in fin:\n",
    "                gene_id = line.strip()\n",
    "                self.val_genes.add(gene_id)\n",
    "    def process(self,allids,allseq,gene_to_rci):\n",
    "        # quick and dirty\n",
    "        # there are 676 genes with A549 RCI > 0\n",
    "        # there are 676 genes with A549 RCI < -0.72\n",
    "        HIGH = 0.0\n",
    "        LOW  = 0.0\n",
    "        size = len(allids)\n",
    "        pos,neg,excl = 0,0,0\n",
    "        rci_pos=[]\n",
    "        for t in range(size):\n",
    "            gene_id,tran_id = allids[t]\n",
    "            oneX            = allseq[t]\n",
    "            oneY            = gene_to_rci[gene_id]\n",
    "            RCI = gene_to_rci[gene_id]\n",
    "            if gene_id == PROBLEM:\n",
    "                print(gene_id,'\\n',oneY,'\\n',oneX)\n",
    "            if RCI >= HIGH:\n",
    "                pos+=1\n",
    "                rci_pos.append(RCI)\n",
    "            elif RCI < LOW:\n",
    "                neg+=1\n",
    "            else:\n",
    "                excl+=1\n",
    "            if RCI >= HIGH or RCI <= LOW:\n",
    "                if gene_id in self.val_genes:\n",
    "                    self.val_ids.append(allids[t])\n",
    "                    self.val_seq.append(allseq[t])\n",
    "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
    "                else:\n",
    "                    self.train_ids.append(allids[t])\n",
    "                    self.train_seq.append(allseq[t])\n",
    "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
    "        print('pos/neg/excl',pos,neg,excl)\n",
    "        s = sorted(rci_pos)\n",
    "        print(s[:10])\n",
    "        print(s[-10:])\n",
    "    def get_ids(self):\n",
    "        return self.train_ids,self.val_ids\n",
    "    def get_seq(self):\n",
    "        return self.train_seq,self.val_seq\n",
    "    def get_rci(self):\n",
    "        return self.train_rci,self.val_rci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "824ca249-8f18-43ea-e39c-3c9f9aae824c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:33:18.462202\n",
      "Load RCI from /Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.csv\n",
      "Number of RCI values loaded 1635\n",
      "Num RCI: 1635\n",
      "Load sequence from /Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
      "ENSG00000240137 ENST00000670089 5421\n",
      "ENSG00000240137 ENST00000670089 5421 not included\n",
      "Loaded 1565 sequences.\n",
      "Do the 80/20 train/valid split...\n",
      "pos/neg/excl 676 889 0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[3.05889, 3.16599, 3.24793, 3.32193, 3.35462, 3.37851, 3.48543, 3.54432, 4.24031, 4.33787]\n",
      "Training samples: 1263\n",
      "Testing samples: 302\n",
      "2023-03-21 10:33:21.264324\n",
      "\n",
      "Training # 1 1\n",
      "2023-03-21 10:33:21.264351\n",
      "2023-03-21 10:33:21.264372\n",
      "Discriminator ZERO -1\n",
      "Train 1:0 805:458 63.74%\n",
      "Computed class weights: {0: 1.3788209606986899, 1: 0.784472049689441}\n",
      "FIT\n",
      "2023-03-21 10:33:21.996859\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m cvdo \u001b[38;5;241m=\u001b[39m CrossValidator(EPOCHS,BREAK)\n\u001b[1;32m     67\u001b[0m cvdo\u001b[38;5;241m.\u001b[39mset_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mcvdo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_new_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_allids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_allseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_gene_to_rci\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_allids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_allseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_gene_to_rci\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mCrossValidator.train_new_model\u001b[0;34m(self, train_ids, train_seq, train_rci, valid_ids, valid_seq, valid_rci)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;66;03m# class_weight=cwd) \u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRETTY_PICTURES:\n\u001b[0;32m--> 128\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m)\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m    129\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "mcc=[]\n",
    "auprc=[]\n",
    "auroc=[]\n",
    "\n",
    "loader = DataLoader()\n",
    "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
    "print(\"Load RCI from\",filepath)\n",
    "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
    "print('Load sequence from',filepath)\n",
    "allids,allseq = loader.load_sequence(filepath)\n",
    "print('Loaded',len(allseq),'sequences.')\n",
    "test_gene_to_rci = None\n",
    "test_allids = None\n",
    "test_allseq = None\n",
    "if SEQ_FILE_TEST is not None:\n",
    "    # Train on the entire train set (no cross-validation).\n",
    "    # Evaluate with the test files.\n",
    "    test_loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE_TEST\n",
    "    print(\"Load RCI from\",filepath)\n",
    "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
    "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
    "    print('Load sequence from',filepath)\n",
    "    test_allids,test_allseq = test_loader.load_sequence(filepath)\n",
    "    print('Loaded',len(test_allseq),'sequences.')\n",
    "\n",
    "REPEATS = 2\n",
    "FOLDS = 5\n",
    "for repeat in range(REPEATS):\n",
    "    for fold in range(FOLDS):\n",
    "        r = repeat+1\n",
    "        f = fold+1\n",
    "\n",
    "        if SEQ_FILE_TEST is None:\n",
    "            print('Do the 80/20 train/valid split...')\n",
    "            separator = Separator()\n",
    "            separator.load(DATA_DIR,r,f)\n",
    "            separator.process(allids,allseq,gene_to_rci)\n",
    "            train_allids,test_allids = separator.get_ids()\n",
    "            train_allseq,test_allseq = separator.get_seq()\n",
    "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
    "        else:\n",
    "            print('Will train on entire train set, test on entire test set...')\n",
    "            train_allids = allids\n",
    "            train_allseq = allseq\n",
    "            train_gene_to_rci = gene_to_rci\n",
    "            test_allids = None\n",
    "            test_allseq = None\n",
    "            test_gene_to_rci = None\n",
    "\n",
    "        print('Training samples:',len(train_allids))\n",
    "        print('Testing samples:',len(test_allids))\n",
    "        print(datetime.now())\n",
    "        print()\n",
    "        print(\"Training #\",r,f)\n",
    "        print(datetime.now())\n",
    "        cvdo = CrossValidator(EPOCHS,BREAK)\n",
    "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "        cvdo.train_new_model(\n",
    "            train_allids,train_allseq,train_gene_to_rci,\n",
    "            test_allids,test_allseq,test_gene_to_rci)\n",
    "           \n",
    "        print()\n",
    "        print(datetime.now())\n",
    "        print()\n",
    "        print(\"Testing #\",r,f)\n",
    "        print(datetime.now())\n",
    "        cvdo.reset_statistics()\n",
    "        cvdo.test_without_training(\n",
    "            test_allids,test_allseq,test_gene_to_rci)\n",
    "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
    "            cvdo.get_statistics()\n",
    "\n",
    "        print(\" accuracy\" ,  cv_accuracy)\n",
    "        print(\" precision\" , cv_precision)\n",
    "        print(\" recall\" ,    cv_recall)\n",
    "        print(\" F1\" ,        cv_f1)\n",
    "        print(\" MCC\" ,       cv_mcc)\n",
    "        print(\" AUPRC\" ,     cv_auprc)\n",
    "        print(\" AUROC\" ,     cv_auroc)\n",
    "\n",
    "        accuracy.append(cv_accuracy)\n",
    "        precision.append(cv_precision)\n",
    "        recall.append(cv_recall)\n",
    "        f1.append(cv_f1)\n",
    "        mcc.append(cv_mcc)\n",
    "        auprc.append(cv_auprc)\n",
    "        auroc.append(cv_auroc)\n",
    "        if BREAK: break\n",
    "    if BREAK: break\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkCeDg_HdQ36"
   },
   "outputs": [],
   "source": [
    "def STD (values):\n",
    "    return np.std(values,ddof=1)\n",
    "\n",
    "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
    "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
    "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
    "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
    "print(\" MCC mean %.2f%% std %.2f\" %       (np.mean(mcc),       STD(mcc)))\n",
    "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
    "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
    "\n",
    "print(\" accuracy\"  , accuracy)\n",
    "print(\" precision\" , precision)\n",
    "print(\" recall\"    , recall)\n",
    "print(\" F1\"        , f1)\n",
    "print(\" MCC\"       , mcc)\n",
    "print(\" AUPRC\"     , auprc)\n",
    "print(\" AUROC\"     , auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjSVa72v4IsA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
