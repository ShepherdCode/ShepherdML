{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# LSTM\n",
    "The past few notebooks may have run with the bug of using RCI value \n",
    "(a float) as the label without converting it to a zero or one.\n",
    "That would be fine for regression but not classification.\n",
    "We briefly introduced a \"fix\" that led to 100% accuracy on every run.\n",
    "In fact, there was no bug but the conversion to zero or one\n",
    "was buried in obscurity.\n",
    "Here, we introduced the explicit function rci_to_label().\n",
    "A small test ran ok on CoLab and was committed to git.\n",
    "\n",
    "Further code restructure\n",
    "to address problem that data loading is spread across \n",
    "nake code, functions, and data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "f2e0448c-965c-4bf4-ce03-839fd145f9bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:29.190397\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUtGXPrcFLA8"
   },
   "source": [
    "We prevously used sklearn.model_selection.ShuffleSplit   \n",
    "Now we avoid it due to this note in the \n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
    "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRX-UEr8FLA8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:32.573236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "K=4\n",
    "RCI_THRESHOLD=0.0\n",
    "RCELLS=16\n",
    "EPOCHS=5\n",
    "FOLDS=5      \n",
    "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
    "BREAK = True   # break after first fold\n",
    "MINLEN=1000\n",
    "MAXLEN=2000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "f249be71-b2da-4739-9f46-125bf1160480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmiller/WVU/Localization/TrainTest/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'    # Mac\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "GENES_FILE =    'CNRCI_coding_train_genes.csv'\n",
    "RCI_FILE =      'CNRCI_coding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_coding_train_transcripts.gc42.csv'\n",
    "COUNTS_FILE=    'CNRCI_coding_train_counts.K4.gc42.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3p4QzQJFLA_",
    "outputId": "997b8df9-34ea-4d69-f398-63606ea6fa61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 1 = H1.hESC\n"
     ]
    }
   ],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549',\\\n",
    "      'H1.hESC',\\\n",
    "      'HeLa.S3',\\\n",
    "      'HepG2',\\\n",
    "      'HT1080',\\\n",
    "      'HUVEC',\\\n",
    "      'MCF.7',\\\n",
    "      'NCI.H460',\\\n",
    "      'NHEK',\\\n",
    "      'SK.MEL.5',\\\n",
    "      'SK.N.DZ',\\\n",
    "      'SK.N.SH',\\\n",
    "      'GM12878',\\\n",
    "      'K562',\\\n",
    "      'IMR.90']\n",
    "    return ordered_list\n",
    "CELL_LINE_NUMBER=1\n",
    "all_cell_lines = get_ordered_list()\n",
    "cell_line_name = all_cell_lines[CELL_LINE_NUMBER]\n",
    "print('Cell line for today:',CELL_LINE_NUMBER,'=',cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,cell_line):\n",
    "        '''\n",
    "        Load from RCI csv file.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        gene_to_rci = {}\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row # skip file's header line\n",
    "                else:\n",
    "                    line = row.strip()\n",
    "                    fields = line.split(',')\n",
    "                    gene_id = fields[0]\n",
    "                    rci_val = fields[cell_line+1]\n",
    "                    if rci_val != \"nan\":\n",
    "                        # Convert string nan to float(nan)\n",
    "                        gene_to_rci[gene_id] = float(rci_val)\n",
    "        return gene_to_rci\n",
    "    \n",
    "    def seq_to_kmer_values(self,rna,K):\n",
    "        # The cache may represent more than one K. Probably not a problem.\n",
    "        N_indicator = 0 # indicator value\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYoYDc93FLBB",
    "outputId": "5773d6af-a58d-4788-b474-3b6100bc42d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:41.924521\n",
      "Num RCI: 13000\n",
      "[('ENSG00000000003', 1.85734), ('ENSG00000000005', 5.88264), ('ENSG00000000419', 2.58954)]\n",
      "2022-12-17 12:01:41.959940\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "loader = DataLoader()\n",
    "gene_to_rci = loader.load_gene_rci_values(DATA_DIR+RCI_FILE,CELL_LINE_NUMBER)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "print(list(gene_to_rci.items())[:3])\n",
    "all_genes = list(gene_to_rci.keys())\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNrOKHddFycs",
    "outputId": "e3faeb44-4085-4c79-bf7b-94fe839a8a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[20, 16]\n",
      "[63, 57]\n",
      "[64, 0]\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "print(loader.seq_to_kmer_values('AAAA',3))\n",
    "print(loader.seq_to_kmer_values('CATT',3))\n",
    "print(loader.seq_to_kmer_values('TTGA',3))\n",
    "print(loader.seq_to_kmer_values('TTTN',3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANYkiGD0um16",
    "outputId": "ae89700d-441d-4d28-f1a1-e010ff6ba17e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def rci_to_label(rci):\n",
    "    CYTO_LABEL = 1\n",
    "    NUCLEAR_LABEL = 0\n",
    "    # cnrci = log (cyto-to-nuclear ratio)\n",
    "    # rci > 0 implies cytoplasmic\n",
    "    if rci > RCI_THRESHOLD:\n",
    "        return CYTO_LABEL\n",
    "    return NUCLEAR_LABEL\n",
    "print(rci_to_label(-0.9))\n",
    "print(rci_to_label(1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooyTeQr-FLBB",
    "outputId": "62b58e47-97d1-4021-b70e-0e77c5805702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:42.030231\n",
      "Load sequence\n",
      "2022-12-17 12:01:53.943810\n",
      "Num IDs: 13143\n",
      "Count 6959 ones out of 13143 labels.\n",
      "Num counts: 13143\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Load sequence')\n",
    "filepath = DATA_DIR+SEQUENCE_FILE\n",
    "labels=[]\n",
    "allids=[]\n",
    "allseq=[]\n",
    "NREPEAT = str('N'*MAXLEN)\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line    = row.strip()\n",
    "            fields  = line.split(',')\n",
    "            tran_id = fields[0]  # with version number\n",
    "            gene_id = fields[1]        # without version number\n",
    "            seq_len = int(fields[3])\n",
    "            seq_txt = fields[4]\n",
    "            if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                allids.append( (gene_id,tran_id) )\n",
    "                rci_val = gene_to_rci[gene_id]\n",
    "                rci_label = rci_to_label(rci_val)\n",
    "                labels.append(rci_label)\n",
    "                if seq_len<MAXLEN:\n",
    "                    seq_txt = seq_txt + NREPEAT\n",
    "                    seq_txt = seq_txt[:MAXLEN]\n",
    "                # change this to self instead of loader\n",
    "                hot_vec = loader.seq_to_kmer_values(seq_txt,K)\n",
    "                allseq.append(hot_vec)\n",
    "print(datetime.now())\n",
    "\n",
    "print('Num IDs:',len(allids))\n",
    "#print('Examples:',[allids[x] for x in [10, 20, 30, 40]] )\n",
    "print('Count',np.count_nonzero(labels),'ones out of',len(labels),'labels.')\n",
    "#print('Examples:',[labels[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num counts:',len(allseq))\n",
    "#print('Example:',allseq[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "def get_gene_subset(all_genes,sub_index):\n",
    "    sub_genes = set()\n",
    "    for index in sub_index:\n",
    "        one_gene = all_genes[index]\n",
    "        sub_genes.add(one_gene)\n",
    "    return sub_genes\n",
    "def get_X_y(gene_set,allids,allX,allY):\n",
    "    cnt = len(allids)\n",
    "    subsetX=[]\n",
    "    subsetY=[]\n",
    "    if cnt != len(allX) or cnt!= len(allY):\n",
    "        raise Exception('Lengths differ')\n",
    "    for i in range(cnt):\n",
    "        gene_id,tran_id = allids[i]\n",
    "        if gene_id in gene_set:\n",
    "            oneX = allX[i]\n",
    "            oneY = allY[i]\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "    subsetX = np.array(subsetX)\n",
    "    subsetY = np.array(subsetY).reshape((-1,1))\n",
    "    return subsetX,subsetY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ALPHABET=4**K+1  # NUMBER OF DISTINCT KMERS POSSIBLE, add one if N gets mask value\n",
    "    ADJUST_LENGTH = MAXLEN-K+1  # fixed length sequences\n",
    "    rnn = Sequential()\n",
    "    # To do: try with and without masking layer\n",
    "    # To do: try the embedding layer with mask, instead of masking layer\n",
    "    #mask_layer = Masking(mask_value=0, input_shape=(ADJUST_LENGTH, K))\n",
    "    #mask_layer = Masking(mask_value=0, input_shape=(ADJUST_LENGTH, 1))\n",
    "    # This layer automatically converts inputs to one-hot using alphabet size.\n",
    "    embed_layer = Embedding(ALPHABET,EMBED_DIMEN,input_length=ADJUST_LENGTH,mask_zero=True)   \n",
    "    # rnn1_layer = LSTM(16, return_sequences=True, input_shape=[MAXLEN,DIMEN]) \n",
    "    # rnn1_layer = LSTM(RCELLS, return_sequences=False) # True)\n",
    "    rnn1_layer = Bidirectional( LSTM(RCELLS, return_sequences=False) )\n",
    "    # rnn1_layer = LSTM(16, return_sequences=True) \n",
    "    # rnn2_layer = LSTM(16, return_sequences=True)\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    #dense1_layer = Dense(16,activation='sigmoid',dtype=dt)\n",
    "    #dropout1_layer = Dropout(0.25)\n",
    "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
    "\n",
    "    #rnn.add(mask_layer)\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    #rnn.add(rnn2_layer)\n",
    "    #rnn.add(dense1_layer)\n",
    "    #rnn.add(dropout1_layer)\n",
    "    #rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "cd7b9a84-71d6-490e-cc9a-d41fc97abe90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:54.011820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:54.019762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1997, 4)           1028      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32)               2688      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,749\n",
      "Trainable params: 3,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model.summary())  # Print this only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqO0a9evFLBG",
    "outputId": "8722ca94-b51b-4463-9a41-d0af8e89b8a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:56.379961\n"
     ]
    }
   ],
   "source": [
    "def do_cross_validation(eps):\n",
    "    cv_accuracy=[]\n",
    "    cv_precision=[]\n",
    "    cv_recall=[]\n",
    "    cv_f1=[]\n",
    "    fold=0\n",
    "    print(datetime.now())\n",
    "    print('splitting')\n",
    "    # KFold shuffles once before making the partitions\n",
    "    splitter = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n",
    "    for train_index,valid_index in splitter.split(all_genes):\n",
    "        fold += 1\n",
    "        print('Fold',fold)\n",
    "        train_genes = get_gene_subset(all_genes,train_index)\n",
    "        valid_genes = get_gene_subset(all_genes,valid_index)\n",
    "        X_train,y_train = get_X_y(train_genes,allids,allseq,labels)\n",
    "        X_valid,y_valid = get_X_y(valid_genes,allids,allseq,labels)\n",
    "\n",
    "        print('Training example')\n",
    "        print(X_train[0])\n",
    "        \n",
    "        print('Train sizes',X_train.shape,y_train.shape)\n",
    "        print('Valid sizes',X_valid.shape,y_valid.shape)\n",
    "        print('Train set ones/size',\n",
    "              np.count_nonzero(y_train),'/',len(y_train))\n",
    "        print('Valid set ones/size',\n",
    "              np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model()\n",
    "\n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Compute valiation accuracy\")\n",
    "        print(datetime.now())\n",
    "        yhat_pred=model.predict(X_valid, verbose=0) \n",
    "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "        THRESHOLD=0.5\n",
    "        yhat_classes=np.where(yhat_pred > THRESHOLD, 1, 0)\n",
    "        print('Predicted zeros and ones',np.count_nonzero(yhat_classes==0),np.count_nonzero(yhat_classes==1))\n",
    "        # accuracy: (tp + tn) / (p + n)\n",
    "        accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
    "        # precision tp / (tp + fp)\n",
    "        precision = precision_score(y_valid, yhat_classes)*100.\n",
    "        # recall: tp / (tp + fn)\n",
    "        recall = recall_score(y_valid, yhat_classes)*100.\n",
    "        # f1: 2 tp / (2 tp + fp + fn)\n",
    "        f1 = f1_score(y_valid, yhat_classes)*100.\n",
    "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%% F1: %.2f%%' % (accuracy,precision,recall,f1)) \n",
    "        print(datetime.now())\n",
    "        cv_accuracy.append(accuracy)\n",
    "        cv_precision.append(precision)\n",
    "        cv_recall.append(recall)\n",
    "        cv_f1.append(f1)\n",
    "        \n",
    "        if BREAK:\n",
    "            break\n",
    "        \n",
    "    print()\n",
    "    return cv_accuracy, cv_precision, cv_recall, cv_f1\n",
    "\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "94bb2f98-4cf8-4c49-bfb2-52feecb99dfd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:01:56.403077\n",
      "2022-12-17 12:01:56.403708\n",
      "splitting\n",
      "Fold 1\n",
      "Training example\n",
      "[ 60 238 182 ...   0   0   0]\n",
      "Train sizes (10521, 1997) (10521, 1)\n",
      "Valid sizes (2622, 1997) (2622, 1)\n",
      "Train set ones/size 5609 / 10521\n",
      "Valid set ones/size 1350 / 2622\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "2022-12-17 12:02:00.448077\n",
      "Epoch 1/5\n",
      " 29/329 [=>............................] - ETA: 5:59 - loss: 0.6927 - accuracy: 0.5129"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "cv_accuracy, cv_precision, cv_recall, cv_f1 = do_cross_validation(EPOCHS)   \n",
    "print(\"Cross validation %d folds %d epochs\" % (FOLDS,EPOCHS)) \n",
    "print(\" accuracy mean %.2f%% +/- %.2f\" % (np.mean(cv_accuracy), np.std(cv_accuracy)))\n",
    "print(\" precision mean %.2f%% +/- %.2f\" % (np.mean(cv_precision), np.std(cv_precision)))\n",
    "print(\" recall mean %.2f%% +/- %.2f\" % (np.mean(cv_recall), np.std(cv_recall)))\n",
    "print(\" F1 mean %.2f%% +/- %.2f\" % (np.mean(cv_f1), np.std(cv_f1)))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j56xTZdJm2B6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
