{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# CNN + GlobalAvgPool\n",
    "Run this model on all lncRNA cell lines using some theshold. This notebook tests zero.\n",
    "\n",
    "* zero\n",
    "* mean RCI\n",
    "* Antilog threshold set by EM/GMM.\n",
    "\n",
    "Slight disconnect: transcripts are filtered by length, but RCI threshold is computed with the RCI from all genes.\n",
    "\n",
    "Ran on CoLab Pro. RAM 5.6/12.7 GB. GPU 1.9/15.0 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "d9993269-9f14-4380-9e83-c206673ac2f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:31:06.151791\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUtGXPrcFLA8"
   },
   "source": [
    "We prevously used sklearn.model_selection.ShuffleSplit   \n",
    "Now we avoid it due to this note in the \n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
    "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRX-UEr8FLA8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:31:08.301322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "K=4\n",
    "CFILTERS=64\n",
    "FILTERSIZE=16\n",
    "RCELLS=32\n",
    "DCELLS=16\n",
    "EPOCHS=3\n",
    "FOLDS=5      \n",
    "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
    "BREAK = False   # break after first fold\n",
    "MINLEN=200\n",
    "MAXLEN=5000   \n",
    "PRETTY_PICTURES = False\n",
    "RCI_THRESHOLD_MECHANISM = 'Zero'\n",
    "CACHING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "09b99189-f6a4-49db-db61-6cec969bff47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmiller/WVU/Localization/TrainTest/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'    # Mac\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this run will read sequence from cache.\n"
     ]
    }
   ],
   "source": [
    "RCI_FILE =      'CNRCI_noncoding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_noncoding_train_transcripts.gc42.csv'\n",
    "CACHE_SEQUENCE = 'cache.seq.pickle'\n",
    "CACHE_IDS = 'cache.id.pickle'\n",
    "if CACHING:\n",
    "    cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "    cache_ids = DATA_DIR+CACHE_IDS \n",
    "    if isfile(cache_seq) and isfile(cache_ids):\n",
    "        print('WARNING: this run will read sequence from cache.')\n",
    "    else:\n",
    "        print('INFO: this run will write sequence to cache.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()\n",
    "\n",
    "EXCLUSIONS = [1,7]   # use these though they are clearly different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,cell_line):\n",
    "        '''\n",
    "        Load from RCI csv file.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        gene_to_rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row # skip file's header line\n",
    "                else:\n",
    "                    line = row.strip()\n",
    "                    fields = line.split(',')\n",
    "                    gene_id = fields.pop(0)\n",
    "                    rci_str = fields[cell_line]\n",
    "                    if rci_str != \"nan\":\n",
    "                        rci_val = float(rci_str)\n",
    "                        gene_to_rci[gene_id] = rci_val\n",
    "        print('Number of RCI values loaded',len(gene_to_rci.keys()))\n",
    "        return gene_to_rci\n",
    "\n",
    "    def get_threshold(self,cell_line,gene_to_rci):\n",
    "        return 0   # IN THIS EXPERIMENT, ALL POSITIVE RCI IS CYTO\n",
    "    \n",
    "    def seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "        cache_ids = DATA_DIR+CACHE_IDS \n",
    "        if CACHING and isfile(cache_seq) and isfile(cache_ids):\n",
    "            # Warning: the cache may represent the wrong K.\n",
    "            with open(cache_seq,'rb') as fin:\n",
    "                allseq = pickle.load(fin)\n",
    "            with open(cache_ids,'rb') as fin:\n",
    "                allids = pickle.load(fin)\n",
    "            return allids,allseq           \n",
    "        NREPEAT = str('N'*MAXLEN)\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # with version number\n",
    "                    gene_id = fields[1]        # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        if seq_len<MAXLEN:\n",
    "                            seq_txt = seq_txt + NREPEAT\n",
    "                            seq_txt = seq_txt[:MAXLEN]\n",
    "                        hot_vec = self.seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        if CACHING:\n",
    "            with open(cache_seq,'wb') as fout:\n",
    "                pickle.dump(allseq,fout)\n",
    "            with open(cache_ids,'wb') as fout:\n",
    "                pickle.dump(allids,fout)\n",
    "        return allids,allseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ALPHABET=4**K+1  # NUMBER OF DISTINCT KMERS POSSIBLE, add one if N gets mask value\n",
    "    ADJUST_LENGTH = MAXLEN-K+1  # fixed length sequences\n",
    "    cnn = Sequential()\n",
    "    embed_layer = Embedding(ALPHABET,EMBED_DIMEN,input_length=ADJUST_LENGTH,mask_zero=True)   \n",
    "    cnn1_layer = Conv1D(CFILTERS, FILTERSIZE)\n",
    "    pool_layer = MaxPooling1D(pool_size=FILTERSIZE, strides=FILTERSIZE//2)\n",
    "    #pool_layer = GlobalAveragePooling1D()\n",
    "    flat_layer = Flatten()\n",
    "    dens_layer = Dense(DCELLS)\n",
    "    drop_layer = Dropout(0.5)\n",
    "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
    "\n",
    "    cnn.add(embed_layer)\n",
    "    cnn.add(cnn1_layer)\n",
    "    cnn.add(pool_layer)\n",
    "    cnn.add(flat_layer)\n",
    "    cnn.add(dens_layer)\n",
    "    cnn.add(drop_layer)\n",
    "    cnn.add(output_layer)\n",
    "\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    cnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "49511540-dc96-4017-8e79-db6937f31e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:31:13.700719\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4997, 4)           1028      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4982, 64)          4160      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 621, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 39744)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                635920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:31:13.705807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 641,125\n",
      "Trainable params: 641,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model.summary())  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,folds,quick_test=False,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.folds = folds\n",
    "        self.quick_test = quick_test\n",
    "        self.score_threshold = score_threshold\n",
    "        \n",
    "    def set_sequences(self, allids, allseq):\n",
    "        self.all_ids = allids\n",
    "        self.all_seqs = allseq\n",
    "        \n",
    "    def set_rci_map(self, gene_to_rci):\n",
    "        self.rci_map = gene_to_rci\n",
    "    \n",
    "    def get_gene_subset(self, all_genes, sub_index):\n",
    "        sub_genes = set()\n",
    "        for index in sub_index:\n",
    "            one_gene = all_genes[index]\n",
    "            sub_genes.add(one_gene)\n",
    "        return sub_genes\n",
    "    \n",
    "    def get_X_y(self, gene_set):\n",
    "        cnt = len(self.all_ids)\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        for i in range(cnt):\n",
    "            gene_id,tran_id = self.all_ids[i]\n",
    "            if gene_id in gene_set:\n",
    "                oneX = self.all_seqs[i]\n",
    "                oneY = self.rci_map[gene_id]\n",
    "                subsetX.append(oneX)\n",
    "                subsetY.append(oneY)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def rcis_to_labels(self, array_of_rci, rci_threshold):\n",
    "        IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "        return np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "    \n",
    "    def choose_rci_threshold(self, rci_values):\n",
    "        #if RCI_THRESHOLD_MECHANISM == 'Zero':\n",
    "        return 0\n",
    "        \n",
    "    def do_cross_validation(self):\n",
    "        cv_accuracy=[]\n",
    "        cv_precision=[]\n",
    "        cv_recall=[]\n",
    "        cv_f1=[]\n",
    "        cv_auprc=[]\n",
    "        cv_auroc=[]\n",
    "        fold=0\n",
    "        print(datetime.now())\n",
    "        print('splitting')\n",
    "        # KFold shuffles once before making the partitions\n",
    "        splitter = KFold(n_splits=self.folds,shuffle=True,random_state=42)\n",
    "        splits = splitter.split(all_genes)\n",
    "        splitter = None\n",
    "        for train_index,valid_index in splits:\n",
    "            fold += 1\n",
    "            print('Fold',fold)\n",
    "            train_genes = self.get_gene_subset(all_genes,train_index)\n",
    "            X_train,y_train = self.get_X_y(train_genes)\n",
    "            train_based_rci_threshold = self.choose_rci_threshold(y_train)\n",
    "            y_train = self.rcis_to_labels(y_train,train_based_rci_threshold)\n",
    "            valid_genes = self.get_gene_subset(all_genes,valid_index)\n",
    "            X_valid,y_valid = self.get_X_y(valid_genes)\n",
    "            y_valid = self.rcis_to_labels(y_valid,train_based_rci_threshold) # yes, train_based\n",
    "\n",
    "            #print('Training example')\n",
    "            #print(X_train[0])\n",
    "            #print(\"BUILD MODEL\")\n",
    "            model=build_model()\n",
    "            print(\"FIT\")\n",
    "            print(datetime.now())\n",
    "            history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "              epochs=self.epochs, verbose=0,  # verbose=1 for ascii art, verbose=0 for none\n",
    "              validation_data=(X_valid,y_valid) )\n",
    "            print(\"PREDICT\")\n",
    "            print(datetime.now())\n",
    "            yhat_pred=model.predict(X_valid, verbose=0)             \n",
    "            yhat_classes=np.where(yhat_pred > self.score_threshold, 1, 0)\n",
    "\n",
    "            # accuracy: (tp + tn) / (p + n)\n",
    "            accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
    "            # precision tp / (tp + fp)\n",
    "            precision = precision_score(y_valid, yhat_classes)*100.\n",
    "            # recall: tp / (tp + fn)\n",
    "            recall = recall_score(y_valid, yhat_classes)*100.\n",
    "            # f1: 2 tp / (2 tp + fp + fn)\n",
    "            f1 = f1_score(y_valid, yhat_classes)*100.\n",
    "            # PRC\n",
    "            prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
    "            auprc = auc(prc_X,prc_Y)*100.\n",
    "            auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
    "\n",
    "            if PRETTY_PICTURES:\n",
    "                pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "                plt.grid(True)\n",
    "                plt.gca().set_ylim(0,1)\n",
    "                plt.show()\n",
    "\n",
    "                print('Train set ones/size',\n",
    "                      np.count_nonzero(y_train),'/',len(y_train))\n",
    "                print(\"Compute valiation accuracy\")\n",
    "                print('Valid sizes',X_valid.shape,y_valid.shape)\n",
    "                print('Valid set ones/size',\n",
    "                      np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "                print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "                print('Score threshold',self.score_threshold)\n",
    "                print('Prediction set ones/size',\n",
    "                      np.count_nonzero(yhat_classes),'/',len(yhat_classes))\n",
    "            \n",
    "                count_ones= len(y_valid[y_valid==1])\n",
    "                count_zeros= len(y_valid[y_valid==0])\n",
    "                guess = max(count_ones,count_zeros) / len(y_valid)\n",
    "                plt.plot(prc_X, prc_Y, marker='.')\n",
    "                plt.plot([0, 1], [guess,guess], linestyle='--')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.show()\n",
    "                # ROC\n",
    "                fpr, tpr, roc_bins = roc_curve(y_valid, yhat_pred)\n",
    "                plt.plot(fpr, tpr, marker='.')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.show()\n",
    "            \n",
    "            print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "            print('F1: %.2f%% AUPRC: %.2f%% AUROC: %.2f%%' % (f1,auprc,auroc)) \n",
    "            cv_accuracy.append(accuracy)\n",
    "            cv_precision.append(precision)\n",
    "            cv_recall.append(recall)\n",
    "            cv_f1.append(f1)\n",
    "            cv_auprc.append(auprc)\n",
    "            cv_auroc.append(auroc)\n",
    "            \n",
    "            print(datetime.now())\n",
    "            if self.quick_test:   \n",
    "                print('Break -- this was for code testing only')\n",
    "                break\n",
    "\n",
    "            # There is a memory leak within the fit() command!\n",
    "            # Each successive call to fit() consumes more memory.\n",
    "            model = None\n",
    "            history = None\n",
    "            prc_Y = None\n",
    "            prc_X = None\n",
    "            prc_bins = None\n",
    "            yhat_classes = None\n",
    "            X_train = None\n",
    "            y_train = None\n",
    "            train_genes = None\n",
    "            X_valid = None\n",
    "            y_valid = None\n",
    "            valid_genes = None\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            time.sleep(1)  # hope gc kicks in\n",
    "        print()\n",
    "        return cv_accuracy, cv_precision, cv_recall, cv_f1, cv_auprc, cv_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "01a6a028-4ced-4bad-81b4-bbf431e01095",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:31:14.102152\n",
      "Start cell Line 0 A549\n",
      "Number of RCI values loaded 1447\n",
      "Num RCI: 1447\n",
      "Example RCI: [('ENSG00000116652', -1.848), ('ENSG00000117242', -0.25673), ('ENSG00000125462', 0.13734)]\n",
      "RCI threshold 0\n",
      "Load sequence...\n",
      "Num IDs: 8687\n",
      "Cross validation...\n",
      "2023-02-05 13:31:15.615497\n",
      "splitting\n",
      "Fold 1\n",
      "FIT\n",
      "2023-02-05 13:31:19.740550\n",
      "PREDICT\n",
      "2023-02-05 13:33:14.027753\n",
      "Accuracy: 53.59% Precision: 52.68% Recall: 82.41%\n",
      "F1: 64.27% AUPRC: 55.64% AUROC: 56.40%\n",
      "2023-02-05 13:33:17.105507\n",
      "Fold 2\n",
      "FIT\n",
      "2023-02-05 13:33:26.492697\n",
      "PREDICT\n",
      "2023-02-05 13:35:15.372817\n",
      "Accuracy: 45.55% Precision: 48.21% Recall: 42.50%\n",
      "F1: 45.18% AUPRC: 48.53% AUROC: 45.33%\n",
      "2023-02-05 13:35:17.471729\n",
      "Fold 3\n",
      "FIT\n",
      "2023-02-05 13:35:24.988609\n",
      "PREDICT\n",
      "2023-02-05 13:37:10.891224\n",
      "Accuracy: 49.45% Precision: 55.42% Recall: 52.57%\n",
      "F1: 53.96% AUPRC: 56.49% AUROC: 50.12%\n",
      "2023-02-05 13:37:12.570502\n",
      "Fold 4\n",
      "FIT\n",
      "2023-02-05 13:37:17.908040\n",
      "PREDICT\n",
      "2023-02-05 13:38:45.578296\n",
      "Accuracy: 54.41% Precision: 48.09% Recall: 60.47%\n",
      "F1: 53.57% AUPRC: 51.15% AUROC: 58.38%\n",
      "2023-02-05 13:38:47.932260\n",
      "Fold 5\n",
      "FIT\n",
      "2023-02-05 13:38:53.094855\n",
      "PREDICT\n",
      "2023-02-05 13:40:31.570176\n",
      "Accuracy: 54.06% Precision: 64.22% Recall: 58.31%\n",
      "F1: 61.12% AUPRC: 63.17% AUROC: 54.31%\n",
      "2023-02-05 13:40:32.874248\n",
      "\n",
      "Completed cross validation 5 folds 3 epochs\n",
      " accuracy mean 51.41% +/- 3.43\n",
      " precision mean 53.72% +/- 5.94\n",
      " recall mean 59.25% +/- 13.14\n",
      " F1 mean 55.62% +/- 6.65\n",
      " AUPRC mean 55.00% +/- 5.02\n",
      " AUROC mean 52.91% +/- 4.68\n",
      "Finished cell Line 0 A549\n",
      "\n",
      "2023-02-05 13:40:34.326052\n"
     ]
    }
   ],
   "source": [
    "for CELL_LINE in range(1):   # AFTER SOFTWARE TESTING, GO BACK TO range(15):\n",
    "    print(datetime.now())\n",
    "    print('Start cell Line',CELL_LINE,all_cell_lines[CELL_LINE])\n",
    "    loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE\n",
    "    gene_to_rci = loader.load_gene_rci_values(filepath,CELL_LINE)\n",
    "    print('Num RCI:', len(gene_to_rci.keys()))\n",
    "    print('Example RCI:', list(gene_to_rci.items())[:3])\n",
    "    all_genes = list(gene_to_rci.keys())\n",
    "    RCI_THRESHOLD = loader.get_threshold(CELL_LINE,gene_to_rci)\n",
    "    print('RCI threshold',RCI_THRESHOLD)\n",
    "    print('Load sequence...')\n",
    "    filepath = DATA_DIR+SEQUENCE_FILE\n",
    "    allids,allseq = loader.load_sequence(filepath)\n",
    "    print('Num IDs:',len(allids))\n",
    "    loader = None  # drop K-mer cache to save RAM\n",
    "\n",
    "    print(\"Cross validation...\")\n",
    "    cvdo = CrossValidator(EPOCHS,FOLDS,BREAK)\n",
    "    cvdo.set_sequences(allids,allseq)\n",
    "    cvdo.set_rci_map(gene_to_rci)\n",
    "    cv_accuracy, cv_precision, cv_recall, cv_f1, cv_auprc, cv_auroc = cvdo.do_cross_validation()   \n",
    "    cvdo = None\n",
    "    print(\"Completed cross validation %d folds %d epochs\" % (FOLDS,EPOCHS)) \n",
    "    print(\" accuracy mean %.2f%% +/- %.2f\" % (np.mean(cv_accuracy), np.std(cv_accuracy)))\n",
    "    print(\" precision mean %.2f%% +/- %.2f\" % (np.mean(cv_precision), np.std(cv_precision)))\n",
    "    print(\" recall mean %.2f%% +/- %.2f\" % (np.mean(cv_recall), np.std(cv_recall)))\n",
    "    print(\" F1 mean %.2f%% +/- %.2f\" % (np.mean(cv_f1), np.std(cv_f1)))\n",
    "    print(\" AUPRC mean %.2f%% +/- %.2f\" % (np.mean(cv_auprc), np.std(cv_auprc)))\n",
    "    print(\" AUROC mean %.2f%% +/- %.2f\" % (np.mean(cv_auroc), np.std(cv_auroc)))\n",
    "    print('Finished cell Line',CELL_LINE,all_cell_lines[CELL_LINE])\n",
    "    print()\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkCeDg_HdQ36"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
