{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:34:10.987830\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LayerNormalization\n",
    "\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx(dt)\n",
    "\n",
    "EPOCHS=20\n",
    "SPLITS=3\n",
    "EMBED_DIMEN=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS_DIR = '/Users/jasonmiller/WVU/Localization/LncAtlas/'\n",
    "RCI_FILE = 'CNRCI_coding_train_genes.csv'\n",
    "GENCODE_DIR = '/Users/jasonmiller/WVU/Localization/GenCode/'\n",
    "SEQUENCE_FILE = 'Homo_sapiens.GRCh38.cds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 0 A549\n"
     ]
    }
   ],
   "source": [
    "from cell_lines import Cell_Lines\n",
    "all_cell_lines = Cell_Lines.get_ordered_list()\n",
    "cell_line_number = 0\n",
    "cell_line_name = all_cell_lines[cell_line_number]\n",
    "print('Cell line for today:',cell_line_number,cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:34:23.114124\n",
      "Genes: 14216\n",
      "Gene labels: 10392\n",
      "Positive labels: 5412\n"
     ]
    }
   ],
   "source": [
    "def load_labels(atlas_file,cells):\n",
    "    gene_labels = {}\n",
    "    with open(atlas_file,'r') as atlas:\n",
    "        header = None\n",
    "        genes_considered = 0\n",
    "        positives = 0\n",
    "        csv = reader(atlas)\n",
    "        for row in csv:\n",
    "            if header is None:\n",
    "                header = row\n",
    "            else:\n",
    "                gene = row[0]\n",
    "                genes_considered += 1\n",
    "                rci = float(row[1+cells])\n",
    "                if not math.isnan(rci):\n",
    "                    # GENERATE BINARY LABELS\n",
    "                    label = 0   # RCI<0\n",
    "                    if rci>=0:  # THRESHOLD\n",
    "                        label = 1   #RCI>=0\n",
    "                        positives += 1\n",
    "                    gene_labels[gene]=label\n",
    "    print('Genes:',genes_considered)\n",
    "    print('Gene labels:',len(gene_labels))\n",
    "    print('Positive labels:',positives)\n",
    "    return gene_labels\n",
    "    \n",
    "print(datetime.now())\n",
    "atlas_path = ATLAS_DIR+RCI_FILE\n",
    "gene_label = load_labels(atlas_path,cell_line_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(gencode_file,gene_label):\n",
    "    gid_tid = []\n",
    "    labels = []\n",
    "    tseqs = []\n",
    "    with open(gencode_file,'r') as gencode:\n",
    "        header = None\n",
    "        csv = reader(gencode)\n",
    "        for row in csv:\n",
    "            if header is None:\n",
    "                header = row\n",
    "            else:\n",
    "                tran_id = row[0]\n",
    "                gene_id = row[1]\n",
    "                tseq = row[4]\n",
    "                if gene_id in gene_label:\n",
    "                    label = gene_label[gene_id]\n",
    "                    gid_tid.append ((gene_id,tran_id))\n",
    "                    labels.append(label)\n",
    "                    tseqs.append(tseq)\n",
    "    return gid_tid,labels,tseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:34:23.192637\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "gencode_path = GENCODE_DIR+SEQUENCE_FILE\n",
    "ordered_gid_tid,ordered_labels,ordered_seqs = \\\n",
    "    load_sequences(gencode_path,gene_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=4\n",
    "MAX_COUNT = 2**8-1\n",
    "VOCABULARY_SIZE = 4**K\n",
    "def seq_to_kmer_counts(seq):\n",
    "    counts = np.zeros(VOCABULARY_SIZE,np.int8)\n",
    "    letter_values={'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    for p in range(len(seq)-K+1):\n",
    "        valid = True\n",
    "        kmer_seq=seq[p:p+K]\n",
    "        kmer_hash=0\n",
    "        for d in range(K):\n",
    "            letter = kmer_seq[d]\n",
    "            if letter in letter_values:\n",
    "                additional = letter_values[letter]\n",
    "                kmer_hash = kmer_hash * 4  # left shift\n",
    "                kmer_hash = kmer_hash + additional\n",
    "            else:\n",
    "                valid = False\n",
    "        #print(p, kmer_seq, kmer_hash, valid)\n",
    "        if valid and counts[kmer_hash]<MAX_COUNT:\n",
    "            counts[kmer_hash] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:40:02.720129\n",
      ".....................................................2022-10-04 17:46:09.351225\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "ordered_kmer_counts = []\n",
    "tock = 1000\n",
    "tick = 0\n",
    "for seq in ordered_seqs:\n",
    "    tick += 1\n",
    "    if tick >= tock:\n",
    "        tick = 1\n",
    "        print('.',end='')\n",
    "    counts = seq_to_kmer_counts(seq)\n",
    "    ordered_kmer_counts.append(counts)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    act=\"sigmoid\"\n",
    "    #embed_layer  = keras.layers.Embedding(\n",
    "    #    VOCABULARY_SIZE,EMBED_DIMEN,input_length=maxlen);\n",
    "    dense1_layer = keras.layers.Dense(64, activation=act,dtype=dt,\n",
    "                                      input_dim=VOCABULARY_SIZE)\n",
    "    dense2_layer = keras.layers.Dense(64, activation=act,dtype=dt)\n",
    "    dense3_layer = keras.layers.Dense(64, activation=act,dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,  activation=\"softmax\",dtype=dt)\n",
    "\n",
    "    mlp = keras.models.Sequential()\n",
    "    #mlp.add(embed_layer)\n",
    "    mlp.add(dense1_layer)\n",
    "    mlp.add(dense2_layer)\n",
    "    mlp.add(dense3_layer)\n",
    "    mlp.add(output_layer)\n",
    "    \n",
    "    # Logit=True ranges from + to - infinity.\n",
    "    # Logit=False i.e. probabilities range from 0 to 1.\n",
    "    # If your output layer has a 'softmax' activation, from_logits should be False. If your output layer doesn't have a 'softmax' activation, from_logits should be True. \n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    mlp.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    splitter = ShuffleSplit(n_splits=SPLITS, test_size=0.2, random_state=37863)\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        X_train=X[train_index] # use iloc[] for dataframe\n",
    "        y_train=y[train_index]\n",
    "        X_valid=X[valid_index]\n",
    "        y_valid=y[valid_index]\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model(maxlen,dimen)\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (rnn2.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:47:04.692498\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,833\n",
      "Trainable params: 24,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 17:47:04.726840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Sequence to Kmer\n",
      "Cross valiation\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m ordered_kmer_counts\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross valiation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdo_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m splitter \u001b[38;5;241m=\u001b[39m ShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39mSPLITS, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m37863\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index,valid_index \u001b[38;5;129;01min\u001b[39;00m splitter\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[0;32m----> 6\u001b[0m     X_train\u001b[38;5;241m=\u001b[39m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# use iloc[] for dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my[train_index]\n\u001b[1;32m      8\u001b[0m     X_valid\u001b[38;5;241m=\u001b[39mX[valid_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "y = ordered_labels\n",
    "X = ordered_kmer_counts\n",
    "\n",
    "print (\"Cross valiation\")\n",
    "do_cross_validation(X,y,EPOCHS)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "Do train/valid split with respect to genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
