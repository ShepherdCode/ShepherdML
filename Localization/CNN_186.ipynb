{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# CNN + MaxPool\n",
    "Redo CNN_183 with code from CNN_185 that flips the GMM labels as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "41b32346-ed16-4f31-f4be-173385988f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-14 12:17:39.919920\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUtGXPrcFLA8"
   },
   "source": [
    "We prevously used sklearn.model_selection.ShuffleSplit   \n",
    "Now we avoid it due to this note in the \n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
    "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRX-UEr8FLA8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 12:17:43.492438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "K=4\n",
    "CFILTERS=64\n",
    "FILTERSIZE=16\n",
    "RCELLS=32\n",
    "DCELLS=16\n",
    "EPOCHS=3\n",
    "FOLDS=10      \n",
    "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
    "MINLEN=200\n",
    "MAXLEN=5000   \n",
    "PRETTY_PICTURES = True\n",
    "RCI_THRESHOLD_MECHANISM = 'RCI_GMM' # 'ZERO' 'THE_MEAN'\n",
    "BREAK = False   # break after first fold\n",
    "CACHING = False   # have not worked out how to cache multiple cell lines\n",
    "NUM_LINES = 15   # 15 to analyze all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "fd3962c8-c3f6-4063-b96e-da7b567b830b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmiller/WVU/Localization/TrainTest/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'    # Mac\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnkpVKdMFLA-",
    "outputId": "8a023894-997c-438a-fa43-4543f8a3d639"
   },
   "outputs": [],
   "source": [
    "RCI_FILE =      'CNRCI_noncoding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_noncoding_train_transcripts.gc42.csv'\n",
    "CACHE_SEQUENCE = 'cache.seq.pickle'\n",
    "CACHE_IDS = 'cache.id.pickle'\n",
    "if CACHING:\n",
    "    cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "    cache_ids = DATA_DIR+CACHE_IDS \n",
    "    if isfile(cache_seq) and isfile(cache_ids):\n",
    "        print('WARNING: this run will read sequence from cache.')\n",
    "    else:\n",
    "        print('INFO: this run will write sequence to cache.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()\n",
    "\n",
    "EXCLUSIONS = [1,7]   # use these though they are clearly different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,cell_line):\n",
    "        '''\n",
    "        Load from RCI csv file.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        gene_to_rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row # skip file's header line\n",
    "                else:\n",
    "                    line = row.strip()\n",
    "                    fields = line.split(',')\n",
    "                    gene_id = fields.pop(0)\n",
    "                    rci_str = fields[cell_line]\n",
    "                    if rci_str != \"nan\":\n",
    "                        rci_val = float(rci_str)\n",
    "                        gene_to_rci[gene_id] = rci_val\n",
    "        print('Number of RCI values loaded',len(gene_to_rci.keys()))\n",
    "        return gene_to_rci\n",
    "\n",
    "    def seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "        cache_ids = DATA_DIR+CACHE_IDS \n",
    "        if CACHING and isfile(cache_seq) and isfile(cache_ids):\n",
    "            # Warning: the cache may represent the wrong K.\n",
    "            with open(cache_seq,'rb') as fin:\n",
    "                allseq = pickle.load(fin)\n",
    "            with open(cache_ids,'rb') as fin:\n",
    "                allids = pickle.load(fin)\n",
    "            return allids,allseq           \n",
    "        NREPEAT = str('N'*MAXLEN)\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # with version number\n",
    "                    gene_id = fields[1]        # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        if seq_len<MAXLEN:\n",
    "                            seq_txt = seq_txt + NREPEAT\n",
    "                            seq_txt = seq_txt[:MAXLEN]\n",
    "                        hot_vec = self.seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        if CACHING:\n",
    "            with open(cache_seq,'wb') as fout:\n",
    "                pickle.dump(allseq,fout)\n",
    "            with open(cache_ids,'wb') as fout:\n",
    "                pickle.dump(allids,fout)\n",
    "        return allids,allseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDZ6siB_Kq04"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ALPHABET=4**K+1  # NUMBER OF DISTINCT KMERS POSSIBLE, add one if N gets mask value\n",
    "    ADJUST_LENGTH = MAXLEN-K+1  # fixed length sequences\n",
    "    cnn = Sequential()\n",
    "    embed_layer = Embedding(ALPHABET,EMBED_DIMEN,input_length=ADJUST_LENGTH,mask_zero=True)   \n",
    "    cnn1_layer = Conv1D(CFILTERS, FILTERSIZE)\n",
    "    pool_layer = MaxPooling1D(pool_size=FILTERSIZE, strides=FILTERSIZE//2)\n",
    "    #pool_layer = GlobalAveragePooling1D()\n",
    "    flat_layer = Flatten()\n",
    "    dens_layer = Dense(DCELLS)\n",
    "    drop_layer = Dropout(0.5)\n",
    "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
    "\n",
    "    cnn.add(embed_layer)\n",
    "    cnn.add(cnn1_layer)\n",
    "    cnn.add(pool_layer)\n",
    "    cnn.add(flat_layer)\n",
    "    cnn.add(dens_layer)\n",
    "    cnn.add(drop_layer)\n",
    "    cnn.add(output_layer)\n",
    "\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    cnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "e169bb96-0844-4beb-d803-88a9d19647de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-14 12:17:53.039662\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4997, 4)           1028      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4982, 64)          4160      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 621, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 39744)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                635920    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 12:17:53.052888: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 641,125\n",
      "Trainable params: 641,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model.summary())  # Print this only once\n",
    "model=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,folds,quick_test=False,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.folds = folds\n",
    "        self.quick_test = quick_test\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = None\n",
    "        self.flip = False    \n",
    "        \n",
    "    def set_sequences(self, allids, allseq):\n",
    "        # It is critical to keep IDs and sequences in same order!\n",
    "        self.all_ids = allids  # pairs of (gene_id,tran_id)\n",
    "        self.all_seqs = allseq  # may be vectors of K-mers\n",
    "        genes = []\n",
    "        for i in range(len(allids)):\n",
    "            (one_gene,one_tran) = allids[i]\n",
    "            genes.append(one_gene)\n",
    "        self.all_genes = genes\n",
    "            \n",
    "    def set_rci_map(self, gene_to_rci):\n",
    "        # The map is for fast lookup, not gene order!\n",
    "        self.rci_map = gene_to_rci # map gene_id to RCI value\n",
    "    \n",
    "    def get_gene_subset(self, sub_index):\n",
    "        sub_genes = set()\n",
    "        for index in sub_index:\n",
    "            one_gene = self.all_genes[index]\n",
    "            sub_genes.add(one_gene)\n",
    "        return sub_genes   # this is a set: unordered with fast lookup\n",
    "    \n",
    "    def _get_X_y(self, gene_index):\n",
    "        cnt = len(self.all_ids)\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        next_index = 0\n",
    "        for i in range(cnt):\n",
    "            if next_index==len(gene_index):\n",
    "                break\n",
    "            if i==gene_index[next_index]:\n",
    "                gene_id,tran_id = self.all_ids[i]\n",
    "                oneX = self.all_seqs[i]\n",
    "                oneY = self.rci_map[gene_id]\n",
    "                subsetX.append(oneX)\n",
    "                subsetY.append(oneY)\n",
    "                next_index += 1\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        '''Takes list of float, returns list of labels [0,1].'''\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                covariance_type='spherical', n_init=100) \n",
    "            gmm.fit(rci_values)\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm\n",
    "        elif RCI_THRESHOLD_MECHANISM == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        else:\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-2,-1.5,-1,-0.5,0,0.5,1,1.5,2]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "        \n",
    "    def do_cross_validation(self):\n",
    "        cv_accuracy=[]\n",
    "        cv_precision=[]\n",
    "        cv_recall=[]\n",
    "        cv_f1=[]\n",
    "        cv_auprc=[]\n",
    "        cv_auroc=[]\n",
    "        fold=0\n",
    "        print(datetime.now())\n",
    "        print('splitting')\n",
    "        # KFold shuffles once before making the partitions\n",
    "        splitter = KFold(n_splits=self.folds,shuffle=True,random_state=42)\n",
    "        splits = splitter.split(self.all_genes)\n",
    "        splitter = None\n",
    "        for train_index,valid_index in splits:\n",
    "            fold += 1\n",
    "            print('Fold',fold)\n",
    "            X_train,y_rci = self._get_X_y(train_index)\n",
    "            self._prepare_threshold(y_rci)  # use train subset only!\n",
    "            self._explain_threshold()\n",
    "            y_train = self._apply_threshold(y_rci)\n",
    "            X_valid,y_rci = self._get_X_y(valid_index)\n",
    "            y_valid = self._apply_threshold(y_rci) \n",
    "            y_rci = None\n",
    "\n",
    "            #print('Training example')\n",
    "            #print(X_train[0])\n",
    "            #print(\"BUILD MODEL\")\n",
    "            model=build_model()\n",
    "            print(\"FIT\")\n",
    "            print(datetime.now())\n",
    "            history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "              epochs=self.epochs, verbose=0,  # verbose=1 for ascii art, verbose=0 for none\n",
    "              validation_data=(X_valid,y_valid) )\n",
    "            print(\"PREDICT\")\n",
    "            print(datetime.now())\n",
    "            yhat_pred=model.predict(X_valid, verbose=0)             \n",
    "            yhat_classes=np.where(yhat_pred > self.score_threshold, 1, 0)\n",
    "\n",
    "            # accuracy: (tp + tn) / (p + n)\n",
    "            accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
    "            # precision tp / (tp + fp)\n",
    "            precision = precision_score(y_valid, yhat_classes)*100.\n",
    "            # recall: tp / (tp + fn)\n",
    "            recall = recall_score(y_valid, yhat_classes)*100.\n",
    "            # f1: 2 tp / (2 tp + fp + fn)\n",
    "            f1 = f1_score(y_valid, yhat_classes)*100.\n",
    "            # PRC\n",
    "            prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
    "            auprc = auc(prc_X,prc_Y)*100.\n",
    "            auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
    "\n",
    "            if PRETTY_PICTURES:\n",
    "                pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "                plt.grid(True)\n",
    "                plt.gca().set_ylim(0,1)\n",
    "                plt.show()\n",
    "\n",
    "                print('Train set ones/size',\n",
    "                      np.count_nonzero(y_train),'/',len(y_train))\n",
    "                print(\"Compute valiation accuracy\")\n",
    "                print('Valid sizes',X_valid.shape,y_valid.shape)\n",
    "                print('Valid set ones/size',\n",
    "                      np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "                print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "                print('Score threshold',self.score_threshold)\n",
    "                print('Prediction set ones/size',\n",
    "                      np.count_nonzero(yhat_classes),'/',len(yhat_classes))\n",
    "\n",
    "                count_ones= len(y_valid[y_valid==1])\n",
    "                count_zeros= len(y_valid[y_valid==0])\n",
    "                guess = max(count_ones,count_zeros) / len(y_valid)\n",
    "                plt.plot(prc_X, prc_Y, marker='.')\n",
    "                plt.plot([0, 1], [guess,guess], linestyle='--')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.show()\n",
    "                # ROC\n",
    "                fpr, tpr, roc_bins = roc_curve(y_valid, yhat_pred)\n",
    "                plt.plot(fpr, tpr, marker='.')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.show()\n",
    "\n",
    "            print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
    "            print('F1: %.2f%% AUPRC: %.2f%% AUROC: %.2f%%' % (f1,auprc,auroc)) \n",
    "            cv_accuracy.append(accuracy)\n",
    "            cv_precision.append(precision)\n",
    "            cv_recall.append(recall)\n",
    "            cv_f1.append(f1)\n",
    "            cv_auprc.append(auprc)\n",
    "            cv_auroc.append(auroc)\n",
    "            \n",
    "            print(datetime.now())\n",
    "            if self.quick_test:   \n",
    "                print('Break -- this was for code testing only')\n",
    "                break\n",
    "\n",
    "            # There is a memory leak within the fit() command!\n",
    "            # Each successive call to fit() consumes more memory.\n",
    "            model = None\n",
    "            history = None\n",
    "            prc_Y = None\n",
    "            prc_X = None\n",
    "            prc_bins = None\n",
    "            yhat_classes = None\n",
    "            X_train = None\n",
    "            y_train = None\n",
    "            X_valid = None\n",
    "            y_valid = None\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            time.sleep(1)  # hope gc kicks in\n",
    "        print()\n",
    "        return cv_accuracy, cv_precision, cv_recall, cv_f1, cv_auprc, cv_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "8e8edfc3-dc87-4238-d9d9-ca2fae41579f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-14 12:17:53.468450\n",
      "Start cell Line 0 A549\n",
      "Number of RCI values loaded 1447\n",
      "Num RCI: 1447\n",
      "Load sequence...\n",
      "Cross validation...\n",
      "2023-02-14 12:18:10.337545\n",
      "splitting\n",
      "Fold 1\n",
      "Discriminator is GMM\n",
      "Means [0.571546392899654, -0.9896825632572325]\n",
      "Variances [0.86236851 1.91441125]\n",
      "Priors [0.5786628 0.4213372]\n",
      "[-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
      "[0 0 0 1 1 1 1 1 1]\n",
      "2023-02-14 12:18:17.851987\n",
      "Fold 2\n",
      "Discriminator is GMM\n",
      "Means [0.5892183504728793, -0.9801958135434615]\n",
      "Variances [0.89607412 1.93724719]\n",
      "Priors [0.57658017 0.42341983]\n",
      "[-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
      "[0 0 0 1 1 1 1 1 1]\n",
      "2023-02-14 12:18:25.670073\n",
      "Fold 3\n",
      "Discriminator is GMM\n",
      "Means [0.5721255512854978, -0.921536009010897]\n",
      "Variances [0.89348863 1.8901682 ]\n",
      "Priors [0.56791907 0.43208093]\n",
      "[-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
      "[0 0 0 1 1 1 1 1 1]\n",
      "2023-02-14 12:18:33.184753\n",
      "\n",
      "Completed cross validation 3 folds 3 epochs\n",
      "Finished cell Line 0 A549\n",
      "\n",
      "2023-02-14 12:18:34.580206\n",
      "Start cell Line 1 H1.hESC\n",
      "Number of RCI values loaded 3327\n",
      "Num RCI: 3327\n",
      "Load sequence...\n",
      "Cross validation...\n",
      "2023-02-14 12:19:02.179113\n",
      "splitting\n",
      "Fold 1\n",
      "Discriminator is GMM\n",
      "Means [0.43663540494351916, -0.9353084699055065]\n",
      "Variances [1.40120385 1.37694847]\n",
      "Priors [0.4752185 0.5247815]\n",
      "[-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
      "[0 0 0 0 1 1 1 1 1]\n",
      "2023-02-14 12:19:13.134356\n",
      "Fold 2\n",
      "Discriminator is GMM\n",
      "Means [-0.9227138322668256, 0.41036912513741175]\n",
      "Variances [1.39207385 1.44112029]\n",
      "Priors [0.52694437 0.47305563]\n",
      "[-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]\n",
      "[0 0 0 0 1 1 1 1 1]\n",
      "2023-02-14 12:19:25.332917\n"
     ]
    }
   ],
   "source": [
    "for CELL_LINE in range(NUM_LINES):\n",
    "    print(datetime.now())\n",
    "    print('Start cell Line',CELL_LINE,all_cell_lines[CELL_LINE])\n",
    "    loader = DataLoader()\n",
    "    filepath = DATA_DIR+RCI_FILE\n",
    "    gene_to_rci = loader.load_gene_rci_values(filepath,CELL_LINE)\n",
    "    print('Num RCI:', len(gene_to_rci.keys()))\n",
    "    print('Load sequence...')\n",
    "    filepath = DATA_DIR+SEQUENCE_FILE\n",
    "    allids,allseq = loader.load_sequence(filepath)\n",
    "    loader = None  # drop K-mer cache to save RAM\n",
    "\n",
    "    print(\"Cross validation...\")\n",
    "    cvdo = CrossValidator(EPOCHS,FOLDS,BREAK)\n",
    "    cvdo.set_sequences(allids,allseq)\n",
    "    cvdo.set_rci_map(gene_to_rci)\n",
    "    cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "    cv_accuracy, cv_precision, cv_recall, cv_f1, cv_auprc, cv_auroc = cvdo.do_cross_validation()   \n",
    "    cvdo = None\n",
    "    print(\"Completed cross validation %d folds %d epochs\" % (FOLDS,EPOCHS)) \n",
    "    print(\" accuracy mean %.2f%% +/- %.2f\" % (np.mean(cv_accuracy), np.std(cv_accuracy,ddof=1)))\n",
    "    print(\" precision mean %.2f%% +/- %.2f\" % (np.mean(cv_precision), np.std(cv_precision,ddof=1)))\n",
    "    print(\" recall mean %.2f%% +/- %.2f\" % (np.mean(cv_recall), np.std(cv_recall,ddof=1)))\n",
    "    print(\" F1 mean %.2f%% +/- %.2f\" % (np.mean(cv_f1), np.std(cv_f1,ddof=1)))\n",
    "    print(\" AUPRC mean %.2f%% +/- %.2f\" % (np.mean(cv_auprc), np.std(cv_auprc,ddof=1)))\n",
    "    print(\" AUROC mean %.2f%% +/- %.2f\" % (np.mean(cv_auroc), np.std(cv_auroc,ddof=1)))\n",
    "    print('Finished cell Line',CELL_LINE,all_cell_lines[CELL_LINE])\n",
    "    print()\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkCeDg_HdQ36"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
