{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM\n",
    "Use sequence from GenCode files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 14:12:32.206568\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prevously used sklearn.model_selection.ShuffleSplit   \n",
    "Now we avoid it due to this note in the \n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
    "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "EPOCHS=10\n",
    "FOLDS=5\n",
    "EMBED_DIMEN=16\n",
    "MAXLEN=4000   # this is problematic as some genes will be excluded entirely or partially\n",
    "\n",
    "from cell_lines import Cell_Lines\n",
    "CELL_LINE_NUMBER=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'\n",
    "GENES_FILE = 'CNRCI_coding_train_genes.csv'\n",
    "RCI_FILE = 'CNRCI_coding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_coding_train_transcripts.gc42.csv'\n",
    "COUNTS_FILE='CNRCI_coding_train_counts.K4.gc42.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 0 = A549\n"
     ]
    }
   ],
   "source": [
    "# Consider a Cell_Lines object to represent today's cell line.\n",
    "all_cell_lines = Cell_Lines.get_ordered_list()\n",
    "cell_line_name = all_cell_lines[CELL_LINE_NUMBER]\n",
    "print('Cell line for today:',CELL_LINE_NUMBER,'=',cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 14:12:44.885062\n",
      "Num RCI: 10338\n",
      "[('ENSG00000000003', 1.08068), ('ENSG00000000419', 1.32679), ('ENSG00000000457', 0.434284)]\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "# labels\n",
    "filepath = DATA_DIR+RCI_FILE\n",
    "gene_to_rci = {}\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line = row.strip()\n",
    "            fields = line.split(',')\n",
    "            gene_id = fields[0]\n",
    "            rci_val = fields[CELL_LINE_NUMBER+1]\n",
    "            # Could implement Gudenas style threshold here\n",
    "            if rci_val != \"nan\":\n",
    "                gene_to_rci[gene_id] = float(rci_val)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "print(list(gene_to_rci.items())[:3])\n",
    "all_genes = list(gene_to_rci.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 14:12:44.958226\n",
      "Load sequence\n",
      "2022-11-03 14:13:01.374935\n",
      "Num IDs: 44332\n",
      "Num labels: 44332\n",
      "Num counts: 44332\n"
     ]
    }
   ],
   "source": [
    "# one hot\n",
    "print(datetime.now())\n",
    "print('Load sequence')\n",
    "filepath = DATA_DIR+SEQUENCE_FILE\n",
    "labels=[]\n",
    "allids=[]\n",
    "allseq=[]\n",
    "HOTS = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line    = row.strip()\n",
    "            fields  = line.split(',')\n",
    "            tran_id = fields[0]  # with version number\n",
    "            gene_id = fields[1]        # without version number\n",
    "            seq_len = int(fields[3])\n",
    "            seq_txt = fields[4]\n",
    "            if seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                rci_val = gene_to_rci[gene_id]\n",
    "                allids.append( (gene_id,tran_id) )\n",
    "                labels.append(rci_val)\n",
    "                seq_chr = list(seq_txt)\n",
    "                seq_hot = []\n",
    "                for c in seq_chr:\n",
    "                    one_hot = HOTS[c]\n",
    "                    seq_hot.append(one_hot)\n",
    "                allseq.append(seq_hot)\n",
    "print(datetime.now())\n",
    "print('Num IDs:',len(allids))\n",
    "#print('Examples:',[allids[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num labels:',len(labels))\n",
    "#print('Examples:',[labels[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num counts:',len(allseq))\n",
    "#print('Example:',allseq[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_subset(all_genes,sub_index):\n",
    "    sub_genes = set()\n",
    "    for index in sub_index:\n",
    "        one_gene = all_genes[index]\n",
    "        sub_genes.add(one_gene)\n",
    "    return sub_genes\n",
    "def get_X_y(gene_set,allids,allX,allY,threshold):\n",
    "    cnt = len(allids)\n",
    "    subsetX=[]\n",
    "    subsetY=[]\n",
    "    if cnt != len(allX) or cnt!= len(allY):\n",
    "        raise Exception('Lengths differ')\n",
    "    for i in range(cnt):\n",
    "        gene_id,tran_id = allids[i]\n",
    "        if gene_id in gene_set:\n",
    "            oneX = allX[i]\n",
    "            oneY = allY[i]\n",
    "            if oneY < threshold:\n",
    "                Yvalue = int(0)\n",
    "            else:\n",
    "                Yvalue = int(1)\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(Yvalue)\n",
    "    return subsetX,subsetY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    DIMEN=4  # ONE HOT CATEGORIES\n",
    "    ACT = 'sigmoid'\n",
    "    rnn = Sequential()\n",
    "    embed_layer = Embedding(DIMEN,EMBED_DIMEN,input_length=MAXLEN);\n",
    "    rnn1_layer = Bidirectional(\n",
    "        LSTM(16, return_sequences=True, input_shape=[MAXLEN,DIMEN]))\n",
    "    rnn2_layer = Bidirectional(LSTM(16, return_sequences=True))\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    dense1_layer = Dense(16,activation=ACT,dtype=dt)\n",
    "    dense2_layer = Dense(16,activation=ACT,dtype=dt)\n",
    "    output_layer = Dense(1,activation=ACT,dtype=dt)\n",
    "\n",
    "    rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    rnn.add(rnn2_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = False\n",
    "def do_cross_validation(eps):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    print(datetime.now())\n",
    "    print('splitting')\n",
    "    # KFold shuffles once before making the partitions\n",
    "    splitter = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n",
    "    for train_index,valid_index in splitter.split(all_genes):\n",
    "        train_genes = get_gene_subset(all_genes,train_index)\n",
    "        valid_genes = get_gene_subset(all_genes,valid_index)\n",
    "        X_train,y_train = get_X_y(train_genes,allids,allseq,labels,0)\n",
    "        X_valid,y_valid = get_X_y(valid_genes,allids,allseq,labels,0)\n",
    "\n",
    "        if SCALING:\n",
    "            print('scaling')\n",
    "            print(datetime.now())\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_valid = scaler.transform(X_valid)\n",
    "\n",
    "        fold += 1\n",
    "        print('Fold',fold)\n",
    "        print('Train sizes',len(X_train),len(y_train))\n",
    "        print('Valid sizes',len(X_valid),len(y_valid))\n",
    "        print('Train set ones/size',\n",
    "              np.count_nonzero(y_train),'/',len(y_train))\n",
    "        print('Valid set ones/size',\n",
    "              np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model()\n",
    "\n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Compute valiation accuracy\")\n",
    "        print(datetime.now())\n",
    "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(datetime.now())\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    return cv_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 14:13:01.490806\n",
      "2022-11-03 14:13:01.491125\n",
      "splitting\n",
      "Fold 1\n",
      "Train sizes 35636 35636\n",
      "Valid sizes 8696 8696\n",
      "Train set ones/size 18432 / 35636\n",
      "Valid set ones/size 4467 / 8696\n",
      "BUILD MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 14:13:01.538845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILE\n",
      "FIT\n",
      "2022-11-03 14:13:03.875096\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "cv_scores = do_cross_validation(EPOCHS)    \n",
    "print(\"Cross validation acc mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
