{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Gradient Boost\n",
        "canonical lncRNA, -1 threshold, cross-valiation, all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "a7bb6ccd-af35-4233-a628-6a70c4b72403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:22.448940\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "69cf7899-c793-49ab-ab20-3e566ad6ce4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "# tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
        "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/'    # Mac\n",
        "    MODEL_DIR = '/Users/jasonmiller/WVU/Localization/Models/'    # Mac\n",
        "print(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "8fe4dc66-bdc2-482d-83a3-483fcca84d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "import pickle\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import BinaryCrossentropy\n",
        "#from keras.losses import Hinge\n",
        "\n",
        "K=5\n",
        "ALPHABET=4**K + 1\n",
        "CFILTERS=64 \n",
        "FILTERSIZE=8\n",
        "RCELLS=32\n",
        "DCELLS=16\n",
        "EPOCHS=150 \n",
        "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
        "# MINLEN=200   # NO LONGER USED\n",
        "# MAXLEN=5000\n",
        "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
        "BREAK = False   # break after first fold\n",
        "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
        "FILTER_TRAIN        = True\n",
        "FILTER_TAILS_TRAIN  = False\n",
        "FILTER_MIDDLE_TRAIN = True\n",
        "FILTER_TEST         = True\n",
        "FILTER_TAILS_TEST   = False\n",
        "FILTER_MIDDLE_TEST  = True\n",
        "REPEATS = 2\n",
        "FOLDS = 5\n",
        "\n",
        "SAVE_MODEL_FILENAME = None # 'RF_101'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LnkpVKdMFLA-"
      },
      "outputs": [],
      "source": [
        "RCI_FILE_TRAIN = 'train.lncRNA_RCI.csv'\n",
        "RCI_FILE_TEST  = None #'test.lncRNA_RCI.csv'\n",
        "\n",
        "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
        "SEQ_FILE_TEST  = None #'test.canon_lncRNA_transcripts.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e3p4QzQJFLA_"
      },
      "outputs": [],
      "source": [
        "def get_ordered_list():\n",
        "    ordered_list = \\\n",
        "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
        "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
        "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
        "    return ordered_list\n",
        "all_cell_lines = get_ordered_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        self.cache=dict() \n",
        "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "        self.gene2rci = dict()\n",
        "        \n",
        "    def load_gene_rci_values(self,filepath,exclusions):\n",
        "        '''\n",
        "        Load all the genes from the given RCI csv file.\n",
        "        The given file usually contains train or test, not both.\n",
        "        Return dict with keys=gene:str and values=RCI:float.\n",
        "        '''\n",
        "        self.gene2rci = {}\n",
        "        overall_sum = 0\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row # skip file's header line\n",
        "                else:\n",
        "                    line = row.strip()\n",
        "                    fields = line.split(',')\n",
        "                    gene_id = fields.pop(0)\n",
        "                    log_mean = float(fields.pop(0))\n",
        "                    self.gene2rci[gene_id] = log_mean\n",
        "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
        "        return self.gene2rci\n",
        "\n",
        "    def _seq_to_kmer_values(self,rna,K):\n",
        "        vec=[] # seq converted to list of K-mers \n",
        "        N_indicator = 0 # indicator value\n",
        "        length = len(rna)\n",
        "        for i in range(length-K+1):\n",
        "            kmer = rna[i:i+K]\n",
        "            if 'N' in kmer:\n",
        "                value = N_indicator\n",
        "            elif kmer in self.cache.keys():\n",
        "                value = self.cache[kmer]\n",
        "            else:\n",
        "                value = 0\n",
        "                for j in range(K):\n",
        "                    value *= 4   \n",
        "                    nextnuc = kmer[j] \n",
        "                    nucval = self.vals[nextnuc]\n",
        "                    value += nucval\n",
        "                value += 1   # NNN => 0, AAA => 1\n",
        "                self.cache[kmer] = value\n",
        "            vec.append(value)\n",
        "        return vec\n",
        "\n",
        "    def load_sequence(self,filepath):\n",
        "        '''\n",
        "        Load all the sequences from the given file. \n",
        "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
        "        Each line has IDs plus sequence.\n",
        "        The IDs in the file do not include dot-version numbers.\n",
        "        The file may already be filtered e.g. canonical transcripts.\n",
        "        '''\n",
        "        allids=[]\n",
        "        allseq=[]\n",
        "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row\n",
        "                else:\n",
        "                    line    = row.strip()\n",
        "                    fields  = line.split(',')\n",
        "                    tran_id = fields[0]  # without version number\n",
        "                    gene_id = fields[1]  # without version number\n",
        "                    seq_len = int(fields[3])\n",
        "                    seq_txt = fields[4]\n",
        "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
        "                    # We have validated this by spot checking.\n",
        "                    # TO DO: validate this programmatically.\n",
        "                    if gene_id in self.gene2rci.keys():\n",
        "                        # no MAXLEN for MLP\n",
        "                        #if seq_len<=MAXLEN:\n",
        "                        #    seq_txt = seq_txt + NREPEAT\n",
        "                        #seq_txt = seq_txt[:MAXLEN]\n",
        "                        allids.append( (gene_id,tran_id) )\n",
        "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
        "                        allseq.append(hot_vec)\n",
        "        self.cache=dict() # save RAM\n",
        "        return allids,allseq\n",
        "\n",
        "    def load_spectra(self,filepath):\n",
        "        '''\n",
        "        Load all (variable-length) sequences as lists of kmers.\n",
        "        Then convert each sequence to (fixed-length) kmer histograms.\n",
        "        '''\n",
        "        allids,allseq = self.load_sequence(filepath)\n",
        "        allspectra = []\n",
        "        for seq in allseq:\n",
        "            spectrum = np.zeros(ALPHABET)\n",
        "            for kmer in seq:\n",
        "                spectrum[kmer] += 1\n",
        "            spectrum /= len(seq)\n",
        "            allspectra.append(spectrum)\n",
        "        return allids,allspectra        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    gbc = GBC()\n",
        "    return gbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "ed993de1-0f2a-4d93-8c16-f40e5ba88993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:56.319990\n",
            "GradientBoostingClassifier()\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "model=build_model()\n",
        "print(model)  # Print this only once\n",
        "model=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W9xiFzNbFLBE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class CrossValidator():\n",
        "    def __init__(self,epochs,score_threshold=0.5):\n",
        "        self.epochs = epochs\n",
        "        self.score_threshold = score_threshold\n",
        "        self.mechanism = 'ZERO'\n",
        "        self.discriminator = -1 # or zero\n",
        "        self.flip = False\n",
        "        self.reset_statistics()\n",
        "        \n",
        "    def reset_statistics(self):\n",
        "        self.cv_accuracy=[]\n",
        "        self.cv_precision=[]\n",
        "        self.cv_recall=[]\n",
        "        self.cv_f1=[]\n",
        "        self.cv_auprc=[]\n",
        "        self.cv_auroc=[]\n",
        "        self.cv_mcc=[]\n",
        "        \n",
        "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
        "        # Prepare X and y for training or testing.\n",
        "        subsetX=[]\n",
        "        subsetY=[]\n",
        "        for t in range(len(all_ids)):\n",
        "            gene_id,tran_id = all_ids[t]\n",
        "            oneX            = all_seqs[t]\n",
        "            oneY            = rci_map[gene_id]\n",
        "            subsetX.append(oneX)\n",
        "            subsetY.append(oneY)\n",
        "        subsetX = np.array(subsetX)\n",
        "        subsetY = np.array(subsetY).reshape((-1,1))\n",
        "        return subsetX,subsetY\n",
        "    \n",
        "    def set_threshold_mechanism(self, mechanism):\n",
        "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
        "            raise Exception('Unrecognized mechansm:',mechanism)\n",
        "        self.mechanism = mechanism\n",
        "    \n",
        "    def _apply_threshold(self, array_of_rci):\n",
        "        # Takes list of float, returns list of labels [0,1].\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            labels = self.discriminator.predict(array_of_rci)\n",
        "            if self.flip:\n",
        "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
        "                labels = np.array(list(map(IS_CYTO, labels)))\n",
        "        else:  # 'THE_MEAN' or 'ZERO'\n",
        "            rci_threshold = self.discriminator\n",
        "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
        "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
        "        return labels\n",
        "    \n",
        "    def _prepare_threshold(self, rci_values, create=True):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            if create:  # during training, create a new GMM\n",
        "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
        "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
        "                gmm.fit(rci_values)\n",
        "            else:   # during testing, use existing GMM\n",
        "                gmm=self.discriminator\n",
        "            self.flip = False\n",
        "            # The GMM labels are arbitrary.\n",
        "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
        "                self.flip = True\n",
        "            self.discriminator = gmm   # redundant but consistent\n",
        "        elif self.mechanism == 'THE_MEAN':\n",
        "            self.discriminator = np.mean(rci_values)\n",
        "        elif self.mechanism == 'ZERO':\n",
        "            self.discriminator = -1   # 0 usually, -1 is as in Yuan et al.\n",
        "        else: # not expected\n",
        "            self.discriminator = 0\n",
        "    \n",
        "    def _explain_threshold(self):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            gmm=self.discriminator\n",
        "            print('Discriminator is GMM')\n",
        "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
        "            print('Variances',gmm.covariances_)\n",
        "            print('Priors',gmm.weights_)\n",
        "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
        "            print(test_rcis)\n",
        "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
        "        else:\n",
        "            print('Discriminator',self.mechanism,self.discriminator)\n",
        "    \n",
        "    def _show_sizes(self,label,values):\n",
        "        a = np.count_nonzero(values==1)\n",
        "        b = np.count_nonzero(values==0)\n",
        "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
        "        \n",
        "    def save_model(self,filename):\n",
        "        if self.model is not None:\n",
        "            filepath = MODEL_DIR + filename\n",
        "            #self.model.save(filepath)\n",
        "            print('? Saved model to',filepath)\n",
        "        \n",
        "    def load_model(self,filename):\n",
        "        filepath = MODEL_DIR + filename\n",
        "        #self.model = keras.models.load_model(filepath)\n",
        "        print('? Loaded model from',filepath)\n",
        "        \n",
        "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
        "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
        "        print(datetime.now())\n",
        "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
        "        self._prepare_threshold(y_rci,True)  \n",
        "        self._explain_threshold()\n",
        "        y_train = self._apply_threshold(y_rci)\n",
        "        self._show_sizes('Train',y_train)\n",
        "        #cw = class_weight.compute_class_weight('balanced', classes=[0,1], y=y_train)\n",
        "        #cwd = {0: cw[0], 1: cw[1]}\n",
        "        #print('Computed class weights:',cwd)\n",
        "        if valid_ids is not None:\n",
        "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
        "            y_valid = self._apply_threshold(y_rci)\n",
        "            self._show_sizes('Valid',y_valid)\n",
        "        y_rci = None\n",
        "\n",
        "        self.model=build_model()\n",
        "        \n",
        "        print(\"FIT\")\n",
        "        print(datetime.now())\n",
        "        self.model.fit(X_train, y_train) # sample weight\n",
        "\n",
        "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
        "        # For final test, do no train.\n",
        "        # Assume set_sequences() set the test set.\n",
        "        print(datetime.now())\n",
        "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
        "        y_test = self._apply_threshold(y_rci)\n",
        "        y_rci = None\n",
        "        \n",
        "        print(\"PREDICT\")\n",
        "        print(datetime.now())        \n",
        "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
        "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
        "        \n",
        "        print('debug pred',yhat_pred[:3])\n",
        "        print('debug class',yhat_classes[:3])\n",
        "\n",
        "        self._show_sizes('Test',y_test)\n",
        "        self._show_sizes('Predict',yhat_classes)\n",
        "        print('Test sizes',X_test.shape,y_test.shape)\n",
        "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "        print('Score threshold',self.score_threshold)\n",
        "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
        "        print('Confusion matrix\\n',cm1)\n",
        "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
        "        print('Normalized matrix\\n',cm2)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
        "        precision = precision_score(y_test, yhat_classes)*100.\n",
        "        recall = recall_score(y_test, yhat_classes)*100.\n",
        "        f1 = f1_score(y_test, yhat_classes)*100.\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
        "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
        "\n",
        "        correct_pos = 0\n",
        "        correct_neg = 0\n",
        "        wrong_pos = 0\n",
        "        wrong_neg = 0\n",
        "        for i in range(len(y_test)):\n",
        "            if yhat_pred[i]>=0.65:\n",
        "                if y_test[i]==1:\n",
        "                    correct_pos += 1\n",
        "                else:\n",
        "                    wrong_pos += 1\n",
        "            elif yhat_pred[i]<=0.35:\n",
        "                if y_test[i]==0:\n",
        "                    correct_neg += 1\n",
        "                else:\n",
        "                    wrong_neg += 1\n",
        "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
        "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
        "\n",
        "        #self._pretty_pictures(y_test,yhat_pred,prc_X,prc_Y)\n",
        "        \n",
        "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
        "\n",
        "        self.cv_accuracy.append(accuracy)\n",
        "        self.cv_precision.append(precision)\n",
        "        self.cv_recall.append(recall)\n",
        "        self.cv_f1.append(f1)\n",
        "        self.cv_mcc.append(mcc)\n",
        "        self.cv_auprc.append(auprc)\n",
        "        self.cv_auroc.append(auroc)\n",
        "\n",
        "    def _pretty_pictures(self,y_valid,yhat_pred,prc_X,prc_Y):\n",
        "        count_ones= len(y_valid[y_valid==1])\n",
        "        count_zeros= len(y_valid[y_valid==0])\n",
        "        guess = max(count_ones,count_zeros) / len(y_valid)\n",
        "        # PRC\n",
        "        plt.plot(prc_X, prc_Y, marker='.')\n",
        "        plt.plot([0, 1], [guess,guess], linestyle='--')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.show()\n",
        "        # ROC\n",
        "        fpr, tpr, roc_bins = roc_curve(y_valid, yhat_pred)\n",
        "        plt.plot(fpr, tpr, marker='.')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.show()\n",
        "        \n",
        "    def get_statistics(self):\n",
        "        return \\\n",
        "        self.cv_accuracy,\\\n",
        "        self.cv_precision,\\\n",
        "        self.cv_recall,\\\n",
        "        self.cv_f1,\\\n",
        "        self.cv_mcc,\\\n",
        "        self.cv_auprc,\\\n",
        "        self.cv_auroc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td97uyyj5qDq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "poe3rwAF4Ir7"
      },
      "outputs": [],
      "source": [
        "class Separator():\n",
        "    def __init__(self):\n",
        "        self.train_ids = []\n",
        "        self.train_seq = []\n",
        "        self.train_rci = dict()\n",
        "        self.val_ids = []\n",
        "        self.val_seq = []\n",
        "        self.val_rci = dict()\n",
        "    def load(self,data_dir,rep,fold):\n",
        "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
        "        filename = data_dir + filename\n",
        "        self.val_genes = set()\n",
        "        print('Opening file',filename)\n",
        "        with open(filename,'r') as fin:\n",
        "            for line in fin:\n",
        "                gene_id = line.strip()\n",
        "                self.val_genes.add(gene_id)\n",
        "    def process(self,allids,allseq,gene_to_rci):\n",
        "        size = len(allids)\n",
        "        for t in range(size):\n",
        "            gene_id,tran_id = allids[t]\n",
        "            oneX            = allseq[t]\n",
        "            oneY            = gene_to_rci[gene_id]\n",
        "            in_middle = gene_to_rci[gene_id] >= -2 and gene_to_rci[gene_id] <= 0\n",
        "            in_tails = gene_to_rci[gene_id] < -2 or gene_to_rci[gene_id] > 0\n",
        "            if gene_id in self.val_genes:\n",
        "                if FILTER_TEST and (\\\n",
        "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.val_ids.append(allids[t])\n",
        "                    self.val_seq.append(allseq[t])\n",
        "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
        "            else:\n",
        "                if FILTER_TRAIN and (\\\n",
        "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.train_ids.append(allids[t])\n",
        "                    self.train_seq.append(allseq[t])\n",
        "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
        "    def get_ids(self):\n",
        "        return self.train_ids,self.val_ids\n",
        "    def get_seq(self):\n",
        "        return self.train_seq,self.val_seq\n",
        "    def get_rci(self):\n",
        "        return self.train_rci,self.val_rci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC9m0W-pFLBH",
        "outputId": "0d3fa697-5a38-4439-d06a-597ae292bf54",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:56.416451\n",
            "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.csv\n",
            "Number of RCI values loaded 4371\n",
            "Num RCI: 4371\n",
            "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
            "Loaded 4371 sequences.\n",
            "\n",
            "Training # 1 1\n",
            "2023-04-18 13:02:07.058642\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
            "2023-04-18 13:02:07.246042\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 939:1175 44.42%\n",
            "Valid 1:0 228:311 42.30%\n",
            "FIT\n",
            "2023-04-18 13:02:07.273581\n",
            "\n",
            "Testing # 1 1\n",
            "2023-04-18 13:03:01.765367\n",
            "2023-04-18 13:03:01.765432\n",
            "PREDICT\n",
            "2023-04-18 13:03:01.771106\n",
            "debug pred [0.4511863561144715, 0.13154434690077618, 0.20932085320507787]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 228:311 42.30%\n",
            "Predict 1:0 199:340 36.92%\n",
            "Test sizes (539, 1025) (539,)\n",
            "Distrib of scores: 0.435840841593967 mean 0.19598566452854405 std\n",
            "Range of scores: 0.06276745355293853 to 0.882280231860531\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[230  81]\n",
            " [110 118]]\n",
            "Normalized matrix\n",
            " [[0.42671614 0.15027829]\n",
            " [0.20408163 0.21892393]]\n",
            "Extreme scores correct, pos:neg 56 146\n",
            "Extreme scores incorrect pos:neg 34 54\n",
            "Accuracy: 64.56% Precision: 59.30% Recall: 51.75%\n",
            "F1: 55.27% MCC: 0.2632\n",
            "AUPRC: 60.48% AUROC: 69.00%\n",
            " accuracy [64.56400742115028]\n",
            " precision [59.2964824120603]\n",
            " recall [51.75438596491229]\n",
            " F1 [55.26932084309134]\n",
            " MCC [0.26319222399444125]\n",
            " AUPRC [60.47747365636971]\n",
            " AUROC [69.00208721159812]\n",
            "\n",
            "Training # 1 2\n",
            "2023-04-18 13:03:01.816935\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
            "2023-04-18 13:03:02.050243\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 926:1181 43.95%\n",
            "Valid 1:0 241:305 44.14%\n",
            "FIT\n",
            "2023-04-18 13:03:02.068254\n",
            "\n",
            "Testing # 1 2\n",
            "2023-04-18 13:03:57.588826\n",
            "2023-04-18 13:03:57.588887\n",
            "PREDICT\n",
            "2023-04-18 13:03:57.593018\n",
            "debug pred [0.45365937293624103, 0.48339801052804143, 0.07583867171961807]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 241:305 44.14%\n",
            "Predict 1:0 210:336 38.46%\n",
            "Test sizes (546, 1025) (546,)\n",
            "Distrib of scores: 0.44637128038184276 mean 0.19311276161310584 std\n",
            "Range of scores: 0.05834977581099977 to 0.9103423452618203\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[226  79]\n",
            " [110 131]]\n",
            "Normalized matrix\n",
            " [[0.41391941 0.14468864]\n",
            " [0.2014652  0.23992674]]\n",
            "Extreme scores correct, pos:neg 65 147\n",
            "Extreme scores incorrect pos:neg 38 48\n",
            "Accuracy: 65.38% Precision: 62.38% Recall: 54.36%\n",
            "F1: 58.09% MCC: 0.2904\n",
            "AUPRC: 63.98% AUROC: 69.97%\n",
            " accuracy [65.38461538461539]\n",
            " precision [62.38095238095238]\n",
            " recall [54.356846473029044]\n",
            " F1 [58.09312638580931]\n",
            " MCC [0.2904296196823669]\n",
            " AUPRC [63.98362483860049]\n",
            " AUROC [69.97211074076594]\n",
            "\n",
            "Training # 1 3\n",
            "2023-04-18 13:03:57.627458\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
            "2023-04-18 13:03:57.882507\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 951:1183 44.56%\n",
            "Valid 1:0 216:303 41.62%\n",
            "FIT\n",
            "2023-04-18 13:03:57.899254\n",
            "\n",
            "Testing # 1 3\n",
            "2023-04-18 13:04:52.307180\n",
            "2023-04-18 13:04:52.307571\n",
            "PREDICT\n",
            "2023-04-18 13:04:52.312845\n",
            "debug pred [0.384222456797031, 0.453501239540812, 0.07924577021190261]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 216:303 41.62%\n",
            "Predict 1:0 187:332 36.03%\n",
            "Test sizes (519, 1025) (519,)\n",
            "Distrib of scores: 0.4454814662806205 mean 0.18077517570539087 std\n",
            "Range of scores: 0.07767090353373945 to 0.8989389847189124\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[231  72]\n",
            " [101 115]]\n",
            "Normalized matrix\n",
            " [[0.44508671 0.13872832]\n",
            " [0.19460501 0.22157996]]\n",
            "Extreme scores correct, pos:neg 54 132\n",
            "Extreme scores incorrect pos:neg 33 40\n",
            "Accuracy: 66.67% Precision: 61.50% Recall: 53.24%\n",
            "F1: 57.07% MCC: 0.3027\n",
            "AUPRC: 58.73% AUROC: 69.68%\n",
            " accuracy [66.66666666666666]\n",
            " precision [61.49732620320856]\n",
            " recall [53.24074074074075]\n",
            " F1 [57.07196029776674]\n",
            " MCC [0.3026646703957888]\n",
            " AUPRC [58.72544997317482]\n",
            " AUROC [69.68280161349469]\n",
            "\n",
            "Training # 1 4\n",
            "2023-04-18 13:04:52.353860\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
            "2023-04-18 13:04:52.609741\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 936:1202 43.78%\n",
            "Valid 1:0 231:284 44.85%\n",
            "FIT\n",
            "2023-04-18 13:04:52.634211\n",
            "\n",
            "Testing # 1 4\n",
            "2023-04-18 13:05:46.984633\n",
            "2023-04-18 13:05:46.985095\n",
            "PREDICT\n",
            "2023-04-18 13:05:46.991354\n",
            "debug pred [0.30545067433401524, 0.3475372534350697, 0.42807737223825565]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 231:284 44.85%\n",
            "Predict 1:0 169:346 32.82%\n",
            "Test sizes (515, 1025) (515,)\n",
            "Distrib of scores: 0.425378929144714 mean 0.17694575068754276 std\n",
            "Range of scores: 0.05740337772304436 to 0.9180414737334949\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[219  65]\n",
            " [127 104]]\n",
            "Normalized matrix\n",
            " [[0.42524272 0.12621359]\n",
            " [0.24660194 0.20194175]]\n",
            "Extreme scores correct, pos:neg 45 136\n",
            "Extreme scores incorrect pos:neg 19 56\n",
            "Accuracy: 62.72% Precision: 61.54% Recall: 45.02%\n",
            "F1: 52.00% MCC: 0.2344\n",
            "AUPRC: 61.73% AUROC: 68.01%\n",
            " accuracy [62.71844660194175]\n",
            " precision [61.53846153846154]\n",
            " recall [45.02164502164502]\n",
            " F1 [52.0]\n",
            " MCC [0.2344498524478559]\n",
            " AUPRC [61.73262894064181]\n",
            " AUROC [68.01414547893422]\n",
            "\n",
            "Training # 1 5\n",
            "2023-04-18 13:05:47.035519\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
            "2023-04-18 13:05:47.271230\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 916:1203 43.23%\n",
            "Valid 1:0 251:283 47.00%\n",
            "FIT\n",
            "2023-04-18 13:05:47.295205\n",
            "\n",
            "Testing # 1 5\n",
            "2023-04-18 13:06:41.883951\n",
            "2023-04-18 13:06:41.884037\n",
            "PREDICT\n",
            "2023-04-18 13:06:41.887805\n",
            "debug pred [0.09872485812842054, 0.22306843359678707, 0.37151752520119863]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 251:283 47.00%\n",
            "Predict 1:0 193:341 36.14%\n",
            "Test sizes (534, 1025) (534,)\n",
            "Distrib of scores: 0.43276159130758707 mean 0.18487173603994783 std\n",
            "Range of scores: 0.05328409882670511 to 0.933102590050983\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[216  67]\n",
            " [125 126]]\n",
            "Normalized matrix\n",
            " [[0.40449438 0.12546816]\n",
            " [0.2340824  0.23595506]]\n",
            "Extreme scores correct, pos:neg 58 144\n",
            "Extreme scores incorrect pos:neg 21 51\n",
            "Accuracy: 64.04% Precision: 65.28% Recall: 50.20%\n",
            "F1: 56.76% MCC: 0.2756\n",
            "AUPRC: 67.33% AUROC: 70.62%\n",
            " accuracy [64.04494382022472]\n",
            " precision [65.28497409326425]\n",
            " recall [50.199203187250994]\n",
            " F1 [56.75675675675676]\n",
            " MCC [0.2755611744539461]\n",
            " AUPRC [67.32695170612486]\n",
            " AUROC [70.61647403319584]\n",
            "\n",
            "Training # 2 1\n",
            "2023-04-18 13:06:41.919168\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
            "2023-04-18 13:06:42.182416\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 941:1187 44.22%\n",
            "Valid 1:0 226:299 43.05%\n",
            "FIT\n",
            "2023-04-18 13:06:42.199634\n",
            "\n",
            "Testing # 2 1\n",
            "2023-04-18 13:07:36.996770\n",
            "2023-04-18 13:07:36.996848\n",
            "PREDICT\n",
            "2023-04-18 13:07:37.000730\n",
            "debug pred [0.38805264675694084, 0.1478727472555351, 0.31318918059937745]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 226:299 43.05%\n",
            "Predict 1:0 179:346 34.10%\n",
            "Test sizes (525, 1025) (525,)\n",
            "Distrib of scores: 0.425625581379321 mean 0.18917835914936101 std\n",
            "Range of scores: 0.06964248037393145 to 0.8990544205216866\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[218  81]\n",
            " [128  98]]\n",
            "Normalized matrix\n",
            " [[0.4152381  0.15428571]\n",
            " [0.24380952 0.18666667]]\n",
            "Extreme scores correct, pos:neg 45 140\n",
            "Extreme scores incorrect pos:neg 30 60\n",
            "Accuracy: 60.19% Precision: 54.75% Recall: 43.36%\n",
            "F1: 48.40% MCC: 0.1700\n",
            "AUPRC: 55.08% AUROC: 64.71%\n",
            " accuracy [60.1904761904762]\n",
            " precision [54.7486033519553]\n",
            " recall [43.36283185840708]\n",
            " F1 [48.39506172839506]\n",
            " MCC [0.16997316157292444]\n",
            " AUPRC [55.084397430501376]\n",
            " AUROC [64.70683990884068]\n",
            "\n",
            "Training # 2 2\n",
            "2023-04-18 13:07:37.030552\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
            "2023-04-18 13:07:37.239006\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 929:1189 43.86%\n",
            "Valid 1:0 238:297 44.49%\n",
            "FIT\n",
            "2023-04-18 13:07:37.255631\n",
            "\n",
            "Testing # 2 2\n",
            "2023-04-18 13:08:31.994807\n",
            "2023-04-18 13:08:31.994862\n",
            "PREDICT\n",
            "2023-04-18 13:08:31.999864\n",
            "debug pred [0.09576327605584044, 0.20448779029955122, 0.3135148344420218]\n",
            "debug class [0 0 0]\n",
            "Test 1:0 238:297 44.49%\n",
            "Predict 1:0 201:334 37.57%\n",
            "Test sizes (535, 1025) (535,)\n",
            "Distrib of scores: 0.4417916903374669 mean 0.19526503264927492 std\n",
            "Range of scores: 0.05575629145566005 to 0.9154744489134637\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[228  69]\n",
            " [106 132]]\n",
            "Normalized matrix\n",
            " [[0.42616822 0.12897196]\n",
            " [0.19813084 0.24672897]]\n",
            "Extreme scores correct, pos:neg 70 146\n",
            "Extreme scores incorrect pos:neg 25 46\n",
            "Accuracy: 67.29% Precision: 65.67% Recall: 55.46%\n",
            "F1: 60.14% MCC: 0.3307\n",
            "AUPRC: 66.31% AUROC: 72.90%\n",
            " accuracy [67.28971962616822]\n",
            " precision [65.67164179104478]\n",
            " recall [55.46218487394958]\n",
            " F1 [60.1366742596811]\n",
            " MCC [0.33071499153274253]\n",
            " AUPRC [66.30829727300201]\n",
            " AUROC [72.90269643210819]\n",
            "\n",
            "Training # 2 3\n",
            "2023-04-18 13:08:32.039302\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
            "2023-04-18 13:08:32.342922\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 924:1198 43.54%\n",
            "Valid 1:0 243:288 45.76%\n",
            "FIT\n",
            "2023-04-18 13:08:32.358944\n",
            "\n",
            "Testing # 2 3\n",
            "2023-04-18 13:09:27.047352\n",
            "2023-04-18 13:09:27.047440\n",
            "PREDICT\n",
            "2023-04-18 13:09:27.051207\n",
            "debug pred [0.48181261263474356, 0.9043313509227059, 0.35830677445618364]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 243:288 45.76%\n",
            "Predict 1:0 193:338 36.35%\n",
            "Test sizes (531, 1025) (531,)\n",
            "Distrib of scores: 0.4352263718973934 mean 0.17791768397343327 std\n",
            "Range of scores: 0.07114647618487932 to 0.9043313509227059\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[212  76]\n",
            " [126 117]]\n",
            "Normalized matrix\n",
            " [[0.3992467  0.14312618]\n",
            " [0.23728814 0.22033898]]\n",
            "Extreme scores correct, pos:neg 40 144\n",
            "Extreme scores incorrect pos:neg 25 56\n",
            "Accuracy: 61.96% Precision: 60.62% Recall: 48.15%\n",
            "F1: 53.67% MCC: 0.2254\n",
            "AUPRC: 62.16% AUROC: 68.57%\n",
            " accuracy [61.95856873822976]\n",
            " precision [60.62176165803109]\n",
            " recall [48.148148148148145]\n",
            " F1 [53.669724770642205]\n",
            " MCC [0.22537538562345572]\n",
            " AUPRC [62.15774246628667]\n",
            " AUROC [68.56852994970279]\n",
            "\n",
            "Training # 2 4\n",
            "2023-04-18 13:09:27.081568\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
            "2023-04-18 13:09:27.298842\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 953:1173 44.83%\n",
            "Valid 1:0 214:313 40.61%\n",
            "FIT\n",
            "2023-04-18 13:09:27.316266\n",
            "\n",
            "Testing # 2 4\n",
            "2023-04-18 13:10:21.513023\n",
            "2023-04-18 13:10:21.513414\n",
            "PREDICT\n",
            "2023-04-18 13:10:21.518629\n",
            "debug pred [0.4919602324192543, 0.5536494175299789, 0.4351891778052671]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 214:313 40.61%\n",
            "Predict 1:0 191:336 36.24%\n",
            "Test sizes (527, 1025) (527,)\n",
            "Distrib of scores: 0.4346874008795797 mean 0.18856951900118174 std\n",
            "Range of scores: 0.07558917979260489 to 0.9080746002404921\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[234  79]\n",
            " [102 112]]\n",
            "Normalized matrix\n",
            " [[0.44402277 0.14990512]\n",
            " [0.19354839 0.21252372]]\n",
            "Extreme scores correct, pos:neg 49 148\n",
            "Extreme scores incorrect pos:neg 31 48\n",
            "Accuracy: 65.65% Precision: 58.64% Recall: 52.34%\n",
            "F1: 55.31% MCC: 0.2768\n",
            "AUPRC: 55.53% AUROC: 67.65%\n",
            " accuracy [65.65464895635674]\n",
            " precision [58.63874345549738]\n",
            " recall [52.336448598130836]\n",
            " F1 [55.30864197530864]\n",
            " MCC [0.2768287881836627]\n",
            " AUPRC [55.530871319317086]\n",
            " AUROC [67.65101071929773]\n",
            "\n",
            "Training # 2 5\n",
            "2023-04-18 13:10:21.557581\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
            "2023-04-18 13:10:21.809691\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 921:1197 43.48%\n",
            "Valid 1:0 246:289 45.98%\n",
            "FIT\n",
            "2023-04-18 13:10:21.832862\n",
            "\n",
            "Testing # 2 5\n",
            "2023-04-18 13:11:15.337291\n",
            "2023-04-18 13:11:15.337344\n",
            "PREDICT\n",
            "2023-04-18 13:11:15.343753\n",
            "debug pred [0.3458950836217165, 0.6820949069323956, 0.2280524874336803]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 246:289 45.98%\n",
            "Predict 1:0 183:352 34.21%\n",
            "Test sizes (535, 1025) (535,)\n",
            "Distrib of scores: 0.4338832928726546 mean 0.17900502157114312 std\n",
            "Range of scores: 0.0873774685152696 to 0.9017141698696463\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[229  60]\n",
            " [123 123]]\n",
            "Normalized matrix\n",
            " [[0.42803738 0.11214953]\n",
            " [0.22990654 0.22990654]]\n",
            "Extreme scores correct, pos:neg 47 136\n",
            "Extreme scores incorrect pos:neg 19 52\n",
            "Accuracy: 65.79% Precision: 67.21% Recall: 50.00%\n",
            "F1: 57.34% MCC: 0.3072\n",
            "AUPRC: 65.66% AUROC: 70.34%\n",
            " accuracy [65.7943925233645]\n",
            " precision [67.21311475409836]\n",
            " recall [50.0]\n",
            " F1 [57.34265734265733]\n",
            " MCC [0.3071697643333185]\n",
            " AUPRC [65.66166054865587]\n",
            " AUROC [70.33926913663599]\n",
            "2023-04-18 13:11:15.373290\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "\n",
        "accuracy=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "mcc=[]\n",
        "auprc=[]\n",
        "auroc=[]\n",
        "\n",
        "loader = DataLoader()\n",
        "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
        "print(\"Load RCI from\",filepath)\n",
        "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "print('Num RCI:', len(gene_to_rci.keys()))\n",
        "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
        "print('Load sequence from',filepath)\n",
        "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
        "print('Loaded',len(allseq),'sequences.')\n",
        "test_gene_to_rci = None\n",
        "test_allids = None\n",
        "test_allseq = None\n",
        "if SEQ_FILE_TEST is not None:\n",
        "    # Train on the entire train set (no cross-validation).\n",
        "    # Evaluate with the test files.\n",
        "    test_loader = DataLoader()\n",
        "    filepath = DATA_DIR+RCI_FILE_TEST\n",
        "    print(\"Load RCI from\",filepath)\n",
        "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
        "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
        "    print('Load sequence from',filepath)\n",
        "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
        "    print('Loaded',len(test_allseq),'sequences.')\n",
        "\n",
        "for repeat in range(REPEATS):\n",
        "    for fold in range(FOLDS):\n",
        "        show_r = repeat+1  # display one-based counting\n",
        "        show_f = fold+1    # display one-based counting\n",
        "\n",
        "        print()\n",
        "        print(\"Training #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo = CrossValidator(EPOCHS)\n",
        "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
        "        if SEQ_FILE_TEST is None:\n",
        "            # Train on 80% and evaluate on 20%.\n",
        "            separator = Separator()\n",
        "            separator.load(DATA_DIR,show_r,show_f)\n",
        "            separator.process(allids,allseq,gene_to_rci)\n",
        "            train_allids,test_allids = separator.get_ids()\n",
        "            train_allseq,test_allseq = separator.get_seq()\n",
        "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                test_allids,test_allseq,test_gene_to_rci)\n",
        "            if SAVE_MODEL_FILENAME is not None:\n",
        "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
        "                cvdo.save_model(filename)\n",
        "        else:\n",
        "            # Train on the entire train set (no cross-validation).\n",
        "            # Evaluate with the test files.\n",
        "            train_allids = allids\n",
        "            train_allseq = allseq\n",
        "            train_gene_to_rci = gene_to_rci\n",
        "            BREAK = True\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                None,None,None)\n",
        "\n",
        "        print()\n",
        "        print(\"Testing #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo.reset_statistics()\n",
        "        cvdo.test_without_training(\n",
        "            test_allids,test_allseq,test_gene_to_rci)\n",
        "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
        "            cvdo.get_statistics()\n",
        "\n",
        "        print(\" accuracy\" ,  cv_accuracy)\n",
        "        print(\" precision\" , cv_precision)\n",
        "        print(\" recall\" ,    cv_recall)\n",
        "        print(\" F1\" ,        cv_f1)\n",
        "        print(\" MCC\" ,       cv_mcc)\n",
        "        print(\" AUPRC\" ,     cv_auprc)\n",
        "        print(\" AUROC\" ,     cv_auroc)\n",
        "\n",
        "        accuracy.append(cv_accuracy)\n",
        "        precision.append(cv_precision)\n",
        "        recall.append(cv_recall)\n",
        "        f1.append(cv_f1)\n",
        "        mcc.append(cv_mcc)\n",
        "        auprc.append(cv_auprc)\n",
        "        auroc.append(cv_auroc)\n",
        "        if BREAK: break\n",
        "    if BREAK: break\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkCeDg_HdQ36",
        "outputId": "54a15f02-1bc3-4d69-a6ec-ef0f1c436bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy mean 64.43% std 2.23\n",
            " precision mean 61.69% std 3.71\n",
            " recall mean 50.39% std 3.93\n",
            " F1 mean 55.40% std 3.36\n",
            " MCC mean 0.2676 std 0.0470\n",
            " AUPRC mean 61.70% std 4.30\n",
            " AUROC mean 69.15% std 2.17\n",
            " accuracy [[64.56400742115028], [65.38461538461539], [66.66666666666666], [62.71844660194175], [64.04494382022472], [60.1904761904762], [67.28971962616822], [61.95856873822976], [65.65464895635674], [65.7943925233645]]\n",
            " precision [[59.2964824120603], [62.38095238095238], [61.49732620320856], [61.53846153846154], [65.28497409326425], [54.7486033519553], [65.67164179104478], [60.62176165803109], [58.63874345549738], [67.21311475409836]]\n",
            " recall [[51.75438596491229], [54.356846473029044], [53.24074074074075], [45.02164502164502], [50.199203187250994], [43.36283185840708], [55.46218487394958], [48.148148148148145], [52.336448598130836], [50.0]]\n",
            " F1 [[55.26932084309134], [58.09312638580931], [57.07196029776674], [52.0], [56.75675675675676], [48.39506172839506], [60.1366742596811], [53.669724770642205], [55.30864197530864], [57.34265734265733]]\n",
            " MCC [[0.26319222399444125], [0.2904296196823669], [0.3026646703957888], [0.2344498524478559], [0.2755611744539461], [0.16997316157292444], [0.33071499153274253], [0.22537538562345572], [0.2768287881836627], [0.3071697643333185]]\n",
            " AUPRC [[60.47747365636971], [63.98362483860049], [58.72544997317482], [61.73262894064181], [67.32695170612486], [55.084397430501376], [66.30829727300201], [62.15774246628667], [55.530871319317086], [65.66166054865587]]\n",
            " AUROC [[69.00208721159812], [69.97211074076594], [69.68280161349469], [68.01414547893422], [70.61647403319584], [64.70683990884068], [72.90269643210819], [68.56852994970279], [67.65101071929773], [70.33926913663599]]\n"
          ]
        }
      ],
      "source": [
        "def STD (values):\n",
        "    # ddof=1 reduces bias when extrapolating from sample to population\n",
        "    return np.std(values,ddof=1)\n",
        "\n",
        "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
        "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
        "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
        "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
        "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
        "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
        "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
        "\n",
        "print(\" accuracy\"  , accuracy)\n",
        "print(\" precision\" , precision)\n",
        "print(\" recall\"    , recall)\n",
        "print(\" F1\"        , f1)\n",
        "print(\" MCC\"       , mcc)\n",
        "print(\" AUPRC\"     , auprc)\n",
        "print(\" AUROC\"     , auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjSVa72v4IsA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}