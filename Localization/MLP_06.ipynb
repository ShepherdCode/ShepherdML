{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 04:17:06.219023\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import math\n",
    "import random\n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LayerNormalization\n",
    "\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx(dt)\n",
    "\n",
    "from KmerCounter import KmerCounter\n",
    "K=4\n",
    "counter = KmerCounter()\n",
    "counter.setK(K)\n",
    "VOCABULARY_SIZE = counter.get_vocabulary_size()\n",
    "\n",
    "from TrainValidSplit import Splitter\n",
    "EPOCHS=10\n",
    "SPLITS=3\n",
    "EMBED_DIMEN=16\n",
    "\n",
    "from cell_lines import Cell_Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS_DIR = '/Users/jasonmiller/WVU/Localization/LncAtlas/'\n",
    "RCI_FILE = 'CNRCI_coding_train_genes.csv'\n",
    "GENCODE_DIR = '/Users/jasonmiller/WVU/Localization/GenCode/'\n",
    "SEQUENCE_FILE = 'Homo_sapiens.GRCh38.cds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 0 A549\n"
     ]
    }
   ],
   "source": [
    "all_cell_lines = Cell_Lines.get_ordered_list()\n",
    "cell_line_number = 0\n",
    "cell_line_name = all_cell_lines[cell_line_number]\n",
    "print('Cell line for today:',cell_line_number,cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 04:17:18.321603\n",
      "Genes: 14216\n",
      "Gene labels: 10392\n",
      "Positive labels: 5412\n"
     ]
    }
   ],
   "source": [
    "def load_labels(atlas_file,cells):\n",
    "    gene_labels = {}\n",
    "    with open(atlas_file,'r') as atlas:\n",
    "        header = None\n",
    "        genes_considered = 0\n",
    "        positives = 0\n",
    "        csv = reader(atlas)\n",
    "        for row in csv:\n",
    "            if header is None:\n",
    "                header = row\n",
    "            else:\n",
    "                gene = row[0]\n",
    "                genes_considered += 1\n",
    "                rci = float(row[1+cells])\n",
    "                if not math.isnan(rci):\n",
    "                    # GENERATE BINARY LABELS\n",
    "                    label = 0   # RCI<0\n",
    "                    if rci>=0:  # THRESHOLD\n",
    "                        label = 1   #RCI>=0\n",
    "                        positives += 1\n",
    "                    gene_labels[gene]=label\n",
    "    print('Genes:',genes_considered)\n",
    "    print('Gene labels:',len(gene_labels))\n",
    "    print('Positive labels:',positives)\n",
    "    return gene_labels\n",
    "    \n",
    "print(datetime.now())\n",
    "atlas_path = ATLAS_DIR+RCI_FILE\n",
    "gene_label = load_labels(atlas_path,cell_line_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(gencode_file,gene_label):\n",
    "    gid_tid = []\n",
    "    labels = []\n",
    "    tseqs = []\n",
    "    with open(gencode_file,'r') as gencode:\n",
    "        header = None\n",
    "        csv = reader(gencode)\n",
    "        for row in csv:\n",
    "            if header is None:\n",
    "                header = row\n",
    "            else:\n",
    "                tran_id = row[0]\n",
    "                gene_id = row[1]\n",
    "                tseq = row[4]\n",
    "                if gene_id in gene_label:\n",
    "                    label = gene_label[gene_id]\n",
    "                    gid_tid.append ((gene_id,tran_id))\n",
    "                    labels.append(label)\n",
    "                    tseqs.append(tseq)\n",
    "    return gid_tid,labels,tseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 04:17:18.428533\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "gencode_path = GENCODE_DIR+SEQUENCE_FILE\n",
    "ordered_gid_tid,ordered_labels,ordered_seqs = \\\n",
    "    load_sequences(gencode_path,gene_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 04:18:24.547609\n",
      ".....................................................\n",
      "2022-10-11 04:25:59.889751\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "ordered_kmer_counts = []\n",
    "tock = 1000\n",
    "tick = 0\n",
    "for seq in ordered_seqs:\n",
    "    tick += 1\n",
    "    if tick >= tock:\n",
    "        tick = 1\n",
    "        print('.',end='')\n",
    "    counts = counter.seq_to_kmer_counts(seq)\n",
    "    ordered_kmer_counts.append(counts)\n",
    "print()\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter=Splitter(ordered_gid_tid,ordered_kmer_counts,ordered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    act=\"sigmoid\"\n",
    "    #embed_layer  = keras.layers.Embedding(\n",
    "    #    VOCABULARY_SIZE,EMBED_DIMEN,input_length=maxlen);\n",
    "    dense1_layer = keras.layers.Dense(64, activation=act,dtype=dt,\n",
    "                                      input_dim=VOCABULARY_SIZE)\n",
    "    dense2_layer = keras.layers.Dense(64, activation=act,dtype=dt)\n",
    "    dense3_layer = keras.layers.Dense(64, activation=act,dtype=dt)\n",
    "    #output_layer = keras.layers.Dense(1,  activation=\"softmax\",dtype=dt)\n",
    "    output_layer = keras.layers.Dense(1,  activation=act,dtype=dt)\n",
    "\n",
    "    mlp = keras.models.Sequential()\n",
    "    #mlp.add(embed_layer)\n",
    "    mlp.add(dense1_layer)\n",
    "    mlp.add(dense2_layer)\n",
    "    mlp.add(dense3_layer)\n",
    "    mlp.add(output_layer)\n",
    "    \n",
    "    # Logit=True ranges from + to - infinity.\n",
    "    # Logit=False i.e. probabilities range from 0 to 1.\n",
    "    # If your output layer has a 'softmax' activation, from_logits should be False. If your output layer doesn't have a 'softmax' activation, from_logits should be True. \n",
    "    bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    mlp.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,eps):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    PARTITIONS=5\n",
    "    # PARTITIONS=1   # for testing\n",
    "    for i in range(PARTITIONS):\n",
    "        X_train,y_train,X_valid,y_valid = \\\n",
    "            splitter.train_valid_split(i,PARTITIONS)\n",
    "        print('Fold',i)\n",
    "        print('Train set ones/size',\n",
    "              np.count_nonzero(y_train),'/',len(y_train))\n",
    "        print('Valid set ones/size',\n",
    "              np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model()\n",
    "\n",
    "        print(\"FIT\")\n",
    "        # this is complaining about string to float\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=eps, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "                        \n",
    "        fold += 1\n",
    "        print(\"Fold %d, %d epochs\"%(fold,eps))\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        # What are the other metrics_names?\n",
    "        # Try this from Geron page 505:\n",
    "        # np.mean(keras.losses.mean_squared_error(y_valid,y_pred))\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    print()\n",
    "    print(\"Validation core mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 04:30:51.110292\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,833\n",
      "Trainable params: 24,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Sequence to Kmer\n",
      "Cross valiation\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Splitter.train_valid_split() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m ordered_kmer_counts\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross valiation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdo_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, eps)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# PARTITIONS=1   # for testing\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(PARTITIONS):\n\u001b[1;32m      8\u001b[0m     X_train,y_train,X_valid,y_valid \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m----> 9\u001b[0m         \u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_valid_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPARTITIONS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain set ones/size\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m           np\u001b[38;5;241m.\u001b[39mcount_nonzero(y_train),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(y_train))\n",
      "\u001b[0;31mTypeError\u001b[0m: Splitter.train_valid_split() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once\n",
    "\n",
    "print (\"Sequence to Kmer\")\n",
    "y = ordered_labels\n",
    "X = ordered_kmer_counts\n",
    "\n",
    "print (\"Cross valiation\")\n",
    "do_cross_validation(X,y,EPOCHS)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "Do train/valid split with respect to genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
