{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# LSTM\n",
    "Use sequence from GenCode files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "d04193cd-4111-40fa-bb51-1fa51af9cdc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:36:31.726743\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUtGXPrcFLA8"
   },
   "source": [
    "We prevously used sklearn.model_selection.ShuffleSplit   \n",
    "Now we avoid it due to this note in the \n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
    "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRX-UEr8FLA8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "EPOCHS=5\n",
    "FOLDS=5   # but terminate after one\n",
    "EMBED_DIMEN=4\n",
    "MAXLEN=4000   # this is problematic as some genes will be excluded entirely or partially\n",
    "MINLEN=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "7c57c098-eccd-4905-fad3-2aa816011189"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'    # Mac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "GENES_FILE =    'CNRCI_coding_train_genes.csv'\n",
    "RCI_FILE =      'CNRCI_coding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_coding_train_transcripts.gc42.csv'\n",
    "COUNTS_FILE=    'CNRCI_coding_train_counts.K4.gc42.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3p4QzQJFLA_",
    "outputId": "2c692462-eb3d-4ada-e73c-7f836aced655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 0 = A549\n"
     ]
    }
   ],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549',\\\n",
    "      'H1.hESC',\\\n",
    "      'HeLa.S3',\\\n",
    "      'HepG2',\\\n",
    "      'HT1080',\\\n",
    "      'HUVEC',\\\n",
    "      'MCF.7',\\\n",
    "      'NCI.H460',\\\n",
    "      'NHEK',\\\n",
    "      'SK.MEL.5',\\\n",
    "      'SK.N.DZ',\\\n",
    "      'SK.N.SH',\\\n",
    "      'GM12878',\\\n",
    "      'K562',\\\n",
    "      'IMR.90']\n",
    "    return ordered_list\n",
    "CELL_LINE_NUMBER=0\n",
    "all_cell_lines = get_ordered_list()\n",
    "cell_line_name = all_cell_lines[CELL_LINE_NUMBER]\n",
    "print('Cell line for today:',CELL_LINE_NUMBER,'=',cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYoYDc93FLBB",
    "outputId": "333d4012-8039-440c-9c5a-4e3a2a1e39a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:36:47.897212\n",
      "Num RCI: 10338\n",
      "[('ENSG00000000003', 1.08068), ('ENSG00000000419', 1.32679), ('ENSG00000000457', 0.434284)]\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "# labels\n",
    "filepath = DATA_DIR+RCI_FILE\n",
    "gene_to_rci = {}\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line = row.strip()\n",
    "            fields = line.split(',')\n",
    "            gene_id = fields[0]\n",
    "            rci_val = fields[CELL_LINE_NUMBER+1]\n",
    "            # Could implement Gudenas style threshold here\n",
    "            if rci_val != \"nan\":\n",
    "                gene_to_rci[gene_id] = float(rci_val)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "print(list(gene_to_rci.items())[:3])\n",
    "all_genes = list(gene_to_rci.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGTACATTT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def simulate_RNA(length):\n",
    "    bases = list('ACGT')\n",
    "    seq = ''\n",
    "    for i in range(length):\n",
    "        rnd = random.randrange(4)\n",
    "        nuc = bases[rnd]\n",
    "        seq += nuc\n",
    "    return seq\n",
    "print(simulate_RNA(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooyTeQr-FLBB",
    "outputId": "29f504f6-fe47-45a8-e40e-dd064e15ab5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:36:47.986291\n",
      "Load sequence\n",
      "2022-11-13 18:41:56.106935\n",
      "Num IDs: 5579\n",
      "Num labels: 5579\n",
      "Num counts: 5579\n"
     ]
    }
   ],
   "source": [
    "# one hot\n",
    "print(datetime.now())\n",
    "print('Load sequence')\n",
    "filepath = DATA_DIR+SEQUENCE_FILE\n",
    "labels=[]\n",
    "allids=[]\n",
    "allseq=[]\n",
    "NREPEAT = str('N'*MAXLEN)\n",
    "HOTS = {'A':[1,0,0,0], 'C':[0,1,0,0], 'G':[0,0,1,0], 'T':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line    = row.strip()\n",
    "            fields  = line.split(',')\n",
    "            tran_id = fields[0]  # with version number\n",
    "            gene_id = fields[1]        # without version number\n",
    "            seq_len = int(fields[3])\n",
    "            seq_txt = fields[4]\n",
    "            seq_txt = simulate_RNA(4000)\n",
    "            if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                rci_val = gene_to_rci[gene_id]\n",
    "                allids.append( (gene_id,tran_id) )\n",
    "                labels.append(rci_val)\n",
    "                if seq_len<MAXLEN:\n",
    "                    seq_txt = seq_txt + NREPEAT\n",
    "                    seq_txt = seq_txt[:MAXLEN]\n",
    "                seq_chr = list(seq_txt)\n",
    "                seq_hot = []\n",
    "                for c in seq_chr:\n",
    "                    one_hot = HOTS[c]\n",
    "                    seq_hot.append(one_hot)\n",
    "                allseq.append(seq_hot)\n",
    "print(datetime.now())\n",
    "print('Num IDs:',len(allids))\n",
    "#print('Examples:',[allids[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num labels:',len(labels))\n",
    "#print('Examples:',[labels[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num counts:',len(allseq))\n",
    "#print('Example:',allseq[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "def get_gene_subset(all_genes,sub_index):\n",
    "    sub_genes = set()\n",
    "    for index in sub_index:\n",
    "        one_gene = all_genes[index]\n",
    "        sub_genes.add(one_gene)\n",
    "    return sub_genes\n",
    "def get_X_y(gene_set,allids,allX,allY,threshold):\n",
    "    cnt = len(allids)\n",
    "    subsetX=[]\n",
    "    subsetY=[]\n",
    "    if cnt != len(allX) or cnt!= len(allY):\n",
    "        raise Exception('Lengths differ')\n",
    "    for i in range(cnt):\n",
    "        gene_id,tran_id = allids[i]\n",
    "        if gene_id in gene_set:\n",
    "            oneX = allX[i]\n",
    "            oneY = allY[i]\n",
    "            if oneY < threshold:\n",
    "                Yvalue = int(0)\n",
    "            else:\n",
    "                Yvalue = int(1)\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(Yvalue)\n",
    "    subsetX = np.array(subsetX)\n",
    "    subsetY = np.array(subsetY).reshape((-1,1))\n",
    "    return subsetX,subsetY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AwMbRjm0FLBF"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    DIMEN=4  # ONE HOT CATEGORIES\n",
    "    rnn = Sequential()\n",
    "    # embed_layer = Embedding(DIMEN,EMBED_DIMEN,input_length=MAXLEN);\n",
    "    # rnn1_layer = Bidirectional(\n",
    "    # rnn1_layer = LSTM(16, return_sequences=True, input_shape=[MAXLEN,DIMEN]) \n",
    "    rnn1_layer = LSTM(16, input_shape=[MAXLEN,DIMEN]) \n",
    "    # rnn2_layer = LSTM(16, return_sequences=True)\n",
    "    # Dense can handle sequence input. Is it the best thing to do?\n",
    "    dense1_layer = Dense(8,activation='sigmoid',dtype=dt)\n",
    "    # dropout1_layer = Dropout(0.25)\n",
    "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
    "\n",
    "    #rnn.add(embed_layer)\n",
    "    rnn.add(rnn1_layer)\n",
    "    #rnn.add(rnn2_layer)\n",
    "    rnn.add(dense1_layer)\n",
    "    #rnn.add(dropout1_layer)\n",
    "    #rnn.add(dense2_layer)\n",
    "    rnn.add(output_layer)\n",
    "\n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE\")\n",
    "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clj-wufgFLBF",
    "outputId": "a5d9ec4c-9131-4d7d-83aa-d44703327026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:41:56.219931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:41:56.225347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILE\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                1344      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,489\n",
      "Trainable params: 1,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print(model.summary())  # Print this only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqO0a9evFLBG",
    "outputId": "989e513a-9e3b-4828-c60d-8610dc164ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:41:57.106539\n"
     ]
    }
   ],
   "source": [
    "SCALING = False\n",
    "def do_cross_validation(eps):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    print(datetime.now())\n",
    "    print('splitting')\n",
    "    # KFold shuffles once before making the partitions\n",
    "    splitter = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n",
    "    for train_index,valid_index in splitter.split(all_genes):\n",
    "        fold += 1\n",
    "        print('Fold',fold)\n",
    "        train_genes = get_gene_subset(all_genes,train_index)\n",
    "        valid_genes = get_gene_subset(all_genes,valid_index)\n",
    "        X_train,y_train = get_X_y(train_genes,allids,allseq,labels,0)\n",
    "        X_valid,y_valid = get_X_y(valid_genes,allids,allseq,labels,0)\n",
    "\n",
    "        if SCALING:\n",
    "            print('scaling')\n",
    "            print(datetime.now())\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_valid = scaler.transform(X_valid)\n",
    "\n",
    "        print('Train sizes',X_train.shape,y_train.shape)\n",
    "        print('Valid sizes',X_valid.shape,y_valid.shape)\n",
    "        print('Train set ones/size',\n",
    "              np.count_nonzero(y_train),'/',len(y_train))\n",
    "        print('Valid set ones/size',\n",
    "              np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model()\n",
    "\n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Compute valiation accuracy\")\n",
    "        print(datetime.now())\n",
    "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(datetime.now())\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "        \n",
    "        break  # just do one round!\n",
    "        \n",
    "    print()\n",
    "    return cv_scores\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFEy7jQYFLBG"
   },
   "source": [
    "Issues to address:\n",
    "\n",
    "Reduce dtype to int8?\n",
    "Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n",
    "inputs=tf.Tensor(shape=(None, 4000, 4), dtype=int32)\n",
    "\n",
    "The genes were shuffled but the transcripts were not.  \n",
    "That could retard training.\n",
    "\n",
    "Loading sequence takes minutes. Save one-hot dataset to binary file. \n",
    "\n",
    "Loading sequence takes RAM. A numpy array of one-hot might require less RAM. Write a just-in-time loader.\n",
    "\n",
    "Accuracy goes down at the start of each epoch. This could mean that the data are not shuffled sufficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "4468c74c-5c38-4803-fec4-7c39b1b0a301",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-13 18:41:57.123819\n",
      "2022-11-13 18:41:57.124310\n",
      "splitting\n",
      "Fold 1\n",
      "Train sizes (4473, 4000, 4) (4473, 1)\n",
      "Valid sizes (1106, 4000, 4) (1106, 1)\n",
      "Train set ones/size 1989 / 4473\n",
      "Valid set ones/size 487 / 1106\n",
      "BUILD MODEL\n",
      "COMPILE\n",
      "FIT\n",
      "2022-11-13 18:42:20.962191\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 200s 1s/step - loss: 0.6884 - accuracy: 0.5529 - val_loss: 0.6869 - val_accuracy: 0.5597\n",
      "Epoch 2/5\n",
      "106/140 [=====================>........] - ETA: 39s - loss: 0.6878 - accuracy: 0.5531"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "cv_scores = do_cross_validation(EPOCHS)    \n",
    "print(\"Cross validation acc mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riMTsEsCFLBJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
