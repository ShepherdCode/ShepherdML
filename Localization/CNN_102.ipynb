{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# CNN + LSTM \n",
        "With restructured code from LSTM 127 notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "fde87c03-5480-48b8-9216-505a20ceb2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-17 20:04:20.616964\n",
            "Python 3.8.16\n",
            "sklearn 1.0.2\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())\n",
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUtGXPrcFLA8"
      },
      "source": [
        "We prevously used sklearn.model_selection.ShuffleSplit   \n",
        "Now we avoid it due to this note in the \n",
        "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html):\n",
        "Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PRX-UEr8FLA8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) \n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "K=4\n",
        "RCI_THRESHOLD=0.0\n",
        "CFILTERS=16\n",
        "FILTERSIZE=10\n",
        "RCELLS=16\n",
        "EPOCHS=5\n",
        "FOLDS=5      \n",
        "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
        "BREAK = True   # break after first fold\n",
        "MINLEN=1000\n",
        "MAXLEN=2000   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "b6d48e84-16ee-4ff2-8fd4-040945d7dca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data/Localization/TrainTest/\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
        "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'    # Mac\n",
        "print(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LnkpVKdMFLA-"
      },
      "outputs": [],
      "source": [
        "GENES_FILE =    'CNRCI_coding_train_genes.csv'\n",
        "RCI_FILE =      'CNRCI_coding_train_RCI.gc42.csv'\n",
        "SEQUENCE_FILE = 'CNRCI_coding_train_transcripts.gc42.csv'\n",
        "COUNTS_FILE=    'CNRCI_coding_train_counts.K4.gc42.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3p4QzQJFLA_",
        "outputId": "3d1be703-e03a-41c0-9bf4-7a2182f0791e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell line for today: 1 = H1.hESC\n"
          ]
        }
      ],
      "source": [
        "def get_ordered_list():\n",
        "    ordered_list = \\\n",
        "    ['A549',\\\n",
        "      'H1.hESC',\\\n",
        "      'HeLa.S3',\\\n",
        "      'HepG2',\\\n",
        "      'HT1080',\\\n",
        "      'HUVEC',\\\n",
        "      'MCF.7',\\\n",
        "      'NCI.H460',\\\n",
        "      'NHEK',\\\n",
        "      'SK.MEL.5',\\\n",
        "      'SK.N.DZ',\\\n",
        "      'SK.N.SH',\\\n",
        "      'GM12878',\\\n",
        "      'K562',\\\n",
        "      'IMR.90']\n",
        "    return ordered_list\n",
        "CELL_LINE_NUMBER=1\n",
        "all_cell_lines = get_ordered_list()\n",
        "cell_line_name = all_cell_lines[CELL_LINE_NUMBER]\n",
        "print('Cell line for today:',CELL_LINE_NUMBER,'=',cell_line_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5218098-d0c7-447e-95bc-46db849f2714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1]\n",
            "[20, 16]\n",
            "[63, 57]\n",
            "[64, 0]\n",
            "0\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        self.cache=dict() \n",
        "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "        \n",
        "    def load_gene_rci_values(self,filepath,cell_line):\n",
        "        '''\n",
        "        Load from RCI csv file.\n",
        "        Return dict with keys=gene:str and values=RCI:float.\n",
        "        '''\n",
        "        gene_to_rci = {}\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row # skip file's header line\n",
        "                else:\n",
        "                    line = row.strip()\n",
        "                    fields = line.split(',')\n",
        "                    gene_id = fields[0]\n",
        "                    rci_val = fields[cell_line+1]\n",
        "                    if rci_val != \"nan\":\n",
        "                        # Convert string nan to float(nan)\n",
        "                        gene_to_rci[gene_id] = float(rci_val)\n",
        "        return gene_to_rci\n",
        "    \n",
        "    def seq_to_kmer_values(self,rna,K):\n",
        "        # The cache may represent more than one K. Probably not a problem.\n",
        "        N_indicator = 0 # indicator value\n",
        "        vec=[] # seq converted to list of K-mers \n",
        "        length = len(rna)\n",
        "        for i in range(length-K+1):\n",
        "            kmer = rna[i:i+K]\n",
        "            if 'N' in kmer:\n",
        "                value = N_indicator\n",
        "            elif kmer in self.cache.keys():\n",
        "                value = self.cache[kmer]\n",
        "            else:\n",
        "                value = 0\n",
        "                for j in range(K):\n",
        "                    value *= 4   \n",
        "                    nextnuc = kmer[j] \n",
        "                    nucval = self.vals[nextnuc]\n",
        "                    value += nucval\n",
        "                value += 1   # NNN => 0, AAA => 1\n",
        "                self.cache[kmer] = value\n",
        "            vec.append(value)\n",
        "        return vec\n",
        "\n",
        "    def rci_to_label(self,rci):\n",
        "        CYTO_LABEL = 1\n",
        "        NUCLEAR_LABEL = 0\n",
        "        # cnrci = log (cyto-to-nuclear ratio)\n",
        "        # rci > 0 implies cytoplasmic\n",
        "        if rci > RCI_THRESHOLD:\n",
        "            return CYTO_LABEL\n",
        "        return NUCLEAR_LABEL\n",
        "\n",
        "    def load_sequence(self,filepath):\n",
        "        labels=[]\n",
        "        allids=[]\n",
        "        allseq=[]\n",
        "        NREPEAT = str('N'*MAXLEN)\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row\n",
        "                else:\n",
        "                    line    = row.strip()\n",
        "                    fields  = line.split(',')\n",
        "                    tran_id = fields[0]  # with version number\n",
        "                    gene_id = fields[1]        # without version number\n",
        "                    seq_len = int(fields[3])\n",
        "                    seq_txt = fields[4]\n",
        "                    if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
        "                        allids.append( (gene_id,tran_id) )\n",
        "                        rci_val = gene_to_rci[gene_id]\n",
        "                        rci_label = self.rci_to_label(rci_val)\n",
        "                        labels.append(rci_label)\n",
        "                        if seq_len<MAXLEN:\n",
        "                            seq_txt = seq_txt + NREPEAT\n",
        "                            seq_txt = seq_txt[:MAXLEN]\n",
        "                        hot_vec = self.seq_to_kmer_values(seq_txt,K)\n",
        "                        allseq.append(hot_vec)\n",
        "        return labels,allids,allseq\n",
        "    \n",
        "loader = DataLoader()\n",
        "# test it\n",
        "print(loader.seq_to_kmer_values('AAAA',3))\n",
        "print(loader.seq_to_kmer_values('CATT',3))\n",
        "print(loader.seq_to_kmer_values('TTGA',3))\n",
        "print(loader.seq_to_kmer_values('TTTN',3))\n",
        "# test it\n",
        "print(loader.rci_to_label(-0.9))\n",
        "print(loader.rci_to_label(1.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYoYDc93FLBB",
        "outputId": "efc427eb-3fc5-4bbe-cf6e-6113b0dcdc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-17 20:04:41.515402\n",
            "Load RCI values...\n",
            "Num RCI: 13000\n",
            "Example RCI: [('ENSG00000000003', 1.85734), ('ENSG00000000005', 5.88264), ('ENSG00000000419', 2.58954)]\n",
            "Load genes...\n",
            "2022-12-17 20:04:42.609951\n",
            "Load sequence...\n",
            "2022-12-17 20:04:53.458911\n",
            "Num IDs: 13143\n",
            "Example IDs: [('ENSG00000186827', 'ENST00000379236.4'), ('ENSG00000127054', 'ENST00000620829.4'), ('ENSG00000235098', 'ENST00000520296.5'), ('ENSG00000187730', 'ENST00000638411.1')]\n",
            "Count 6959 ones out of 13143 labels.\n",
            "Example labels: [0, 0, 0, 0]\n",
            "Num counts: 13143\n",
            "Example sequence: [60, 238, 182, 213, 81, 67, 11, 43, 171, 169, 164, 142, 54, 216, 95, 122, 229, 147, 75, 44, 175, 186, 229, 148, 78, 54, 216, 94, 118, 215, 89, 100, 142, 56, 223, 122, 231, 153, 98, 136, 31, 122, 230, 150, 87, 91, 107, 170, 168, 159, 122, 230, 151, 89, 97, 132, 13, 52, 206, 54, 216, 94, 118, 214, 86, 87, 91, 108, 175, 185, 225, 130, 6, 23, 91, 107, 171, 171, 170, 167, 155, 106, 168, 159, 123, 234, 165, 147, 73, 34, 133, 17, 67, 9, 35, 139, 41, 162, 133, 19, 76, 46, 183, 218, 102, 150, 88, 95, 122, 230, 152, 95, 122, 230, 151, 90, 102, 150, 87, 91, 105, 161, 130, 6, 24, 95, 121, 225, 131, 9, 33, 131, 11, 41, 163, 138, 39, 153, 97, 130, 8, 30, 118, 214, 85, 83, 74, 40, 160, 126, 248, 222, 120, 223, 122, 230, 149, 83, 74, 39, 153, 100, 143, 59, 236, 175, 185, 226, 133, 19, 74, 39, 153, 98, 135, 27, 107, 169, 163, 140, 47, 187, 234, 166, 150, 86, 85, 82, 70, 24, 95, 124, 239, 187, 235, 170, 167, 155, 106, 167, 155, 106, 166, 149, 83, 75, 42, 168, 160, 127, 249, 225, 131, 10, 37, 147, 75, 41, 163, 139, 41, 164, 143, 59, 236, 174, 182, 215, 90, 101, 146, 69, 20, 78, 54, 215, 92, 109, 180, 206, 53, 212, 79, 57, 225, 131, 9, 35, 137, 33, 131, 9, 35, 140, 46, 182, 213, 82, 69, 18, 70, 22, 85, 82, 72, 31, 123, 235, 169, 162, 135, 28, 111, 185, 225, 130, 5, 20, 78, 56, 222, 120, 224, 128, 254, 246, 215, 89, 99, 137, 35, 139, 42, 167, 156, 110, 182, 216, 95, 122, 229, 147, 74, 38, 149, 83, 75, 41, 162, 135, 27, 106, 165, 145, 66, 6, 24, 96, 126, 246, 214, 85, 82, 70, 22, 88, 94, 117, 212, 77, 52, 206, 54, 213, 83, 74, 39, 156, 110, 182, 213, 82, 70, 23, 90, 101, 147, 74, 38, 151, 90, 102, 149, 82, 70, 24, 94, 119, 220, 112, 189, 244, 207, 58, 230, 150, 87, 89, 99, 138, 37, 148, 78, 53, 211, 73, 35, 138, 38, 151, 90, 104, 159, 124, 239, 185, 225, 132, 16, 62, 246, 213, 83, 73, 35, 137, 35, 139, 42, 165, 147, 74, 38, 152, 95, 123, 233, 163, 137, 36, 144, 63, 251, 234, 166, 152, 95, 122, 231, 153, 98, 134, 22, 87, 90, 102, 151, 91, 108, 175, 185, 226, 134, 24, 95, 124, 240, 191, 251, 235, 170, 165, 145, 67, 9, 35, 139, 42, 168, 159, 123, 235, 170, 166, 151, 90, 104, 158, 118, 214, 86, 86, 86, 87, 92, 109, 180, 206, 53, 211, 74, 37, 147, 74, 39, 153, 98, 136, 31, 122, 232, 160, 128, 256, 254, 245, 211, 73, 35, 137, 33, 131, 9, 35, 139, 43, 170, 165, 146, 71, 25, 97, 131, 10, 39, 153, 97, 132, 14, 55, 218, 102, 152, 94, 117, 209, 67, 10, 37, 147, 73, 35, 139, 42, 167, 154, 104, 159, 122, 232, 159, 122, 232, 159, 122, 230, 151, 90, 103, 155, 107, 169, 163, 138, 40, 159, 123, 235, 171, 170, 166, 150, 85, 83, 74, 37, 148, 79, 59, 234, 166, 150, 86, 87, 91, 105, 163, 139, 41, 162, 134, 21, 84, 80, 61, 242, 198, 23, 90, 102, 151, 91, 106, 168, 160, 127, 252, 239, 188, 238, 181, 211, 74, 37, 146, 72, 31, 121, 227, 138, 39, 153, 99, 139, 42, 166, 149, 83, 74, 37, 146, 70, 24, 96, 128, 255, 249, 227, 139, 41, 162, 134, 22, 88, 94, 117, 211, 74, 39, 154, 102, 152, 94, 120, 221, 114, 198, 21, 82, 70, 24, 95, 123, 235, 170, 166, 152, 94, 118, 214, 86, 85, 83, 74, 38, 149, 82, 71, 27, 108, 175, 185, 227, 139, 41, 162, 134, 22, 85, 82, 70, 22, 88, 95, 123, 234, 165, 148, 79, 57, 228, 142, 54, 214, 86, 86, 88, 94, 117, 212, 78, 53, 210, 70, 24, 94, 118, 214, 86, 85, 83, 74, 38, 149, 82, 71, 25, 100, 142, 56, 222, 118, 216, 95, 121, 227, 139, 43, 172, 174, 182, 215, 91, 106, 165, 147, 75, 41, 163, 139, 44, 175, 187, 234, 167, 155, 106, 168, 159, 122, 229, 147, 74, 40, 158, 120, 223, 121, 227, 139, 43, 171, 170, 166, 150, 86, 85, 83, 76, 47, 187, 234, 166, 152, 95, 123, 233, 161, 131, 10, 38, 150, 85, 82, 70, 24, 95, 122, 230, 150, 88, 94, 118, 216, 94, 118, 213, 82, 71, 27, 106, 165, 147, 75, 44, 174, 181, 211, 74, 39, 156, 110, 183, 219, 105, 161, 131, 10, 37, 147, 75, 43, 170, 166, 152, 95, 123, 234, 168, 158, 117, 211, 74, 37, 146, 70, 23, 91, 107, 169, 163, 139, 43, 170, 167, 154, 102, 151, 90, 102, 150, 86, 85, 83, 74, 40, 159, 122, 230, 151, 90, 102, 150, 86, 87, 92, 110, 182, 216, 96, 126, 248, 222, 119, 219, 105, 163, 137, 35, 139, 43, 169, 163, 138, 40, 159, 122, 230, 152, 94, 117, 211, 74, 38, 151, 90, 102, 150, 86, 86, 86, 88, 96, 127, 250, 232, 159, 124, 238, 183, 218, 102, 151, 90, 101, 147, 73, 33, 132, 15, 58, 230, 150, 86, 88, 94, 117, 210, 71, 28, 110, 183, 218, 102, 150, 88, 95, 123, 235, 170, 166, 150, 86, 86, 85, 84, 78, 56, 222, 117, 211, 75, 42, 166, 150, 86, 86, 86, 88, 96, 126, 246, 216, 95, 123, 235, 171, 171, 172, 175, 186, 230, 150, 88, 94, 119, 219, 106, 168, 158, 120, 223, 124, 239, 186, 230, 149, 83, 73, 34, 134, 22, 86, 85, 83, 75, 42, 168, 157, 114, 199, 27, 106, 168, 160, 126, 246, 216, 95, 122, 230, 150, 86, 86, 86, 87, 90, 103, 154, 101, 147, 75, 42, 167, 155, 105, 163, 137, 36, 143, 60, 240, 190, 247, 218, 102, 152, 95, 123, 234, 165, 147, 74, 37, 147, 75, 41, 163, 138, 40, 158, 118, 216, 95, 122, 231, 155, 105, 161, 131, 10, 37, 147, 73, 33, 130, 6, 24, 95, 123, 234, 166, 150, 87, 91, 106, 168, 159, 123, 233, 163, 138, 40, 159, 122, 230, 150, 87, 90, 102, 151, 89, 98, 134, 24, 94, 118, 216, 95, 122, 231, 155, 106, 165, 147, 73, 33, 131, 11, 41, 163, 138, 40, 159, 123, 233, 163, 137, 35, 138, 39, 154, 103, 154, 103, 154, 102, 150, 85, 82, 69, 19, 74, 40, 159, 122, 232, 159, 123, 234, 167, 154, 102, 150, 87, 89, 99, 137, 34, 134, 23, 90, 102, 150, 88, 95, 122, 231, 154, 102, 150, 86, 85, 81, 66, 7, 25, 98, 135, 27, 106, 167, 154, 102, 151, 89, 99, 139, 41, 163, 138, 40, 159, 122, 229, 147, 74, 39, 155, 106, 167, 154, 103, 155, 107, 171, 170, 166, 150, 88, 95, 122, 232, 159, 123, 236, 175, 186, 232, 159, 121, 225, 130, 6, 21, 82, 71, 27, 106, 167, 154, 103, 155, 106, 167, 154, 102, 149, 82, 72, 31, 122, 232, 159, 123, 234, 166, 150, 88, 95, 122, 230, 150, 86, 86, 86, 86, 85, 83, 75, 43, 171, 170, 166, 150, 86, 86, 87, 91, 107, 170, 168, 158, 118, 215, 91, 105, 162, 134, 22, 86, 86, 86, 85, 82, 70, 22, 86, 87, 92, 110, 182, 214, 87, 91, 107, 169, 162, 136, 30, 120, 223, 122, 230, 150, 87, 91, 106, 167, 153, 99, 138, 38, 150, 86, 86, 86, 87, 91, 105, 161, 131, 11, 43, 171, 171, 171, 172, 174, 182, 214, 87, 91, 106, 166, 150, 88, 95, 122, 230, 152, 94, 117, 211, 74, 39, 154, 103, 155, 106, 166, 150, 85, 83, 74, 39, 153, 99, 140, 46, 182, 213, 81, 67, 11, 41, 163, 137, 36, 143, 57, 226, 135, 27, 107, 171, 171, 170, 168, 157, 115, 203, 42, 168, 158, 120, 223, 123, 235, 170, 165, 146, 69, 17, 67, 9, 36, 143, 59, 234, 168, 158, 119, 219, 105, 161, 131, 9, 34, 135, 25, 99, 138, 38, 150, 86, 86, 86, 85, 81, 65, 3, 9, 34, 136, 30, 119, 219, 105, 162, 135, 27, 105, 163, 137, 35, 139, 41, 162, 134, 22, 86, 87, 89, 99, 137, 34, 135, 27, 106, 165, 147, 74, 40, 159, 124, 240, 191, 251, 235, 172, 175, 186, 229, 147, 75, 43, 171, 171, 170, 166, 150, 85, 82, 72, 30, 118, 215, 91, 107, 170, 166, 149, 81, 67, 10, 40, 158, 118, 213, 83, 74, 40, 159, 123, 233, 163, 139, 43, 171, 170, 166, 151, 91, 106, 167, 154, 102, 151, 89, 99, 139, 43, 171, 169, 161, 131, 11, 43, 171, 170, 168, 160, 128, 256, 254, 246, 214, 85, 83, 75, 43, 172, 174, 182, 213, 82, 69, 18, 72, 31, 122, 230, 150, 86, 88, 95, 123, 235, 170, 168, 160, 126, 246, 214, 88, 96, 125, 244, 207, 58, 230, 151, 92, 110, 181, 211, 74, 38, 150, 86, 88, 93, 114, 200, 32, 126, 246, 213, 82, 69, 18, 69, 19, 75, 42, 167, 154, 103, 155, 108, 173, 179, 203, 43, 171, 171, 169, 162, 136, 30, 120, 222, 118, 213, 84, 79, 59, 233, 164, 143, 59, 235, 171, 169, 163, 139, 41, 163, 139, 42, 166, 150, 86, 85, 83, 74, 38, 150, 86, 88, 95, 121, 227, 139, 41, 162, 135, 28, 110, 181, 210, 70, 21, 81, 67, 12, 47, 187, 233, 162, 134, 23, 92, 111, 187, 233, 164, 143, 57, 226, 135, 28, 110, 184, 223, 122, 229, 147, 74, 40, 160, 126, 247, 220, 111, 187, 235, 171, 171, 171, 170, 166, 152, 95, 124, 238, 184, 223, 123, 234, 168, 159, 124, 239, 187, 233, 163, 137, 35, 140, 45, 178, 197, 18, 72, 30, 119, 219, 107, 172, 174, 184, 224, 126, 245, 211, 75, 43, 169, 163, 138, 37, 147, 75, 43, 171, 169, 164, 142, 55, 217, 98, 135, 27, 107, 171, 169, 163, 137, 34, 134, 22, 88, 95, 122, 230, 149, 82, 72, 31, 122, 232, 159, 121, 226, 135, 27, 105, 163, 139, 41, 163, 138, 37, 146, 70, 24, 95, 122, 232, 159, 121, 226, 134, 21, 81, 66, 5, 20, 79, 59, 235, 171, 170, 168, 159, 121, 225, 131, 10, 40, 159, 123, 235, 171, 170, 166, 150, 87, 90, 102, 150, 88, 94, 117, 209, 67, 9, 36, 142, 54, 215, 91, 107, 170, 166, 150, 85, 83, 74, 38, 149, 82, 70, 21, 81, 66, 6, 22, 88, 95, 122, 231, 155, 107, 170, 166, 150, 86, 87, 91, 105, 163, 138, 39, 153, 99, 137, 33, 130, 8, 30, 119, 219, 106, 165, 146, 69, 19, 75, 41, 163, 137, 35, 138, 37, 147, 74, 38, 150, 88, 96, 127, 252, 238, 182, 214, 86, 86, 85, 82, 71, 25, 98, 135, 27, 106, 166, 149, 82, 71, 28, 110, 182, 214, 86, 86, 88, 93, 116, 207, 59, 233, 163, 139, 43, 171, 171, 170, 166, 149, 82, 71, 26, 102, 150, 88, 96, 127, 250, 230, 151, 91, 108, 174, 181, 209, 65, 2, 8, 32, 126, 245, 210, 70, 22, 85, 81, 67, 10, 37, 147, 75, 41, 163, 137, 33, 132, 15, 59, 235, 169, 162, 134, 24, 96, 127, 251, 234, 168, 158, 120, 221, 114, 200, 32, 126, 246, 213, 83, 75, 43, 171, 170, 166, 150, 86, 86, 87, 89, 98, 134, 22, 88, 96, 126, 246, 214, 85, 83, 74, 38, 152, 94, 120, 223, 124, 239, 188, 240, 191, 249, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "print(\"Load RCI values...\")\n",
        "loader = DataLoader()\n",
        "filepath = DATA_DIR+RCI_FILE\n",
        "gene_to_rci = loader.load_gene_rci_values(filepath,CELL_LINE_NUMBER)\n",
        "print('Num RCI:', len(gene_to_rci.keys()))\n",
        "print('Example RCI:', list(gene_to_rci.items())[:3])\n",
        "print(\"Load genes...\")\n",
        "all_genes = list(gene_to_rci.keys())\n",
        "print(datetime.now())\n",
        "print('Load sequence...')\n",
        "filepath = DATA_DIR+SEQUENCE_FILE\n",
        "labels,allids,allseq = loader.load_sequence(filepath)\n",
        "print(datetime.now())\n",
        "print('Num IDs:',len(allids))\n",
        "print('Example IDs:',[allids[x] for x in [10, 20, 30, 40]] )\n",
        "print('Count',np.count_nonzero(labels),'ones out of',len(labels),'labels.')\n",
        "print('Example labels:',[labels[x] for x in [10, 20, 30, 40]] )\n",
        "print('Num counts:',len(allseq))\n",
        "print('Example sequence:',allseq[3])\n",
        "loader = None  # drop K-mer cache to save RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    ALPHABET=4**K+1  # NUMBER OF DISTINCT KMERS POSSIBLE, add one if N gets mask value\n",
        "    ADJUST_LENGTH = MAXLEN-K+1  # fixed length sequences\n",
        "    rnn = Sequential()\n",
        "    embed_layer = Embedding(ALPHABET,EMBED_DIMEN,input_length=ADJUST_LENGTH,mask_zero=True)   \n",
        "    cnn1_layer = Conv1D(CFILTERS, FILTERSIZE)\n",
        "    rnn1_layer = Bidirectional( LSTM(RCELLS, return_sequences=False) )\n",
        "    output_layer = Dense(1,activation='sigmoid',dtype=dt)\n",
        "\n",
        "    rnn.add(embed_layer)\n",
        "    rnn.add(cnn1_layer)\n",
        "    rnn.add(rnn1_layer)\n",
        "    rnn.add(output_layer)\n",
        "\n",
        "    bc=BinaryCrossentropy(from_logits=False)\n",
        "    print(\"COMPILE\")\n",
        "    rnn.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "    return rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "decf92b4-a075-4a95-9462-d5fd3f1658fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-17 20:04:53.530715\n",
            "COMPILE\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1997, 4)           1028      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1988, 16)          656       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32)               4224      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,941\n",
            "Trainable params: 5,941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "model=build_model()\n",
        "print(model.summary())  # Print this only once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W9xiFzNbFLBE"
      },
      "outputs": [],
      "source": [
        "class CrossValidator():\n",
        "    def __init__(self,epochs,folds,quick_test=False,pred_threshold=0.5):\n",
        "        self.epochs = epochs\n",
        "        self.folds = folds\n",
        "        self.quick_test = quick_test\n",
        "        self.threshold = pred_threshold # e.g. score>0.5 => class 1\n",
        "    \n",
        "    def get_gene_subset(self,all_genes,sub_index):\n",
        "        sub_genes = set()\n",
        "        for index in sub_index:\n",
        "            one_gene = all_genes[index]\n",
        "            sub_genes.add(one_gene)\n",
        "        return sub_genes\n",
        "    \n",
        "    def get_X_y(self,gene_set,allids,allX,allY):\n",
        "        cnt = len(allids)\n",
        "        subsetX=[]\n",
        "        subsetY=[]\n",
        "        if cnt != len(allX) or cnt!= len(allY):\n",
        "            raise Exception('Lengths differ')\n",
        "        for i in range(cnt):\n",
        "            gene_id,tran_id = allids[i]\n",
        "            if gene_id in gene_set:\n",
        "                oneX = allX[i]\n",
        "                oneY = allY[i]\n",
        "                subsetX.append(oneX)\n",
        "                subsetY.append(oneY)\n",
        "        subsetX = np.array(subsetX)\n",
        "        subsetY = np.array(subsetY).reshape((-1,1))\n",
        "        return subsetX,subsetY\n",
        "    \n",
        "    def do_cross_validation(self):\n",
        "        cv_accuracy=[]\n",
        "        cv_precision=[]\n",
        "        cv_recall=[]\n",
        "        cv_f1=[]\n",
        "        fold=0\n",
        "        print(datetime.now())\n",
        "        print('splitting')\n",
        "        # KFold shuffles once before making the partitions\n",
        "        splitter = KFold(n_splits=self.folds,shuffle=True,random_state=42)\n",
        "        for train_index,valid_index in splitter.split(all_genes):\n",
        "            fold += 1\n",
        "            print('Fold',fold)\n",
        "            train_genes = self.get_gene_subset(all_genes,train_index)\n",
        "            valid_genes = self.get_gene_subset(all_genes,valid_index)\n",
        "            X_train,y_train = self.get_X_y(train_genes,allids,allseq,labels)\n",
        "            X_valid,y_valid = self.get_X_y(valid_genes,allids,allseq,labels)\n",
        "\n",
        "            print('Training example')\n",
        "            print(X_train[0])\n",
        "\n",
        "            print('Train sizes',X_train.shape,y_train.shape)\n",
        "            print('Valid sizes',X_valid.shape,y_valid.shape)\n",
        "            print('Train set ones/size',\n",
        "                  np.count_nonzero(y_train),'/',len(y_train))\n",
        "            print('Valid set ones/size',\n",
        "                  np.count_nonzero(y_valid),'/',len(y_valid))\n",
        "\n",
        "            print(\"BUILD MODEL\")\n",
        "            model=build_model()\n",
        "\n",
        "            print(\"FIT\")\n",
        "            print(datetime.now())\n",
        "            history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
        "                    epochs=self.epochs, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
        "                    validation_data=(X_valid,y_valid) )\n",
        "\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1)\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Compute valiation accuracy\")\n",
        "            print(datetime.now())\n",
        "            yhat_pred=model.predict(X_valid, verbose=0) \n",
        "            print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "            yhat_classes=np.where(yhat_pred > self.threshold, 1, 0)\n",
        "            print('Predicted zeros and ones',np.count_nonzero(yhat_classes==0),np.count_nonzero(yhat_classes==1))\n",
        "            # accuracy: (tp + tn) / (p + n)\n",
        "            accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
        "            # precision tp / (tp + fp)\n",
        "            precision = precision_score(y_valid, yhat_classes)*100.\n",
        "            # recall: tp / (tp + fn)\n",
        "            recall = recall_score(y_valid, yhat_classes)*100.\n",
        "            # f1: 2 tp / (2 tp + fp + fn)\n",
        "            f1 = f1_score(y_valid, yhat_classes)*100.\n",
        "            print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%% F1: %.2f%%' % (accuracy,precision,recall,f1)) \n",
        "            print(datetime.now())\n",
        "            cv_accuracy.append(accuracy)\n",
        "            cv_precision.append(precision)\n",
        "            cv_recall.append(recall)\n",
        "            cv_f1.append(f1)\n",
        "            if self.quick_test:   \n",
        "                print('Break -- this was for code testing only')\n",
        "                break\n",
        "        print()\n",
        "        return cv_accuracy, cv_precision, cv_recall, cv_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XC9m0W-pFLBH",
        "outputId": "452ba9de-919a-42d5-a9b7-0e5bbc12aefa",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-17 20:08:25.269218\n",
            "2022-12-17 20:08:25.276470\n",
            "splitting\n",
            "Fold 1\n",
            "Training example\n",
            "[ 60 238 182 ...   0   0   0]\n",
            "Train sizes (10521, 1997) (10521, 1)\n",
            "Valid sizes (2622, 1997) (2622, 1)\n",
            "Train set ones/size 5609 / 10521\n",
            "Valid set ones/size 1350 / 2622\n",
            "BUILD MODEL\n",
            "COMPILE\n",
            "FIT\n",
            "2022-12-17 20:08:29.374473\n",
            "Epoch 1/5\n",
            "329/329 [==============================] - 39s 104ms/step - loss: 0.6874 - accuracy: 0.5478 - val_loss: 0.6958 - val_accuracy: 0.5336\n",
            "Epoch 2/5\n",
            "329/329 [==============================] - 34s 103ms/step - loss: 0.6766 - accuracy: 0.5767 - val_loss: 0.6951 - val_accuracy: 0.5160\n",
            "Epoch 3/5\n",
            "329/329 [==============================] - 34s 104ms/step - loss: 0.6775 - accuracy: 0.5728 - val_loss: 0.6904 - val_accuracy: 0.5435\n",
            "Epoch 4/5\n",
            "329/329 [==============================] - 36s 111ms/step - loss: 0.6691 - accuracy: 0.5932 - val_loss: 0.7097 - val_accuracy: 0.4916\n",
            "Epoch 5/5\n",
            "329/329 [==============================] - 34s 104ms/step - loss: 0.6722 - accuracy: 0.5819 - val_loss: 0.6884 - val_accuracy: 0.5511\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compute valiation accuracy\n",
            "2022-12-17 20:11:27.035800\n",
            "Range of scores: 0.34092736 to 0.7394983\n",
            "Predicted zeros and ones 1085 1537\n",
            "Accuracy: 55.11% Precision: 55.63% Recall: 63.33% F1: 59.23%\n",
            "2022-12-17 20:11:32.805311\n",
            "Break -- this was for code testing only\n",
            "\n",
            "Cross validation 5 folds 5 epochs\n",
            " accuracy mean 55.11% +/- 0.00\n",
            " precision mean 55.63% +/- 0.00\n",
            " recall mean 63.33% +/- 0.00\n",
            " F1 mean 59.23% +/- 0.00\n",
            "2022-12-17 20:11:32.808684\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "cvdo = CrossValidator(EPOCHS,FOLDS,BREAK)\n",
        "cv_accuracy, cv_precision, cv_recall, cv_f1 = cvdo.do_cross_validation()   \n",
        "print(\"Cross validation %d folds %d epochs\" % (FOLDS,EPOCHS)) \n",
        "print(\" accuracy mean %.2f%% +/- %.2f\" % (np.mean(cv_accuracy), np.std(cv_accuracy)))\n",
        "print(\" precision mean %.2f%% +/- %.2f\" % (np.mean(cv_precision), np.std(cv_precision)))\n",
        "print(\" recall mean %.2f%% +/- %.2f\" % (np.mean(cv_recall), np.std(cv_recall)))\n",
        "print(\" F1 mean %.2f%% +/- %.2f\" % (np.mean(cv_f1), np.std(cv_f1)))\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thQspN3Nga5S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}