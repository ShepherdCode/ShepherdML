{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Gradient Boost\n",
        "canonical lncRNA, -1 threshold, cross-valiation, all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "5229aaa5-dea1-458a-f3f4-041cbb03c914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:12.682312\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "52270ce7-719c-45eb-a916-c0b79ea7b3ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "# tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/Localization/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
        "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/'    # Mac\n",
        "    MODEL_DIR = '/Users/jasonmiller/WVU/Localization/Models/'    # Mac\n",
        "print(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX-UEr8FLA8",
        "outputId": "9d8e4333-3022-489f-ce4e-93e7ba50192e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "import pickle\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "from matplotlib import pyplot as plt \n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import BinaryCrossentropy\n",
        "#from keras.losses import Hinge\n",
        "\n",
        "K=5\n",
        "ALPHABET=4**K + 1\n",
        "CFILTERS=64 \n",
        "FILTERSIZE=8\n",
        "RCELLS=32\n",
        "DCELLS=16\n",
        "EPOCHS=150 \n",
        "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
        "# MINLEN=200   # NO LONGER USED\n",
        "# MAXLEN=5000\n",
        "RCI_THRESHOLD_MECHANISM = 'ZERO'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
        "BREAK = False   # break after first fold\n",
        "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC\n",
        "FILTER_TRAIN        = False\n",
        "FILTER_TAILS_TRAIN  = False\n",
        "FILTER_MIDDLE_TRAIN = False\n",
        "FILTER_TEST         = False\n",
        "FILTER_TAILS_TEST   = False\n",
        "FILTER_MIDDLE_TEST  = False\n",
        "REPEATS = 2\n",
        "FOLDS = 5\n",
        "\n",
        "SAVE_MODEL_FILENAME = None # 'RF_101'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LnkpVKdMFLA-"
      },
      "outputs": [],
      "source": [
        "RCI_FILE_TRAIN = 'train.lncRNA_RCI.csv'\n",
        "RCI_FILE_TEST  = None #'test.lncRNA_RCI.csv'\n",
        "\n",
        "SEQ_FILE_TRAIN = 'train.canon_lncRNA_transcripts.csv'\n",
        "SEQ_FILE_TEST  = None #'test.canon_lncRNA_transcripts.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e3p4QzQJFLA_"
      },
      "outputs": [],
      "source": [
        "def get_ordered_list():\n",
        "    ordered_list = \\\n",
        "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
        "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
        "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
        "    return ordered_list\n",
        "all_cell_lines = get_ordered_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        self.cache=dict() \n",
        "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "        self.gene2rci = dict()\n",
        "        \n",
        "    def load_gene_rci_values(self,filepath,exclusions):\n",
        "        '''\n",
        "        Load all the genes from the given RCI csv file.\n",
        "        The given file usually contains train or test, not both.\n",
        "        Return dict with keys=gene:str and values=RCI:float.\n",
        "        '''\n",
        "        self.gene2rci = {}\n",
        "        overall_sum = 0\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row # skip file's header line\n",
        "                else:\n",
        "                    line = row.strip()\n",
        "                    fields = line.split(',')\n",
        "                    gene_id = fields.pop(0)\n",
        "                    log_mean = float(fields.pop(0))\n",
        "                    self.gene2rci[gene_id] = log_mean\n",
        "        print('Number of RCI values loaded',len(self.gene2rci.keys()))\n",
        "        return self.gene2rci\n",
        "\n",
        "    def _seq_to_kmer_values(self,rna,K):\n",
        "        vec=[] # seq converted to list of K-mers \n",
        "        N_indicator = 0 # indicator value\n",
        "        length = len(rna)\n",
        "        for i in range(length-K+1):\n",
        "            kmer = rna[i:i+K]\n",
        "            if 'N' in kmer:\n",
        "                value = N_indicator\n",
        "            elif kmer in self.cache.keys():\n",
        "                value = self.cache[kmer]\n",
        "            else:\n",
        "                value = 0\n",
        "                for j in range(K):\n",
        "                    value *= 4   \n",
        "                    nextnuc = kmer[j] \n",
        "                    nucval = self.vals[nextnuc]\n",
        "                    value += nucval\n",
        "                value += 1   # NNN => 0, AAA => 1\n",
        "                self.cache[kmer] = value\n",
        "            vec.append(value)\n",
        "        return vec\n",
        "\n",
        "    def load_sequence(self,filepath):\n",
        "        '''\n",
        "        Load all the sequences from the given file. \n",
        "        Load our version of GenCode -- csv, easier to parse than fasta.\n",
        "        Each line has IDs plus sequence.\n",
        "        The IDs in the file do not include dot-version numbers.\n",
        "        The file may already be filtered e.g. canonical transcripts.\n",
        "        '''\n",
        "        allids=[]\n",
        "        allseq=[]\n",
        "        #NREPEAT = str('N'*MAXLEN)   # not used for MLP\n",
        "        with open (filepath,'r') as handle:\n",
        "            header = None\n",
        "            for row in handle:\n",
        "                if header is None:\n",
        "                    header = row\n",
        "                else:\n",
        "                    line    = row.strip()\n",
        "                    fields  = line.split(',')\n",
        "                    tran_id = fields[0]  # without version number\n",
        "                    gene_id = fields[1]  # without version number\n",
        "                    seq_len = int(fields[3])\n",
        "                    seq_txt = fields[4]\n",
        "                    # Keep only transcripts having numeric RCI given the cell lines in use.\n",
        "                    # We have validated this by spot checking.\n",
        "                    # TO DO: validate this programmatically.\n",
        "                    if gene_id in self.gene2rci.keys():\n",
        "                        # no MAXLEN for MLP\n",
        "                        #if seq_len<=MAXLEN:\n",
        "                        #    seq_txt = seq_txt + NREPEAT\n",
        "                        #seq_txt = seq_txt[:MAXLEN]\n",
        "                        allids.append( (gene_id,tran_id) )\n",
        "                        hot_vec = self._seq_to_kmer_values(seq_txt,K)\n",
        "                        allseq.append(hot_vec)\n",
        "        self.cache=dict() # save RAM\n",
        "        return allids,allseq\n",
        "\n",
        "    def load_spectra(self,filepath):\n",
        "        '''\n",
        "        Load all (variable-length) sequences as lists of kmers.\n",
        "        Then convert each sequence to (fixed-length) kmer histograms.\n",
        "        '''\n",
        "        allids,allseq = self.load_sequence(filepath)\n",
        "        allspectra = []\n",
        "        for seq in allseq:\n",
        "            spectrum = np.zeros(ALPHABET)\n",
        "            for kmer in seq:\n",
        "                spectrum[kmer] += 1\n",
        "            spectrum /= len(seq)\n",
        "            allspectra.append(spectrum)\n",
        "        return allids,allspectra        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    gbc = GBC()\n",
        "    return gbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj-wufgFLBF",
        "outputId": "ed04dcf4-b820-439d-c8f9-ae606c6162cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:48.586537\n",
            "GradientBoostingClassifier()\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "model=build_model()\n",
        "print(model)  # Print this only once\n",
        "model=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrC1alOKq07"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W9xiFzNbFLBE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class CrossValidator():\n",
        "    def __init__(self,epochs,score_threshold=0.5):\n",
        "        self.epochs = epochs\n",
        "        self.score_threshold = score_threshold\n",
        "        self.mechanism = 'ZERO'\n",
        "        self.discriminator = -1 # or zero\n",
        "        self.flip = False\n",
        "        self.reset_statistics()\n",
        "        \n",
        "    def reset_statistics(self):\n",
        "        self.cv_accuracy=[]\n",
        "        self.cv_precision=[]\n",
        "        self.cv_recall=[]\n",
        "        self.cv_f1=[]\n",
        "        self.cv_auprc=[]\n",
        "        self.cv_auroc=[]\n",
        "        self.cv_mcc=[]\n",
        "        \n",
        "    def _get_X_y(self, all_ids, all_seqs, rci_map): \n",
        "        # Prepare X and y for training or testing.\n",
        "        subsetX=[]\n",
        "        subsetY=[]\n",
        "        for t in range(len(all_ids)):\n",
        "            gene_id,tran_id = all_ids[t]\n",
        "            oneX            = all_seqs[t]\n",
        "            oneY            = rci_map[gene_id]\n",
        "            subsetX.append(oneX)\n",
        "            subsetY.append(oneY)\n",
        "        subsetX = np.array(subsetX)\n",
        "        subsetY = np.array(subsetY).reshape((-1,1))\n",
        "        return subsetX,subsetY\n",
        "    \n",
        "    def set_threshold_mechanism(self, mechanism):\n",
        "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
        "            raise Exception('Unrecognized mechansm:',mechanism)\n",
        "        self.mechanism = mechanism\n",
        "    \n",
        "    def _apply_threshold(self, array_of_rci):\n",
        "        # Takes list of float, returns list of labels [0,1].\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            labels = self.discriminator.predict(array_of_rci)\n",
        "            if self.flip:\n",
        "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
        "                labels = np.array(list(map(IS_CYTO, labels)))\n",
        "        else:  # 'THE_MEAN' or 'ZERO'\n",
        "            rci_threshold = self.discriminator\n",
        "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
        "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
        "        return labels\n",
        "    \n",
        "    def _prepare_threshold(self, rci_values, create=True):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            if create:  # during training, create a new GMM\n",
        "                gmm = GaussianMixture(n_components=2, verbose=0, \n",
        "                  covariance_type='spherical', n_init=100) # random_state=42) \n",
        "                gmm.fit(rci_values)\n",
        "            else:   # during testing, use existing GMM\n",
        "                gmm=self.discriminator\n",
        "            self.flip = False\n",
        "            # The GMM labels are arbitrary.\n",
        "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
        "                self.flip = True\n",
        "            self.discriminator = gmm   # redundant but consistent\n",
        "        elif self.mechanism == 'THE_MEAN':\n",
        "            self.discriminator = np.mean(rci_values)\n",
        "        elif self.mechanism == 'ZERO':\n",
        "            self.discriminator = -1   # 0 usually, -1 is as in Yuan et al.\n",
        "        else: # not expected\n",
        "            self.discriminator = 0\n",
        "    \n",
        "    def _explain_threshold(self):\n",
        "        if self.mechanism == 'RCI_GMM':\n",
        "            gmm=self.discriminator\n",
        "            print('Discriminator is GMM')\n",
        "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
        "            print('Variances',gmm.covariances_)\n",
        "            print('Priors',gmm.weights_)\n",
        "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
        "            print(test_rcis)\n",
        "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
        "        else:\n",
        "            print('Discriminator',self.mechanism,self.discriminator)\n",
        "    \n",
        "    def _show_sizes(self,label,values):\n",
        "        a = np.count_nonzero(values==1)\n",
        "        b = np.count_nonzero(values==0)\n",
        "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
        "        \n",
        "    def save_model(self,filename):\n",
        "        if self.model is not None:\n",
        "            filepath = MODEL_DIR + filename\n",
        "            #self.model.save(filepath)\n",
        "            print('? Saved model to',filepath)\n",
        "        \n",
        "    def load_model(self,filename):\n",
        "        filepath = MODEL_DIR + filename\n",
        "        #self.model = keras.models.load_model(filepath)\n",
        "        print('? Loaded model from',filepath)\n",
        "        \n",
        "    def train_new_model(self,train_ids,train_seq,train_rci,\n",
        "            valid_ids=None,valid_seq=None,valid_rci=None):\n",
        "        print(datetime.now())\n",
        "        X_train,y_rci = self._get_X_y(train_ids,train_seq,train_rci) \n",
        "        self._prepare_threshold(y_rci,True)  \n",
        "        self._explain_threshold()\n",
        "        y_train = self._apply_threshold(y_rci)\n",
        "        self._show_sizes('Train',y_train)\n",
        "        #cw = class_weight.compute_class_weight('balanced', classes=[0,1], y=y_train)\n",
        "        #cwd = {0: cw[0], 1: cw[1]}\n",
        "        #print('Computed class weights:',cwd)\n",
        "        if valid_ids is not None:\n",
        "            X_valid,y_rci = self._get_X_y(valid_ids,valid_seq,valid_rci) \n",
        "            y_valid = self._apply_threshold(y_rci)\n",
        "            self._show_sizes('Valid',y_valid)\n",
        "        y_rci = None\n",
        "\n",
        "        self.model=build_model()\n",
        "        \n",
        "        print(\"FIT\")\n",
        "        print(datetime.now())\n",
        "        self.model.fit(X_train, y_train) # sample weight\n",
        "\n",
        "    def test_without_training(self,test_ids,test_seq,test_rci):\n",
        "        # For final test, do no train.\n",
        "        # Assume set_sequences() set the test set.\n",
        "        print(datetime.now())\n",
        "        X_test,y_rci = self._get_X_y(test_ids,test_seq,test_rci) \n",
        "        y_test = self._apply_threshold(y_rci)\n",
        "        y_rci = None\n",
        "        \n",
        "        print(\"PREDICT\")\n",
        "        print(datetime.now())        \n",
        "        yhat_pairs=self.model.predict_proba(X_test)  # [ prob of 0, prob of 1 ]\n",
        "        yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "        yhat_classes=self.model.predict(X_test)  # 0 or 1\n",
        "        \n",
        "        print('debug pred',yhat_pred[:3])\n",
        "        print('debug class',yhat_classes[:3])\n",
        "\n",
        "        self._show_sizes('Test',y_test)\n",
        "        self._show_sizes('Predict',yhat_classes)\n",
        "        print('Test sizes',X_test.shape,y_test.shape)\n",
        "        print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "        print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "        print('Score threshold',self.score_threshold)\n",
        "        cm1 = confusion_matrix(y_test,yhat_classes)\n",
        "        print('Confusion matrix\\n',cm1)\n",
        "        cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
        "        print('Normalized matrix\\n',cm2)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
        "        precision = precision_score(y_test, yhat_classes)*100.\n",
        "        recall = recall_score(y_test, yhat_classes)*100.\n",
        "        f1 = f1_score(y_test, yhat_classes)*100.\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
        "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
        "\n",
        "        correct_pos = 0\n",
        "        correct_neg = 0\n",
        "        wrong_pos = 0\n",
        "        wrong_neg = 0\n",
        "        for i in range(len(y_test)):\n",
        "            if yhat_pred[i]>=0.65:\n",
        "                if y_test[i]==1:\n",
        "                    correct_pos += 1\n",
        "                else:\n",
        "                    wrong_pos += 1\n",
        "            elif yhat_pred[i]<=0.35:\n",
        "                if y_test[i]==0:\n",
        "                    correct_neg += 1\n",
        "                else:\n",
        "                    wrong_neg += 1\n",
        "        print('Extreme scores correct, pos:neg',correct_pos,correct_neg)  \n",
        "        print('Extreme scores incorrect pos:neg',wrong_pos,wrong_neg)  \n",
        "\n",
        "        #self._pretty_pictures(y_test,yhat_pred,prc_X,prc_Y)\n",
        "        \n",
        "        print('Accuracy: %.2f%% Precision: %.2f%% Recall: %.2f%%' % (accuracy,precision,recall)) \n",
        "        print('F1: %.2f%% MCC: %.4f' % (f1,mcc)) \n",
        "        print('AUPRC: %.2f%% AUROC: %.2f%%' % (auprc,auroc)) \n",
        "\n",
        "        self.cv_accuracy.append(accuracy)\n",
        "        self.cv_precision.append(precision)\n",
        "        self.cv_recall.append(recall)\n",
        "        self.cv_f1.append(f1)\n",
        "        self.cv_mcc.append(mcc)\n",
        "        self.cv_auprc.append(auprc)\n",
        "        self.cv_auroc.append(auroc)\n",
        "\n",
        "    def _pretty_pictures(self,y_valid,yhat_pred,prc_X,prc_Y):\n",
        "        count_ones= len(y_valid[y_valid==1])\n",
        "        count_zeros= len(y_valid[y_valid==0])\n",
        "        guess = max(count_ones,count_zeros) / len(y_valid)\n",
        "        # PRC\n",
        "        plt.plot(prc_X, prc_Y, marker='.')\n",
        "        plt.plot([0, 1], [guess,guess], linestyle='--')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.show()\n",
        "        # ROC\n",
        "        fpr, tpr, roc_bins = roc_curve(y_valid, yhat_pred)\n",
        "        plt.plot(fpr, tpr, marker='.')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.show()\n",
        "        \n",
        "    def get_statistics(self):\n",
        "        return \\\n",
        "        self.cv_accuracy,\\\n",
        "        self.cv_precision,\\\n",
        "        self.cv_recall,\\\n",
        "        self.cv_f1,\\\n",
        "        self.cv_mcc,\\\n",
        "        self.cv_auprc,\\\n",
        "        self.cv_auroc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td97uyyj5qDq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "poe3rwAF4Ir7"
      },
      "outputs": [],
      "source": [
        "class Separator():\n",
        "    def __init__(self):\n",
        "        self.train_ids = []\n",
        "        self.train_seq = []\n",
        "        self.train_rci = dict()\n",
        "        self.val_ids = []\n",
        "        self.val_seq = []\n",
        "        self.val_rci = dict()\n",
        "    def load(self,data_dir,rep,fold):\n",
        "        filename='cv.{}.{}.validation_genes.txt'.format(rep,fold)\n",
        "        filename = data_dir + filename\n",
        "        self.val_genes = set()\n",
        "        print('Opening file',filename)\n",
        "        with open(filename,'r') as fin:\n",
        "            for line in fin:\n",
        "                gene_id = line.strip()\n",
        "                self.val_genes.add(gene_id)\n",
        "    def process(self,allids,allseq,gene_to_rci):\n",
        "        size = len(allids)\n",
        "        for t in range(size):\n",
        "            gene_id,tran_id = allids[t]\n",
        "            oneX            = allseq[t]\n",
        "            oneY            = gene_to_rci[gene_id]\n",
        "            in_middle = gene_to_rci[gene_id] >= -2 and gene_to_rci[gene_id] <= 0\n",
        "            in_tails = gene_to_rci[gene_id] < -2 or gene_to_rci[gene_id] > 0\n",
        "            if gene_id in self.val_genes:\n",
        "                if FILTER_TEST and (\\\n",
        "                    (FILTER_TAILS_TEST and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TEST and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.val_ids.append(allids[t])\n",
        "                    self.val_seq.append(allseq[t])\n",
        "                    self.val_rci[gene_id]=gene_to_rci[gene_id]\n",
        "            else:\n",
        "                if FILTER_TRAIN and (\\\n",
        "                    (FILTER_TAILS_TRAIN and in_tails) or \\\n",
        "                    (FILTER_MIDDLE_TRAIN and in_middle)):\n",
        "                    pass\n",
        "                else:\n",
        "                    self.train_ids.append(allids[t])\n",
        "                    self.train_seq.append(allseq[t])\n",
        "                    self.train_rci[gene_id]=gene_to_rci[gene_id]\n",
        "    def get_ids(self):\n",
        "        return self.train_ids,self.val_ids\n",
        "    def get_seq(self):\n",
        "        return self.train_seq,self.val_seq\n",
        "    def get_rci(self):\n",
        "        return self.train_rci,self.val_rci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC9m0W-pFLBH",
        "outputId": "59086866-63b4-432e-fbdb-313115908730",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 13:01:48.764292\n",
            "Load RCI from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.lncRNA_RCI.csv\n",
            "Number of RCI values loaded 4371\n",
            "Num RCI: 4371\n",
            "Load sequence from /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/train.canon_lncRNA_transcripts.csv\n",
            "Loaded 4371 sequences.\n",
            "\n",
            "Training # 1 1\n",
            "2023-04-18 13:01:59.929164\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.1.validation_genes.txt\n",
            "2023-04-18 13:02:00.190827\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1659:1837 47.45%\n",
            "Valid 1:0 402:473 45.94%\n",
            "FIT\n",
            "2023-04-18 13:02:00.231219\n",
            "\n",
            "Testing # 1 1\n",
            "2023-04-18 13:03:38.452158\n",
            "2023-04-18 13:03:38.452688\n",
            "PREDICT\n",
            "2023-04-18 13:03:38.463156\n",
            "debug pred [0.743887654825236, 0.40416302914435676, 0.3294568084362316]\n",
            "debug class [1 0 0]\n",
            "Test 1:0 402:473 45.94%\n",
            "Predict 1:0 383:492 43.77%\n",
            "Test sizes (875, 1025) (875,)\n",
            "Distrib of scores: 0.47895518819361327 mean 0.14476083263963208 std\n",
            "Range of scores: 0.13531315933237292 to 0.8648347338710385\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[315 158]\n",
            " [177 225]]\n",
            "Normalized matrix\n",
            " [[0.36       0.18057143]\n",
            " [0.20228571 0.25714286]]\n",
            "Extreme scores correct, pos:neg 72 126\n",
            "Extreme scores incorrect pos:neg 41 55\n",
            "Accuracy: 61.71% Precision: 58.75% Recall: 55.97%\n",
            "F1: 57.32% MCC: 0.2267\n",
            "AUPRC: 57.99% AUROC: 63.80%\n",
            " accuracy [61.71428571428571]\n",
            " precision [58.7467362924282]\n",
            " recall [55.970149253731336]\n",
            " F1 [57.324840764331206]\n",
            " MCC [0.226685039019068]\n",
            " AUPRC [57.985322629303546]\n",
            " AUROC [63.799922165073156]\n",
            "\n",
            "Training # 1 2\n",
            "2023-04-18 13:03:38.532481\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.2.validation_genes.txt\n",
            "2023-04-18 13:03:38.850450\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1643:1853 47.00%\n",
            "Valid 1:0 418:457 47.77%\n",
            "FIT\n",
            "2023-04-18 13:03:38.892533\n",
            "\n",
            "Testing # 1 2\n",
            "2023-04-18 13:05:14.195452\n",
            "2023-04-18 13:05:14.195509\n",
            "PREDICT\n",
            "2023-04-18 13:05:14.202717\n",
            "debug pred [0.42831788066602494, 0.4004444070289095, 0.688911265248656]\n",
            "debug class [0 0 1]\n",
            "Test 1:0 418:457 47.77%\n",
            "Predict 1:0 372:503 42.51%\n",
            "Test sizes (875, 1025) (875,)\n",
            "Distrib of scores: 0.4678567289111384 mean 0.1472305593883857 std\n",
            "Range of scores: 0.08564454453140047 to 0.867370670774532\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[302 155]\n",
            " [201 217]]\n",
            "Normalized matrix\n",
            " [[0.34514286 0.17714286]\n",
            " [0.22971429 0.248     ]]\n",
            "Extreme scores correct, pos:neg 65 144\n",
            "Extreme scores incorrect pos:neg 39 61\n",
            "Accuracy: 59.31% Precision: 58.33% Recall: 51.91%\n",
            "F1: 54.94% MCC: 0.1818\n",
            "AUPRC: 58.63% AUROC: 62.80%\n",
            " accuracy [59.31428571428572]\n",
            " precision [58.333333333333336]\n",
            " recall [51.91387559808612]\n",
            " F1 [54.936708860759495]\n",
            " MCC [0.18184088508606755]\n",
            " AUPRC [58.63079800527888]\n",
            " AUROC [62.80349271826873]\n",
            "\n",
            "Training # 1 3\n",
            "2023-04-18 13:05:14.234879\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.3.validation_genes.txt\n",
            "2023-04-18 13:05:14.497453\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1671:1826 47.78%\n",
            "Valid 1:0 390:484 44.62%\n",
            "FIT\n",
            "2023-04-18 13:05:14.522397\n",
            "\n",
            "Testing # 1 3\n",
            "2023-04-18 13:06:50.188093\n",
            "2023-04-18 13:06:50.188167\n",
            "PREDICT\n",
            "2023-04-18 13:06:50.197031\n",
            "debug pred [0.5708512556124224, 0.506095757968601, 0.18686849268988132]\n",
            "debug class [1 1 0]\n",
            "Test 1:0 390:484 44.62%\n",
            "Predict 1:0 360:514 41.19%\n",
            "Test sizes (874, 1025) (874,)\n",
            "Distrib of scores: 0.4709610991870105 mean 0.14315974623564767 std\n",
            "Range of scores: 0.09700132833892303 to 0.9110386682372482\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[317 167]\n",
            " [197 193]]\n",
            "Normalized matrix\n",
            " [[0.36270023 0.19107551]\n",
            " [0.22540046 0.2208238 ]]\n",
            "Extreme scores correct, pos:neg 62 123\n",
            "Extreme scores incorrect pos:neg 37 49\n",
            "Accuracy: 58.35% Precision: 53.61% Recall: 49.49%\n",
            "F1: 51.47% MCC: 0.1513\n",
            "AUPRC: 55.02% AUROC: 62.61%\n",
            " accuracy [58.35240274599543]\n",
            " precision [53.61111111111111]\n",
            " recall [49.48717948717949]\n",
            " F1 [51.46666666666667]\n",
            " MCC [0.15132905627548277]\n",
            " AUPRC [55.0244485349633]\n",
            " AUROC [62.60860351769442]\n",
            "\n",
            "Training # 1 4\n",
            "2023-04-18 13:06:50.234827\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.4.validation_genes.txt\n",
            "2023-04-18 13:06:50.514723\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1637:1860 46.81%\n",
            "Valid 1:0 424:450 48.51%\n",
            "FIT\n",
            "2023-04-18 13:06:50.541130\n",
            "\n",
            "Testing # 1 4\n",
            "2023-04-18 13:08:26.207928\n",
            "2023-04-18 13:08:26.207988\n",
            "PREDICT\n",
            "2023-04-18 13:08:26.215147\n",
            "debug pred [0.47855475184454577, 0.2895299868475009, 0.6439181976840328]\n",
            "debug class [0 0 1]\n",
            "Test 1:0 424:450 48.51%\n",
            "Predict 1:0 348:526 39.82%\n",
            "Test sizes (874, 1025) (874,)\n",
            "Distrib of scores: 0.46621442689332954 mean 0.14833691435896093 std\n",
            "Range of scores: 0.10574903499340936 to 0.8610575530159115\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[302 148]\n",
            " [224 200]]\n",
            "Normalized matrix\n",
            " [[0.34553776 0.16933638]\n",
            " [0.25629291 0.22883295]]\n",
            "Extreme scores correct, pos:neg 72 132\n",
            "Extreme scores incorrect pos:neg 37 67\n",
            "Accuracy: 57.44% Precision: 57.47% Recall: 47.17%\n",
            "F1: 51.81% MCC: 0.1458\n",
            "AUPRC: 58.84% AUROC: 61.16%\n",
            " accuracy [57.43707093821511]\n",
            " precision [57.47126436781609]\n",
            " recall [47.16981132075472]\n",
            " F1 [51.813471502590666]\n",
            " MCC [0.14580182208212022]\n",
            " AUPRC [58.836482419977855]\n",
            " AUROC [61.16142557651991]\n",
            "\n",
            "Training # 1 5\n",
            "2023-04-18 13:08:26.257612\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.1.5.validation_genes.txt\n",
            "2023-04-18 13:08:26.479936\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1634:1864 46.71%\n",
            "Valid 1:0 427:446 48.91%\n",
            "FIT\n",
            "2023-04-18 13:08:26.505166\n",
            "\n",
            "Testing # 1 5\n",
            "2023-04-18 13:10:01.206239\n",
            "2023-04-18 13:10:01.206679\n",
            "PREDICT\n",
            "2023-04-18 13:10:01.214768\n",
            "debug pred [0.16446289806083905, 0.5748524974652255, 0.3540056281855051]\n",
            "debug class [0 1 0]\n",
            "Test 1:0 427:446 48.91%\n",
            "Predict 1:0 356:517 40.78%\n",
            "Test sizes (873, 1025) (873,)\n",
            "Distrib of scores: 0.4641606421865074 mean 0.13587973213876972 std\n",
            "Range of scores: 0.12807296729896325 to 0.8367975116949548\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[307 139]\n",
            " [210 217]]\n",
            "Normalized matrix\n",
            " [[0.35166094 0.15922108]\n",
            " [0.24054983 0.24856816]]\n",
            "Extreme scores correct, pos:neg 47 132\n",
            "Extreme scores incorrect pos:neg 28 61\n",
            "Accuracy: 60.02% Precision: 60.96% Recall: 50.82%\n",
            "F1: 55.43% MCC: 0.1999\n",
            "AUPRC: 60.68% AUROC: 64.09%\n",
            " accuracy [60.02290950744559]\n",
            " precision [60.95505617977528]\n",
            " recall [50.81967213114754]\n",
            " F1 [55.42784163473819]\n",
            " MCC [0.19992015816775235]\n",
            " AUPRC [60.677980066921876]\n",
            " AUROC [64.08617846903519]\n",
            "\n",
            "Training # 2 1\n",
            "2023-04-18 13:10:01.260386\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.1.validation_genes.txt\n",
            "2023-04-18 13:10:01.557903\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1655:1841 47.34%\n",
            "Valid 1:0 406:469 46.40%\n",
            "FIT\n",
            "2023-04-18 13:10:01.595474\n",
            "\n",
            "Testing # 2 1\n",
            "2023-04-18 13:11:39.478121\n",
            "2023-04-18 13:11:39.478211\n",
            "PREDICT\n",
            "2023-04-18 13:11:39.484009\n",
            "debug pred [0.5667525233751569, 0.37272916360416464, 0.21409318902182026]\n",
            "debug class [1 0 0]\n",
            "Test 1:0 406:469 46.40%\n",
            "Predict 1:0 361:514 41.26%\n",
            "Test sizes (875, 1025) (875,)\n",
            "Distrib of scores: 0.4669374225223203 mean 0.14755143183660033 std\n",
            "Range of scores: 0.10514109137082639 to 0.8754464257622293\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[318 151]\n",
            " [196 210]]\n",
            "Normalized matrix\n",
            " [[0.36342857 0.17257143]\n",
            " [0.224      0.24      ]]\n",
            "Extreme scores correct, pos:neg 68 138\n",
            "Extreme scores incorrect pos:neg 35 66\n",
            "Accuracy: 60.34% Precision: 58.17% Recall: 51.72%\n",
            "F1: 54.76% MCC: 0.1978\n",
            "AUPRC: 56.75% AUROC: 61.88%\n",
            " accuracy [60.34285714285714]\n",
            " precision [58.17174515235457]\n",
            " recall [51.724137931034484]\n",
            " F1 [54.758800521512384]\n",
            " MCC [0.19782059681671807]\n",
            " AUPRC [56.75249988458748]\n",
            " AUROC [61.87832827418151]\n",
            "\n",
            "Training # 2 2\n",
            "2023-04-18 13:11:39.523146\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.2.validation_genes.txt\n",
            "2023-04-18 13:11:39.774731\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1645:1851 47.05%\n",
            "Valid 1:0 416:459 47.54%\n",
            "FIT\n",
            "2023-04-18 13:11:39.803936\n",
            "\n",
            "Testing # 2 2\n",
            "2023-04-18 13:13:15.851222\n",
            "2023-04-18 13:13:15.851284\n",
            "PREDICT\n",
            "2023-04-18 13:13:15.859191\n",
            "debug pred [0.5517221131613591, 0.5631216626029643, 0.12569660264753585]\n",
            "debug class [1 1 0]\n",
            "Test 1:0 416:459 47.54%\n",
            "Predict 1:0 409:466 46.74%\n",
            "Test sizes (875, 1025) (875,)\n",
            "Distrib of scores: 0.48473214551698524 mean 0.14756230367817827 std\n",
            "Range of scores: 0.12569660264753585 to 0.8464079991772069\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[296 163]\n",
            " [170 246]]\n",
            "Normalized matrix\n",
            " [[0.33828571 0.18628571]\n",
            " [0.19428571 0.28114286]]\n",
            "Extreme scores correct, pos:neg 80 135\n",
            "Extreme scores incorrect pos:neg 38 43\n",
            "Accuracy: 61.94% Precision: 60.15% Recall: 59.13%\n",
            "F1: 59.64% MCC: 0.2364\n",
            "AUPRC: 63.29% AUROC: 67.30%\n",
            " accuracy [61.94285714285714]\n",
            " precision [60.14669926650367]\n",
            " recall [59.13461538461539]\n",
            " F1 [59.63636363636364]\n",
            " MCC [0.2364431274402019]\n",
            " AUPRC [63.28839762852473]\n",
            " AUROC [67.30350259762025]\n",
            "\n",
            "Training # 2 3\n",
            "2023-04-18 13:13:15.895507\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.3.validation_genes.txt\n",
            "2023-04-18 13:13:16.187254\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1634:1863 46.73%\n",
            "Valid 1:0 427:447 48.86%\n",
            "FIT\n",
            "2023-04-18 13:13:16.216126\n",
            "\n",
            "Testing # 2 3\n",
            "2023-04-18 13:14:52.668186\n",
            "2023-04-18 13:14:52.668277\n",
            "PREDICT\n",
            "2023-04-18 13:14:52.675324\n",
            "debug pred [0.4646231387732528, 0.5372805138102981, 0.6537004782760746]\n",
            "debug class [0 1 1]\n",
            "Test 1:0 427:447 48.86%\n",
            "Predict 1:0 341:533 39.02%\n",
            "Test sizes (874, 1025) (874,)\n",
            "Distrib of scores: 0.4630619211829409 mean 0.14393528854480203 std\n",
            "Range of scores: 0.08341523474868041 to 0.9068149114315661\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[305 142]\n",
            " [228 199]]\n",
            "Normalized matrix\n",
            " [[0.34897025 0.1624714 ]\n",
            " [0.26086957 0.22768879]]\n",
            "Extreme scores correct, pos:neg 62 149\n",
            "Extreme scores incorrect pos:neg 32 49\n",
            "Accuracy: 57.67% Precision: 58.36% Recall: 46.60%\n",
            "F1: 51.82% MCC: 0.1520\n",
            "AUPRC: 61.23% AUROC: 64.17%\n",
            " accuracy [57.66590389016019]\n",
            " precision [58.35777126099707]\n",
            " recall [46.604215456674474]\n",
            " F1 [51.822916666666664]\n",
            " MCC [0.1520440468516132]\n",
            " AUPRC [61.23034115147511]\n",
            " AUROC [64.17071394516658]\n",
            "\n",
            "Training # 2 4\n",
            "2023-04-18 13:14:52.712213\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.4.validation_genes.txt\n",
            "2023-04-18 13:14:52.978578\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1669:1829 47.71%\n",
            "Valid 1:0 392:481 44.90%\n",
            "FIT\n",
            "2023-04-18 13:14:53.012545\n",
            "\n",
            "Testing # 2 4\n",
            "2023-04-18 13:16:27.480909\n",
            "2023-04-18 13:16:27.480970\n",
            "PREDICT\n",
            "2023-04-18 13:16:27.488339\n",
            "debug pred [0.48661918925308306, 0.3202688602126669, 0.5560932721751749]\n",
            "debug class [0 0 1]\n",
            "Test 1:0 392:481 44.90%\n",
            "Predict 1:0 352:521 40.32%\n",
            "Test sizes (873, 1025) (873,)\n",
            "Distrib of scores: 0.46712739252180285 mean 0.14633304133036037 std\n",
            "Range of scores: 0.12803863956636333 to 0.8899256078235853\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[330 151]\n",
            " [191 201]]\n",
            "Normalized matrix\n",
            " [[0.37800687 0.17296678]\n",
            " [0.2187858  0.23024055]]\n",
            "Extreme scores correct, pos:neg 57 146\n",
            "Extreme scores incorrect pos:neg 42 55\n",
            "Accuracy: 60.82% Precision: 57.10% Recall: 51.28%\n",
            "F1: 54.03% MCC: 0.2016\n",
            "AUPRC: 55.21% AUROC: 62.60%\n",
            " accuracy [60.824742268041234]\n",
            " precision [57.10227272727273]\n",
            " recall [51.275510204081634]\n",
            " F1 [54.032258064516135]\n",
            " MCC [0.20160351084530137]\n",
            " AUPRC [55.21120729346196]\n",
            " AUROC [62.597585811871525]\n",
            "\n",
            "Training # 2 5\n",
            "2023-04-18 13:16:27.523150\n",
            "Opening file /content/drive/My Drive/data/Localization/TrainTest/TrainTest_ver43/cv.2.5.validation_genes.txt\n",
            "2023-04-18 13:16:27.765020\n",
            "Discriminator ZERO -1\n",
            "Train 1:0 1641:1856 46.93%\n",
            "Valid 1:0 420:454 48.05%\n",
            "FIT\n",
            "2023-04-18 13:16:27.800556\n",
            "\n",
            "Testing # 2 5\n",
            "2023-04-18 13:18:03.498030\n",
            "2023-04-18 13:18:03.498090\n",
            "PREDICT\n",
            "2023-04-18 13:18:03.504516\n",
            "debug pred [0.6969510015288264, 0.6396582276665077, 0.5382573066999397]\n",
            "debug class [1 1 1]\n",
            "Test 1:0 420:454 48.05%\n",
            "Predict 1:0 368:506 42.11%\n",
            "Test sizes (874, 1025) (874,)\n",
            "Distrib of scores: 0.4733641451483522 mean 0.1402447305395789 std\n",
            "Range of scores: 0.09811246451744673 to 0.8414573790412959\n",
            "Score threshold 0.5\n",
            "Confusion matrix\n",
            " [[317 137]\n",
            " [189 231]]\n",
            "Normalized matrix\n",
            " [[0.36270023 0.15675057]\n",
            " [0.21624714 0.26430206]]\n",
            "Extreme scores correct, pos:neg 66 126\n",
            "Extreme scores incorrect pos:neg 30 53\n",
            "Accuracy: 62.70% Precision: 62.77% Recall: 55.00%\n",
            "F1: 58.63% MCC: 0.2512\n",
            "AUPRC: 62.82% AUROC: 66.54%\n",
            " accuracy [62.70022883295194]\n",
            " precision [62.77173913043478]\n",
            " recall [55.00000000000001]\n",
            " F1 [58.629441624365484]\n",
            " MCC [0.25120105964513806]\n",
            " AUPRC [62.82378243955164]\n",
            " AUROC [66.54342353681561]\n",
            "2023-04-18 13:18:03.545685\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "\n",
        "accuracy=[]\n",
        "precision=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "mcc=[]\n",
        "auprc=[]\n",
        "auroc=[]\n",
        "\n",
        "loader = DataLoader()\n",
        "filepath = DATA_DIR+RCI_FILE_TRAIN\n",
        "print(\"Load RCI from\",filepath)\n",
        "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "print('Num RCI:', len(gene_to_rci.keys()))\n",
        "filepath = DATA_DIR+SEQ_FILE_TRAIN\n",
        "print('Load sequence from',filepath)\n",
        "allids,allseq = loader.load_spectra(filepath)  # for MLP (load_sequence() for CNN)\n",
        "print('Loaded',len(allseq),'sequences.')\n",
        "test_gene_to_rci = None\n",
        "test_allids = None\n",
        "test_allseq = None\n",
        "if SEQ_FILE_TEST is not None:\n",
        "    # Train on the entire train set (no cross-validation).\n",
        "    # Evaluate with the test files.\n",
        "    test_loader = DataLoader()\n",
        "    filepath = DATA_DIR+RCI_FILE_TEST\n",
        "    print(\"Load RCI from\",filepath)\n",
        "    test_gene_to_rci = test_loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
        "    print('Num RCI:', len(test_gene_to_rci.keys()))\n",
        "    filepath = DATA_DIR+SEQ_FILE_TEST\n",
        "    print('Load sequence from',filepath)\n",
        "    test_allids,test_allseq = test_loader.load_spectra(filepath)\n",
        "    print('Loaded',len(test_allseq),'sequences.')\n",
        "\n",
        "for repeat in range(REPEATS):\n",
        "    for fold in range(FOLDS):\n",
        "        show_r = repeat+1  # display one-based counting\n",
        "        show_f = fold+1    # display one-based counting\n",
        "\n",
        "        print()\n",
        "        print(\"Training #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo = CrossValidator(EPOCHS)\n",
        "        cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
        "        if SEQ_FILE_TEST is None:\n",
        "            # Train on 80% and evaluate on 20%.\n",
        "            separator = Separator()\n",
        "            separator.load(DATA_DIR,show_r,show_f)\n",
        "            separator.process(allids,allseq,gene_to_rci)\n",
        "            train_allids,test_allids = separator.get_ids()\n",
        "            train_allseq,test_allseq = separator.get_seq()\n",
        "            train_gene_to_rci,test_gene_to_rci = separator.get_rci()\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                test_allids,test_allseq,test_gene_to_rci)\n",
        "            if SAVE_MODEL_FILENAME is not None:\n",
        "                filename = f\"{SAVE_MODEL_FILENAME}.{show_r}.{show_f}.model\"\n",
        "                cvdo.save_model(filename)\n",
        "        else:\n",
        "            # Train on the entire train set (no cross-validation).\n",
        "            # Evaluate with the test files.\n",
        "            train_allids = allids\n",
        "            train_allseq = allseq\n",
        "            train_gene_to_rci = gene_to_rci\n",
        "            BREAK = True\n",
        "            cvdo.train_new_model(\n",
        "                train_allids,train_allseq,train_gene_to_rci,\n",
        "                None,None,None)\n",
        "\n",
        "        print()\n",
        "        print(\"Testing #\",show_r,show_f)\n",
        "        print(datetime.now())\n",
        "        cvdo.reset_statistics()\n",
        "        cvdo.test_without_training(\n",
        "            test_allids,test_allseq,test_gene_to_rci)\n",
        "        cv_accuracy,cv_precision,cv_recall,cv_f1,cv_mcc,cv_auprc,cv_auroc=\\\n",
        "            cvdo.get_statistics()\n",
        "\n",
        "        print(\" accuracy\" ,  cv_accuracy)\n",
        "        print(\" precision\" , cv_precision)\n",
        "        print(\" recall\" ,    cv_recall)\n",
        "        print(\" F1\" ,        cv_f1)\n",
        "        print(\" MCC\" ,       cv_mcc)\n",
        "        print(\" AUPRC\" ,     cv_auprc)\n",
        "        print(\" AUROC\" ,     cv_auroc)\n",
        "\n",
        "        accuracy.append(cv_accuracy)\n",
        "        precision.append(cv_precision)\n",
        "        recall.append(cv_recall)\n",
        "        f1.append(cv_f1)\n",
        "        mcc.append(cv_mcc)\n",
        "        auprc.append(cv_auprc)\n",
        "        auroc.append(cv_auroc)\n",
        "        if BREAK: break\n",
        "    if BREAK: break\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkCeDg_HdQ36",
        "outputId": "1ca9c3ce-fa0a-4fb5-9383-b90e781adcf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy mean 60.03% std 1.83\n",
            " precision mean 58.57% std 2.45\n",
            " recall mean 51.91% std 3.89\n",
            " F1 mean 54.98% std 2.87\n",
            " MCC mean 0.1945 std 0.0370\n",
            " AUPRC mean 59.05% std 2.93\n",
            " AUROC mean 63.70% std 1.96\n",
            " accuracy [[61.71428571428571], [59.31428571428572], [58.35240274599543], [57.43707093821511], [60.02290950744559], [60.34285714285714], [61.94285714285714], [57.66590389016019], [60.824742268041234], [62.70022883295194]]\n",
            " precision [[58.7467362924282], [58.333333333333336], [53.61111111111111], [57.47126436781609], [60.95505617977528], [58.17174515235457], [60.14669926650367], [58.35777126099707], [57.10227272727273], [62.77173913043478]]\n",
            " recall [[55.970149253731336], [51.91387559808612], [49.48717948717949], [47.16981132075472], [50.81967213114754], [51.724137931034484], [59.13461538461539], [46.604215456674474], [51.275510204081634], [55.00000000000001]]\n",
            " F1 [[57.324840764331206], [54.936708860759495], [51.46666666666667], [51.813471502590666], [55.42784163473819], [54.758800521512384], [59.63636363636364], [51.822916666666664], [54.032258064516135], [58.629441624365484]]\n",
            " MCC [[0.226685039019068], [0.18184088508606755], [0.15132905627548277], [0.14580182208212022], [0.19992015816775235], [0.19782059681671807], [0.2364431274402019], [0.1520440468516132], [0.20160351084530137], [0.25120105964513806]]\n",
            " AUPRC [[57.985322629303546], [58.63079800527888], [55.0244485349633], [58.836482419977855], [60.677980066921876], [56.75249988458748], [63.28839762852473], [61.23034115147511], [55.21120729346196], [62.82378243955164]]\n",
            " AUROC [[63.799922165073156], [62.80349271826873], [62.60860351769442], [61.16142557651991], [64.08617846903519], [61.87832827418151], [67.30350259762025], [64.17071394516658], [62.597585811871525], [66.54342353681561]]\n"
          ]
        }
      ],
      "source": [
        "def STD (values):\n",
        "    # ddof=1 reduces bias when extrapolating from sample to population\n",
        "    return np.std(values,ddof=1)\n",
        "\n",
        "print(\" accuracy mean %.2f%% std %.2f\" %  (np.mean(accuracy),  STD(accuracy)))\n",
        "print(\" precision mean %.2f%% std %.2f\" % (np.mean(precision), STD(precision)))\n",
        "print(\" recall mean %.2f%% std %.2f\" %    (np.mean(recall),    STD(recall)))\n",
        "print(\" F1 mean %.2f%% std %.2f\" %        (np.mean(f1),        STD(f1)))\n",
        "print(\" MCC mean %.4f std %.4f\" %       (np.mean(mcc),       STD(mcc)))\n",
        "print(\" AUPRC mean %.2f%% std %.2f\" %     (np.mean(auprc),     STD(auprc)))\n",
        "print(\" AUROC mean %.2f%% std %.2f\" %     (np.mean(auroc),     STD(auroc)))\n",
        "\n",
        "print(\" accuracy\"  , accuracy)\n",
        "print(\" precision\" , precision)\n",
        "print(\" recall\"    , recall)\n",
        "print(\" F1\"        , f1)\n",
        "print(\" MCC\"       , mcc)\n",
        "print(\" AUPRC\"     , auprc)\n",
        "print(\" AUROC\"     , auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjSVa72v4IsA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}