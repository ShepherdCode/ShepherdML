{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG-tGRnlFLA3"
   },
   "source": [
    "# Train/Test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RmwUsVLFLA6",
    "outputId": "ca6ac5ec-bd49-430d-ea05-b9ee1631ff9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-11 13:32:49.607863\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlzN9OdsFWEU",
    "outputId": "c83889fb-445b-40e0-829f-79f2a345b851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/TrainTest/TrainTest_ver43/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = 'D:/Adjeroh/Localization/TrainTest/'   # Windows\n",
    "    DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/TrainTest_ver43/'    # Mac\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRX-UEr8FLA8",
    "outputId": "2df05dda-18d7-422b-8358-5eeeeba6b963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 13:32:53.494587: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import time # sleep function\n",
    "from os.path import isfile\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "dt='float32'\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "K=4\n",
    "CFILTERS=64\n",
    "FILTERSIZE=16\n",
    "RCELLS=32\n",
    "DCELLS=16\n",
    "EPOCHS=12\n",
    "FOLDS=5      \n",
    "EMBED_DIMEN = 4 # arbitrary hyperparameter\n",
    "MINLEN=200\n",
    "MAXLEN=5000   \n",
    "PRETTY_PICTURES = True\n",
    "RCI_THRESHOLD_MECHANISM = 'RCI_GMM'  # 'RCI_GMM' 'ZERO' 'THE_MEAN'\n",
    "BREAK = False   # break after first fold\n",
    "CACHING = False   # have not worked out how to cache multiple cell lines\n",
    "NUM_LINES = 15   # 15 to analyze all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LnkpVKdMFLA-"
   },
   "outputs": [],
   "source": [
    "RCI_FILE       = 'train.lncRNA_RCI.csv'\n",
    "SEQUENCE_FILE  = 'train.all_lncRNA_transcripts.csv'\n",
    "CACHE_SEQUENCE = 'cache.seq.pickle'\n",
    "CACHE_IDS      = 'cache.id.pickle'\n",
    "if CACHING:\n",
    "    cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "    cache_ids = DATA_DIR+CACHE_IDS \n",
    "    if isfile(cache_seq) and isfile(cache_ids):\n",
    "        print('WARNING: this run will read sequence from cache.')\n",
    "    else:\n",
    "        print('INFO: this run will write sequence to cache.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e3p4QzQJFLA_"
   },
   "outputs": [],
   "source": [
    "def get_ordered_list():\n",
    "    ordered_list = \\\n",
    "    ['A549','H1.hESC','HeLa.S3','HepG2','HT1080',\\\n",
    "      'HUVEC','MCF.7','NCI.H460','NHEK','SK.MEL.5',\\\n",
    "      'SK.N.DZ','SK.N.SH','GM12878','K562','IMR.90']\n",
    "    return ordered_list\n",
    "all_cell_lines = get_ordered_list()\n",
    "\n",
    "EXCLUSIONS = [1]   # possibly exclude cell line 1 = H1.hESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtqdpJOxFLBA"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p35ehKV3Kq0z"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.cache=dict() \n",
    "        self.vals = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "        \n",
    "    def load_gene_rci_values(self,filepath,exclusions):\n",
    "        '''\n",
    "        Load from RCI csv file.\n",
    "        Return dict with keys=gene:str and values=RCI:float.\n",
    "        '''\n",
    "        gene_to_rci = {}\n",
    "        overall_sum = 0\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row # skip file's header line\n",
    "                else:\n",
    "                    line = row.strip()\n",
    "                    fields = line.split(',')\n",
    "                    gene_id = fields.pop(0)\n",
    "                    cell_line_index = 0\n",
    "                    rci_values = []\n",
    "                    for rci_str in fields:\n",
    "                        if cell_line_index not in exclusions:\n",
    "                            if rci_str != \"nan\":\n",
    "                                rci_val = float(rci_str)\n",
    "                                rci_values.append(rci_val)\n",
    "                        cell_line_index += 1\n",
    "                    if len(rci_values)>0:\n",
    "                        values = np.array(rci_values)\n",
    "                        antilogs = np.power(values,2)\n",
    "                        big_mean = np.mean(antilogs)\n",
    "                        if np.absolute(big_mean)<0.000001:\n",
    "                            log_mean = 0.0\n",
    "                        else:\n",
    "                            log_mean = np.log2(big_mean) \n",
    "                        gene_to_rci[gene_id] = log_mean\n",
    "        print('Number of RCI values loaded',len(gene_to_rci.keys()))\n",
    "        return gene_to_rci\n",
    "\n",
    "    def seq_to_kmer_values(self,rna,K):\n",
    "        vec=[] # seq converted to list of K-mers \n",
    "        N_indicator = 0 # indicator value\n",
    "        length = len(rna)\n",
    "        for i in range(length-K+1):\n",
    "            kmer = rna[i:i+K]\n",
    "            if 'N' in kmer:\n",
    "                value = N_indicator\n",
    "            elif kmer in self.cache.keys():\n",
    "                value = self.cache[kmer]\n",
    "            else:\n",
    "                value = 0\n",
    "                for j in range(K):\n",
    "                    value *= 4   \n",
    "                    nextnuc = kmer[j] \n",
    "                    nucval = self.vals[nextnuc]\n",
    "                    value += nucval\n",
    "                value += 1   # NNN => 0, AAA => 1\n",
    "                self.cache[kmer] = value\n",
    "            vec.append(value)\n",
    "        return vec\n",
    "\n",
    "    def load_sequence(self,filepath):\n",
    "        allids=[]\n",
    "        allseq=[]\n",
    "        cache_seq = DATA_DIR+CACHE_SEQUENCE \n",
    "        cache_ids = DATA_DIR+CACHE_IDS \n",
    "        if CACHING and isfile(cache_seq) and isfile(cache_ids):\n",
    "            # Warning: the cache may represent the wrong K.\n",
    "            with open(cache_seq,'rb') as fin:\n",
    "                allseq = pickle.load(fin)\n",
    "            with open(cache_ids,'rb') as fin:\n",
    "                allids = pickle.load(fin)\n",
    "            return allids,allseq           \n",
    "        NREPEAT = str('N'*MAXLEN)\n",
    "        with open (filepath,'r') as handle:\n",
    "            header = None\n",
    "            for row in handle:\n",
    "                if header is None:\n",
    "                    header = row\n",
    "                else:\n",
    "                    line    = row.strip()\n",
    "                    fields  = line.split(',')\n",
    "                    tran_id = fields[0]  # with version number\n",
    "                    gene_id = fields[1]        # without version number\n",
    "                    seq_len = int(fields[3])\n",
    "                    seq_txt = fields[4]\n",
    "                    if seq_len>=MINLEN and seq_len<=MAXLEN and gene_id in gene_to_rci.keys():\n",
    "                        allids.append( (gene_id,tran_id) )\n",
    "                        if seq_len<MAXLEN:\n",
    "                            seq_txt = seq_txt + NREPEAT\n",
    "                            seq_txt = seq_txt[:MAXLEN]\n",
    "                        hot_vec = self.seq_to_kmer_values(seq_txt,K)\n",
    "                        allseq.append(hot_vec)\n",
    "        if CACHING:\n",
    "            with open(cache_seq,'wb') as fout:\n",
    "                pickle.dump(allseq,fout)\n",
    "            with open(cache_ids,'wb') as fout:\n",
    "                pickle.dump(allids,fout)\n",
    "        return allids,allseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgrC1alOKq07"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W9xiFzNbFLBE"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CrossValidator():\n",
    "    def __init__(self,epochs,folds,quick_test=False,score_threshold=0.5):\n",
    "        self.epochs = epochs\n",
    "        self.folds = folds\n",
    "        self.quick_test = quick_test\n",
    "        self.score_threshold = score_threshold\n",
    "        self.mechanism = 'ZERO'\n",
    "        self.discriminator = None\n",
    "        self.flip = False    \n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "        self.cv_mcc=[]\n",
    "        self.fn = 10\n",
    "        \n",
    "    def set_sequences(self, allids, allseq):\n",
    "        # Keep IDs and sequences in same order.\n",
    "        self.all_ids = allids  # pairs of (gene_id,tran_id)\n",
    "        self.all_seqs = allseq  # may be vectors of K-mers\n",
    "        genes = []\n",
    "        for i in range(len(allids)):\n",
    "            (one_gene,one_tran) = allids[i]\n",
    "            genes.append(one_gene)\n",
    "        self.all_genes = genes\n",
    "            \n",
    "    def set_rci_map(self, gene_to_rci):\n",
    "        # The map is for fast lookup, not gene order.\n",
    "        self.rci_map = gene_to_rci # map gene_id to RCI value\n",
    "    \n",
    "    def get_gene_subset(self, sub_index):\n",
    "        sub_genes = set()\n",
    "        for index in sub_index:\n",
    "            one_gene = self.all_genes[index]\n",
    "            sub_genes.add(one_gene)\n",
    "        return sub_genes   # this is a set: unordered with fast lookup\n",
    "    \n",
    "    def _get_X_y(self, gene_index, exclude_middle=False):\n",
    "        # gene_index is ndarray with subset of indices of all_ids\n",
    "        subsetX=[]\n",
    "        subsetY=[]\n",
    "        show_gene=list()\n",
    "        show_tran=list()\n",
    "        uniq_gene=set()\n",
    "        for i in gene_index:\n",
    "            gene_id,tran_id = self.all_ids[i]\n",
    "            oneX            = self.all_seqs[i]\n",
    "            oneY            = self.rci_map[gene_id]\n",
    "            if exclude_middle and oneY >= -2 and oneY <= 0:\n",
    "                # Exclude middle from train set only, for comparison to Yuan et al\n",
    "                continue\n",
    "            show_gene.append(gene_id)\n",
    "            show_tran.append(tran_id)\n",
    "            uniq_gene.add(gene_id)\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(oneY)\n",
    "        self.fn += 1\n",
    "        with open ('unique_gene.'+str(self.fn)+'.csv','w') as fout:\n",
    "            for g in uniq_gene:\n",
    "                print(g,file=fout)\n",
    "        subsetX = np.array(subsetX)\n",
    "        subsetY = np.array(subsetY).reshape((-1,1))\n",
    "        return subsetX,subsetY\n",
    "    \n",
    "    def set_threshold_mechanism(self, mechanism):\n",
    "        if mechanism not in ['RCI_GMM','THE_MEAN','ZERO']:\n",
    "            raise Exception('Unrecognized mechansm:',mechanism)\n",
    "        self.mechanism = mechanism\n",
    "    \n",
    "    def _apply_threshold(self, array_of_rci):\n",
    "        # Takes list of float, returns list of labels [0,1].\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            labels = self.discriminator.predict(array_of_rci)\n",
    "            if self.flip:\n",
    "                IS_CYTO = lambda label: 1 if label==0 else 0\n",
    "                labels = np.array(list(map(IS_CYTO, labels)))\n",
    "        else:  # 'THE_MEAN' or 'ZERO'\n",
    "            rci_threshold = self.discriminator\n",
    "            IS_CYTO = lambda rci: 1 if rci>rci_threshold else 0\n",
    "            labels = np.array(list(map(IS_CYTO, array_of_rci)))\n",
    "        return labels\n",
    "    \n",
    "    def _prepare_threshold(self, rci_values):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm = GaussianMixture(n_components=2, verbose=0, \n",
    "                covariance_type='spherical', n_init=100) \n",
    "            gmm.fit(rci_values)\n",
    "            self.flip = False\n",
    "            # The GMM labels are arbitrary.\n",
    "            if gmm.means_[0][0] > gmm.means_[1][0]:\n",
    "                self.flip = True\n",
    "            self.discriminator = gmm\n",
    "        elif self.mechanism == 'THE_MEAN':\n",
    "            self.discriminator = np.mean(rci_values)\n",
    "        elif self.mechanism == 'ZERO':\n",
    "            self.discriminator = -1   # 0 usually, -1 is as in Yuan et al.\n",
    "        else: # not expected\n",
    "            self.discriminator = 0\n",
    "    \n",
    "    def _explain_threshold(self):\n",
    "        if self.mechanism == 'RCI_GMM':\n",
    "            gmm=self.discriminator\n",
    "            print('Discriminator is GMM')\n",
    "            print('Means',[gmm.means_[0][0],gmm.means_[1][0]])\n",
    "            print('Variances',gmm.covariances_)\n",
    "            print('Priors',gmm.weights_)\n",
    "            test_rcis=[-5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,3]\n",
    "            print(test_rcis)\n",
    "            print(self._apply_threshold(np.array(test_rcis).reshape((-1,1))))\n",
    "        else:\n",
    "            print('Discriminator',self.mechanism,self.discriminator)\n",
    "    \n",
    "    def _show_sizes(self,label,values):\n",
    "        a = np.count_nonzero(values==1)\n",
    "        b = np.count_nonzero(values==0)\n",
    "        print('%s 1:0 %d:%d %5.2f%%'%(label,a,b,100*a/(a+b)))\n",
    "        \n",
    "    def do_cross_validation(self,repetition):\n",
    "        fold=0\n",
    "        print()\n",
    "        print(datetime.now())\n",
    "        print('splitting')\n",
    "        # KFold shuffles once before making the partitions\n",
    "        splitter = KFold(n_splits=self.folds,shuffle=True) # random_state=42)\n",
    "        splits = splitter.split(self.all_genes)\n",
    "        splitter = None\n",
    "        for train_index,valid_index in splits:\n",
    "            fold += 1\n",
    "            print(datetime.now())\n",
    "            print('Repetition',repetition,'Fold',fold)\n",
    "            print('train',train_index[:10])\n",
    "            print('valid',valid_index[:10])\n",
    "            print('Prepare train set')\n",
    "            X_train,y_rci = self._get_X_y(train_index) \n",
    "            self._prepare_threshold(y_rci)  # use train subset only!\n",
    "            self._explain_threshold()\n",
    "            y_train = self._apply_threshold(y_rci)\n",
    "            \n",
    "            print('Prepare valid set')\n",
    "            X_valid,y_rci = self._get_X_y(valid_index)  \n",
    "            y_valid = self._apply_threshold(y_rci) \n",
    "            print('y_RCI',y_rci)\n",
    "            print('y_valid',y_valid)\n",
    "            \n",
    "            if self.quick_test:   \n",
    "                print('Break -- this was for code testing only')\n",
    "                break\n",
    "\n",
    "    def get_statistics(self):\n",
    "        return \\\n",
    "        self.cv_accuracy,\\\n",
    "        self.cv_precision,\\\n",
    "        self.cv_recall,\\\n",
    "        self.cv_f1,\\\n",
    "        self.cv_mcc,\\\n",
    "        self.cv_auprc,\\\n",
    "        self.cv_auroc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XC9m0W-pFLBH",
    "outputId": "b9854cd7-a9d1-46a3-9a14-4fa65651ee57",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-11 13:41:01.784474\n",
      "Number of RCI values loaded 4369\n",
      "Num RCI: 4369\n",
      "Load sequence...\n",
      "Loaded 19301 sequences.\n",
      "Cross validation...\n",
      "\n",
      "2023-03-11 13:41:37.049920\n",
      "splitting\n",
      "2023-03-11 13:41:37.051107\n",
      "Repetition 1 Fold 1\n",
      "train [ 1  2  3  4  5  6  7  9 10 13]\n",
      "valid [ 0  8 11 12 15 26 32 37 41 49]\n",
      "Prepare train set\n",
      "Discriminator is GMM\n",
      "Means [1.418546577472363, -0.21380618177038693]\n",
      "Variances [2.39261734 8.24060735]\n",
      "Priors [0.7415826 0.2584174]\n",
      "[-5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 3]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "Prepare valid set\n",
      "y_RCI [[1.89121541]\n",
      " [1.34312427]\n",
      " [1.34312427]\n",
      " ...\n",
      " [4.38109066]\n",
      " [4.38109066]\n",
      " [4.38109066]]\n",
      "y_valid [1 1 1 ... 1 1 1]\n",
      "2023-03-11 13:41:52.069625\n",
      "Repetition 1 Fold 2\n",
      "train [ 0  4  5  7  8  9 11 12 14 15]\n",
      "valid [ 1  2  3  6 10 13 20 23 24 25]\n",
      "Prepare train set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m F \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     20\u001b[0m     total_folds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m FOLDS\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mcvdo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mCrossValidator.do_cross_validation\u001b[0;34m(self, repetition)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrepare train set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    137\u001b[0m X_train,y_rci \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_X_y(train_index) \n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_rci\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use train subset only!\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_explain_threshold()\n\u001b[1;32m    140\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_threshold(y_rci)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mCrossValidator._prepare_threshold\u001b[0;34m(self, rci_values)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmechanism \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRCI_GMM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     88\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     89\u001b[0m         covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspherical\u001b[39m\u001b[38;5;124m'\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m) \n\u001b[0;32m---> 90\u001b[0m     \u001b[43mgmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrci_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# The GMM labels are arbitrary.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/mixture/_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        The fitted mixture.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/mixture/_base.py:264\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    262\u001b[0m     prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[0;32m--> 264\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m_step(X, log_resp)\n\u001b[1;32m    266\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/mixture/_base.py:321\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124;03m\"\"\"E step.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m        the point of each sample in X.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(log_prob_norm), log_resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/mixture/_base.py:543\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    541\u001b[0m weighted_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_weighted_log_prob(X)\n\u001b[1;32m    542\u001b[0m log_prob_norm \u001b[38;5;241m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     log_resp \u001b[38;5;241m=\u001b[39m weighted_log_prob \u001b[38;5;241m-\u001b[39m log_prob_norm[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_norm, log_resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:434\u001b[0m, in \u001b[0;36merrstate.__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall \u001b[38;5;241m=\u001b[39m seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexc_info):\n\u001b[1;32m    435\u001b[0m     seterr(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate)\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "loader = DataLoader()\n",
    "filepath = DATA_DIR+RCI_FILE\n",
    "gene_to_rci = loader.load_gene_rci_values(filepath,EXCLUSIONS)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "print('Load sequence...')\n",
    "filepath = DATA_DIR+SEQUENCE_FILE\n",
    "allids,allseq = loader.load_sequence(filepath)\n",
    "print('Loaded',len(allseq),'sequences.')\n",
    "loader = None  # drop K-mer cache to save RAM\n",
    "\n",
    "print(\"Cross validation...\")\n",
    "cvdo = CrossValidator(EPOCHS,FOLDS,BREAK)\n",
    "cvdo.set_sequences(allids,allseq)\n",
    "cvdo.set_rci_map(gene_to_rci)\n",
    "cvdo.set_threshold_mechanism(RCI_THRESHOLD_MECHANISM)\n",
    "# two rounds of 5 for 10 total\n",
    "total_folds = 0\n",
    "for F in range(2):\n",
    "    total_folds += FOLDS\n",
    "    cvdo.do_cross_validation(F+1)   \n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkCeDg_HdQ36"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
