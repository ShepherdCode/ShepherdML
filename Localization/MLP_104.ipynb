{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "K=4.  \n",
    "Normalized K-mer counts.  \n",
    "Two-layer MLP.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:23:54.181652\n",
      "Python 3.10.0\n",
      "sklearn 1.1.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "from platform import python_version\n",
    "print('Python',python_version())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn   # pip install --upgrade scikit-learn\n",
    "print('sklearn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 4 alphabet size= 4 vocabulary size= 256\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt = np.float32\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.random.set_seed(42) \n",
    "#from sklearn.model_selection import ShuffleSplit\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import RepeatedKFold\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import LayerNormalization\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from KmerCounter import KmerCounter\n",
    "ALPHABET_SIZE=4\n",
    "K=4\n",
    "counter=KmerCounter(K)\n",
    "VOCABULARY_SIZE = counter.get_vocabulary_size() \n",
    "print('K=',K,'alphabet size=',ALPHABET_SIZE,'vocabulary size=',VOCABULARY_SIZE)\n",
    "from TrainValidSplit2 import Splitter2\n",
    "EPOCHS=10\n",
    "FOLDS=5\n",
    "from cell_lines import Cell_Lines\n",
    "CELL_LINE_NUMBER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/jasonmiller/WVU/Localization/TrainTest/'\n",
    "GENES_FILE = 'CNRCI_coding_train_genes.csv'\n",
    "RCI_FILE = 'CNRCI_coding_train_RCI.gc42.csv'\n",
    "SEQUENCE_FILE = 'CNRCI_coding_train_transcripts.gc42.csv'\n",
    "COUNTS_FILE='CNRCI_coding_train_counts.K4.gc42.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line for today: 0 = A549\n"
     ]
    }
   ],
   "source": [
    "# Consider a Cell_Lines object to represent today's cell line.\n",
    "all_cell_lines = Cell_Lines.get_ordered_list()\n",
    "cell_line_name = all_cell_lines[CELL_LINE_NUMBER]\n",
    "print('Cell line for today:',CELL_LINE_NUMBER,'=',cell_line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Here is the joke model -- one neuron!\n",
    "    mlp    = Sequential()\n",
    "    layer1 = Dense(64, activation='sigmoid',dtype=dt,input_dim=VOCABULARY_SIZE)\n",
    "    layer2 = Dense(8, activation='sigmoid')\n",
    "    output = Dense(1, activation='sigmoid')\n",
    "    mlp.add(layer1)\n",
    "    mlp.add(layer2)\n",
    "    mlp.add(output)\n",
    "      \n",
    "    bc=BinaryCrossentropy(from_logits=False)\n",
    "    print(\"COMPILE...\")\n",
    "    mlp.compile(loss=bc, optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "    print(\"...COMPILED\")\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:24:06.740372\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "Summarize the model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,977\n",
      "Trainable params: 16,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:24:06.744758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "print(datetime.now())\n",
    "model=build_model()\n",
    "print (\"Summarize the model\")\n",
    "print(model.summary())  # Print this only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:24:06.982272\n",
      "Num RCI: 10338\n",
      "[('ENSG00000000003', 1.08068), ('ENSG00000000419', 1.32679), ('ENSG00000000457', 0.434284)]\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "# labels\n",
    "filepath = DATA_DIR+RCI_FILE\n",
    "gene_to_rci = {}\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line = row.strip()\n",
    "            fields = line.split(',')\n",
    "            gene_id = fields[0]\n",
    "            rci_val = fields[CELL_LINE_NUMBER+1]\n",
    "            # Could implement Gudenas style threshold here\n",
    "            if rci_val != \"nan\":\n",
    "                gene_to_rci[gene_id] = float(rci_val)\n",
    "print('Num RCI:', len(gene_to_rci.keys()))\n",
    "print(list(gene_to_rci.items())[:3])\n",
    "all_genes = list(gene_to_rci.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:24:07.097203\n",
      "Read kmer counts file\n",
      "2022-11-03 13:24:11.230613\n",
      "Normalize\n",
      "2022-11-03 13:24:14.521762\n",
      "Num IDs: 54251\n",
      "Num labels: 54251\n",
      "Num counts: 54251\n"
     ]
    }
   ],
   "source": [
    "# kmer counts\n",
    "print(datetime.now())\n",
    "print('Read kmer counts file')\n",
    "filepath = DATA_DIR+COUNTS_FILE\n",
    "labels=[]\n",
    "allids=[]\n",
    "counts=[]\n",
    "with open (filepath,'r') as handle:\n",
    "    header = None\n",
    "    for row in handle:\n",
    "        if header is None:\n",
    "            header = row\n",
    "        else:\n",
    "            line    = row.strip()\n",
    "            fields  = line.split(',')\n",
    "            gene_id = fields.pop(0)\n",
    "            tran_id = fields.pop(0)\n",
    "            numbers = [int(x) for x in fields]\n",
    "            if gene_id in gene_to_rci.keys():\n",
    "                rci_val = gene_to_rci[gene_id]\n",
    "                allids.append( (gene_id,tran_id) )\n",
    "                labels.append(rci_val)\n",
    "                counts.append(numbers)\n",
    "print(datetime.now())\n",
    "print('Normalize')\n",
    "rows = len(counts)\n",
    "cols = len(counts[0])\n",
    "for row in range(rows):\n",
    "    total = sum(counts[row])\n",
    "    for col in range(cols):\n",
    "        counts[row][col] /= total\n",
    "print(datetime.now())\n",
    "print('Num IDs:',len(allids))\n",
    "#print('Examples:',[allids[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num labels:',len(labels))\n",
    "#print('Examples:',[labels[x] for x in [10, 20, 30, 40]] )\n",
    "print('Num counts:',len(counts))\n",
    "#print('Example:',counts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_subset(all_genes,sub_index):\n",
    "    sub_genes = set()\n",
    "    for index in sub_index:\n",
    "        one_gene = all_genes[index]\n",
    "        sub_genes.add(one_gene)\n",
    "    return sub_genes\n",
    "def get_X_y(gene_set,allids,allX,allY,threshold):\n",
    "    cnt = len(allids)\n",
    "    subsetX=[]\n",
    "    subsetY=[]\n",
    "    if cnt != len(allX) or cnt!= len(allY):\n",
    "        raise Exception('Lengths differ')\n",
    "    for i in range(cnt):\n",
    "        gene_id,tran_id = allids[i]\n",
    "        if gene_id in gene_set:\n",
    "            oneX = allX[i]\n",
    "            oneY = allY[i]\n",
    "            if oneY < threshold:\n",
    "                Yvalue = int(0)\n",
    "            else:\n",
    "                Yvalue = int(1)\n",
    "            subsetX.append(oneX)\n",
    "            subsetY.append(Yvalue)\n",
    "    return subsetX,subsetY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validate with all K-mer counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = False\n",
    "def do_cross_validation(eps):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    print(datetime.now())\n",
    "    print('splitting')\n",
    "    # KFold shuffles once before making the partitions\n",
    "    splitter = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n",
    "    for train_index,valid_index in splitter.split(all_genes):\n",
    "        train_genes = get_gene_subset(all_genes,train_index)\n",
    "        valid_genes = get_gene_subset(all_genes,valid_index)\n",
    "        X_train,y_train = get_X_y(train_genes,allids,counts,labels,0)\n",
    "        X_valid,y_valid = get_X_y(valid_genes,allids,counts,labels,0)\n",
    "\n",
    "        if SCALING:\n",
    "            print('scaling')\n",
    "            print(datetime.now())\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_valid = scaler.transform(X_valid)\n",
    "\n",
    "        fold += 1\n",
    "        print('Fold',fold)\n",
    "        print('Train sizes',len(X_train),len(y_train))\n",
    "        print('Valid sizes',len(X_valid),len(y_valid))\n",
    "        print('Train set ones/size',\n",
    "              np.count_nonzero(y_train),'/',len(y_train))\n",
    "        print('Valid set ones/size',\n",
    "              np.count_nonzero(y_valid),'/',len(y_valid))\n",
    "\n",
    "        print(\"BUILD MODEL\")\n",
    "        model=build_model()\n",
    "\n",
    "        print(\"FIT\")\n",
    "        print(datetime.now())\n",
    "        history=model.fit(X_train, y_train, # batch_size=10, default=32 works nicely\n",
    "                epochs=EPOCHS, verbose=1,  # verbose=1 for ascii art, verbose=0 for none\n",
    "                validation_data=(X_valid,y_valid) )\n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0,1)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Compute valiation accuracy\")\n",
    "        print(datetime.now())\n",
    "        scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(datetime.now())\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-03 13:24:14.645400\n",
      "2022-11-03 13:24:14.650982\n",
      "splitting\n",
      "Fold 1\n",
      "Train sizes 43592 43592\n",
      "Valid sizes 10659 10659\n",
      "Train set ones/size 21682 / 43592\n",
      "Valid set ones/size 5237 / 10659\n",
      "BUILD MODEL\n",
      "COMPILE...\n",
      "...COMPILED\n",
      "FIT\n",
      "2022-11-03 13:24:14.765816\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "cv_scores = do_cross_validation(EPOCHS)    \n",
    "print(\"Cross validation acc mean %.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
